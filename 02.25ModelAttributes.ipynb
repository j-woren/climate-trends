{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = bertopic.BERTopic.load('/Users/trevor/Desktop/Research/climate-trends/BERTopic_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: 0_bp_holocene_cal_ka\n",
      "Representative Documents:\n",
      "  - Pollen-assemblage data from a sediment core from Hulun Lake in northeastern Inner Mongolia describe the changes in the vegetation and climate of the East Asian monsoon margin during the Holocene. Dry steppe dominated the lake basin from ca. 11,000 to 8000 cal yr BP, suggesting a warm and dry climate. Grasses and birch forests expanded 8000 to 6400 cal yr BP, implying a remarkable increase in the monsoon precipitation. From 6400 to 4400 cal yr BP, the climate became cooler and drier. Chenopodiaceae dominated the interval from 4400 to 3350 cal yr BP, marking extremely dry condition.Artemisiarecovered 3350-2050 cal yr BP, denoting an amelioration of climatic conditions. Both temperature and precipitation decreased 2050 to 1000 cal yr BP as indicated by decreasedArtemisiaand the development of pine forests. During the last 1000 yr, human activities might have had a significant influence on the environment of the lake region. We suggest that the East Asian summer monsoon did not become intensified until 8000 cal yr BP due to the existence of remnant ice sheets in the Northern Hemisphere. Changes in the monsoon precipitation on millennial to centennial scales would be related to ocean-atmosphere interactions in the tropical Pacific.\n",
      "  - We obtained a 15 m drill core from Deukryang Bay on the southwest coast of Korea, which is now an area of reclaimed land used for agriculture. We investigated changes in the depositional environment and hydrological climate responses to sea level changes using sedimentary facies, radiocarbon ages, grain-size analysis, total organic carbon (TOC), total sulfur (TS), and stable carbon isotopes (δ13C). Sediment deposition began at 12,000 cal yr BP and was divided into four stages based on changes from fluvial to intertidal environments related to Holocene marine transgression events. Stage 1 (&gt;10,000 cal yr BP) is represented by fluvial sediments; Stage 2 (10,000–7080 cal yr BP) is represented by the deposition of mud facies in an intertidal zone in response to sea level rise; Stage 3 (7080–3300 cal yr BP) was a period of gradually descending sea level following the Holocene maximum sea level and is characterized by gradual changes in TOC, TS, and C/S ratios compared with the mud facies of Stage 2. Stage 4 (3300 to present) was deposited in a supratidal zone and contains low TS and an abundance of TOC. Based on our TS and C/S ratio results, the south coast of Korea was mainly affected by sea level rise between 7000 and 3000 cal yr BP, during the middle Holocene. At 3000 cal yr BP, sea level began to stabilize or gradually decrease. In addition, changes in δ13C values are clearly observed since ca. 5000 cal yr BP, in particular, large hydrological changes via freshwater input are confirmed in 4000–3000 cal yr BP. We consider these shifts in freshwater input indicators of an increased influence of El Niño and La Niña conditions, related to the weakening of the East Asian Summer Monsoon (EASM) and changes in sea surface temperature (SST) of the Western Pacific Ocean during the middle Holocene climatic optimum (between 7800 and 5000 cal yr BP). The cooling periods of SST in East Asia between 8400 and 6600 cal yr BP reported from the west coast of Korea are related closely to changes in vegetation (as evidenced by δ13C) from 7700 cal yrs BP to the present in the southwest coast of Korea. We interpret the freshwater input events at 4000–3000 cal yr BP to be related to changes in SST in response to the weakening of the EASM on the southwest coast of Korea. However, additional research is needed to study the southward migration effect of the westerly jet related to SST and atmospheric circulation controlling terrestrial climate in the middle Holocene.\n",
      "  - It is widely recognised that the acquisition of high‐resolution palaeoclimate records from southern mid‐latitude sites is essential for establishing a coherent picture of inter‐hemispheric climate change and for better understanding of the role of Antarctic climate dynamics in the global climate system. New Zealand is considered to be a sensitive monitor of climate change because it is one of a few sizeable landmasses in the Southern Hemisphere westerly circulation zone, a critical transition zone between subtropical and Antarctic influences. New Zealand has mountainous axial ranges that amplify the climate signals and, consequently, the environmental gradients are highly sensitive to subtle changes in atmospheric and oceanic conditions. Since 1995, INTIMATE has, through a series of international workshops, sought ways to improve procedures for establishing the precise ages of climate events, and to correlate them with high precision, for the last 30 000 calendar years. The NZ‐INTIMATE project commenced in late 2003, and has involved virtually the entire New Zealand palaeoclimate community. Its aim is to develop an event stratigraphy for the New Zealand region over the past 30 000 years, and to reconcile these events against the established climatostratigraphy of the last glacial cycle which has largely been developed from Northern Hemisphere records (e.g. Last Glacial Maximum (LGM), Termination I, Younger Dryas). An initial outcome of NZ‐INTIMATE has been the identification of a series of well‐dated, high‐resolution onshore and offshore proxy records from a variety of latitudes and elevations on a common calendar timescale from 30 000 cal. yr BP to the present day. High‐resolution records for the last glacial coldest period (LGCP) (including the LGM sensu stricto) and last glacial–interglacial transition (LGIT) from Auckland maars, Kaipo and Otamangakau wetlands on eastern and central North Island, marine core MD97‐2121 east of southern North Island, speleothems on northwest South Island, Okarito wetland on southwestern South Island, are presented. Discontinuous (fragmentary) records comprising compilations of glacial sequences, fluvial sequences, loess accumulation, and aeolian quartz accumulation in an andesitic terrain are described. Comparisons with ice‐core records from Antarctica (EPICA Dome C) and Greenland (GISP2) are discussed. A major advantage immediately evident from these records apart from the speleothem record, is that they are linked precisely by one or more tephra layers. Based on these New Zealand terrestrial and marine records, a reasonably coherent, regionally applicable, sequence of climatically linked stratigraphic events over the past 30 000 cal. yr is emerging. Three major climate events are recognised: (1) LGCP beginning at ca. 28 000 cal. yr BP, ending at Termination I, ca. 18 000 cal. yr BP, and including a warmer and more variable phase between ca. 27 000 and 21 000 cal. yr BP, (2) LGIT between ca. 18 000 and 11 600 cal. yr BP, including a Lateglacial warm period from ca. 14 800 to 13 500 cal. yr BP and a Lateglacial climate reversal between ca. 13 500 and 11 600 cal. yr BP, and (3) Holocene interglacial conditions, with two phases of greatest warmth between ca. 11 600 and 10 800 cal. yr BP and from ca. 6 800 to 6 500 cal. yr BP. Some key boundaries coincide with volcanic tephras. Copyright © 2007 John Wiley &amp; Sons, Ltd.\n",
      "--------------------------------------------------\n",
      "Topic 1: 1_safety_school_organizational_employees\n",
      "Representative Documents:\n",
      "  - AimTo examine the association between components of safety climate and psychosocial hazards with safe work behaviours and test the moderating effects of psychosocial hazards on the safety climate‐safety performance relationships.BackgroundThe effects of a strong safety climate on safety performance are well cited, however, the conditions that have an impact on this relationship warrant attention. While the psychosocial hazards commonly reported by nurses are predictors of well‐being and job attitudes, evidence suggests that these may also place boundaries on the effects of safety climate on safe work practices.DesignThis study used a cross‐sectional design to collect data from 146 nurses.MethodsParticipants were recruited through convenience sampling and snowball sampling methods in 2017. Nurses completed an online questionnaire and received a $5 e‐gift card as compensation. SPSS v.23 and PROCESS v3.0 were used to analyse the data.Results/FindingsA strong safety climate was positively associated with nurses' safety performance. While psychosocial hazards did not predict safety performance, they did moderate the safety climate‐performance relationship. High levels of perceived stressors weakened the association between promoting two‐way safety communication, the use and implementation of procedures to promote safe work practices and management's endorsement of health and safety with safe work performance.ConclusionThe positive effects of safety climate on nurses' safety performance are contingent on the levels of psychosocial hazards nurses experience. When aiming to improve safety performance among nurses, it is important for efforts to also focus on the psychosocial conditions of the work environment.\n",
      "  -  This study investigated the associations among school climate domains and how school climate interacts with academic performance. A sample of Kosovan public school students ( N = 855) was assessed using the School Climate Survey. The results showed that students had positive perceptions in the school climate domains of teaching and learning and safety, indicating high school morale. Results further showed a positive correlation between students’ perceptions of school safety and their academic performance. Significant gender differences in perceptions of school safety were noted. Maternal education level was also shown to have an impact on student academic performance. \n",
      "  - Nielsen, M. B., Mearns, K., Matthiesen, S. B. &amp; Eid, J. (2011). Using the Job Demands–Resources model to investigate risk perception, safety climate and job satisfaction in safety critical organizations.Scandinavian Journal of Psychology 52, 465–475.Using the Job Demands–Resources model (JD‐R) as a theoretical framework, this study investigated the relationship between risk perception as a job demand and psychological safety climate as a job resource with regard to job satisfaction in safety critical organizations. In line with the JD‐R model, it was hypothesized that high levels of risk perception is related to low job satisfaction and that a positive perception of safety climate is related to high job satisfaction. In addition, it was hypothesized that safety climate moderates the relationship between risk perception and job satisfaction. Using a sample of Norwegian offshore workers (N = 986), all three hypotheses were supported. In summary, workers who perceived high levels of risk reported lower levels of job satisfaction, whereas this effect diminished when workers perceived their safety climate as positive. Follow‐up analyses revealed that this interaction was dependent on the type of risks in question. The results of this study supports the JD‐R model, and provides further evidence for relationships between safety‐related concepts and work‐related outcomes indicating that organizations should not only develop and implement sound safety procedures to reduce the effects of risks and hazards on workers, but can also enhance other areas of organizational life through a focus on safety.\n",
      "--------------------------------------------------\n",
      "Topic 2: 2_political_media_climate change_social\n",
      "Representative Documents:\n",
      "  - This article explores the role of broadcast news media decisionmakers in shaping public understanding and debate of climate change risks. It locates the media within a “tangled web” of communication and debate between sources, media, and publics. The article draws on new qualitative research in the British context. The main body of it focuses on media source strategies, on climate change storytelling in news, and the “myth of detachment” sustained by many news decisionmakers. The empirical evidence, gathered between 1997 and 2004, is derived primarily from recordings and notes drawn from a series of seminars that has brought together equal numbers of BBC news and television decisionmakers and environment/development specialists. The seminars have created a rare space for extended dialogue between media and specialist perspectives on the communication of complex climate change science and policy. While the article acknowledges the distinctive nature of the BBC as a public sector broadcaster, the evidence confirms and extends current understanding of the career of climate change within the media more broadly. The working group discussions have explored issues arising out of how stories are sourced and, in the context of competitive and time‐pressured newsrooms, shaped and presented in short news pieces. Particularly significant is the disjuncture between ways of talking about uncertainty within science and policy discourse and media constructions of objectivity, truth, and balance. The article concludes with a summary of developments in media culture, technology, and practice that are creating opportunities for enhanced public understanding and debate of climate change risks. It also indicates the need for science and policy communities to be more active critics and sources of news.\n",
      "  - In this paper, we argue for an approach that goes beyond an institutional reading of urban climate governance to engage with the ways in which government is accomplished through social and technical practices. Central to the exercise of government in this manner, we argue, are ‘climate change experiments’– purposive interventions in urban socio‐technical systems designed to respond to the imperatives of mitigating and adapting to climate change in the city. Drawing on three different concepts – of governance experiments, socio‐technical experiments, and strategic experiments – we first develop a framework for understanding the nature and dynamics of urban climate change experiments. We use this conceptual analysis to frame a scoping study of the global dimensions of urban climate change experimentation in a database of 627 urban climate change experiments in 100 global cities. The analysis charts when and where these experiments occur, the relationship between the social and technical aspects of experimentation and the governance of urban climate change experimentation, including the actors involved in their governing and the extent to which new political spaces for experimentation are emerging in the contemporary city. We find that experiments serve to create new forms of political space within the city, as public and private authority blur, and are primarily enacted through forms of technical intervention in infrastructure networks, drawing attention to the importance of such sites in urban climate politics. These findings point to an emerging research agenda on urban climate change experiments that needs to engage with the diversity of experimentation in different urban contexts, how they are conducted in practice and their impacts and implications for urban governance and urban life.\n",
      "  -  Twitter enables an online public sphere for social movement actors, news organizations, and others to frame climate change and the climate movement. In this paper, we analyze five million English tweets posted from 2018 to 2021 demonstrating how peaks in Twitter activity relate to key events and how the framing of the climate strike discourse has evolved over the past three years. We also collected over 30,000 news articles from major news sources in English-speaking countries (Australia, Canada, United States, United Kingdom) to demonstrate how climate movement actors and media differ in their framing of this issue, attention to policy solutions, attribution of blame, and efforts to mobilize citizens to act on this issue. News outlets tend to report on global politicians’ (in)action toward climate policy, the consequences of climate change, and industry's response to the climate crisis. Differently, climate movement actors on Twitter advocate for political actions and policy changes as well as addressing the social justice issues surrounding climate change. We also revealed that conversations around the climate movement on Twitter are highly politicized, with a substantial number of tweets targeting politicians, partisans, and country actors. These findings contribute to our understanding of how people use social media to frame political issues and collective action, in comparison to the traditional mainstream news outlets. \n",
      "--------------------------------------------------\n",
      "Topic 3: 3_ice_model_aerosol_sea\n",
      "Representative Documents:\n",
      "  - . Large wildfires exert strong disturbance on regional andglobal climate systems and ecosystems by perturbing radiative forcing aswell as the carbon and water balance between the atmosphere and land surface,while short- and long-term variations in fire weather, terrestrialecosystems, and human activity modulate fire intensity and reshape fireregimes. The complex climate–fire–ecosystem interactions were not fullyintegrated in previous climate model studies, and the resulting effects onthe projections of future climate change are not well understood. Here weuse the fully interactive REgion-Specific ecosystem feedback Fire model(RESFire) that was developed in the Community Earth System Model (CESM) toinvestigate these interactions and their impacts on climate systems and fireactivity. We designed two sets of decadal simulations using CESM-RESFire forpresent-day (2001–2010) and future (2051–2060) scenarios, respectively, andconducted a series of sensitivity experiments to assess the effects ofindividual feedback pathways among climate, fire, and ecosystems. Ourimplementation of RESFire, which includes online land–atmosphere coupling offire emissions and fire-induced land cover change (LCC), reproduces theobserved aerosol optical depth (AOD) from space-based Moderate ResolutionImaging Spectroradiometer (MODIS) satellite products and ground-basedAErosol RObotic NETwork (AERONET) data; it agrees well with carbon budgetbenchmarks from previous studies. We estimate the global averaged netradiative effect of both fire aerosols and fire-induced LCC at -0.59±0.52 W m−2, which is dominated by fireaerosol–cloud interactions (-0.82±0.19 W m−2), in thepresent-day scenario under climatological conditions of the 2000s. Thefire-related net cooling effect increases by ∼170 % to-1.60±0.27 W m−2 in the 2050s under the conditions ofthe Representative Concentration Pathway 4.5 (RCP4.5) scenario. Suchconsiderably enhanced radiative effect is attributed to the largelyincreased global burned area (+19 %) and fire carbon emissions(+100 %) from the 2000s to the 2050s driven by climate change. The netecosystem exchange (NEE) of carbon between the land and atmospherecomponents in the simulations increases by 33 % accordingly, implying thatbiomass burning is an increasing carbon source at short-term timescales inthe future. High-latitude regions with prevalent peatlands would be morevulnerable to increased fire threats due to climate change, and the increasein fire aerosols could counter the projected decrease in anthropogenicaerosols due to air pollution control policies in many regions. We alsoevaluate two distinct feedback mechanisms that are associated with fireaerosols and fire-induced LCC, respectively. On a global scale, the firstmechanism imposes positive feedbacks to fire activity through enhanceddroughts with suppressed precipitation by fire aerosol–cloud interactions,while the second one manifests as negative feedbacks due to reduced fuelloads by fire consumption and post-fire tree mortality and recoveryprocesses. These two feedback pathways with opposite effects compete atregional to global scales and increase the complexity ofclimate–fire–ecosystem interactions and their climatic impacts.                    \n",
      "  - . Despite decades of effort, the drivers of globallong-term trends in tropospheric ozone are not well understood, impactingestimates of ozone radiative forcing and the global ozone budget. We analyzetropospheric ozone trends since 1980 using ozonesondes and remote surfacemeasurements around the globe and investigate the ability of two atmosphericchemical transport models, GEOS-Chem and MERRA2-GMI, to reproduce thesetrends. Global tropospheric ozone trends measured at 25 ozonesonde sitesfrom 1990–2017 (nine sites since 1980s) show increasing trends averaging 1.8 ± 1.3 ppb per decade across sites in the free troposphere(800–400 hPa). Relative trends in sondes are more pronounced closer to thesurface (3.5 % per decade above 700 hPa, 4.3 % per decade below700 hPa on average), suggesting the importance of surface emissions(anthropogenic, soil NOx, impacts on biogenic volatile organic compounds (VOCs) from land usechanges, etc.) in observed changes. While most surface sites (148 of 238) inthe United States and Europe exhibit decreases in high daytime ozone valuesdue to regulatory efforts, 73 % of global sites outside these regions (24of 33 sites) show increases from 1990–2014 that average 1.4 ± 0.9 ppb per decade. In all regions, increasing ozone trends both at the surfaceand aloft are at least partially attributable to increases in 5thpercentile ozone, which average 1.8 ± 1.3 ppb per decade andreflect the global increase of baseline ozone in rural areas. Observed ozonepercentile distributions at the surface have shifted notably across theglobe: all regions show increases in low tails (i.e., below 25thpercentile), North America and Europe show decreases in high tails (above75th percentile), and the Southern Hemisphere and Japan show increasesacross the entire distribution. Three model simulations comprising differentemissions inventories, chemical schemes, and resolutions, sampled at thesame locations and times of observations, are not able to replicatelong-term ozone trends either at the surface or free troposphere, oftenunderestimating trends. We find that ∼75 % of the averageozone trend from 800–400 hPa across the 25 ozonesonde sites is captured byMERRA2-GMI, and &lt;20 % is captured by GEOS-Chem. MERRA2-GMIperforms better than GEOS-Chem in the northern midlatitude freetroposphere, reproducing nearly half of increasing trends since 1990 andcapturing stratosphere–troposphere exchange (STE) determined via astratospheric ozone tracer. While all models tend to capture the directionof shifts in the ozone distribution and typically capture changes in highand low tails, they tend to underestimate the magnitude of the shift inmedians. However, each model shows an 8 %–12 % (or 23–32 Tg) increase intotal tropospheric ozone burden from 1980 to 2017. Sensitivity simulationsusing GEOS-Chem and the stratospheric ozone tracer in MERRA2-GMI suggestthat in the northern midlatitudes and high latitudes, dynamics such as STE are mostimportant for reproducing ozone trends in models in the middle and uppertroposphere, while emissions are more important closer to the surface. Ourmodel evaluation for the last 4 decades reveals that the recent version ofthe GEOS-Chem model underpredicts free tropospheric ozone across this longtime period, particularly in winter and spring over midlatitudes to high latitudes.Such widespread model underestimation of tropospheric ozone highlights theneed for better understanding of the processes that transport ozone andpromote its production.                    \n",
      "  - . The effect of external forcings on atmospheric circulation is debated. Due tothe short observational period, the analysis of the role of external forcingsis hampered, making it difficult to assess the sensitivity of atmosphericcirculation to external forcings, as well as persistence of the effects. Inobservations, the average response to tropical volcanic eruptions is apositive North Atlantic Oscillation (NAO) during the following winter.However, past major tropical eruptions exceeding the magnitude of eruptionsduring the instrumental era could have had more lasting effects. Decadal NAOvariability has been suggested to follow the 11-year solar cycle, andlinkages have been made between grand solar minima and negative NAO. However,the solar link to NAO found by modeling studies is not unequivocallysupported by reconstructions, and is not consistently present in observationsfor the 20th century. Here we present a reconstruction of atmospheric wintercirculation for the North Atlantic region covering the period 1241–1970 CE.Based on seasonally resolved Greenland ice core records and a 1200-year-longsimulation with an isotope-enabled climate model, we reconstruct sea levelpressure and temperature by matching the spatiotemporal variability in themodeled isotopic composition to that of the ice cores. This method allows usto capture the primary (NAO) and secondary mode (Eastern Atlantic Pattern) ofatmospheric circulation in the North Atlantic region, while, contrary toprevious reconstructions, preserving the amplitude of observed year-to-yearatmospheric variability. Our results show five winters of positive NAO onaverage following major tropical volcanic eruptions, which is more persistentthan previously suggested. In response to decadal minima of solar activity wefind a high-pressure anomaly over northern Europe, while a reinforcedopposite response in pressure emerges with a 5-year time lag. On centennialtimescales we observe a similar response of circulation as for the 5-yeartime-lagged response, with a high-pressure anomaly across North America andsouth of Greenland. This response to solar forcing is correlated to thesecond mode of atmospheric circulation, the Eastern Atlantic Pattern. Theresponse could be due to an increase in blocking frequency, possibly linkedto a weakening of the subpolar gyre. The long-term anomalies of temperatureduring solar minima shows cooling across Greenland, Iceland and westernEurope, resembling the cooling pattern during the Little Ice Age(1450–1850 CE). While our results show significant correlation betweensolar forcing and the secondary circulation pattern on decadal (r=0.29,p&lt;0.01) and centennial timescales (r=0.6, p&lt;0.01), we find noconsistent relationship between solar forcing and NAO. We conclude that solarand volcanic forcing impacts different modes of our reconstructed atmosphericcirculation, which can aid in separating the regional effects of forcings andunderstanding the underlying mechanisms.                    \n",
      "--------------------------------------------------\n",
      "Topic 4: 4_vegetation_china_ndvi_precipitation\n",
      "Representative Documents:\n",
      "  - Vegetation in the terrestrial ecosystem, sensitive to climate change and human activities, exerts a crucial influence on the carbon cycles in land, ocean, and atmosphere. Discrimination between climate and human-induced vegetation dynamics is advocated but still limited, especially in coastal China, which is characterized by a developed economy, a large population, and high food production, but also by unprecedented climate change and warming. Taking coastal China as the research area, our study used the normalized difference vegetation index (NDVI) in growing seasons, as well as precipitation, temperature, and sunlight hours datasets, adopted residual trend analysis at pixel and regional scales in coastal China from 2000–2019 and aims to (1) delineate the patterns and processes of vegetation changes, and (2) separate the relative contributions of climate and human activities by adopting residual trend analysis. The results indicated that (1) coastal China experienced the most vegetation greening (83.04% of the whole region) and partial degradation (16.86% of the whole region) with significant spatial heterogeneity; (2) compared with climate change, human activities have a greater positive impact on NDVI, and the regions were mainly located in the north of the North China Plain and the south of southern China; (3) the relative contribution rates of climate change and human activities were detected to be 0–60% and 60–100%, respectively; (4) in the northern coastal areas, the improvement of cultivated land management greatly promoted the greening of vegetation and thus the increase of grain yield, while in southern coastal areas, afforestation and the restoration of degraded forest were responsible for vegetation restoration; and (5) similar results obtained by partial correlation between nighttime lights and NDVI indicated the reliability of the residual trend analysis. The linear relationships of precipitation, temperature, and radiation on NDVI may limit the accurate estimation of climate drivers on vegetation, and further ecosystem process-modeling approaches can be used to estimate the relative contribution of climate change and human activities. The findings in our research emphasized that the attribution for vegetation dynamics with heterogeneity can provide evidence for the designation of rational ecological conservation policies.\n",
      "  - Climate change and human activities are the two primary driving factors in the vegetation degradation process, and the assessment of their relative roles in vegetation degradation is important to understand the driving mechanisms of vegetation degradation. In this study, net primary productivity (NPP) was selected as an indicator to distinguish the relative roles of climate change and human activities in vegetation degradation and restoration from 2001 to 2010 in North Xinjiang, China. The potential NPP and the human appropriation of NPP were served as the indicator of the effects of climate change and human activities in vegetation degradation and restoration. The results showed that human activities were the dominant factor that induced vegetation degradation, accounts for 55% (153 720 km2) of the total degradation, whereas 25% (69 336 km2) of the total degradation resulted from climate change; the combination of human activities and climate change was the cause in 20% (55 429 km2) of the total degradation. In contrast, 61% (66 927 km2) of the total vegetation restoration was dominated by human activities and 29% (31 553 km2) was caused by climate change; the areas of vegetation restoration caused by the combination of human activities and climate change were 10 551 km2 (10%). The relative roles of the two factors possessed great spatial heterogeneity in five vegetation types. Climate dominated degradation expansion and human activities dominated vegetation restoration in forest. Both the degradation and restoration were dominated by human activities in grassland. In desert, degradation was dominated by human activities and vegetation restoration by climate. In cropland and crop/natural vegetation mosaic, degradation was dominated by both human activities and climate change and restoration was dominated by human activities. These results demonstrated that human activities played a demonstrably positive role in vegetation restoration, and ecological restoration projects were effective on mitigating vegetation degradation and also promoting restoration in the southern areas of North Xinjiang.\n",
      "  - The spatiotemporal evolution of vegetation and its influencing factors can be used to explore the relationships among vegetation, climate change, and human activities, which are of great importance for guiding scientific management of regional ecological environments. In recent years, remote sensing technology has been widely used in dynamic monitoring of vegetation. In this study, the normalized difference vegetation index (NDVI) and standardized precipitation–evapotranspiration index (SPEI) from 1998 to 2017 were used to study the spatiotemporal variation of NDVI in China. The influences of climate change and human activities on NDVI variation were investigated based on the Mann–Kendall test, correlation analysis, and other methods. The results show that the growth rate of NDVI in China was 0.003 year−1. Regions with improved and degraded vegetation accounted for 71.02% and 22.97% of the national territorial area, respectively. The SPEI decreased in 60.08% of the area and exhibited an insignificant drought trend overall. Human activities affected the vegetation cover in the directions of both destruction and restoration. As the elevation and slope increased, the correlation between NDVI and SPEI gradually increased, whereas the impact of human activities on vegetation decreased. Further studies should focus on vegetation changes in the Continental Basin, Southwest Rivers, and Liaohe River Basin.\n",
      "--------------------------------------------------\n",
      "Topic 5: 5_farmers_adaptation_households_household\n",
      "Representative Documents:\n",
      "  - PurposeThis study aims to examine smallholder farmers’ perceptions toward the adoption of climate-smart agriculture (CSA) in smallholder farmers in the Upper Blue Nile Highlands of Ethiopia. Available research focused on profitability and economic constraints alone, disregarding the farmers’ perception of the adoption of CSA innovations. There is relatively little empirical work on farmers’ perceptions of innovations. Hence, a critical research gap that will strengthen CSA innovation research and practice includes understanding farmers’ perceptions about CSA innovations and how these perceptions interact with their adoption.Design/methodology/approachA cross-sectional household survey was conducted among 424 smallholder farmers selected from five agro-ecosystems. A structured questionnaire was used to collect primary data and a review of literature and documents was used to collect secondary data. The study used a multivariate probit model to examine perception factors affecting the likelihood of adopting multiple CSA innovations. The dependent variables were eight CSA innovations, while the independent variables were crafted from the three pillars of CSA.FindingsMajor CSA innovations adopted by farmers include improved variety, crop residue management, crop rotation, compost, row planting, soil and water conservation, intercropping and agroforestry. Farmers’ perception toward CSA innovations includes: CSA innovations sustainably increase productivity and income; enhance soil fertility; diversify livestock feed and energy sources; reduce soil erosion, weed infestation and crop failure; enhance soil organic matter, reduce chemical fertilizer use and rehabilitate land. Farmers’ positive perceptions of the benefits of CSA innovations for increasing crop productivity, reducing agricultural vulnerability to climate change and lowering farm greenhouse gas emissions have boosted adoption.Practical implicationsFarmers’ perceptions toward CSA innovations must be enhanced to increase the adoption of CSA innovations in the smallholder agriculture system. The CSA innovation scale-up strategies should focus on farmers’ perception of CSA innovation benefits toward food security, climate change adaption and mitigation outcomes. Awareness of CSA needs the close collaboration of public extension as well as local institutions such as farmers’ training centers.Originality/valueThe study adopts a multivariate probit model that models farmers’ simultaneous CSA innovation choices. Hence, this study contributes to the literature in four significant areas. First, it argues for differential treatment of the perception of smallholder farmers about innovations is needed. Second, it recognizes the interdependence of the adoption of innovations. Third, it directly assesses the farmers’ perception, while others use proxies to measure it. Finally, there are limited or no studies that address the perception of innovations within the lens of adopter perception theory.\n",
      "  - PurposeSmallholder farmers have always been profoundly the first to be impacted by climate change, and therefore, farmers understanding of climate change and accessibility to alternative adaptation strategies are crucial for reducing the effect of climate change. The purpose of this study is to assess the perception of farmers to climate change, adaptation strategies and determinants of adaptation choice in central Ethiopia.Design/methodology/approachThe study used data from randomly selected 240 farm households. Descriptive statistics were used to describe farmers’ perceptions of climate change and adaptation strategies. Also, a multivariate probit model was used to identify the major factors affecting farmers’ choice of adaptation strategies to climate change in central Ethiopia.FindingsSmallholder farmers perceive climate change in the past two decades in response; the majority (91.47%) of farmers used adaptation options. Improved crop varieties and input intensity, crop diversification, planting date adjustment, soil and water conservation activities and changing of the crop type were used as adaptation options in the study area. A few of these strategies were significantly confirmed a complementary and supplementary relationship. The study identified sex, family size, agroecology, climate information, crop-fail history and formal extension service as significant determinants for farmers’ adaptation choices as these variables significantly affected more than two farmers’ adaptation strategies simultaneously.Research limitations/implicationsFarmers’ choice of adaptation was highly constrained by institutional factors and all these identified factors can be possibly addressed through a better institutional service provision system. It is, therefore, recommended that local administrators should explore the institutional service provision system for a better farm-level adaptation while considering demographic characteristics as well.Originality/valueThis study identified factors affecting farmers’ several adaptation strategies at a time and provides information for the policymaker to make cost-effective interventions for better farm-level adaptation practices.\n",
      "  -                Purpose                – The purpose of this paper is to analyze smallholder farmers’ perceptions of climate change and its adverse effects, identify major adaptation strategies used by farmers and analyze the factors that influence the choice of adaptation strategy by smallholder farmers in eastern Ethiopia.                                        Design/methodology/approach                – The study was based on a cross-sectional survey of 296 sample households selected from three districts in east Ethiopia. Data were collected with the aid of a semi-structured questionnaire and review of literature, documents and databases.                                        Findings                – The study provides empirical evidence that majority of farmers in the study area are aware of climate change patterns and their adverse effect on income, food security, diversity, forest resources, food prices and crop and livestock diseases. In response to these adverse effects, major adaptation strategies used by farmers include cultivating different crops, planting different crop varieties, changing planting dates, use of soil and water conservation techniques, conservation agriculture practices and engaging in non-farm income activities. Choice of adaptation strategies are influenced by gender of household head, household size, farm size, distance from market and number of farm plots.                                        Practical implications                – The study suggests that developing more effective climate change adaptation strategies need support from the government. Such an effort needs provision of the necessary resources such as credit, information and extension services on climate change adaptation strategies and technologies, and investing in climate smart and resilient projects.                                        Originality/value                – The study adopts multivariate probit model that models farmers’ simultaneous adaptation choice behavior which has been rarely addressed by previous researches.            \n",
      "--------------------------------------------------\n",
      "Topic 6: 6_breeding_survival_population_birds\n",
      "Representative Documents:\n",
      "  - Climate change is profoundly affecting the phenology of many species. In migratory birds, there is evidence for advances in their arrival time at the breeding ground and their timing of breeding, yet empirical studies examining the interdependence between arrival and breeding time are lacking. Hence, evidence is scarce regarding how breeding time may be adjusted via the arrival‐breeding interval to help local populations adapt to local conditions or climate change. We used long‐term data from an intensively monitored population of the northern wheatear (Oenanthe oenanthe) to examine the factors related to the length of 734 separate arrival‐to‐breeding events from 549 individual females. From 1993 to 2017, the mean arrival and egg‐laying dates advanced by approximately the same amount (~5–6 days), with considerable between‐individual variation in the arrival‐breeding interval. The arrival‐breeding interval was shorter for: (a) individuals that arrived later in the season compared to early‐arriving birds, (b) for experienced females compared to first‐year breeders, (c) as spring progressed, and (d) in later years compared to earlier ones. The influence of these factors was much larger for birds arriving earlier in the season compared to later arriving birds, with most effects on variation in the arrival‐breeding interval being absent in late‐arriving birds. Thus, in this population it appears that the timing of breeding is not constrained by arrival for early‐ to midarriving birds, but instead is dependent on local conditions after arrival. For late‐arriving birds, however, the timing of breeding appears to be influenced by arrival constraints. Hence, impacts of climate change on arrival dates and local conditions are expected to vary for different parts of the population, with potential negative impacts associated with these factors likely to differ for early‐ versus late‐arriving birds.\n",
      "  - Climate is an important driver of changes in animal population size, but its effect on the underlying demographic rates remains insufficiently understood. This is particularly true for avian long-distance migrants which are exposed to different climatic factors at different phases of their annual cycle. To fill this knowledge gap, we used data collected by a national-wide bird ringing scheme for eight migratory species wintering in sub-Saharan Africa and investigated the impact of climate variability on their breeding productivity and adult survival. While temperature at the breeding grounds could relate to the breeding productivity either positively (higher food availability in warmer springs) or negatively (food scarcity in warmer springs due to trophic mismatch), water availability at the non-breeding should limit the adult survival and the breeding productivity. Consistent with the prediction of the trophic mismatch hypothesis, we found that warmer springs at the breeding grounds were linked with lower breeding productivity, explaining 29% of temporal variance across all species. Higher water availability at the sub-Saharan non-breeding grounds was related to higher adult survival (18% temporal variance explained) but did not carry-over to breeding productivity. Our results show that climate variability at both breeding and non-breeding grounds shapes different demographic rates of long-distance migrants.\n",
      "  - In seasonal environments, fluctuating early‐season weather conditions and short breeding windows limit reproductive opportunities such that breeding earlier or later than the optimum may be particularly costly. Given the risk of early‐season energy limitations, time‐ and energy‐based carry‐over effects stemming from environmental conditions across the annual cycle may have pronounced consequences for breeding phenology and fitness. Generally, when and where environmental conditions are most influential are poorly understood, limiting our ability to predict the future of climate‐sensitive populations.For an alpine‐breeding, migratory population of horned lark Eremophila alpestris in northern British Columbia, Canada (54.8°N), we assessed how weather conditions across the annual cycle influenced clutch initiation date and offspring development. We also addressed how cross‐seasonal effects on breeding parameters combine to influence reproductive fitness.With 12 years of breeding data and 3 years of migration data, we used a sliding window approach to identify points during the annual cycle when weather events most influenced breeding phenology and offspring development. Consequences for breeding success were assessed using nest survival simulations.Average clutch initiation date varied up to 11 days among years but did not advance from 2003 to 2019. Warmer temperatures at stopover and breeding sites advanced clutch initiation, but winter conditions had no effect. Sub‐zero stopover temperatures carried over to prolong offspring development independent of clutch initiation date, potentially indicating energy‐based carry‐over effects acting on parental investment. Nest survival decreased with both later clutch initiation and prolonged offspring development such that females nesting earlier and fledging offspring at a younger age were up to 45% more likely to reproduce successfully.We demonstrate that stronger carry‐over effects originated from environmental conditions closer to the breeding site in time and space, as well as the potential for energy‐based mechanisms to link pre‐breeding conditions to reproductive fitness. We also highlight the importance of extended stopovers for songbirds breeding in seasonal environments, particularly given that climatic conditions are becoming increasingly decoupled across stages of the annual cycle. Understanding the cross‐seasonal mechanisms shaping breeding decisions in stochastic environments allows for more accurate predictions of population‐level responses to climate change.\n",
      "--------------------------------------------------\n",
      "Topic 7: 7_pacific_anomalies_anomalous_niño\n",
      "Representative Documents:\n",
      "  -                A season-reliant empirical orthogonal function (S-EOF) analysis is applied to seasonal mean precipitation over East Asia for the period of 1979–2004. The first two dominant modes account for 44% of the total interannual variance, corresponding to post-ENSO and ENSO turnabout years, respectively. The first mode indicates that in El Niño decaying summer, an anomalous anticyclone appears over the western North Pacific (WNP). This anticyclone is associated with strong positive precipitation anomalies from central China to southern Japan. In the following fall, enhanced convection appears over the WNP as a result of the underlying warm SST anomalies caused by the increase of the shortwave radiative flux in the preceding summer. A dry condition appears over southeastern China. The anomalous precipitation pattern persists throughout the subsequent winter and spring. The second mode shows that during the El Niño developing summer the anomalous heating over the equatorial central Pacific forces a cyclonic vorticity over the WNP. This strengthens the WNP monsoon. Meanwhile, an anomalous anticyclone develops in the northern Indian Ocean and moves eastward to the South China Sea and the WNP in the subsequent fall and winter. This leads to the increase of precipitation over southeastern China. The anticyclone and precipitation anomalies are maintained in the following spring through local air–sea interactions.               The diagnosis of upper-level velocity potential and midlevel vertical motion fields reveals a season-dependent Indian Ocean forcing scenario. The Indian Ocean basinwide warming during the El Niño mature winter and the subsequent spring does not have a significant impact on anomalous circulation in the WNP, because convection over the tropical Indian Ocean is suppressed by the remote forcing from the equatorial central-eastern Pacific. The basinwide warming plays an active role in impacting the WNP anomalous anticyclone during the ENSO decaying summer through atmospheric Kelvin waves or Hadley circulation.\n",
      "  -                Previous studies documented that a distinct southward shift of central Pacific low-level wind anomalies occurring during the ENSO decaying phase is caused by an interaction between the western Pacific annual cycle and El Niño–Southern Oscillation (ENSO) variability. The present study finds that the meridional movement of the central Pacific wind anomalies appears only during traditional eastern Pacific El Niño (EP El Niño) events rather than in central Pacific El Niño (CP El Niño) events in which sea surface temperature (SST) anomalies are confined to the central Pacific. The zonal structure of ENSO-related SST anomalies therefore has an important effect on meridional asymmetry in the associated atmospheric response and its modulation by the annual cycle. In contrast to EP El Niño events, the SST anomalies of CP El Niño events extend farther west toward the warm pool region with its climatological warm SSTs. In the warm pool region, relatively small SST anomalies are thus able to excite convection anomalies on both sides of the equator, even with a meridionally asymmetric SST background state. Therefore, almost meridionally symmetric precipitation and wind anomalies are observed over the central Pacific during the decaying phase of CP El Niño events. The SST anomaly pattern of La Niña events is similar to CP El Niño events with a reversed sign. Accordingly, no distinct southward displacement of the atmospheric response occurs over the central Pacific during the La Niña decaying phase. These results have important implications for ENSO climate impacts over East Asia, since the anomalous low-level anticyclone over the western North Pacific is an integral part of the annual cycle–modulated ENSO response.\n",
      "  -  Using multiple datasets and a partial correlation method, the authors analyze the different impacts of eastern Pacific (EP) and central Pacific (CP) El Niño on East Asian climate, focusing on the features from El Niño developing summer to El Niño decaying summer. Unlike the positive–negative–positive (+/−/+) anomalous precipitation pattern over East Asia and the equatorial Pacific during EP El Niño, an anomalous −/+/− rainfall pattern appears during CP El Niño. The anomalous dry conditions over southeastern China and the northwestern Pacific during CP El Niño seem to result from the anomalous low-level anticyclone over southern China and the South China Sea, which is located more westward than the Philippine Sea anticyclone during EP El Niño. The continuous anomalous sinking motion over southeastern China, as part of the anomalous Walker circulation associated with CP El Niño, also contributes to these dry conditions.  During the developing summer, the impact of CP El Niño on East Asian climate is more significant than the influence of EP El Niño. During the decaying summer, however, EP El Niño exerts a stronger influence on East Asia, probably due to the long-lasting anomalous warming over the tropical Indian Ocean accompanying EP El Niño.  Temperatures over portions of East Asia and the northwestern Pacific tend to be above normal during EP El Niño but below normal from the developing autumn to the next spring during CP El Niño. A possible reason is the weakened (enhanced) East Asian winter monsoon related to EP (CP) El Niño. \n",
      "--------------------------------------------------\n",
      "Topic 8: 8_soil_microbial_warming_litter\n",
      "Representative Documents:\n",
      "  - Global surface temperature is predicted to increase by 1.4–5.8°C by the end of this century. However, the impacts of this projected warming on soil C balance and the C budget of terrestrial ecosystems are not clear. One major source of uncertainty stems from warming effects on soil microbes, which exert a dominant influence on the net C balance of terrestrial ecosystems by controlling organic matter decomposition and plant nutrient availability. We, therefore, conducted an experiment in a tallgrass prairie ecosystem at the Great Plain Apiaries (near Norman, OK) to study soil microbial responses to temperature elevation of about 2°C through artificial heating in clipped and unclipped field plots. While warming did not induce significant changes in net N mineralization, soil microbial biomass and respiration rate, it tended to reduce extractable inorganic N during the second and third warming years, likely through increasing plant uptake. In addition, microbial substrate utilization patterns and the profiles of microbial phospholipid fatty acids (PLFAs) showed that warming caused a shift in the soil microbial community structure in unclipped subplots, leading to the relative dominance of fungi as evidenced by the increased ratio of fungal to bacterial PLFAs. However, no warming effect on soil microbial community structure was found in clipped subplots where a similar scale of temperature increase occurred. Clipping also significantly reduced soil microbial biomass and respiration rate in both warmed and unwarmed plots. These results indicated that warming‐led enhancement of plant growth rather than the temperature increase itself may primarily regulate soil microbial response. Our observations show that warming may increase the relative contribution of fungi to the soil microbial community, suggesting that shifts in the microbial community structure may constitute a major mechanism underlying warming acclimatization of soil respiration.\n",
      "  - Soil microbial communities control critical ecosystem processes such as decomposition, nutrient cycling, and soil organic matter formation. Continental scale patterns in the composition and functioning of microbial communities are related to climatic, biotic, and edaphic factors such as temperature and precipitation, plant community composition, and soil carbon, nitrogen, and pH. Although these relationships have been well explored individually, the examination of the factors that may act directly on microbial communities vs. those that may act indirectly through other ecosystem properties has not been well developed. To further such understanding, we utilized structural equation modeling (SEM) to evaluate a set of hypotheses about the direct and indirect effects of climatic, biotic, and edaphic variables on microbial communities across the continental United States. The primary goals of this work were to test our current understanding of the interactions among climate, soils, and plants in affecting microbial community composition, and to examine whether variation in the composition of the microbial community affects potential rates of soil enzymatic activities. A model of interacting factors created through SEM shows several expected patterns. Distal factors such as climate had indirect effects on microbial communities by influencing plant productivity, soil mineralogy, and soil pH, but factors related to soil organic matter chemistry had the most direct influence on community composition. We observed that both plant productivity and soil mineral composition were important indirect influences on community composition at the continental scale, both interacting to affect organic matter content and microbial biomass and ultimately community composition. Although soil hydrolytic enzymes were related to the moisture regime and soil carbon, oxidative enzymes were also affected by community composition, reflected in the abundance of soil fungi. These results highlight that soil microbial communities can be modeled within the context of multiple interacting ecosystem properties acting both directly and indirectly on their composition and function, and this provides a rich and informative context with which to examine communities. This work also highlights that variation in climate, microbial biomass, and microbial community composition can affect maximum rates of soil enzyme activities, potentially influencing rates of decomposition and nutrient mineralization in soils.\n",
      "  - Climate change can profoundly impact carbon (C) cycling of terrestrial ecosystems. A field experiment was conducted to examine responses of total soil and microbial respiration, and microbial biomass to experimental warming and increased precipitation in a semiarid temperate steppe in northern China since April 2005. We measured soil respiration twice a month over the growing seasons, soil microbial biomass C (MBC) and N (MBN), microbial respiration (MR) once a year in the middle growing season from 2005 to 2007. The results showed that interannual variations in soil respiration, MR, and microbial biomass were positively related to interannual fluctuations in precipitation. Laboratory incubation with a soil moisture gradient revealed a constraint of the temperature responses of MR by low soil moisture contents. Across the 3 years, experimental warming decreased soil moisture, and consequently caused significant reductions in total and microbial respiration, and microbial biomass, suggesting stronger negatively indirect effects through warming‐induced water stress than the positively direct effects of elevated temperature. Increased evapotranspiration under experimental warming could have reduced soil water availability below a stress threshold, thus leading to suppression of plant growth, root and microbial activities. Increased precipitation significantly stimulated total soil and microbial respiration and all other microbial parameters and the positive precipitation effects increased over time. Our results suggest that soil water availability is more important than temperature in regulating soil and microbial respiratory processes, microbial biomass and their responses to climate change in the semiarid temperate steppe. Experimental warming caused greater reductions in soil respiration than in gross ecosystem productivity (GEP). In contrast, increased precipitation stimulated GEP more than soil respiration. Our observations suggest that climate warming may cause net C losses, whereas increased precipitation may lead to net C gains in the semiarid temperate steppe. Our findings highlight that unless there is concurrent increase in precipitation, the temperate steppe in the arid and semiarid regions of northern China may act as a net C source under climate warming.\n",
      "--------------------------------------------------\n",
      "Topic 9: 9_genetic_populations_species_diversity\n",
      "Representative Documents:\n",
      "  - Assessing population evolutionary potential has become a central tenet of conservation biology. Since adaptive responses require allelic variation at functional genes, consensus has grown that genetic variation at genes under selection is a better surrogate for adaptive evolutionary potential than neutral genetic diversity. Although consistent with prevailing theory, this argument lacks empirical support and ignores recent theoretical advances questioning the very concept of neutral genetic diversity. In this study, we quantified genome-wide responses of single nucleotide polymorphism loci linked to climatic factors over a strong latitudinal gradient in natural populations of the high Andean wetland plant, Carex gayana, and then assessed whether genetic variation of candidate climate-selected loci better predicted their genome-wide responses than genetic variation of non-candidate loci. Contrary to this expectation, genomic responses of climate-linked loci only related significantly to environmental variables and genetic diversity of non-candidate loci. The effects of genome-wide genetic diversity detected in this study may be a result of either the combined influence of small effect variants or neutral and demographic factors altering the adaptive evolutionary potential of C. gayana populations. Regardless of the processes involved, our results redeem genome-wide genetic diversity as a potentially useful indicator of population adaptive evolutionary potential.\n",
      "  - AimsQuaternary climate changes dramatically affected species' distributions and thus impacted genetic diversity patterns, particularly for rear‐edge populations. Empirical studies have shown the southernmost (rear‐edge), fragmented populations of Japanese woody plants can harbour high genetic diversity owing to their origin in southern glacial refugia. The effect of Holocene climate warming on rear‐edge populations has, however, rarely been demonstrated. We assessed whether the genetic structure of populations of temperate plants in Japan can be interpreted to show legacies of both icy (Last Glacial Maximum, LGM) and warm (Holocene) climates.LocationJapanese Archipelago.TaxonHemerocallis middendorffii (Asphodelaceae).MethodsPopulation genetic profiles of 737 individuals from 41 populations were analysed to examine population structure and past population demography, using 12 EST‐SSR markers. Present and past suitable habitat areas during the LGM and the Holocene climatic optimum were estimated by ecological niche modelling (ENM). Reconstructed palaeodistribution was combined with population genetics to statistically predict population demographics in relation to past climate changes.ResultsGenetic analysis of the 41 populations revealed 6 regional population groups. Four groups widely dominating the northern–central ranges harboured high genetic diversity, whereas genetic divergence within the groups was low. In contrast, the two groups at the southwestern edge were geographically and genetically isolated, and they showed the lowest genetic diversity. The estimated palaeodistributions showed a decrease in the suitable range during the Holocene in comparison with that at the LGM, and only habitat suitability in the Holocene was able to predict the genetic diversity across the range.Main conclusionsPopulations at the centre of the current distribution harbour high genetic diversity because they remained stable during both cold and warm periods. However, habitat fragmentation and population decline in relation to climate warming during the Holocene resulted in genetic isolation and impoverishment of the rear‐edge populations.\n",
      "  -                                  Background and Aims                  Understanding adaptive genetic variation and whether it can keep pace with predicted future climate change is critical in assessing the genetic vulnerability of species and developing conservation management strategies. The lack of information on adaptive genetic variation in relict species carrying abundant genetic resources hinders the assessment of genetic vulnerability. Using a landscape genomics approach, this study aimed to determine how adaptive genetic variation shapes population divergence and to predict the adaptive potential of Pterocarya macroptera (a vulnerable relict species in China) under future climate scenarios.                                                Methods                  We applied restriction site-associated DNA sequencing (RAD-seq) to obtain 8244 single-nucleotide polymorphisms (SNPs) from 160 individuals across 28 populations. We examined the pattern of genetic diversity and divergence, and then identified outliers by genetic differentiation (FST) and genotype–environment association (GEA) methods. We further dissected the effect of geographical/environmental gradients on genetic variation. Finally, we predicted genetic vulnerability and adaptive risk under future climate scenarios.                                                Key Results                  We identified three genetic lineages within P. macroptera: the Qinling-Daba-Tianmu Mountains (QDT), Western Sichuan (WS) and Northwest Yunnan (NWY) lineages, which showed significant signals of isolation by distance (IBD) and isolation by environment (IBE). IBD and IBE explained 3.7–5.7 and 8.6–12.8 % of the genetic structure, respectively. The identified GEA SNP-related genes were involved in chemical defence and gene regulation and may exhibit higher genetic variation to adapt to the environment. Gradient forest analysis revealed that the genetic variation was mainly shaped by temperature-related variables, indicating its adaptation to local thermal environments. A limited adaptive potential was suggested by the high levels of genetic vulnerability in marginal populations.                                                Conclusions                  Environmental gradient mainly shaped the population differentiation of P. macroptera. Marginal populations may be at high risk of extinction, and thus proactive management measures, such as assisted gene flow, are required to ensure the survival of these populations.               \n",
      "--------------------------------------------------\n",
      "Topic 10: 10_groundwater_water_streamflow_runoff\n",
      "Representative Documents:\n",
      "  -                The mountainous areas of Colorado are used for tourism and recreation, and they provide water storage and supply for municipalities, industries, and agriculture. Recent studies suggest that water supply and tourist industries such as skiing are at risk from climate change. In this study, a distributed-parameter watershed model, the Precipitation-Runoff Modeling System (PRMS), is used to identify the potential effects of future climate on hydrologic conditions for two Colorado basins, the East River at Almont and the Yampa River at Steamboat Springs, and at the subbasin scale for two ski areas within those basins.               Climate-change input files for PRMS were generated by modifying daily PRMS precipitation and temperature inputs with mean monthly climate-change fields of precipitation and temperature derived from five general circulation model (GCM) simulations using one current and three future carbon emission scenarios. All GCM simulations of mean daily minimum and maximum air temperature for the East and Yampa River basins indicate a relatively steady increase of up to several degrees Celsius from baseline conditions by 2094. GCM simulations of precipitation in the two basins indicate little change or trend in precipitation, but there is a large range associated with these projections. PRMS projections of basin mean daily streamflow vary by scenario but indicate a central tendency toward slight decreases, with a large range associated with these projections.               Decreases in water content or changes in the spatial extent of snowpack in the East and Yampa River basins are important because of potential adverse effects on water supply and recreational activities. PRMS projections of each future scenario indicate a central tendency for decreases in basin mean snow-covered area and snowpack water equivalent, with the range in the projected decreases increasing with time. However, when examined on a monthly basis, the projected decreases are most dramatic during fall and spring. Presumably, ski area locations are picked because of a tendency to receive snow and keep snowpack relative to the surrounding area. This effect of ski area location within the basin was examined by comparing projections of March snow-covered area and snowpack water equivalent for the entire basin with more local projections for the portion of the basin that represents the ski area in the PRMS models. These projections indicate a steady decrease in March snow-covered area for the basins but only small changes in March snow-covered area at both ski areas for the three future scenarios until around 2050. After 2050, larger decreases are possible, but there is a large range in the projections of future scenarios. The rates of decrease for snowpack water equivalent and precipitation that falls as snow are similar at the basin and subbasin scale in both basins. Results from this modeling effort show that there is a wide range of possible outcomes for future snowpack conditions in Colorado. The results also highlight the differences between projections for entire basins and projections for local areas or subbasins within those basins.\n",
      "  - The Nooksack River has its headwaters in the North Cascade Mountains and drains an approximately 2000 km2 watershed in northwestern Washington State. The timing and magnitude of streamflow in a snowpack‐dominated drainage basin such as the Nooksack River basin are strongly influenced by temperature and precipitation. Projections of future climate made by general circulation models (GCMs) indicate increases in temperature and variable changes in precipitation for the Nooksack River basin. Understanding the response of the river to climate change is crucial for regional water resources planning because municipalities, tribes, and industry depend on the river for water use and for fish habitat.We combine three different climate scenarios downscaled from GCMs and the Distributed‐Hydrology‐Soil‐Vegetation Model to simulate future changes to timing and magnitude of streamflow in the higher elevations of the Nooksack River. Simulations of future streamflow and snowpack in the basin project a range of magnitudes, which reflects the variable meteorological changes indicated by the three GCM scenarios and the local natural variability employed in the modeling. Simulation results project increased winter flows, decreased summer flows, decreased snowpack, and a shift in timing of the spring melt peak and maximum snow water equivalent. These results are consistent with previous regional studies, but the magnitude of increased winter flows and total annual runoff is higher. Increases in temperature dominate snowpack declines and changes to spring and summer streamflow, whereas a combination of increases in temperature and precipitation control increased winter streamflow. Copyright © 2013 John Wiley &amp; Sons, Ltd.\n",
      "  - Climate warming may alter the quantity and timing of groundwater discharge to streams in high alpine watersheds due to changes in the timing of the duration of seasonal freezing in the subsurface and snowmelt recharge. It is imperative to understand the effects of seasonal freezing and recharge on groundwater discharge to streams in warming alpine watersheds as streamflow originating from these watersheds is a critical water resource for downstream users. This study evaluates how climate warming may alter groundwater discharge due to changes in seasonally frozen ground and snowmelt using a 2‐D coupled flow and heat transport model with freeze and thaw capabilities for variably saturated media. The model is applied to a representative snowmelt‐dominated watershed in the Rocky Mountains of central Colorado, USA, with snowmelt time series reconstructed from a 12 year data set of hydrometeorological records and satellite‐derived snow covered area. Model analyses indicate that the duration of seasonal freezing in the subsurface controls groundwater discharge to streams, while snowmelt timing controls groundwater discharge to hillslope faces. Climate warming causes changes to subsurface ice content and duration, rerouting groundwater flow paths but not altering the total magnitude of future groundwater discharge outside of the bounds of hydrologic parameter uncertainties. These findings suggest that frozen soil routines play an important role for predicting the future location of groundwater discharge in watersheds underlain by seasonally frozen ground.\n",
      "--------------------------------------------------\n",
      "Topic 11: 11_building_thermal_comfort_buildings\n",
      "Representative Documents:\n",
      "  - The energy-supply crisis, aggravated by the war in Ukraine, has prompted EU governments to approve urgent energy-saving measures. The new Spanish energy-saving standard aims to reduce energy consumption by changing the regulatory limits for indoor hygrothermal conditions in buildings. This regulation has provoked a great social debate about its real effectiveness and its impact on user comfort. This work explores the hygrothermal performance of an office building in southeastern Spain. The objective of this research is to determine qualitatively and quantitatively how the new energy-saving standard in Spain influences energy efficiency and indoor thermal comfort, by considering the characteristics of the dry Mediterranean climate (BShs) within a warm semi-arid climate (BSh). The scientific novelty of the study is to demonstrate that the new Spanish standard not only reduces energy costs but also makes the indoor comfort of buildings much worse; for this reason, an improvement in the standard is also proposed. The study methodology consists of a comparative study between the thermal performance, thermal comfort, and energy demand of the building, considering both the new and previous standards’ requirements. It also includes the evaluation of a proposal to improve the current standard. The results showed that the new energy-saving standard reduced energy consumption by 21.78% in comparison to former standards, but the new comfort ranges were not acceptable for 60% of the users. The proposed improvement does achieve acceptable comfort for most users (75%) and an additional reduction in energy demand of 48.76% compared to current standard. We conclude that the thermal comfort requirements of the current energy standard should be modified to better adapt the design criteria to the dry Mediterranean climate.\n",
      "  - This study aims to propose building envelope retrofit packages for existing naturally ventilated school buildings in the hot–humid climatic region of Chennai, India. Indoor thermal parameters were collected through field studies from nine sample classrooms of a selected school building in May 2019, between 9.00 am and 4.00 pm. The thermal performance assessment of the existing building was performed by examining the discomfort hours using the CBE thermal comfort tool. Envelope retrofit strategies gathered from the literature and building standards were applied and studied through simulation. The findings reveal the enormous potential to increase the thermal comfort of existing school buildings through envelope retrofit measures. The results demonstrate that the whole-building temperature can be reduced up to 3.2 °C in summer and up to 3.4 °C in winter. Implementing retrofit measures to the building envelopes of existing buildings will help school owners to increase the comfortable hours of whole buildings by up to 17%. In comparison, annual energy savings of up to 13% for the whole building can be made by enhancing the thermal performance of the building envelope. The findings will also help architects to optimise thermal performance and energy usage with minimal interventions.\n",
      "  - Residential buildings have a list of functions, and one of the top priories is the thermal comfort of its occupants. Thermal comfort can be one of the measurements of successful building performance, and it can be addressed in various ways to provide a good quality indoor climate. The way to address the need for thermal comfort determines the consumption and conservation of energy. Adapting passive strategies and thermal mass to a building can reduce energy consumption significantly. Applying these strategies to a building does not need additional investment from the initial capital, and renovating a building to implement the strategy will cut the energy usage of a building and save the additional financing of new technology for heating and cooling, ventilation, and so on. In this study, two residential buildings located in North Cyprus with the same geographical location, climate zone, and different construction materials were studied. The study aimed to make a technical test to reduce energy consumption and improve energy conservation in the building by applying passive solar and energy efficiency design strategies (PSEEDS). The thermal mass has been used and discussed as an improbable energy technique alongside other insulation materials and shading devices. The article discusses and compares the energy consumption and thermal comfort of traditional Mediterranean houses with contemporary houses. The study uses 2D drawings, 3D modeling, and energy simulation programs to evaluate energy consumption in both real and assumed scenarios. The study finds that traditional Mediterranean homes, with their thick walls and built-in shading mechanisms, require less energy for heating and cooling than contemporary houses. The implementation of passive solar energy efficient design strategies (PSEEDS) significantly reduces energy consumption in both types of houses, but traditional Mediterranean houses still show more efficiency due to their higher thermal mass. The research demonstrates that improving windows, examining the orientation of the structure, altering shade devices, and decreasing infiltration rates can reduce overall energy consumption by up to 34.71% To sum up, in this study, PSEEDS, the performance of thermal mass, and pre-design measures significantly decrease energy consumption. In addition, implementing passive strategies during a renovation of a building also compensates for the investment and lifecycle cost of new technologies and energy usage.\n",
      "--------------------------------------------------\n",
      "Topic 12: 12_urban_adaptation_measures_planning\n",
      "Representative Documents:\n",
      "  - In climate-responsive design the building becomes an intermediary in its own energy housekeeping, forming a link between the harvest of climate resources and low energy provision of comfort. Essential here is the employment of climate-responsive building elements, defined as structural and architectural elements in which the energy infrastructure is far-reaching integrated. This thesis presents the results of research conducted on what knowledge is needed in the early stages of the design process and how to transfer and transform that knowledge to the field of the architect in order for them to successfully implement the principles of climate-responsive design. The derived content, form and functional requirements provide the framework for a design decision support tool. These requirements were incorporated into a concept tool that has been presented to architects in the field, in order to gain their feedback.Climate-responsive design makes the complex task of designing even more complex. Architects are helped when sufficient information on the basics of climate-responsive design and its implications are provided as informative support during decision making in the early design stages of analysis and energy concept development. This informative support on climate-responsive design should address to different design styles in order to be useful to any type of architects.What is defined as comfortable has far-reaching implications for the way buildings are designed and how they operate. This in turn gives an indication of the energy used for maintaining a comfortable indoor environment. Comfort is not a strict situation, but subjective. Diversity is appreciated and comfort is improved when users have the ability to exert influence on their environment. Historically, the provision of comfort has led to the adoption of mechanical climate control systems that operate in many cases indifferent from the building space and mass and its environment. Climate-responsive design restores the context of local climate and environment as a design parameter. Many spatial, functional and comfort-related boundary conditions that have an effect on the energy design concept have been distinguished. There are many low-graded energy sources that can be put to use in the built environment, with local climate as the primary component. When exploring the potential of local climate, urban context needs to be taken into account since it heavily affects the actual potential. Since buildings are typically build to last for decades, consideration of changing climate and its expected effect on the energy potential is an important factor in the strategy to follow. The study of the energy potential of local climate resulted in a set of climate-related and context-related boundary conditions.The principles of climate-responsive design - the conceptual relations between energy source, energy treatment and comfort demand - can be translated into various design solutions, the contextual, architectural and technical implementation of these principles into an actual design. The design solutions can be divided into six categories- site planning, building form and layout, skin, structure, finish and (integrated)building service - that cover various dimensions in planning and construction. In this thesis a non-exhaustive list of design principles and solutions is presented using different matrices.In order to design using climate-responsive design principles the architect should be given an overview of the comfort contribution and energy performance of design solutions. Furthermore, the identification of collaborations and conflicts when using multiple design principles together is essential. The generation of a satisfying design is more than just stacking solutions upon each other. It should also be made clear what a possible energy function of a building element is besides its primary function. This is where comfort and energy related design objectives of climate-responsive design meet other objectives (i.e. spatial, functional and structural). Finally, the impact of climatere sponsive building elements on the appearance of design is relevant to concept orientated architects. Together this can be considered as the content requirements of the design-decision support tool.In the early stages of the design process climate-responsive design is about the generation of energy concepts. In this phase accessible guidelines and the option to compare alternatives is more important than to assess absolute performance. The conceptual design phase is dynamic and has many iterations. Informative, context specific knowledge reduces the number of iterations before the architect has generated a satisfying number of design options from which it can continue to the next design phase of assessment. Functional requirements for the framework of the design decision support tool are the inclusion of a knowledge base with expert knowledge and best practice examples, the provision of informative, context-specific knowledge, the provision of accessible guidelines, the provision of an option to compare alternatives, the inclusion of the ability to inform during and assist in decision-making (i.e. intelligence) and the limitation of complexity and the generation of easy to interpret output.The tool is primarily developed for the architect so it needs to blend in the architect’s workflow enabling the architect’s creativity and guiding his intuition. Other form requirements of the design-decision support tool are the presence of customisation options and custom navigation patterns, all presented in a visual style.A concept of the web-based tool has been developed in order to illustrate what a climate-responsive design-decision support tool could look like. The heart of the tool is formed by the knowledge base, constructed from items grouped into one of four categories: principles, solutions, projects and guidelines. Relationships between items are incorporated within the knowledge base as hyperlinks, which makes it easy to navigate from one item to another. The stored information is presented in numerous ways. Info sheets provide the most detailed presentation style containing all available information for an item, while catalogues, matrices and a gallery provide quick overviews and reveal direct relationships with other items.In order to become a true design-decision support tool, the presented tool needs to be further developed. This includes the use of a more context-specific presentation style and the inclusion of more context-specific knowledge, the addition of layers in which the knowledge is presented varying from more general to practical, the development and implementation of performance indicators and a more direct and visual approach to pinpoint synergetic and conflicting effects.By using the tool, architects can access relevant knowledge in different ways that suit their method of working. It enables the presentation of complex relationships in a clear way and by doing so unlocking a much broader part of the content to them. That will help speeding up the process of design iteration before the energy concept can be assessed in the successive phase of the design process.\n",
      "  - In climate-responsive design the building becomes an intermediary in its own energy housekeeping, forming a link between the harvest of climate resources and low energy provision of comfort. Essential here is the employment of climate-responsive building elements, defined as structural and architectural elements in which the energy infrastructure is far-reaching integrated. This thesis presents the results of research conducted on what knowledge is needed in the early stages of the design process and how to transfer and transform that knowledge to the field of the architect in order for them to successfully implement the principles of climate-responsive design. The derived content, form and functional requirements provide the framework for a design decision support tool. These requirements were incorporated into a concept tool that has been presented to architects in the field, in order to gain their feedback.Climate-responsive design makes the complex task of designing even more complex. Architects are helped when sufficient information on the basics of climate-responsive design and its implications are provided as informative support during decision making in the early design stages of analysis and energy concept development. This informative support on climate-responsive design should address to different design styles in order to be useful to any type of architects.What is defined as comfortable has far-reaching implications for the way buildings are designed and how they operate. This in turn gives an indication of the energy used for maintaining a comfortable indoor environment. Comfort is not a strict situation, but subjective. Diversity is appreciated and comfort is improved when users have the ability to exert influence on their environment. Historically, the provision of comfort has led to the adoption of mechanical climate control systems that operate in many cases indifferent from the building space and mass and its environment. Climate-responsive design restores the context of local climate and environment as a design parameter. Many spatial, functional and comfort-related boundary conditions that have an effect on the energy design concept have been distinguished. There are many low-graded energy sources that can be put to use in the built environment, with local climate as the primary component. When exploring the potential of local climate, urban context needs to be taken into account since it heavily affects the actual potential. Since buildings are typically build to last for decades, consideration of changing climate and its expected effect on the energy potential is an important factor in the strategy to follow. The study of the energy potential of local climate resulted in a set of climate-related and context-related boundary conditions.The principles of climate-responsive design - the conceptual relations between energy source, energy treatment and comfort demand - can be translated into various design solutions, the contextual, architectural and technical implementation of these principles into an actual design. The design solutions can be divided into six categories- site planning, building form and layout, skin, structure, finish and (integrated)building service - that cover various dimensions in planning and construction. In this thesis a non-exhaustive list of design principles and solutions is presented using different matrices.In order to design using climate-responsive design principles the architect should be given an overview of the comfort contribution and energy performance of design solutions. Furthermore, the identification of collaborations and conflicts when using multiple design principles together is essential. The generation of a satisfying design is more than just stacking solutions upon each other. It should also be made clear what a possible energy function of a building element is besides its primary function. This is where comfort and energy related design objectives of climate-responsive design meet other objectives (i.e. spatial, functional and structural). Finally, the impact of climatere sponsive building elements on the appearance of design is relevant to concept orientated architects. Together this can be considered as the content requirements of the design-decision support tool.In the early stages of the design process climate-responsive design is about the generation of energy concepts. In this phase accessible guidelines and the option to compare alternatives is more important than to assess absolute performance. The conceptual design phase is dynamic and has many iterations. Informative, context specific knowledge reduces the number of iterations before the architect has generated a satisfying number of design options from which it can continue to the next design phase of assessment. Functional requirements for the framework of the design decision support tool are the inclusion of a knowledge base with expert knowledge and best practice examples, the provision of informative, context-specific knowledge, the provision of accessible guidelines, the provision of an option to compare alternatives, the inclusion of the ability to inform during and assist in decision-making (i.e. intelligence) and the limitation of complexity and the generation of easy to interpret output.The tool is primarily developed for the architect so it needs to blend in the architect’s workflow enabling the architect’s creativity and guiding his intuition. Other form requirements of the design-decision support tool are the presence of customisation options and custom navigation patterns, all presented in a visual style.A concept of the web-based tool has been developed in order to illustrate what a climate-responsive design-decision support tool could look like. The heart of the tool is formed by the knowledge base, constructed from items grouped into one of four categories: principles, solutions, projects and guidelines. Relationships between items are incorporated within the knowledge base as hyperlinks, which makes it easy to navigate from one item to another. The stored information is presented in numerous ways. Info sheets provide the most detailed presentation style containing all available information for an item, while catalogues, matrices and a gallery provide quick overviews and reveal direct relationships with other items.In order to become a true design-decision support tool, the presented tool needs to be further developed. This includes the use of a more context-specific presentation style and the inclusion of more context-specific knowledge, the addition of layers in which the knowledge is presented varying from more general to practical, the development and implementation of performance indicators and a more direct and visual approach to pinpoint synergetic and conflicting effects.By using the tool, architects can access relevant knowledge in different ways that suit their method of working. It enables the presentation of complex relationships in a clear way and by doing so unlocking a much broader part of the content to them. That will help speeding up the process of design iteration before the energy concept can be assessed in the successive phase of the design process.\n",
      "  - IntroductionClimate change can no longer be ignored. It is globally recognised that the evidence for climate change is unequivocal and that action needs to be taken in order to address its negative effects.These effects, such as warmer and drier summers and more extreme rainfall, may threaten the quality of life of those living in urban environments. To limit these threats, a number of climate change adaptation measures can be taken to pre-empt the negative effects of climate change.The challenge of increasing the implementation of climate change adaptation measures is addressed in this thesis by engaging the construction sector while focusing on the housing stock that is owned and maintained by Dutch housing associations. By implementing climate change adaptation measures, dwellings will become more resilient to some of the effects of climate change, becoming less vulnerable for damage and ensuring the comfort, safety and quality of life of their occupants. Because housing associations are regarded as societal entrepreneurs, these are expected to use resources and commercial profits to achieve societal aims that are in the common interest, such as making timely adaptations, so that changing climatic conditions cannot threaten the quality of their dwellings. Moreover, there are relatively few housing associations compared to the number of houses they own and maintain. In 2012, there were 381 housing associations that owned and maintained a stock of 2.4 million dwellings, representing 32% of the total Dutch housing stock. This means that approaching the Dutch social rented sector was seen as an effective way of generating a greater societal impact.In the past decade, external influences such as the recent economic crisis and political pressure, have led housing associations to become more cost effective and to make changes in their organisational strategies, which has resulted in the adoption of more integrated project delivery methods, such as partnering. These integrated methods aim to involve the construction sector early in the development of plans so that they can contribute their expertise. This creates a more efficient construction and maintenance process and delivers dwellings of higher quality.The housing associations cannot pre-empt all the effects of climate change alone. For adaptation measures at the neighbourhood level, they are dependent on collaboration with other stakeholders such as municipalities, but there are measures that can be applied at the building level, which falls within their range of influence. An example is the application of lighter colours on building façades in order to reflect radiation and reduce the air temperature close to the façades. The hazards of overflowing sewage systems caused by extreme precipitation can be reduced by applying measures to retain water temporarily, such as ‘green roofs’ or to ensure effective drainage such as open pavements. These measures reduce the peak load on the sewage system. Another effective measure is the use of materials that are not negatively affected by water so that if, despite all the precautionary measures, flooding does occur, the consequences would be less severe.Problem formulationThis research assesses the potential of adopting a partnering approach as a governance tool with which to increase the implementation of climate change adaptation measures like those described above. The housing stock owned by Dutch housing associations is taken as a case study. Involving the construction sector through a partnering approach is promising, since construction companies are the ones who carry out the works. Their early commitment reduces the risks of miscommunication or  failure and enhances opportunities for innovative solutions. By doing this, not only do housing associations take responsibility for their actions, but the construction sector as a whole gains more responsibility for solving societal challenges and is enabled to co-create solutions that can then be disseminated more easily.The main research question is: How can partnering in construction increase the implementation of climate change adaptation measures in dwellings owned by Dutch housing associations?Research approach and resultsTo formulate an answer to this research question, several separate studies were conducted. First, the characteristics of three types of governance were studied in a literature review, these being hierarchic, market and network governance. Based on these types of governance, many tools have been developed over time, but to increase the implementation of climate change adaptation measures in social housing, not all tools are equally successful, at least not from a theoretical point of view. To improve the implementation of measures, tools could be combined to create a more solid basis for action, and there is room for extra governance tools in the current palette.Based on the literature review on partnering, it was concluded that this could be classified as a combined ‘market’ and ‘network’ type of tool. The market aspect refers to the knowledge of climate change adaptation that is gained by the participating construction companies, which can imply a competitive advantage for them. The network aspect is closely linked to collaboration within a partnering approach. In other contexts, the partnering approach has been shown to remove the barriers of fragmentation in the construction sector; to provide for a more efficient and integral construction process, and to allow for the easier flow of knowledge on climate change adaptation.Next, the current state of knowledge among housing associations was studied with regard to climate change adaptation measures for the housing stock. A content analysis was conducted on the annual reports and policy plans of the 25 largest Dutch housing associations and revealed that they display no awareness of climate change adaptation in their policy documents. As such, they were categorised as ‘unaware’. However, this does not mean that the building stock is not being adapted to climate change, because in the annual reports they state that they have applied climate change adaptation measures, although they do not name these as such. This means that applying adaptation measures is neither impossible nor unrealistic, as long as they are not implemented solely for climate change adaptation purposes, but for other reasons as well, such as energy-efficiency.In contrast to the corporate policy documents, interviews with individual policy-makers showed that housing associations are aware of climate change at a global scale. However, in relation to climate change adaptation measures in their daily work, such as the impact of flooded streets and overheating interiors of dwellings, awareness is low. They could not name many threats or adaptation measures. However, once they had been made aware of the need for such measures, the employees were fairly well capable of assessing them, even though the implementation of measures was evaluated as unfeasible in most cases. The main reason provided was that the housing associations did not have policy guidelines in place for such adaptation measures. Moreover, in many cases there were financial and/or technical barriers that would have to be addressed first. There was a consensus among employees that all the measures would have a positive effect on the comfort of the dwellings.Partnering in construction can help to increase the implementation of adaptation measures because it can overcome many of these challenges. For this reason, the way that housing associations and construction companies carry out refurbishment projects in a partnering approach was also studied. The researcher participated in a knowledge exchange project in which housing associations and construction and maintenance companies had formed dyads and carried out a refurbishment project. They exchanged their experiences on a regular basis through interviews and plenary sessions.In the interviews, employees of housing associations and construction and maintenance companies were asked how they dealt with the success factors for partnering, which were derived from literature. These success factors were trust, leadership, partner capabilities, commitment, conflict resolution, coordination and communication.Although they did not address all these success factors equally well, the study showed that Dutch housing associations and construction and maintenance companies are indeed capable of carrying out housing refurbishment projects in a partnering approach. This allows for the selection of the construction process as a governance tool with which to implement climate change adaptation measures. These measures are considered new products that can be installed with the aim of improving the technical and functional quality of dwellings. In that sense, they are perceived as product innovations, with the dwellings being the ‘products’ and/or assets of the housing associations. This perspective corresponds with the definition1: “[An innovation is] a new idea that is implemented in a construction project with the intention of deriving additional benefits although there might have been associated risks and uncertainties. The new idea may refer to new design, technology, material component or construction method deployed in a project”. Subsequently, the employees of the housing associations and construction and maintenance companies were asked how they dealt with the implementation of innovations using surveys. Although several studies indicate that innovation can benefit when projects are based on an integrated construction process such as partnering, the current study concludes that partnering does not automatically lead to product innovation. Most of the respondents saw partnering itself as the innovative aspect of their projects – i.e. a process innovation. That process innovation required so much attention that there was less emphasis on opportunities for product innovations. This should be taken into account when developing governance tools to encourage the implementation of product innovations in dwellings such as climate change adaptation measures. Moreover, the choice of partnering as a project delivery method as a governance tool is less likely to resolve issues regarding policy, which remain a barrier for the implementation of measures. In addition, other parties can also become involved, to generate resources for the implementation of measures by housing associations. The adoption of partnering as a project delivery method is therefore not the only possible governance tool.To increase the implementation of climate change adaptation measures, two more conceptual approaches were developed by the researcher in addition to the initially hypothesised partnering approach. These additional conceptual approaches involved policy development by housing associations vis-à-vis climate change adaptation measures and collaboration with external actors who face the same challenges in order to enhance efficiency in solving these issues together. The feasibility of the three conceptual approaches was verified by means of a SWOT analysis performed with practitioners from housing associations and construction companies as well as external players such as water authorities, insurance companies and municipalities. The results of the SWOT analysis made it clear that single-pronged conceptual approaches are unlikely to be successful because they involve serious weaknesses or threats. A combination of conceptual approaches is much more likely to remove the barriers that obstruct the implementation of climate change adaptation measures.The conceptual approaches were therefore combined and renamed as implementation strategies. In on-line questionnaires carried out among all Dutch housing associations, it was assessed if the housing associations found it likely that these strategies would indeed lead to the implementation of climate change adaptation measures. In general, the respondents assessed the feasibility of all strategies as unlikely to neutral. There was no strategy that clearly stood out as more feasible for the implementation of climate change adaptation measures. However, a considerable number of housing associations assessed one or more implementation strategies positively and saw opportunities for the implementation of measures, albeit framed differently, such as measures to increase energy-efficiency or enhance comfort.ConclusionBased on the findings outlined above, the answer to the main research question is: Partnering in construction can increase the implementation of climate change adaptation measures in dwellings owned by housing associations, when it is understood as a catalyst for information-sharing and increased efficiency in the construction process.By looking for shared interests between housing associations and the construction sector, the chances of implementing adaptation measures increase. However, if other stakeholders are involved as well, and if housing associations embed climate change adaptation in their policy guidelines, the likelihood of implementation would increase even more. Although none of the implementation strategies stood out clearly as the strategy most likely to result in the implementation of climate change adaptation measures, a considerable number of housing associations assessed various implementation strategies positively.If the construction process becomes more network-based, which is the case when a partnering approach is adopted, many more parties can become involved and contribute to the implementation of climate change adaptation measures. In such a situation, it no longer matters who introduces the subject during the plan development and construction process, as long as it ends up there and action is taken. To implement these measures more easily, the framing is very important. Climate change adaptation is not enough reason in its own right to begin implementing measures. Insulation to prevent overheating in the summer is considered an ‘extra’ measure - the necessity of which is still questioned by policymakers, for example. However, if the same measure is framed as an energy-saving measure, it is also a cost-cutting measure, which increases the likelihood that policymakers will start making plans to implement it!Scientific implications of the resultsThis thesis has contributed to the development of governance tools to increase the implementation of climate change adaptation measures in dwellings, while current adaptation strategies predominantly target the national or local levels of the built environment. Moreover, this thesis has examined the adoption of partnering as a project delivery method and a governance tool with which to bridge the theoretical fields of network governance and integrated construction and maintenance processes. It extends the palette of governance tools that traditionally consists of information tools, tools relating to the division of property rights, incentives and regulatory tools. It has proven that housing associations can successfully adopt partnering approaches. As such, partnering is a feasible approach by which to increase the implementation of innovative measures such as climate change adaptations.Practical implicationsThe assessment of the five implementation strategies showed that adapting housing for climate change has a low priority as a separate policy field. It is a relatively new area for policymakers, so they may be reluctant to believe that measures are likely to be implemented. Moreover, many other topics may take a higher priority for them, such as improving energy-efficiency and thereby also the affordability of dwellings, and/or preparing the dwellings for an ageing population. In the literature on climate change adaptation, it is suggested that mainstreaming climate change adaptation is the best course, which implies attaching the adaptation policy to existing policy frameworks. This would make policymakers aware of the topic of climate change adaptation and they could look for synergies between measures that were already planned and measures related to climate change adaptations.The refurbishment and maintenance process of housing associations provides opportunities for the mainstreaming of adaptation measures. Housing associations are facing an ageing stock that needs to be improved if it is to continue to meet the ever increasing basic requirements of tenants in terms of quality and comfort and increasingly strict energy-efficiency standards. Since climate change is occurring gradually, there is still time to adapt the building stock gradually, in step with the renovation and maintenance cycles of the housing associations.Bringing in external players, especially municipalities and water authorities, would appear to be a highly feasible approach, given their shared interest in the quality of life in local areas. Bringing together the construction partners requires governance tools that inform them of the benefits of partnering. Particularly if construction companies are to be responsible for the renovation and the maintenance for the rest of the service life of the dwellings, they could focus on improved design solutions that aim to create resilient dwellings, and/or using materials that would be less affected by the effects of climate change. The role of tenants in the implementation of climate change adaptations is primarily that they might exert ‘bottom-up’ pressure by requesting action from housing associations. But for this to happen, they would likely need to be informed about the effects of climate change on their dwellings and/or neighbourhoods, in order for them to be motivated to ensure that their homes are climate change resilient.\n",
      "--------------------------------------------------\n",
      "Topic 13: 13_injection_co2_oil_reservoir\n",
      "Representative Documents:\n",
      "  - This article, written by Senior Technology Editor Dennis Denney, contains highlights of paper SPE 139717, ’Storing CO2 With Next-Generation CO2-EOR Technology,’ by R.C. Ferguson, SPE, V.A. Kuuskraa, SPE, and T.S. Van Leeuwen, SPE, Advanced Resources International, and D. Remson, US Department of Energy, National Energy Technology Laboratory, prepared for the 2010 SPE International Conference on CO2 Capture, Storage, and Utilization, New Orleans, 10-12 November. The paper has not been peer reviewed.               Carbon dioxide enhanced oil recovery (CO2-EOR) has potential for storing significant volumes of CO2 emissions while increasing domestic oil production. The causes of suboptimal CO2 storage and oil-recovery efficiencies by current CO2-EOR practices were examined to determine how a group of advanced or “next-generation” CO2-EOR technologies could increase CO2-storage volumes and oil recovery.                Introduction               A six-part method was used to assess CO2 storage and the EOR potential of domestic oil reservoirs. These steps were assembling and updating the major-oil-reservoirs database; calculating the minimum miscibility pressure for applying CO2-EOR; screening reservoirs favorable for CO2-EOR by use of the minimum miscibility pressure and other criteria; calculating oil recovery from applying next-generation CO2-EOR technology; applying updated costs in an economic model; and performing economic and sensitivity analyses to understand how the combined effects of technology and oil prices influence the results of applying next-generation CO2-EOR and CO2-storage technology.               Domestic-Oil-Resource Base               The USA has a large oil-resource base, on the order of 597 billion bbl of oil originally in place (OOIP). Approximately one-third of this oil-resource base, 204 billion bbl, has been recovered or placed into proved reserves with existing primary- and secondary-oil-recovery technologies. Therefore, 393 billion bbl remains unrecovered as “technically stranded” oil.               Much of this “stranded” oil is in east and central Texas (74 billion bbl), the midcontinent (66 billion bbl), and the Permian Basin of west Texas and New Mexico (62 billion bbl). California, Alaska, the Gulf Coast, and the Rockies also have significant volumes of “stranded” oil.               Not all of the remaining domestic oil resource is technically amenable to CO2-EOR. Favorable reservoir properties for miscible CO2-EOR include sufficiently deep formations with lighter (higher-gravity) oil. Some of the shallower oil reservoirs with heavier (lower-gravity) oil may be amenable to immiscible CO2-EOR.               Impediments to Current CO2-EOR Performance               Large volumes of oil are left stranded after primary- and secondary-oil-recovery methods are completed. This includes oil that is bypassed because of poor water-flood sweep efficiency; oil that is physically unconnected to a wellbore; and, most importantly, oil that is trapped as residual oil by viscous, capillary, and interfacial-tension forces in the pore space.\n",
      "  -                                     A key to the success of long-term storage of CO2 in depleted oil or gas reservoirs is the hydraulic integrity of both the geological formations that bound it, and the wellbores that penetrate it. This paper provides a review of the geomechanical factors affecting the hydraulic integrity of the bounding seals for a depleted oil or gas reservoir slated for use as a CO2 injection zone. Potential leakage mechanisms reviewed include fault reactivation, induced shear failure of the caprock, out-of-zone hydraulic fracturing, and poorly sealed casing cements in enlarged, unstable boreholes. Parameters controlling these mechanisms include the upper and lower bounds of pressure and temperature experienced by the reservoir, the orientation and mechanical properties of existing faults, rock mechanical properties, in situ stresses, and reservoir depth and shape. Approaches to mitigate the likelihood of geomechanics-related leakage include the identification of safe upper limits on injection pressures, preferred injection well locations, review of historical records for reservoir pressures, temperatures and stimulation treatments, drilling program design to mitigate rock yielding in new wells, and assessment of wellbore integrity indicators in existing wells.                                       Introduction                     In order to achieve significant reductions in the atmospheric release of anthropogenic greenhouse gases, the implementation of technologies to capture carbon dioxide (CO2) and store it in geological formations will be necessary. Deep saline aquifers have the largest potential for CO2 sequestration in geological media in terms of volume, duration, and minimum or null environmental impact(1). The first commercial scheme for CO2 sequestration in an aquifer is already in place in the Norwegian sector of the North Sea, where 106 tonnes of CO2 are extracted annually from the Sleipner Gas Field and injected into the 250 m thick Utsira aquifer at a depth of 1,000 m below the sea bed(2).                     In light of the economic benefits of enhanced oil recovery (EOR) derived from CO2 injection in oil reservoirs(3), these types of reservoirs will be attractive CO2 injection targets and, most likely, CO2 storage in depleted oil and gas reservoirs (or in conjunction with EOR) will be implemented before CO2 storage in aquifers. An advantage of CO2 storage in depleted oil or gas fields is the fact that much of the infrastructure for fluid injection (e.g., wellbores, compressors, pipelines) is already in place. The Weyburn CO2 Monitoring and Storage Project in Saskatchewan, Canada(4) is an example of a large-scale application of EOR operations using anthropogenic CO2, in which the oil reservoir is being evaluated for subsequent use as a long-term storage zone.                     A key to the success of long-term storage in depleted oil and gas reservoirs is the hydraulic integrity of both the geological formations that bound it, and the wellbores that penetrate it. The initial integrity of this \"bounding seal\" system is governed by geological factors. A considerable amount of effort has been devoted to the development of procedures for assessing fault seal capacity in potential hydrocarbon reservoirs(5).                                 \n",
      "  - This article, written by JPT Technology Editor Chris Carpenter, contains highlights of paper SPE 181729, “Design and Implementation of the First CO2-Enhanced-Oil-Recovery Demonstration Project in Saudi Arabia,” by Sunil Kokal, SPE, Modiu Sanni, SPE, and Almohannad Alhashboul, SPE, Saudi Aramco, prepared for the 2016 SPE Annual Technical Conference and Exhibition, Dubai, 26–28 September. The paper has not been peer reviewed.               An operator has designed a demonstration project for carbon dioxide (CO2) enhanced oil recovery (EOR) and has implemented it in one of its fields. The main objectives of the demonstration project are estimation of sequestered CO2, determination of incremental oil recovery, and evaluating the risks and uncertainties involved, including migration of CO2 within the reservoir and operational concerns. It is estimated that approximately 40% of the injected CO2 will be sequestered permanently in the reservoir.               Project Design               Conceptual Road Map and Screening Studies. Given the relatively light nature of crude oils and generally high reservoir pressures in Saudi Arabia, CO2 injection is a viable recovery method, especially in flooded reservoirs. An initial screening highlighted several good candidates for CO2 injection. A mature, waterflooded part of a large oil field with a carbonate reservoir was selected as a candidate for CO2 injection. Further studies were conducted for the candidate reservoir that included laboratory, feasibility, and detailed reservoir-simulation studies. This reservoir has been flooded for decades in a peripheral water-injection mode, and considerable reservoir and production data were available.               Laboratory Studies. Two sets of experimental studies must be conducted for any given CO2-EOR prospect: fluid/fluid and fluid/rock interactions. The important laboratory experiments include the minimum miscibility pressure of the crude with CO2, swelling and fluid properties of CO2/oil mixtures, asphaltene precipitation onset and bulk asphaltene deposition, and oil-recovery potential by use of coreflooding studies. It must be emphasized that these experiments need to be conducted at reservoir conditions with live reservoir fluids and supercritical CO2; otherwise, the data have limited value at best.               Simulation Studies. The reservoir selected for CO2 injection is a Jurassic carbonate reservoir, and the area selected is in a downflank, flooded part of the field. The selected area has been on peripheral water injection for more than 50 years and has been well-waterflooded because of its proximity to the peripheral injectors. Approximately 40 MMscf/D of relatively pure CO2 was available from a gas plant approximately 85 km from the pilot site. The slimtube data show that the minimum miscibility pressure is lower than the reservoir pressure, indicating that the CO2 will develop a miscible displacement in the reservoir at current reservoir pressures. The main objectives of the simulation study were as follows:               Carry out screening and mechanistic studies and find areas suitable for a CO2-injection pilot.               Assess the amount of CO2 sequestered over the period of the pilot testing.               Assess incremental oil recoveries associated with different modes of CO2 injection.               Optimize the pilot design within the reservoir and operational constraints.\n",
      "--------------------------------------------------\n",
      "Topic 14: 14_co2 emissions_emissions_economic growth_energy\n",
      "Representative Documents:\n",
      "  - The aim of this study is to examine the empirical cointegration, long-run and short-run dynamics and causal relationships between carbon emissions, energy consumption and economic growth in 14 Danube region countries over the period of 1990–2019. The autoregressive distributed lag (ARDL) bounds testing methodology was applied for each of the examined variables as a dependent variable. Limited by the length of the time series, we excluded two countries from the analysis and obtained valid results for the others for 26 of 36 ARDL models. The ARDL bounds reliably confirmed long-run cointegration between carbon emissions, energy consumption and economic growth in Austria, Czechia, Slovakia, and Slovenia. Economic growth and energy consumption have a significant impact on carbon emissions in the long-run in all of these four countries; in the short-run, the impact of economic growth is significant in Austria. Likewise, when examining cointegration between energy consumption, carbon emissions, and economic growth in the short-run, a significant contribution of CO2 emissions on energy consumptions for seven countries was found as a result of nine valid models. The results contribute to the information base essential for making responsible and informed decisions by policymakers and other stakeholders in individual countries. Moreover, they can serve as a platform for mutual cooperation and cohesion among countries in this region.\n",
      "  - This study presents empirical results regarding the relationships between renewable and non-renewable energy consumption, CO2 emissions, and the GDP within the Visegrád Group (V4) countries. Using FMOLS/DOLS and ARDL approaches, along with causality tests based on the Toda–Yamamoto method, this study explores these relationships at a regional level. The study fills the research gaps for a comprehensive analysis of the indicated relationships in the V4 countries by using both individual and panel models. The findings indicate that renewable energy has a small positive impact on long-term economic growth, with non-renewable energy having a more significant effect. Moreover, CO2 emissions have a negative impact on economic growth, suggesting an ongoing reliance on non-renewable energy sources and a burden on economic expansion. At an individual country level, the effects vary. Poland, Slovakia, and Hungary exhibit a negative relationship between CO2 emissions and economic growth. Energy sources also differ in regards to impact: in Poland, the Czech Republic, and Slovakia, non-renewable energy significantly affects economic growth, while in Hungary, renewable energy plays a more substantial role. Causality tests reveal a causal relationship between CO2 emissions and economic growth in the Czech Republic and Poland, suggesting that CO2 emissions significantly influence economic expansion. In terms of energy production, renewable energy is causally related to economic growth in the Czech Republic and Slovakia. All countries demonstrate significant causality between non-renewable energy and economic growth. Additionally, a relationship between renewable energy and CO2 emissions is confirmed in Poland.\n",
      "  - The members of the Association of Southeast Asian Nations (ASEAN) have made several attempts to adopt renewable energy targets given the economic, energy-related, environmental challenges faced by the governments, policy makers, and stakeholders. However, previous studies have focused limited attention on the role of renewable energy when testing the dynamic link between CO2 emissions, energy consumption and renewable energy consumption. As such, this study is conducted to test a common hypothesis regarding a long-run environmental Kuznets curve (EKC). The paper also investigates the causal link between carbon dioxide (CO2) emissions, energy consumption, renewable energy, population growth, and economic growth for countries in the region. Using various time-series econometrics approaches, our analysis covers five ASEAN members (including Indonesia, Myanmar, Malaysia, the Philippines, and Thailand) for the 1971–2014 period where required data are available. Our results reveal no long-run relationship among the variables of interest in the Philippines and Thailand, but a relationship does exist in Indonesia, Myanmar, and Malaysia. The EKC hypothesis is observed in Myanmar but not in Indonesia and Malaysia. Also, Granger causality among these important variables varies considerably across the selected countries. No Granger causality among carbon emissions, energy consumption, and renewable energy consumption is reported in Malaysia, the Philippines, and Thailand. Indonesia experiences a unidirectional causal effect from economic growth to renewable energy consumption in both short and long run and from economic growth to CO2 emissions and energy consumption. Interestingly, only Myanmar has a unidirectional effect from GDP growth, energy consumption, and population to the adoption of renewable energy. Policy implications have emerged based on the findings achieved from this study for each country in the ASEAN region.\n",
      "--------------------------------------------------\n",
      "Topic 15: 15_soil_ha_yield_kg\n",
      "Representative Documents:\n",
      "  - Summary\t  Application of biochar to rice has shown to elicit positive environmental and agricultural impacts due to its physicochemical properties. However, the relationship between greenhouse gas (GHG) emissions, rice yield, and soil nutrient status under biochar amendment remains unclear. In this study, rice yield and methane (CH4) and nitrous oxide (N2O) emissions were quantified in response to biochar application rate (0, 10, 20, and 40 t ha−1) to early and late subtropical rice cropping systems. We found that application of 10 t of biochar ha−1 to early rice reduced average CH4 emission fluxes, while all biochar application rates diminished average emissions in late rice paddy. Total global warming potential (GWP) and GHG intensity (GHGI) were inherently greater in late rice than early rice cropping. In early rice, GWP and GHGI were found to be similar between soil control, 10 and 20 t of biochar ha−1 treatments, although the largest occurred in the 40 t of biochar ha−1 treatment, whereas in late rice cropping, they were not affected by biochar application rates. Compared to the nil-biochar application, biochar application at varied rates did not affect rice yield. However, compared to 10 t biochar ha−1, increasing biochar application rate to 40 t ha−1 significantly decreased total rice yield (sum of early and late cropping). Generally, application of biochar increased soil salinity and total Fe and Fe2+ content while reducing soil bulk density. Temporal effects of biochar application were noted on CH4 emission flux, soil temperature, and soil Fe2+ and Fe3+ in early rice; and soil temperature, salinity, NH4+-N, NO3−-N, and soil Fe2+ and Fe3+ in late rice. This study confirms that the application of biochar at the lower rate of 10 t ha−1 is optimal for maintaining rice yield while reducing GHG emissions. Moreover, the study demonstrates the potential benefit of biochar in sustainable subtropical rice production.\n",
      "  - Long−term excessive nitrogen fertilizer input has resulted in several environmental problems, including an increase in N2O emissions and the aggravation of nitrate leaching; monitoring nitrogen fertilizer is crucial for maize with high yield. This study aimed to optimize the amount of nitrogen applied to maize by Climate−Smart Agriculture (CSA) so as to continuously improve agricultural productivity and reduce or eliminate N2O emissions as much as possible. Field experiments with a completely randomized design were conducted to examine the effects of six nitrogen treatments (N application levels of 0, 120, 180, 240, 300, 360 kg·ha−1, respectively) on N2O emissions, residual concentration of nitrate and ammonium nitrogen, maize yield, and nitrogen utilization efficiency in 2018 and 2019. The results indicated that the residual concentration of nitrate nitrogen (NO3-−N) in the two seasons significantly increased; N2O emissions significantly increased, and the nitrogen fertilizer agronomic efficiency and partial productivity of maize fell dramatically as the nitrogen application rate increased. The maize grain yield rose when the N application amount was raised (N application amount &lt;300 kg·ha−1) but decreased when the N application amount &gt; 300 kg·ha−1. An increase in the nitrogen application rate can decrease nitrogen use efficiency, increase soil NO3-−N residual, and N2O emissions. Reasonable nitrogen application can increase maize yield and reduce N2O emissions and be conducive to improving nitrogen use efficiency. By considering summer maize yield, nitrogen use efficiency, and farmland ecological environment, 173.94~178.34 kg N kg·ha−1 could be utilized as the nitrogen threshold for summer maize in the North China Plain.\n",
      "  - Long-term different tillage system field trials can provide vital knowledge about sustainable changes in soil health indices and crop productivity. This study examined cotton productivity and soil health indices under different tillage systems and organic materials. The present study was carried out at MNS University of Agriculture, Multan to explore the effect of different tillage systems: conventional tillage (T1), conservation tillage (T2), and organic materials: control (recommended dose of synthetic fertilizers; 160:90:60 kg ha−1NPK), poultry manure (10 t ha−1PM), compost (10 t ha−1CM), farmyard manure (20 t ha−1FYM), and biochar (7 t ha−1BC) on cotton productivity and soil health indices. Two years field trials showed that different tillage systems and organic materials significantly improved the growth, morphological, and yield attributes of cotton and soil health indices. The cotton showed highest seed cotton yield (3692–3736 kg ha−1), and soil organic matter (0.809–0.815%), soil available nitrogen (74.3–74.6 mg kg−1), phosphorus (7.29–7.43 mg kg−1), and potassium (213–216 mg kg−1) under T2in comparison to T1system during both years of field experiment, respectively. Similarly, PM (10 t ha−1) showed highest seed cotton yield (3888–3933 kg ha−1), and soil organic matter (0.794–0.797%), nitrogen (74.7–75.0 mg kg−1), phosphorus (7.39–7.55 mg kg−1), and potassium (221–223 mg kg−1) when these are compared to FYM (20 t ha−1), CM (10 t ha−1), and BC (7 t ha−1) during both years of field experiment, respectively. These findings indicate that conservation tillage system with application of 10 t ha−1PM are the best practices for the sustainable cotton production and to ensure improvement in the soil health indices under arid climatic conditions.\n",
      "--------------------------------------------------\n",
      "Topic 16: 16_rcm_bias_precipitation_resolution\n",
      "Representative Documents:\n",
      "  - ABSTRACTThe increase in extreme precipitation is likely to be one of the most significant impacts of climate change in cities due to increased pluvial flood risk. Hence, reliable information on changes in sub‐daily extreme precipitation is needed for robust adaptation strategies. This study explores extreme precipitation over Denmark generated by the regional climate model (RCM) HIRHAM‐ECEARTH at different spatial resolutions (8, 12, 25 and 50 km), three RCM from the RiskChange project at 8 km resolution and three RCMs from ENSEMBLES at 25 km resolution at temporal aggregations from 1 to 48 h. The performance of the RCM simulations in current climate as well as projected changes for 2081–2100 is evaluated for non‐central moments of order 1–3 and for the 2‐ and 10‐year events. The comparison of the RCM simulations and observations shows that the higher spatial resolution simulations (8 and 12 km) are more consistent across all temporal aggregations in the representation of high‐order moments and extreme precipitation. The biases in the spatial pattern of extreme precipitation change across temporal and spatial resolution. The hourly extreme value distributions of the HIRHAM‐ECEARTH simulations are more skewed than the observational dataset, which leads to an overestimation by the higher spatial resolution simulations. Nevertheless, in general, under current conditions RCM simulations at high spatial resolution represent extreme events and high‐order moments better. The changes projected by the RCM simulations depend on the global climate model (GCM)–RCM combination, spatial resolution and temporal aggregation. The simulations disagree on the magnitude and spatial pattern of the changes. However, there is an agreement on higher changes for lower temporal aggregation and higher spatial resolution. Overall, the results from this study show the influence of the spatial resolution on the precipitation outputs from RCMs. The biases of the RCM simulations increase, and the projected changes decrease for decreasing spatial resolution of the simulations. This points towards the need for high spatial and temporal resolution RCMs to obtain reliable information on changes in sub‐daily extreme precipitation.\n",
      "  - General circulation model outputs are rarely used directly for quantifying climate change impacts on hydrology, due to their coarse resolution and inherent bias. Bias correction methods are usually applied to correct the statistical deviations of climate model outputs from the observed data. However, the use of bias correction methods for impact studies is often disputable, due to the lack of physical basis and the bias nonstationarity of climate model outputs. With the improvement in model resolution and reliability, it is now possible to investigate the direct use of regional climate model (RCM) outputs for impact studies. This study proposes an approach to use RCM simulations directly for quantifying the hydrological impacts of climate change over North America. With this method, a hydrological model (HSAMI) is specifically calibrated using the RCM simulations at the recent past period. The change in hydrological regimes for a future period (2041–2065) over the reference (1971–1995), simulated using bias‐corrected and nonbias‐corrected simulations, is compared using mean flow, spring high flow, and summer–autumn low flow as indicators. Three RCMs driven by three different general circulation models are used to investigate the uncertainty of hydrological simulations associated with the choice of a bias‐corrected or nonbias‐corrected RCM simulation. The results indicate that the uncertainty envelope is generally watershed and indicator dependent. It is difficult to draw a firm conclusion about whether one method is better than the other. In other words, the bias correction method could bring further uncertainty to future hydrological simulations, in addition to uncertainty related to the choice of a bias correction method. This implies that the nonbias‐corrected results should be provided to end users along with the bias‐corrected ones, along with a detailed explanation of the bias correction procedure. This information would be especially helpful to assist end users in making the most informed decisions.\n",
      "  - Bias correction methods are usually applied to climate model outputs before using these outputs for hydrological climate change impact studies. However, the use of a bias correction procedure is debatable, due to the lack of physical basis and the bias nonstationarity of climate model outputs between future and historical periods. The direct use of climate model outputs for impact studies has therefore been recommended in a few studies. This study investigates the possibility of using reanalysis‐driven regional climate model (RCM) outputs directly for hydrological modelling by comparing the performance of bias‐corrected and nonbias‐corrected climate simulations in hydrological simulations over 246 watersheds in the Province of Québec, Canada. When using RCM outputs directly, the hydrological model is specifically calibrated using RCM simulations. Two evaluation metrics (Nash–Sutcliffe efficiency [NSE] and transformed root mean square error [TRMSE]) and three hydrological indicators (mean, high, and low flows) are used as criteria for this comparison. Two reanalysis‐driven RCMs with resolutions of 45 km and 15 km are used to investigate the scale effect of climate model simulations and bias correction approaches on hydrology modelling. The results show that nonbias‐corrected simulations perform better than bias‐corrected simulations for the reproduction of the observed streamflows when using NSE and TRMSE as criteria. The nonbias‐corrected simulations are also better than or comparable with the bias‐corrected simulations in terms of reproducing the three hydrological indicators. These results imply that the raw RCM outputs driven by reanalysis can be used directly for hydrological modelling with a specific calibration of hydrological models using these datasets when gauged observations are scarce or unavailable. The nonbias‐corrected simulations (at a minimum) should be provided to end users, along with the bias‐corrected ones, especially for studying the uncertainty of hydrological climate change impacts. This is especially true when using an RCM with a high resolution, since the scale effect is observed when the RCM resolution increases from a 45‐km to a 15‐km scale.\n",
      "--------------------------------------------------\n",
      "Topic 17: 17_co2 emissions_emissions_china_carbon\n",
      "Representative Documents:\n",
      "  - This study calculated CO2 emissions related to the consumption of primary energy by five sectors in the Yangtze River Delta region over 2000 to 2019. The Logarithmic Mean Divisia Index (LMDI) decomposition method was used to establish the factor decomposition model of CO2 emissions change. The LMDI model was modified to assess the impact of five influencing factors, namely energy structure, energy intensity, industrial structure, economic output, and population size, on CO2 emissions in the Yangtze River Delta region over the study period. The empirical results show that economic output has the largest positive effect on the growth in CO2 emissions. Population size is the second most important factor promoting the growth in CO2 emissions. Energy intensity is the most inhibitory factor to restrain CO2 emissions, with a significant negative effect. Energy structure and industrial structure contribute insignificantly to CO2 emissions. Using data on CO2 emissions in the Yangtze River Delta region from 2000 to 2019, the GM (1, 1) model was applied for future forecasts of primary energy consumption and CO2 emissions. Specific policy suggestions to mitigate CO2 emissions in Yangtze River Delta region are provided.\n",
      "  - The Yangtze River Delta is the most populous and economically active region in China. Studying the reduction in CO2 emissions in this region is of great significance in achieving the goal of “peak carbon and carbon neutrality” in China. In this study, the Tapio decoupling and extended STIRPAT models were used to study the differences in provincial CO2 emissions characteristics and influencing factors in the Yangtze River Delta from 2001 to 2019. The results show that the growth rate of CO2 emissions was slower than that of economic development, which means that CO2 emissions and economic growth were in a state of weak decoupling. As found by ridge regression, the same factor has different impacts on CO2 emissions among provinces. The differences in these influencing factors were mainly caused by the imbalance of development in the Yangtze River Delta. Nine development scenarios were set out to predict the future trend of CO2 emissions based on economic development and carbon emissions technology using the extended STIRPAT model. It was found that low-carbon-emissions technology is conducive to controlling CO2 emissions in the Yangtze River Delta. In that case, the CO2 emissions would peak in 2029 at 1895.78~1908.25 Mt. Compared with the low-carbon-emissions scenarios, both the medium- and high-carbon-emissions scenarios are not conducive to achieving a carbon peak, with a 2~5-year delay in peak time and increasing emissions by 3.69~7.68%. In order to reduce the Yangtze River Delta’s CO2 emissions and pass the peak emissions as soon as possible, it is essential to not only optimize the energy structure, upgrade industries and promote the coordinated development of low-carbon technologies, but also promote emissions reduction in the transportation and construction fields and advocate for a low-carbon lifestyle among the public.\n",
      "  - China is the world’s largest emitter of CO2. As the largest sector of China’s fossil energy consumption and carbon emissions, manufacturing plays an important role in achieving emission reduction targets in China. Using the extended logarithmic mean division index (LMDI) decomposition model, this paper decomposed the factors that affect the CO2 emissions of China’s manufacturing industry into eight effects. The results show the following: (1) China’s manufacturing CO2 emissions increased from 1.91 billion tons in 1995 to 6.25 billion tons in 2015, with an average annual growth rate of 6%. Ferrous metal smelting and rolling were the largest sources of carbon dioxide emissions, followed by chemical raw materials and products and then non-metallic minerals. (2) During the research period, the industrial activity effects were the most important factor leading to increased CO2 emissions in manufacturing and energy intensity was the most important factor in promoting the reduction of CO2 emissions from manufacturing. The investment intensity was the second most influential factor leading to the increase in China’s manufacturing CO2 emissions after the industrial scale and this even exceeded the industrial activity effect in some time periods (2000–2005). R&amp;D efficiency and R&amp;D intensity were shown to have significant roles in reducing CO2 emissions in China’s manufacturing industry. The input of R&amp;D innovation factors is an effective way to achieve emission reductions in China’s manufacturing industry. (3) There were differences in the driving factors of CO2 emissions in the manufacturing industry in different periods that were closely related to the international and domestic economic development environment and the relevant policies of the Chinese government regarding energy conservation and emission reduction. (4) Sub-sector research found that the factors that affect the reduction of CO2 emissions in various industries appear to be differentiated. This paper has important policy significance to allow the Chinese government to implement effective energy-saving and emission reduction measures and to reduce CO2 emissions from the manufacturing industry.\n",
      "--------------------------------------------------\n",
      "Topic 18: 18_fire_pine_tree_forest\n",
      "Representative Documents:\n",
      "  -                 Background                Climate change is eroding forest resilience to disturbance directly through warming climate and indirectly through increasing disturbance activity. Forests characterized by stand-replacing fire regimes and dominated by serotinous species are at risk when the inter-fire period is insufficient for canopy seed bank development and climate conditions for recruitment in the post-fire growing season are unsuitable. Although both factors are critical to serotinous forest persistence, their relative importance for post-fire regeneration in serotinous forests remains poorly understood. To assess the relative effects of each factor, we established plots in severely burned knobcone pine (Pinus attenuata Lemmon) forests in Oregon and California, USA, representing a range of past fire intervals (6 to 31+ years). Specifically, we evaluated effects of fire interval and pre-fire canopy seed bank (proxies for seed supply) and post-fire climate on three metrics of post-fire tree regeneration (seedling density, probability of self-replacement, percent population recovery).                              Results                Seed supply consistently had the strongest effect on post-fire regeneration. Between 6- and 31-year fire intervals, post-fire seedling density increased from 1000 to 100,000 seedlings ha−1, while probability of self-replacement increased from ~ 0 to ~ 100% and percent population recovery increased from 20 to 2000% of the pre-fire population, respectively. Similarly, increasing the canopy seed bank by two orders of magnitude increased seedling density and percent population recovery by two orders and one order of magnitude, respectively, and increased the probability of self-replacement by &gt; 50%. Greater post-fire climatic moisture deficit exacerbated the effect of seed supply; an additional 4–6 years between fires was required under high moisture stress conditions to reach similar regeneration levels as under low moisture stress conditions.                              Conclusion                The overriding effect of seed supply—strongly driven by pre-fire stand age—on post-fire regeneration suggests that altered fire frequency (an indirect effect of climate change) will have a profound impact on serotinous forests. Although direct effects of hot and dry climate are lower in magnitude, they can alter forest recovery where seed supply nears a threshold. These findings reveal how fire interval and climate combine to determine changes in forest cover in the future, informing management and vulnerability mapping.              \n",
      "  - Increased wildfire activity and climate change have intensified disturbance regimes globally and have raised concern among scientists and land managers about the resilience of disturbed landscapes. Here we test the effects of climate, topographic variation and pre‐fire stand structure on regeneration in lodgepole pine (Pinus contorta var. latifolia) forests following high‐severity fire over the past seven decades.We surveyed lodgepole pine regeneration 8–67 years after eight high‐severity fires in western Colorado and southern Wyoming. We used dendroecological methods and machine learning to (a) identify temporal trends in post‐fire regeneration and (b) examine influences of climate on post‐fire regeneration, with focus on post‐fire establishment, initial post‐fire density and radial growth.All burned sites reached a median stocking density of ≥150 seedlings/ ha, but there was a large range of spatial heterogeneity, with regeneration being absent or scarce in many plots, implying a trend of increasing patchiness with likely cascading effects on subsequent patterns and processes. Our analysis indicated that (a) post‐fire regeneration is influenced by pre‐fire stand structure (stand age and density), elevation and post‐fire minimum temperature; (b) pre‐fire densities of &gt;14,000 stems/ha promoted successful stocking (≥150 seedlings/ha) and reduced lag between the disturbance and initial regeneration; and (c) minimum post‐fire temperatures &gt;−1.6°C reduced lag of initial regeneration and promoted initial radial growth.Synthesis. Our study demonstrates that lodgepole pine in high‐elevation forests are regenerating following fires under recent climatic trends, but that regeneration is affected by post‐fire climatic conditions. Importantly, forest patchiness may be increasing in a way that affects future ecological dynamics and may compromise the resilience of these systems.\n",
      "  -                 Background                Increases in fire activity and changes in fire regimes have been documented in recent decades across the western United States. Climate change is expected to continue to exacerbate impacts to forested ecosystems by increasing the frequency, size, and severity of wildfires across the western United States (US). Warming temperatures and shifting precipitation patterns are altering western landscapes and making them more susceptible to high-severity fire. Increases in large patches of high-severity fire can result in significant impacts to landscape processes and ecosystem function and changes to vegetation structure and composition. In this synthesis, we examine the predicted climatic influence on fire regimes and discuss the impacts on fire severity, vegetation dynamics, and the interactions between fire, vegetation, and climate. We describe predicted changes, impacts, and risks related to fire with climate change and discuss how management options may mitigate some impacts of predicted fire severity, and moderate some impacts to forests, carbon, and vegetation changes post fire.                              Results                Climate change is increasing fire size, fire severity, and driving larger patches of high-severity fire. Many regions are predicted to experience an increase in fire severity where conditions are hotter and drier and changes in fire regimes are evident. Increased temperatures, drought conditions, fuels, and weather are important drivers of fire severity. Recent increases in fire severity are attributed to changes in climatic water deficit (CMD), vapor pressure deficit (VPD), evapotranspiration (ET), and fuels. Fire weather and vegetation species composition also influence fire severity. Future increases in fire severity are likely to impact forest resilience and increase the probability of forest type conversions in many ecosystems.                              Conclusions                Increasing warming and drying trends are likely to cause more frequent and severe disturbances in many forested ecosystems in the near future. Large patches of high-severity fire have lasting legacies on vegetation composition and structure, and impacts on tree regeneration. In some ecosystems and under certain fire-weather conditions, restoration and fuel treatments may reduce the area burned at high severity and reduce conversions from forest to non-forest conditions, increasing forest resistance and resilience to wildland fire. Thinning and prescribed fire treatments can be effective at reducing the potential for crown fire, reducing fuels, and promoting forest resilience.              \n",
      "--------------------------------------------------\n",
      "Topic 19: 19_ci_95 ci_95_incidence\n",
      "Representative Documents:\n",
      "  -                                  Funding Acknowledgements                  Type of funding sources: None.                                                Background                  Acute coronary syndromes (ACS) are the leading cause of death all over the world, in the last years chronobiology of their occurrence has been changing.                                                Purpose                  The aim of this study was to assess the influence of climate change on hospital admissions due to ACS.                                                Methods                  Medical records of 10,529 patients hospitalized for ACS in 2008–2017 were examined. Weather conditions data were obtained from the Institute of Meteorology.                                                Results                  Among the patients, 3537 (33.6%) were hospitalized for STEMI, 3947 (37.5%) for NSTEMI, and 3045 (28.9%) for UA. The highest seasonal mean for ACS was recorded in spring (N = 2782, mean = 2.52, SD = 1.7; OR 1.07; 95% CI 1.0-1.2; P = 0.049) and it was a season with the highest temperature changes day to day (Δ temp.=11.7). On the other hand, every 10ºC change in temperature was associated with an increased admission due to ACS by 13% (RR 1.13; 95% CI 1.04-1.3; P = 0.008). Analysis of weekly changes showed that the highest frequency of ACS occurred on Thursday (N = 1703, mean = 2.7, SD = 1.9; OR 1.16; 95% CI 1.0-1.23; P = 0.004), in STEMI subgroup it was Monday (N = 592, mean = 0.9, SD = 1.6, OR 1.2; 95% CI 1.1-1.4; P = 0.002). Sunday was associated with decreased admissions due to all types of ACS (N = 1098, mean = 1.7, SD = 1.4; OR 0.69; 95% CI 0.6-0.8, P &amp;lt; 0.001). In the second half of the study period (2013-2018) the relative risks of hospital admissions due to ACS were 1.043 (95%CI: 1.009-1.079, P = 0.014, lag 0) and 0.957 (95%CI: 0.925-0.990, P = 0.010, lag 1) for each 10ºC decrease in temperature; 1.049 (95% CI: 1.015-1.084, P = 0.004, lag 0) and 1.045 (95%CI: 1.011-1.080, P = 0.008, lag 1) for each 10 hPa decrease in atmospheric pressure and 1.180 (95% CI: 1.078-1.324, P = 0.007, lag 0) for every 10ºC change in temperature. For the first half of the study the risk was significantly lower.                                                Conclusion                  We observed a shift in the seasonal peak of ACS occurrence from winter to spring which may be related to temperature fluctuation associated with climate change in this season. The lowest frequency of ACS took place on weekends. Atmospheric changes had a much more pronounced effect on admissions due to ACS in the second half of the analyzed period, which is in line with the dynamics of global climate change.               \n",
      "  - SummaryMacro‐ and microclimates may have variable impact on dengue incidence in different settings. We estimated the short‐term impact and delayed effects of climate variables on dengue morbidity in Curaçao. Monthly dengue incidence data from 1999 to 2009 were included to estimate the short‐term influences of climate variables by employing wavelet analysis, generalized additive models (GAM) and distributed lag nonlinear models (DLNM) on rainfall, temperature and relative humidity in relation to dengue incidence. Dengue incidence showed a significant irregular 4‐year multi‐annual cycle associated with climate variables. Based on GAM, temperature showed a U‐shape, while humidity and rainfall exhibited a dome‐shaped association, suggesting that deviation from mean temperature increases and deviation from mean humidity and rainfall decreases dengue incidence, respectively. Rainfall was associated with an immediate increase in dengue incidence of 4.1% (95% CI: 2.2–8.1%) after a 10‐mm increase, with a maximum increase of 6.5% (95% CI: 3.2–10.0%) after 1.5 month lag. A 1°C decrease of mean temperature was associated with a RR of 17.4% (95% CI: 11.2–27.0%); the effect was inversed for a 1°C increase of mean temperature (RR= 0.457, 95% CI: 0.278–0.752). Climate variables are important determinants of dengue incidence and provide insight into its short‐term effects. An increase in mean temperature was associated with lower dengue incidence, whereas lower temperatures were associated with higher dengue incidence.\n",
      "  -             Introduction:            American studies have pointed out racial disparities regarding Out-of-Hospital Cardiac Arrest (OHCA) occurrence, but to date, no data exists among immigrants in Europe.                                Hypothesis:            The risk of OHCA may vary according to region of origin among immigrants.                                Methods:            This nationwide study included all immigrants identified from the Danish Cardiac Arrest Register with OHCA with presumed cardiac cause between 18 and 80 years from 2001 to 2014. Regions of origin were defined as Asia, Western countries, Eastern Europe, Africa, South America, and Arabic countries.                                Results:            Overall, among 940,207 immigrants present in Denmark, a total of 1,724 (0.2%) OHCA (median 62 (IQR 50,71) years 70% males) were recorded. History of myocardial infarction, heart failure, and diabetes were present in 23%, 18%, and 16% respectively. 217 OHCA occurred in Asians, 673 in Westerners, 347 in Eastern Europeans, 107 in Africans, 19 in South Americans, and 361 in Arabic immigrants.Crude incidence rate (/ 100 000 person-years) was 15.2 (95%CI 9.14-23.7) in South American, 19.4 (95%CI 16.9-22.2) in Asian, 22.8 (95%CI 18.7-27.5) in African, 24.7 (95%CI 22.2-27.3) in Arabic, 26.2 (95%CI 23.5-29.1) in Eastern European and 32.4 (95%CI 30.0-34.9) in Western immigrants.After Cox regression, factors associated with OHCA were Eastern European origin (HR 1.28, 95%CI 1.13-1.47; P&lt;0.001), African origin (HR 1.31, 95%CI 1.07-1.61; P=0.01), male sex (HR 1.89, 95%CI 1.70-2.10; P&lt;0.001), age (HR 1.05, 95%CI 1.04-1.06; P&lt;0.001), ischemic heart disease (HR 52.02; 95%CI 39.41-68.67; P&lt;0.001), diabetes (HR 7.04; 95%CI 5.42-9.16; P&lt;0.001), and heart failure (HR 1.33, 95%CI 1.06-1.64; P=0.01).                                Conclusions:            This is the first European study assessing the incidence of OHCA among immigrants according to their region of origin. Eastern European and African immigrants had a higher risk of OHCA compared to South American, Asian, Arabic and Western immigrants.                                          \n",
      "--------------------------------------------------\n",
      "Topic 20: 20_elevated_elevated co2_co2_leaf\n",
      "Representative Documents:\n",
      "  - We evaluated the effects of an elevated [CO2] on photosynthesis and growth of cassava plants grown in open-top chambers with an adequate supply of water and N and a sufficient rooting volume. Cassava plants (Manihot esculenta Crantz. cv. Motilona) showed higher photosynthetic rates (Pn) when grown and measured at elevated [CO2] (680 µmol mol-1) than when grown and measured at ambient [CO2] (480 µmol mol-1). No downregulation of photosynthesis due to elevated [CO2] was found, since carboxylation efficiency increased after 220 d in spite of a decrease in leaf soluble protein, Rubisco, and leaf N content. Soluble sugar and starch contents decreased with time under elevated [CO2], the decrease in starch content coinciding with the beginning of the increase in root mass. Canopy Pn by leaf area decreased with time under elevated [CO2] but, when canopy Pn was expressed by ground area, higher and constant rates were observed, suggesting a higher productivity in plants grown at elevated [CO2]. The absence of differences between growth [CO2] in root : shoot ratio observed suggests that elevated [CO2], while causing increases in the shoot as well as the root, did not affect the pattern of biomass allocation. Acclimation responses of gas exchange parameters changed during the experiment. The absence of downregulation of photosynthesis was associated with a decrease in leaf sugar and starch contents of plants grown at elevated [CO2], which suggests a favourable source/sink relationship.\n",
      "  -                 Background                Atmospheric CO2 may double by the year 2100, thereby altering plant growth, photosynthesis, leaf nutrient contents and water relations. Specifically, atmospheric CO2 is currently 50% higher than pre-industrial levels and is projected to rise as high as 936 μmol mol−1 under worst-case scenario in 2100. The objective of the study was to investigate the effects of elevated CO2 on woody plant growth, production, photosynthetic characteristics, leaf N and water relations.                              Methods                A meta-analysis of 611 observations from 100 peer-reviewed articles published from 1985 to 2021 was conducted. We selected articles in which elevated CO2 and ambient CO2 range from 600–1000 and 300–400 μmol mol−1, respectively. Elevated CO2 was categorized into &lt; 700, 700 and &gt; 700 μmol mol−1 concentrations.                              Results                Total biomass increased similarly across the three elevated CO2 concentrations, with leguminous trees (LTs) investing more biomass to shoot, whereas non-leguminous trees (NLTs) invested to root production. Leaf area index, shoot height, and light-saturated photosynthesis (Amax) were unresponsive at &lt; 700 μmol mol−1, but increased significantly at 700 and &gt; 700 μmol mol−1. However, shoot biomass and Amax acclimatized as the duration of woody plants exposure to elevated CO2 increased. Maximum rate of photosynthetic Rubisco carboxylation (Vcmax) and apparent maximum rate of photosynthetic electron transport (Jmax) were downregulated. Elevated CO2 reduced stomatal conductance (gs) by 32% on average and increased water use efficiency by 34, 43 and 63% for &lt; 700, 700 and &gt; 700 μmol mol−1, respectively. Leaf N content decreased two times more in NLTs than LTs growing at elevated CO2 than ambient CO2.                              Conclusions                Our results suggest that woody plants will benefit from elevated CO2 through increased photosynthetic rate, productivity and improved water status, but the responses will vary by woody plant traits and length of exposure to elevated CO2.              \n",
      "  - The effects of elevated CO2 and interaction effects between elevated CO2 and nutrient supplies on growth and the C/N ratio of European beech (Fagus sylvatica L.) saplings were studied. One-year-old beech saplings were grown in a greenhouse at ambient (385 ppm) and elevated CO2 (770 ppm/950 ppm), with or without fertilization for two growing seasons. In this study, emphasis is placed on the combined fertilization including phosphorus, potassium and nitrogen with two level of elevated CO2. The fertilized plants grown under elevated CO2 had the highest net leaf photosynthesis rate (Ac). The saplings grown under elevated CO2 had a significantly lower stomatal conductance (gs) than saplings grown under ambient air. No interaction effect was found between elevated CO2 and fertilization on Ac. A interaction effect between CO2 and fertilization, as well as between date and fertilization and between date and CO2 was detected on gs. Leaf chlorophyll content index (CCI) and leaf nitrogen content were strongly positively correlated to each other and both of them decreased under elevated CO2. At the end of both growing seasons, stem dry weight was greater under elevated CO2 and root dry weight was not affected by different treatments. No interaction effect was detected between elevated CO2 and nutrient supplies on the dry weight of different plant tissues (stems and roots). However, elevated CO2 caused a significant decrease in the nitrogen content of plant tissues. Nitrogen reduction in the leaves under elevated CO2 was about 10% and distinctly higher than in the stem and root. The interaction effect of elevated CO2 and fertilization on C/N ratio in plants tissues was significant. The results led to the conclusion that photosynthesis and the C/N ratio increased while stomatal conductance and leaf nitrogen content decreased under elevated CO2 and nutrient-limited conditions. In general, under nutrient-limited conditions, the plant responses to elevated CO2 were decreased.\n",
      "--------------------------------------------------\n",
      "Topic 21: 21_crop_crops_plant_breeding\n",
      "Representative Documents:\n",
      "  - Rapidly rising population and climate changes are two critical issues that require immediate action to achieve sustainable development goals. The rising population is posing increased demand for food, thereby pushing for an acceleration in agricultural production. Furthermore, increased anthropogenic activities have resulted in environmental pollution such as water pollution and soil degradation as well as alterations in the composition and concentration of environmental gases. These changes are affecting not only biodiversity loss but also affecting the physio-biochemical processes of crop plants, resulting in a stress-induced decline in crop yield. To overcome such problems and ensure the supply of food material, consistent efforts are being made to develop strategies and techniques to increase crop yield and to enhance tolerance toward climate-induced stress. Plant breeding evolved after domestication and initially remained dependent on phenotype-based selection for crop improvement. But it has grown through cytological and biochemical methods, and the newer contemporary methods are based on DNA-marker-based strategies that help in the selection of agronomically useful traits. These are now supported by high-end molecular biology tools like PCR, high-throughput genotyping and phenotyping, data from crop morpho-physiology, statistical tools, bioinformatics, and machine learning. After establishing its worth in animal breeding, genomic selection (GS), an improved variant of marker-assisted selection (MAS), has made its way into crop-breeding programs as a powerful selection tool. To develop novel breeding programs as well as innovative marker-based models for genetic evaluation, GS makes use of molecular genetic markers. GS can amend complex traits like yield as well as shorten the breeding period, making it advantageous over pedigree breeding and marker-assisted selection (MAS). It reduces the time and resources that are required for plant breeding while allowing for an increased genetic gain of complex attributes. It has been taken to new heights by integrating innovative and advanced technologies such as speed breeding, machine learning, and environmental/weather data to further harness the GS potential, an approach known as integrated genomic selection (IGS). This review highlights the IGS strategies, procedures, integrated approaches, and associated emerging issues, with a special emphasis on cereal crops. In this domain, efforts have been taken to highlight the potential of this cutting-edge innovation to develop climate-smart crops that can endure abiotic stresses with the motive of keeping production and quality at par with the global food demand.\n",
      "  - Drought and salinity are the major environmental abiotic stresses that negatively impact crop development and yield. To improve yields under abiotic stress conditions, drought- and salinity-tolerant crops are key to support world crop production and mitigate the demand of the growing world population. Nevertheless, plant responses to abiotic stresses are highly complex and controlled by networks of genetic and ecological factors that are the main targets of crop breeding programs. Several genomics strategies are employed to improve crop productivity under abiotic stress conditions, but traditional techniques are not sufficient to prevent stress-related losses in productivity. Within the last decade, modern genomics studies have advanced our capabilities of improving crop genetics, especially those traits relevant to abiotic stress management. This review provided updated and comprehensive knowledge concerning all possible combinations of advanced genomics tools and the gene regulatory network of reactive oxygen species homeostasis for the appropriate planning of future breeding programs, which will assist sustainable crop production under salinity and drought conditions.\n",
      "  - Wheat is one of the world’s most commonly consumed cereal grains. During abiotic stresses, the physiological and biochemical alterations in the cells reduce growth and development of plants that ultimately decrease the yield of wheat. Therefore, novel approaches are needed for sustainable wheat production under the changing climate to ensure food and nutritional security of the ever-increasing population of the world. There are two ways to alleviate the adverse effects of abiotic stresses in sustainable wheat production. These are (i) development of abiotic stress tolerant wheat cultivars by molecular breeding, speed breeding, genetic engineering, and/or gene editing approaches such as clustered regularly interspaced short palindromic repeats (CRISPR)-Cas toolkit, and (ii) application of improved agronomic, nano-based agricultural technology, and other climate-smart agricultural technologies. The development of stress-tolerant wheat cultivars by mobilizing global biodiversity and using molecular breeding, speed breeding, genetic engineering, and/or gene editing approaches such as CRISPR-Cas toolkit is considered the most promising ways for sustainable wheat production in the changing climate in major wheat-growing regions of the world. This comprehensive review updates the adverse effects of major abiotic stresses and discusses the potentials of some novel approaches such as molecular breeding, biotechnology and genetic-engineering, speed breeding, nanotechnology, and improved agronomic practices for sustainable wheat production in the changing climate.\n",
      "--------------------------------------------------\n",
      "Topic 22: 22_pco2_acidification_ph_elevated\n",
      "Representative Documents:\n",
      "  - Co‐occurring ocean warming, acidification and reduced carbonate mineral saturation have significant impacts on marine biota, especially calcifying organisms. The effects of these stressors on development and calcification in newly metamorphosed juveniles (ca. 0.5 mm test diameter) of the intertidal sea urchin Heliocidaris erythrogramma, an ecologically important species in temperate Australia, were investigated in context with present and projected future conditions. Habitat temperature and pH/pCO2 were documented to place experiments in a biologically and ecologically relevant context. These parameters fluctuated diurnally up to 10 °C and 0.45 pH units. The juveniles were exposed to three temperature (21, 23 and 25 °C) and four pH (8.1, 7.8, 7.6 and 7.4) treatments in all combinations, representing ambient sea surface conditions (21 °C, pH 8.1; pCO2 397; ΩCa 4.7; ΩAr 3.1), near‐future projected change (+2–4 °C, −0.3–0.5 pH units; pCO2 400–1820; ΩCa 5.0–1.6; ΩAr 3.3–1.1), and extreme conditions experienced at low tide (+4 °C, −0.3–0.7 pH units; pCO2 2850–2967; ΩCa 1.1–1.0; ΩAr 0.7–0.6). The lowest pH treatment (pH 7.4) was used to assess tolerance levels. Juvenile survival and test growth were resilient to current and near‐future warming and acidification. Spine development, however, was negatively affected by near‐future increased temperature (+2–4 °C) and extreme acidification (pH 7.4), with a complex interaction between stressors. Near‐future warming was the more significant stressor. Spine tips were dissolved in the pH 7.4 treatments. Adaptation to fluctuating temperature‐pH conditions in the intertidal may convey resilience to juvenile H. erythrogramma to changing ocean conditions, however, ocean warming and acidification may shift baseline intertidal temperature and pH/pCO2 to levels that exceed tolerance limits.\n",
      "  - Summary               Ocean acidification due to increasing atmospheric CO2 concentrations results in a decrease in seawater pH and shifts in the carbonate chemistry that can negatively affect marine organisms. Marine bivalves such as the hard shell clams Mercenaria mercenaria serve as ecosystem engineers in estuaries and coastal zones of the western Atlantic and, as for many marine calcifiers, are sensitive to the impacts of ocean acidification. In estuaries, the effects of ocean acidification can be exacerbated by low buffering capacity of brackish waters, acidic inputs from freshwaters and land, and/or the negative effects of salinity on organisms’ physiology. We determined the interactive effects of 21 weeks of exposure to different levels of CO2 (~395, 800 and 1500 µatm corresponding to pH of 8.2, 8.1 and 7.7 respectively) and salinity (32 vs. 16) on biomineralization, shell properties and energy metabolism of juveniles of the hard shell clam M. mercenaria. Low salinity had profound effects on survival, energy metabolism and biomineralization of hard shell clams and modulated their responses to elevated PCO2. Negative effects of low salinity in juvenile clams were mostly due to the strongly elevated basal energy demand indicating energy deficiency that led to reduced growth, elevated mortality and impaired shell maintenance (evidenced by the extensive damage to the periostracum). The effects of elevated PCO2 on physiology and biomineralization of hard shell clams were more complex. Elevated PCO2 (~800-1500 µatm) had no significant effects on standard metabolic rates (indicative of the basal energy demand), but affected growth and shell mechanical properties in juvenile clams. Moderate hypercapnia (~800 µatm PCO2) increased shell and tissue growth and reduced mortality of juvenile clams in high salinity exposures; however, these effects were abolished under the low salinity conditions or at high PCO2 (~1500 µatm). Mechanical properties of the shell (measured as microhardness and fracture toughness of the shells) were negatively affected by elevated CO2 alone or in combination with low salinity, which may have important implications for protection against predators or environmental stressors. Our data indicate that environmental salinity can strongly modulate responses to ocean acidification in hard shell clams and thus should be taken into account when predicting the effects of ocean acidification on estuarine bivalves.\n",
      "  - The carbonate chemistry in coastal waters is more variable compared with that of open oceans, both in magnitude and time scale of its fluctuations. However, knowledge of the responses of coastal phytoplankton to dynamic changes in pH/pCO2 has been scarcely documented. Hence, we investigated the physiological performance of a coastal isolate of the coccolithophore Emiliania huxleyi (PML B92/11) under fluctuating and stable pCO2 regimes (steady ambient pCO2, 400 μatm; steady elevated pCO2, 1200 μatm; diurnally fluctuating elevated pCO2, 600–1800 μatm). Elevated pCO2 inhibited the calcification rate in both the steady and fluctuating regimes. However, higher specific growth rates and lower ratios of calcification to photosynthesis were detected in the cells grown under diurnally fluctuating elevated pCO2 conditions. The fluctuating pCO2 regime alleviated the negative effects of elevated pCO2 on effective photochemical quantum yield and relative photosynthetic electron transport rate compared with the steady elevated pCO2 treatment. Our results suggest that growth of E. huxleyi could benefit from diel fluctuations of pH/pCO2 under future-projected ocean acidification, but its calcification was reduced by the fluctuation and the increased concentration of CO2, reflecting a necessity to consider the influences of dynamic pH fluctuations on coastal carbon cycles associated with ocean global changes.\n",
      "--------------------------------------------------\n",
      "Topic 23: 23_cu_co2 reduction_co_photocatalytic\n",
      "Representative Documents:\n",
      "  - Renewable electricity-powered CO evolution from CO2emissions is a promising first step in the sustainable production of commodity chemicals, but performing electrochemical CO2reduction economically at scale is challenging since only noble metals, for example, gold and silver, have shown high performance for CO2-to-CO. Cu is a potential catalyst to achieve CO2reduction to CO at the industrial scale, but the C-C coupling process on Cu significantly depletes CO* intermediates, thus limiting the CO evolution rate and producing many hydrocarbon and oxygenate mixtures. Herein, we tune the CO selectivity of Cu by alloying a second metal Sb into Cu, and report an antimony-copper single-atom alloy catalyst (Sb1Cu) of isolated Sb-Cu interfaces that catalyzes the efficient conversion of CO2-to-CO with a Faradaic efficiency over 95%. The partial current density reaches 452 mA cm−2with approximately 91% CO Faradaic efficiency, and negligible C2+products are observed. In situ spectroscopic measurements and theoretical simulations reason that the atomic Sb-Cu interface in Cu promotes CO2adsorption/activation and weakens the binding strength of CO*, which ends up with enhanced CO selectivity and production rates.\n",
      "  - Copper-based bimetallic catalysts have been recently showing promising performance for the selective electrochemical reduction of CO2. In this work, we successfully fabricated the partially reduced oxides SnOx, CuOx modified Cu foam electrode (A-Cu/SnO2) through an electrodeposition-annealing-electroreduction approach. Notably, in comparison with the control electrode (Cu/SnO2) without undergoing annealing step, A-Cu/SnO2 exhibits a significant enhancement in terms of CO2 reduction activity and CO selectivity. By investigating the effect of the amount of the electrodeposited SnO2, it is found that A-Cu/SnO2 electrodes present the characteristic Sn-Cu synergistic catalysis with a feature of dominant CO formation (CO faradaic efficiency, 70~75%), the least HCOOH formation (HCOOH faradaic efficiency, &lt;5%) and the remarkable inhibition of hydrogen evolution reaction. In contrast, Cu/SnO2 electrodes exhibit a SnO2 coverage-dependent catalysis—a shift from CO selectivity to HCOOH selectivity with the increasing deposited SnO2 on Cu foam. The different catalytic performance between Cu/SnO2 and A-Cu/SnO2 might be attributed to the different content of Cu atoms in SnO2 layer, which may affect the density of Cu-Sn interface on the surface. Our work provides a facile annealing-electroreduction strategy to modify the surface composition for understanding the metal effect towards CO2 reduction activity and selectivity for bimetallic Cu-based electrocatalysts.\n",
      "  - Electrochemical reduction of CO2 into high-value hydrocarbons and alcohols by using Cu-based catalysts is a promising and attractive technology for CO2 capture and utilization, resulting from their high catalytic activity and selectivity. The mobility and accessibility of active sites in Cu-based catalysts significantly hinder the development of efficient Cu-based catalysts for CO2 electrochemical reduction reaction (CO2RR). Herein, a facile and effective strategy is developed to engineer accessible and structural stable Cu sites by incorporating single atomic Cu into the nitrogen cavities of the host graphitic carbon nitride (g-C3N4) as the active sites for CO2-to-CH4 conversion in CO2RR. By regulating the coordination and density of Cu sites in g-C3N4, an optimal catalyst corresponding to a one Cu atom in one nitrogen cavity reaches the highest CH4 Faraday efficiency of 49.04% and produces the products with a high CH4/C2H4 ratio over 9. This work provides the first experimental study on g-C3N4-supported single Cu atom catalyst for efficient CH4 production from CO2RR and suggests a principle in designing highly stable and selective high-efficiency Cu-based catalysts for CO2RR by engineering Cu active sites in 2D materials with porous crystal structures.\n",
      "--------------------------------------------------\n",
      "Topic 24: 24_responses_species_interactions_ecological\n",
      "Representative Documents:\n",
      "  - ABSTRACTAim  To identify hypotheses for how climate change affects long‐term population persistence that can be used as a framework for future syntheses of ecological responses to climate change.Location  Global.Methods  We surveyed ecological and evolutionary concepts related to how a changing climate might alter population persistence. We organized established concepts into a two‐stage framework that relates abiotic change to population persistence via changes in the rates or outcomes of ecological and evolutionary processes. We surveyed reviews of climate change responses, and evaluated patterns in light of our conceptual framework.Results  We classified hypotheses for population responses to climate change as one of two types: (1) hypotheses that relate rates of ecological and evolutionary processes (plasticity, dispersal, population growth and evolution) to abiotic change, and (2) hypotheses that relate changes in these processes to four fundamental population‐level responses (colonization, acclimatization, adaptation or extinction). We found that a disproportionate emphasis on response in the climate change literature is difficult to reconcile with ecological and evolutionary theories that emphasize processes. We discuss a set of 24 hypotheses that represent gaps in the literature that limit our ability determine whether observed climate change responses are sufficient to facilitate persistence through future climate change.Main conclusions  Though theory relates environmental change to fundamental ecological and evolutionary processes and population‐level responses, clear hypotheses based on theory have not been systematically formulated and tested in the context of climate change. Stronger links between basic theory and observed impacts of climate change are required to assess which responses are common, likely or able to facilitate population persistence despite ongoing environmental change. We anticipate that a hypothesis‐testing framework will reveal that indirect effects of climate change responses are more pervasive than previously thought and related to a few general processes, even though the patterns they create are incredibly diverse.\n",
      "  - SynthesisPrediction and management of species responses to climate change is an urgent but relatively young research field. Therefore, climate change ecology must by necessity borrow from other fields. Invasion ecology is particularly well‐suited to informing climate change ecology because both invasion ecology and climate change ecology address the trajectories of rapidly changing novel systems. Here we outline the broad range of active research questions in climate change ecology where research from invasion ecology can stimulate advances. We present ideas for how concepts, case‐studies and methodology from invasion ecology can be adapted to improve prediction and management of species responses to climate change.A major challenge in this era of rapid climate change is to predict changes in species distributions and their impacts on ecosystems, and, if necessary, to recommend management strategies for maintenance of biodiversity or ecosystem services. Biological invasions, studied in most biomes of the world, can provide useful analogs for some of the ecological consequences of species distribution shifts in response to climate change. Invasions illustrate the adaptive and interactive responses that can occur when species are confronted with new environmental conditions. Invasion ecology complements climate change research and provides insights into the following questions: 1) how will species distributions respond to climate change? 2) how will species movement affect recipient ecosystems? And 3) should we, and if so how can we, manage species and ecosystems in the face of climate change? Invasion ecology demonstrates that a trait‐based approach can help to predict spread speeds and impacts on ecosystems, and has the potential to predict climate change impacts on species ranges and recipient ecosystems. However, there is a need to analyse traits in the context of life‐history and demography, the stage in the colonisation process (e.g. spread, establishment or impact), the distribution of suitable habitats in the landscape, and the novel abiotic and biotic conditions under which those traits are expressed. As is the case with climate change, invasion ecology is embedded within complex societal goals. Both disciplines converge on similar questions of ‘when to intervene?‘ and ‘what to do?‘ which call for a better understanding of the ecological processes and social values associated with changing ecosystems.\n",
      "  -             BACKGROUND            As global climate change accelerates, one of the most urgent tasks for the coming decades is to develop accurate predictions about biological responses to guide the effective protection of biodiversity. Predictive models in biology provide a means for scientists to project changes to species and ecosystems in response to disturbances such as climate change. Most current predictive models, however, exclude important biological mechanisms such as demography, dispersal, evolution, and species interactions. These biological mechanisms have been shown to be important in mediating past and present responses to climate change. Thus, current modeling efforts do not provide sufficiently accurate predictions. Despite the many complexities involved, biologists are rapidly developing tools that include the key biological processes needed to improve predictive accuracy. The biggest obstacle to applying these more realistic models is that the data needed to inform them are almost always missing. We suggest ways to fill this growing gap between model sophistication and information to predict and prevent the most damaging aspects of climate change for life on Earth.                                ADVANCES            On the basis of empirical and theoretical evidence, we identify six biological mechanisms that commonly shape responses to climate change yet are too often missing from current predictive models: physiology; demography, life history, and phenology; species interactions; evolutionary potential and population differentiation; dispersal, colonization, and range dynamics; and responses to environmental variation. We prioritize the types of information needed to inform each of these mechanisms and suggest proxies for data that are missing or difficult to collect. We show that even for well-studied species, we often lack critical information that would be necessary to apply more realistic, mechanistic models. Consequently, data limitations likely override the potential gains in accuracy of more realistic models. Given the enormous challenge of collecting this detailed information on millions of species around the world, we highlight practical methods that promote the greatest gains in predictive accuracy. Trait-based approaches leverage sparse data to make more general inferences about unstudied species. Targeting species with high climate sensitivity and disproportionate ecological impact can yield important insights about future ecosystem change. Adaptive modeling schemes provide a means to target the most important data while simultaneously improving predictive accuracy.                                OUTLOOK            Strategic collections of essential biological information will allow us to build generalizable insights that inform our broader ability to anticipate species’ responses to climate change and other human-caused disturbances. By increasing accuracy and making uncertainties explicit, scientists can deliver improved projections for biodiversity under climate change together with characterizations of uncertainty to support more informed decisions by policymakers and land managers. Toward this end, a globally coordinated effort to fill data gaps in advance of the growing climate-fueled biodiversity crisis offers substantial advantages in efficiency, coverage, and accuracy. Biologists can take advantage of the lessons learned from the Intergovernmental Panel on Climate Change’s development, coordination, and integration of climate change projections. Climate and weather projections were greatly improved by incorporating important mechanisms and testing predictions against global weather station data. Biology can do the same. We need to adopt this meteorological approach to predicting biological responses to climate change to enhance our ability to mitigate future changes to global biodiversity and the services it provides to humans.                                          Emerging models are beginning to incorporate six key biological mechanisms that can improve predictions of biological responses to climate change.                Models that include biological mechanisms have been used to project (clockwise from top) the evolution of disease-harboring mosquitoes, future environments and land use, physiological responses of invasive species such as cane toads, demographic responses of penguins to future climates, climate-dependent dispersal behavior in butterflies, and mismatched interactions between butterflies and their host plants. Despite these modeling advances, we seldom have the detailed data needed to build these models, necessitating new efforts to collect the relevant data to parameterize more biologically realistic predictive models.                                                  \n",
      "--------------------------------------------------\n",
      "Topic 25: 25_model_models_ensemble_data\n",
      "Representative Documents:\n",
      "  - Estimates of climate change remain uncertain—hampering strategic decision making in many sectors. In large part this uncertainty arises from uncertainty in the computational representation of known physical processes. This model component of climate change uncertainty is increasingly being assessed using perturbed model experiments. Some such model perturbations have, for example, led to headline global warming estimates of as much as 12 °C. These experiments consider many differently perturbed versions of a given base model and assess the likelihood of each perturbed model's climate prediction based on how well it simulates present‐day climate. In these experiments, the computational cost of the model assessment is extremely high unless one assumes that the climate anomalies associated with different model perturbations can be combined linearly. Here we demonstrate a different method, which harnesses the power of the data assimilation system to assess directly the perturbed physics of a model. Data assimilation involves the incorporation of daily observations to produce initial conditions (analyses) for numerical weather prediction (NWP). The method used here quantifies systematic initial tendencies in the first few time steps of a model forecast. After suitable temporal averaging, these initial tendencies imply systematic imbalances in the physical processes associated with model error. We show how these tendencies can be used to produce probability weightings for each model that could be used in the construction of probability distribution functions of climate change. The approach typically costs 5% of the cost of a 100‐year coupled model simulation that might otherwise be used to assess the simulation of present‐day climate. Importantly, since the approach is amenable to linear analysis, it could further reduce the cost of model assessment by several orders of magnitude: making the exercise computationally feasible. The initial tendency approach can only assess ‘fast physics’ perturbations, i.e. perturbations that have an impact on weather forecasts as well as climate. However, recent publications suggest that most of the present model parameter uncertainty is associated with fast physics. If such a test were adopted, assessment of the ability to simulate present‐day climate would then only be required for models that ‘pass’ the fast physics test. The study highlights the advantages of a more seamless approach to forecasting that combines NWP, climate forecasting, and all scales in‐between. Copyright © 2007 Royal Meteorological Society\n",
      "  - . A method, based on climate pattern scaling, has been developed to expand a small number of projections of fields of a selected climate variable (X) into an ensemble that encapsulates a wide range of indicative model structural uncertainties. The method described in this paper is referred to as the Ensemble Projections Incorporating Climate model uncertainty (EPIC) method. Each ensemble member is constructed by adding contributions from (1) a climatology derived from observations that represents the time-invariant part of the signal; (2) a contribution from forced changes in X, where those changes can be statistically related to changes in global mean surface temperature (Tglobal); and (3) a contribution from unforced variability that is generated by a stochastic weather generator. The patterns of unforced variability are also allowed to respond to changes in Tglobal. The statistical relationships between changes in X (and its patterns of variability) and Tglobal are obtained in a training phase. Then, in an implementation phase, 190 simulations of Tglobal are generated using a simple climate model tuned to emulate 19 different global climate models (GCMs) and 10 different carbon cycle models. Using the generated Tglobal time series and the correlation between the forced changes in X and Tglobal, obtained in the training phase, the forced change in the X field can be generated many times using Monte Carlo analysis. A stochastic weather generator is used to generate realistic representations of weather which include spatial coherence. Because GCMs and regional climate models (RCMs) are less likely to correctly represent unforced variability compared to observations, the stochastic weather generator takes as input measures of variability derived from observations, but also responds to forced changes in climate in a way that is consistent with the RCM projections. This approach to generating a large ensemble of projections is many orders of magnitude more computationally efficient than running multiple GCM or RCM simulations. Such a large ensemble of projections permits a description of a probability density function (PDF) of future climate states rather than a small number of individual story lines within that PDF, which may not be representative of the PDF as a whole; the EPIC method largely corrects for such potential sampling biases. The method is useful for providing projections of changes in climate to users wishing to investigate the impacts and implications of climate change in a probabilistic way. A web-based tool, using the EPIC method to provide probabilistic projections of changes in daily maximum and minimum temperatures for New Zealand, has been developed and is described in this paper.                    \n",
      "  - Reconstructing the spatial pattern of a climate field through time from a dataset of overlapping instrumental and climate proxy time series is a nontrivial statistical problem. The need to transform the proxy observations into estimates of the climate field, and the fact that the observed time series are not uniformly distributed in space, further complicate the analysis. Current leading approaches to this problem are based on estimating the full covariance matrix between the proxy time series and instrumental time series over a “calibration” interval and then using this covariance matrix in the context of a linear regression to predict the missing instrumental values from the proxy observations for years prior to instrumental coverage.A fundamentally different approach to this problem is formulated by specifying parametric forms for the spatial covariance and temporal evolution of the climate field, as well as “observation equations” describing the relationship between the data types and the corresponding true values of the climate field. A hierarchical Bayesian model is used to assimilate both proxy and instrumental datasets and to estimate the probability distribution of all model parameters and the climate field through time on a regular spatial grid. The output from this approach includes an estimate of the full covariance structure of the climate field and model parameters as well as diagnostics that estimate the utility of the different proxy time series.This methodology is demonstrated using an instrumental surface temperature dataset after corrupting a number of the time series to mimic proxy observations. The results are compared to those achieved using the regularized expectation–maximization algorithm, and in these experiments the Bayesian algorithm produces reconstructions with greater skill. The assumptions underlying these two methodologies and the results of applying each to simple surrogate datasets are explored in greater detail in Part II.\n",
      "--------------------------------------------------\n",
      "Topic 26: 26_tax_policy_emissions_welfare\n",
      "Representative Documents:\n",
      "  -  This paper provides a comprehensive exploration of the impacts of economy-wide CO2 taxes in the U.S. simulated using a detailed electric sector model [the National Renewable Energy Laboratory’s Regional Energy Deployment System (ReEDS)] linked with a computable general equilibrium model of the U.S. economy [the Massachusetts Institute of Technology’s U.S. Regional Energy Policy (USREP) model]. We implement various tax trajectories and options for using the revenue collected by the tax and describe their impact on household welfare and its distribution across income levels. Overall, we find that our top-down/bottom-up models affects estimates of the distribution and cost of emission reductions as well as the amount of revenue collected, but that these are mostly insensitive to the way the revenue is recycled. We find that substantial abatement opportunities through fuel switching and renewable penetration in the electricity sector allow the economy to accommodate extensive emissions reductions at relatively low cost. While welfare impacts are largely determined by the choice of revenue recycling scheme, all tax levels and schemes provide net benefits when accounting for the avoided global climate change benefits of emission reductions. Recycling revenue through capital income tax rebates is more efficient than labor income tax rebates or uniform transfers to households. While capital tax rebates substantially reduce the overall costs of emission abatement, they profit high income households the most and are regressive. We more generally identify a clear trade-off between equity and efficiency across the various recycling options. However, we show through a set of hybrid recycling schemes that it is possible to limit inequalities in impacts, particularly those on the lowest income households, at relatively little incremental cost. \n",
      "  -  This paper examines carbon tax design options in the United States using an intertemporal computable general equilibrium model of the world economy called G-Cubed. In this paper, we discuss four policy scenarios that explore two overarching issues: (1) the effects of a carbon tax under alternative assumptions about the use of the resulting revenue, and (2) the effects of a system of import charges on carbon-intensive goods (“border carbon adjustments” or BCAs).  Consistent with earlier studies, we find that the carbon tax raises considerable revenue and reduces CO2 emissions significantly relative to baseline, no matter how the revenue is used. Gross annual revenue from the carbon tax with lump sum rebating and no BCA begins at $110 billion in 2020 and rises gradually to $170 billion in 2040. By 2040, annual CO2 emissions fall from 5.5 billion metric tons (BMT) under the baseline to 2.4 BMT, a decline of 3.1 BMT, or 57%. Cumulative emissions over 2020 to 2040 fall by 48 BMT.  Also consistent with earlier studies, we find that the carbon tax has very small overall impacts on gross domestic product (GDP), wages, employment, and consumption. Different uses of the revenue from the carbon tax result in slightly different levels and compositions of GDP across consumption, investment and net exports. Overall, using carbon tax revenue to reduce the capital income tax rate results in better macroeconomic outcomes than using the revenue for lump sum transfers.  Counter to their purported purpose of protecting U.S. trade strength, for a given revenue policy, BCAs tend to produce lower net exports than the carbon taxes alone. This is generally because the BCAs raise the value of the dollar relative to other currencies, thus lowering exports more than they lower imports. This is consistent with standard results in the international trade literature on the effects of import tariffs and export subsidies on real exchange rates, a result that is often overlooked in the discussion of domestic carbon policy.  In a finding new to the literature, our results show that BCAs can have strikingly different effects depending on the use of the revenue. Under a lump sum rebate, BCAs exacerbate the impact of the carbon tax by lowering domestic output further than it would fall under the carbon tax alone. Under a capital tax swap, however, BCAs have a moderating effect: they reduce the impact of the tax on most industries. \n",
      "  -  For EMF 32, we applied a new version of our Intertemporal General Equilibrium Model (IGEM) based on the North American Industry Classification System (NAICS). We simulated the impacts arising from the Energy Modeling Forum’s broad range of carbon taxes under three revenue recycling options — lump sum redistributions, capital tax reductions, and labor tax cuts. We examined their consequences for industry prices and quantities, for the overall economy, and for the welfare of households, individuals, and society, the latter in terms of efficiency and equity. We rank recycling mechanisms from most to least favorable in terms of the magnitudes of their impacts on net social welfare — efficiency net of equity — recognizing that other objectives may be more important to policy makers and the public. Finally, we and the EMF 32 effort focus only on the economic effects of carbon taxation and revenue recycling; the environmental benefits arising from emissions reductions are not within our scope of study.  We find CO2 emissions abatement to be invariant to the chosen recycling scheme. This means that policy makers need not compromise their environmental objectives when designing carbon tax swap options. We also find additional emissions reductions beyond the scope of coverage and points of taxation.  Reducing capital taxes promotes new saving, investment and capital formation and is the most favorable recycling mechanism. In 2010 dollars, the welfare loss per ton abated ranges from $0.19 to $3.90 depending on the path of carbon prices. Reducing labor taxes promotes consumption and work through real-wage incentives and is the next most favorable recycling scheme. Here, the welfare loss per ton abated ranges from $11.09 to $16.49 depending on the carbon tax trajectory. Lump sum redistribution of carbon tax revenues is the least favorable recycling option. It incentivizes neither capital nor labor. Consequently, the damages to the economy and welfare are the greatest among the three schemes. With lump sum recycling, the welfare loss per ton abated ranges from $37.15 to $43.61 as carbon taxation becomes more aggressive. While this ranking is common among the participating EMF 32 models, the spread in our results is the greatest in comparison which we attribute to the substitution possibilities inherent in IGEM’s econometrics, the absence of barriers to factor mobility, and likely differences in the manner in which tax incentives are structured.  We find welfare gains are possible under capital and labor tax recycling when emissions accounting is viewed from a top-down rather than a bottom-up perspective and carbon pricing is at an economy-wide average. However, these gains occur at the expense of abatement.  We find capital tax recycling to be regressive while labor tax recycling is progressive as is redistribution through lump sums. Moreover, we find that the lump sum mechanism provides the best means for sheltering the poorest from the welfare consequences of carbon taxation. Thus, promoting capital formation is the best use of carbon tax revenues in terms of reducing the magnitudes of welfare losses while the lump sum and labor tax options are the best uses for reducing inequality. \n",
      "--------------------------------------------------\n",
      "Topic 27: 27_suitable_distribution_habitat_areas\n",
      "Representative Documents:\n",
      "  - Larix principis-rupprechtii Mayr (larch) is a native conifer species in North China, and also a major silvicultural and timber species in the region. Climate change has led to a change in its suitable distribution area. However, the dominant factors affecting changes in its suitable distribution and migration trends are not clear. In this study, based on forest resource inventory data and bioclimatic data in Hebei and Shanxi provinces, China, we built an ensemble model based on seven algorithms to simulate the larch’s potential suitable distribution areas under three shared socioeconomic pathways (SSPs: SSP1-2.6, SSP2-4.5, and SSP5-8.5) for the current and future (2021–2040, 2041–2060 and 2080–2100). The results revealed that: (1) ensemble models significantly improved the predictive accuracy (ROC = 0.95, TSS = 0.81, KAPPA = 0.65); (2) the current potentially suitable distribution area was concentrated in the Bashang Plateau and the northwestern mountain range of the study area. Among them, 12.38% were highly suitable distribution areas, 12.67% were moderately suitable distribution areas, and 12.01% were lowly suitable distribution areas; (3) the main climatic factors affecting larch distribution were mean temperature of driest quarter, mean diurnal range, precipitation of warmest quarter, and temperature annual range; (4) under different future climate scenarios, the contraction of the suitable distribution area of larch increased significantly with increasing SSP radiation intensity. By 2100, the suitable distribution area of larch was expected to decrease by 26.5% under SSP1-2.6, 57.9% under SSP2-4.5, and 75.7% under SSP5-8.5 scenarios; (5) from 2021 to 2100, the different suitable distribution areas of larch showed a trend of migration to the northeast. Under the SSP5-8.5 scenario, the migration distance of different suitable distribution areas was the largest, in which the high suitable distribution area migrated 232.60 km, the middle suitable distribution area migrated 206.75 km, and the low suitable distribution area migrated 163.43 km. The results revealed the impact of climate change on the larch distribution, which provided a scientific basis for making forest management decisions.\n",
      "  - The white peach scale Pseudaulacaspis pentagona (Hemiptera: Diaspididae) is a pest that causes significant damage to more than 221 genera of host plants in more than 112 countries. P. pentagona primarily feeds on mulberry, peach, and tea, and this leads to the loosening of the epidermis of trees, which damages nutrient and water transportation in the branches, leading to branch death. P. pentagona is native to China and Japan, and has become an invasive species all over the world. However, the potential distribution of P. pentagona remains unclear. In this study, a potential distribution map of P. pentagona was developed using current and future climate information using MaxEnt. The model indicates that Asia, Europe, South America and North America are a highly suitable habitat range for this species. The MaxEnt models for the potential distribution of P. pentagona for the 2050s and 2070s suggest that in the case of no significant increase or even decrease in the highly suitable area, the suitable area increased significantly on any future climatic scenarios. The predicted area gain in the suitable habitat is 2.82 × 107 km2, including more of Asia, such as China, Japan, and Mongolia, and also including India, Vietnam, Romania, Ukraine, Poland, Hungary, Austria, The Czech Republic, Italy, and Germany in Europe, which shows an increase of 24.5% over the current habitat on RCP8.5 emission scenarios for the 2070s. With the warming of the climate, significant expansions are predicted in the suitable area, especially in Europe and East Asia. Under RCP8.5 for the 2050s, the model-predicted that the area of suitable habitat in China and the Korean Peninsula gains an increase of 18.8% over the current suitable habitat area. Under other climate scenarios, RCP8.5-2070s, the suitable areas were the largest, compared to projection for the current climate scenario (ca. 24.1% increase) which increased to 7.89 × 106 km2. In Europe, under RCP8.5 for the 2070s, the highly suitable areas were the largest, compared to the projection for the current climate scenario (ca. 46.2% increase), which increased to 8.64 × 105 km2, the area of suitable habitat suitability increased to 4.99 × 106 km2 (29.2% increase of the current condition). Potential increases or decreases in distribution ranges were modeled under future climatic scenarios. This study suggests that the most important factor that influenced current distribution of this pest was temperature, and BIO3 (isothermality) was the most important factor that contributed to 48.6% of the potential distribution map. Given the rapid spread of P. pentagona and the serious risk this species poses to local ecosystems, warning modelling and practical strategies to prevent the establishment and expansion of this species should be sought. This distribution map will help governments to identify areas that are suitable for current and future infestations, and to optimize pest management strategies.\n",
      "  - Magnolia wufengensis is a newly discovered rare and endangered species endemic to China. The primary objective of this study is to find the most suitable species distribution models (SDMs) by comparing the different SDMs to predict their habitat distribution for protection and introduction in China under climate change. SDMs are important tools for studying species distribution patterns under climate change, and different SDMs have different simulation effects. Thus, to identify the potential habitat for M. wufengensis currently and in the 2050s (2041–2060) and 2070s (2061–2080) under different climate change scenarios (representative concentration pathways RCP2.6, RCP4.5, RCP6.0, and RCP8.5) in China, four SDMs, Maxent, GARP, Bioclim, and Domain, were first used to compare the predicted habitat and explore the dominant environmental factors. The four SDMs predicted that the potential habitats were mainly south of 40° N and east of 97° E in China, with a high distribution potential under current climate conditions. The area under the receiver operating characteristic (ROC) curve (AUC) (0.9479 ± 0.0080) was the highest, and the Kappa value (0.8113 ± 0.0228) of the consistency test and its performance in predicting the potential suitable habitat were the best in the Maxent model. The minimum temperature of the coldest month (−13.36–9.84 °C), mean temperature of the coldest quarter (−6.06–12.66 °C), annual mean temperature (≥4.49 °C), and elevation (0–2803.93 m), were the dominant factors. In the current climate scenario, areas of 46.60 × 104 km2 (4.85%), 122.82 × 104 km2 (12.79%), and 96.36 × 104 km2 (10.03%), which were mainly in central and southeastern China, were predicted to be potential suitable habitats of high, moderate, and low suitability, respectively. The predicted suitable habitats will significantly change by the 2050s (2040–2060) and 2070s (2060–2080), suggesting that M. wufengensis will increase in high-elevation areas and shift northeast with future climate change. The comparison of current and future suitable habitats revealed declines of approximately 4.53%–29.98% in highly suitable habitats and increases of approximately 6.45%–27.09% and 0.77%–21.86% in moderately and lowly suitable habitats, respectively. In summary, these results provide a theoretical basis for the response to climate change, protection, precise introduction, cultivation, and rational site selection of M. wufengensis in the future.\n",
      "--------------------------------------------------\n",
      "Topic 28: 28_yield_crop_maize_wheat\n",
      "Representative Documents:\n",
      "  - SUMMARYWheat is an important crop in the highlands of Northern Ethiopia and climate change is expected to be a major threat to wheat productivity. However, the potential impacts of climate change and adaptation on wheat yield has not been documented for this region. Wheat field experiments were carried out during the 2011–2013 cropping seasons in Northern Ethiopia to: (1) calibrate and evaluate Agricultural Production Systems sIMulator (APSIM)-wheat model for exploring the impacts of climate change and adaptation on wheat yield; (2) explore the response of wheat cultivar/s to possible change in climate and carbon dioxide (CO2) under optimal and sub-optimal fertilizer application and (3) assess the impact of climate change and adaptation practices on wheat yield based on integration of surveyed field data with climate simulations using multi-global climate models (GCMs; for short- and mid-term periods) for the Hintalo-Wajrat areas of Northern Ethiopia. The treatments were two levels of fertilizer (optimal and zero fertilization); treatments were replicated three times and arranged in a randomized complete block design. All required information for model calibration and evaluation were gathered from experimental studies. In addition, a household survey was conducted in 2012 in Northern Ethiopia. Following model calibration and performance testing, response of wheat to various nitrogen (N) fertilizer rates, planting date, temperature and combinations of other climate variables and CO2 were assessed. Crop simulations were conducted with future climate scenarios using 20 different GCMs and compared with a baseline. In addition, simulations were carried out using climate data from five different GCM with and without climate change adaptation practices. The simulated yield showed clear responses to changes in temperature, N fertilizer and CO2. Regardless of choice of cultivar, increasing temperatures alone (by up to 5 °C compared with the baseline) resulted in reduced yield while the addition of other factors (optimal fertilizer with elevated CO2) resulted in increased yield. Considering optimal fertilizer (64 kg/ha N) as an adaptation practice, wheat yield in the short-term (2010–2039) and mid-term (2040–2069) may increase at least by 40%, compared with sub-optimal N levels. Assuming CO2 and present wheat management is unchanged, simulation results based on 20 GCMs showed that median wheat yields will reduce by 10% in the short term and by 11% in the mid-term relative to the baseline data, whereas under changed CO2 with present management, wheat yield will increase slightly, by up to 8% in the short term and by up to 11% in the mid-term period, respectively. Wheat yield will substantially increase, by more than 100%, when simulated based on combined use of optimal planting date and fertilizer applications. Increased temperature in future scenarios will cause yield to decline, whereas CO2 is expected to have positive impacts on wheat yield.\n",
      "  - Climate change is expected to lead to declining crop yields in semi‐arid regions due to higher temperatures and more severe droughts, which calls for adaptations in crop management. We used the WOFOST and AquaCrop crop simulation models to examine the response of crop yield in winter wheat and maize to a set of climate change scenarios up to 2040 in the semi‐arid climate of Mashhad in north‐east Iran. Modelled climate change from six AOGCMs including GFCM21, HADCM3, INCM3, IPCM4, MPEH5 and NCCCSM under IPCC SRES A2 and B1 emission scenarios was used. The crop models were calibrated and validated against 7 years of observed crop yield data, confirming that the models adequately simulated yields of wheat and maize in the study area. The bootstrap method was used to estimate the uncertainty of crop yield projections. The results showed a mean yield decrease of 10–34% for winter wheat and 8–18% for maize, depending on the crop model and climate change scenario. The period of flowering to maturity of winter wheat and maize would be shortened on average by 9 and 5 days, respectively. Changes in crop management were considered for adaptation to climate change. Simulation results indicated that early sowing of winter wheat and late sowing of maize enhanced yield and water productivity across all climate change scenarios and that late‐maturity cultivars of winter wheat and early‐maturity hybrids of maize generally have higher productivity than standard cultivars. Increasing heat tolerance of the crops and changing irrigation management of winter wheat were also found to be beneficial adaptation options. © 2019 John Wiley &amp; Sons, Ltd. © 2019 John Wiley &amp; Sons, Ltd.\n",
      "  - SUMMARYThe objective of the present paper was to study the impact of climate change on grain yield, water balance, crop water productivity (CWP) and water requirements for the summer-sown maize in Faisalabad, Pakistan. Climate-change scenarios (Special Report on Emission Scenarios (SRES) A1B, A2 and B1) were derived from the general circulation model ECHAM 5 and the crop model CERES-Maize was used to simulate impacts of the applied climate scenarios. Calibration and validation of the crop models were carried out for the summer-sown maize in 2007 and for the spring-sown maize in 2008. Three predefined reduced irrigation scenarios were compared to traditional irrigation practices for the summer-sown maize. Under the current conditions, scenario S1 (one irrigation event skipped at the vegetative stage) showed a higher simulated yield than scenario S2 (one irrigation event skipped at the grain-filling stage) due to higher water drainage and nitrogen (N) leaching rates in scenario S2. Scenario S3 (irrigation events skipped at both crop establishment and the grain-filling stage) showed significantly higher grain yield because it had the lowest drainage and N leaching rates. In this irrigation scenario, 60 mm of water were saved compared to the other two scenarios, and much more water was saved compared to the traditional local regime.In the predicted climatic scenarios and with reduced irrigation, the simulated maize yields and crop water productivities were affected differently. For the period from 2036 to 2065, a more significant yield decrease was shown in all emission and irrigation scenarios. A yield decrease was simulated by both, including and not including the direct effect of elevated atmospheric CO2 concentrations on photosynthesis. However, the simulated direct effect of elevated CO2 was to produce higher yield and CWP in all scenarios. The highest grain yields and crop water productivities were achieved in the reduced irrigation scenario S3 for all emission scenarios and climatic periods for the same reason as under the current conditions (N leaching). However, the yield differences between the climate scenarios were mainly due to the shortening of the simulated growing period. This was caused by increased temperatures compared to current conditions. A shortened growing cycle reduced the potential time for biomass accumulation and in the present case it was not balanced by the CO2 fertilizing effect (without a potential change in maize cultivars).By simulating optimum yields (where automatic irrigation is determined by the model to receive optimum yield), under the current conditions it was found that 285 mm of irrigation would ensure the highest grain yield and CWP (30 mm more than under irrigation scenario S3). In this case, actual evapotranspiration reached 373 mm and less deep drainage and N leaching occurred. In the future climate scenarios, optimum yields and irrigation demands diminished depending on the emission scenario, but CWP increased slightly.The present simulation study shows a clear decreasing yield trend for autumn maize under a warm climate for each type of (unchanged) irrigation management due to the shortening of the growing period. However, in the current climate, as well as in the future climate scenarios, maize yield levels could be improved by optimized (and reduced) irrigation compared to traditional irrigation due to reduced N leaching. Even in the scenario with the highest warming trend (A1B emission scenario for the period 2036–65), the current yield levels could be kept or even improved.\n",
      "--------------------------------------------------\n",
      "Topic 29: 29_vibrational_co2_rotational_spectra\n",
      "Representative Documents:\n",
      "  - New six-dimensional ab initio potential energy surfaces (PESs) for the N2–CO2 complex, which involve the stretching vibration of N2 and the Q3 normal mode for the ν3 asymmetric stretching vibration of CO2, were constructed using the CCSD(T)-F12/AVTZ method with midpoint bond functions. Two vibrational averaged 4D interaction potentials were obtained by integrating over the two intramolecular coordinates. It was found that both PESs possess two equivalent T-shaped global minima as well as two in-plane and one out-of-plane saddle points. Based on these PESs, rovibrational bound states and energy levels were calculated applying the radial discrete variable representation/angular finite basis representation method and the Lanczos algorithm. The splitting of the energy levels between oN2–CO2 and pN2–CO2 for the intermolecular vibrational ground state is determined to be only 0.000 09 cm−1 due to the higher barriers. The obtained band origin shift is about +0.471 74 cm−1 in the N2–CO2 infrared spectra with CO2 at the ν3 zone, which coincides with the experimental data of +0.483 74 cm−1. The frequencies of the in-plane geared-bending for N2–CO2 at the ν3 = 0 and 1 states of CO2 turn out to be 21.6152 and 21.4522 cm−1, the latter reproduces the available experimental 21.3793 cm−1 value with CO2 at the ν3 zone. The spectral parameters fitted from the rovibrational energy levels show that this dimer is a near prolate asymmetric rotor. The computed microwave transitions as well as the infrared fundamental and combination bands for the complex agree well with the observed data.\n",
      "  - Theoretical studies of the potential energy surface and bound states were performed for the CO2–N2O van der Waals complex. A four-dimensional intermolecular potential energy surface (PES) was constructed from 11 466 ab initio data points which were calculated at the coupled-cluster single double (triple) level with aug-cc-pVTZ basis set supplemented with bond functions. Three co-planar local minima were found on this surface. They correspond to two equivalent isomers with a slipped parallel structure in which the O atom in N2O is near the C atom in CO2 and a T-shaped isomer in which the terminal N atom in N2O is closest to the C atom in CO2. The two slipped parallel isomers are energetically more stable than the T-shaped isomer by 178 cm−1. Four fundamental vibrational excited states for the slipped parallel isomers and two fundamental vibrational excited states (torsion and disrotation) for the T-shaped isomer were assigned via bound states calculations based on this PES. The theoretical vibrational frequencies are in good agreement with the available experimental values for the slipped parallel isomers. Rotational excitations (J = 0–6) for the ground vibrational state of the slipped parallel structure were calculated and the accuracy of the PES in the vicinity of minima is validated by the good agreement between the theoretical and experimental transition frequencies and spectroscopic parameters.\n",
      "  - We present a new ab initio five-dimensional potential energy surface for the CO–CO2 complex containing the Q3 normal mode for the ν3 asymmetric stretching vibration of the CO2 unit. The potential was calculated by the supermolecular approach at the explicitly correlated coupled cluster [CCSD (T)-F12a] level with aug-cc-pVTZ basis set plus midpoint bond functions. Two vibrationally averaged four-dimensional potentials for CO–CO2 with CO2 at the ground and ν3 excited states were generated by the integration of the five-dimensional potential over the Q3 intramolecular coordinate. Each potential displays a T-shaped global minimum with the C end in the CO unit pointing toward the C atom in the CO2 unit and a T-shaped local minimum but with the CO monomer rotated by 180°. The rovibrational bound states and energy levels for the CO–CO2 dimer were obtained employing the radial discrete variable representation/angular finite basis representation method in conjunction with the Lanczos algorithm. The vibrational ground and some lower excited states for CO–CO2 are localized around the global minimum because of the higher potential barriers. The band origin is blueshifted by 0.2089 cm−1 for CO–CO2 in the CO2 ν3 range, which is consistent with the experimental result of 0.211 cm−1. The geared bending vibrational frequencies for CO–CO2 are 24.7101 and 24.5549 cm−1 at the ground and ν3 excited states of CO2, respectively. The predicted rovibrational frequencies, as well as spectral constants, coincide with the available observations, and these parameters show that the CO–CO2 complex is a nearly prolate asymmetric rotor.\n",
      "--------------------------------------------------\n",
      "Topic 30: 30_co2_catalysts_metal_conversion\n",
      "Representative Documents:\n",
      "  - Electrochemically reducing CO2 to more reduced chemical species is a promising way that not only enables the conversion of intermittent energy resources to stable fuels, but also helps to build a closed-loop anthropogenic carbon cycle. Among various electrocatalysts for electrochemical CO2 reduction, multifunctional metal–organic frameworks (MOFs) have been employed as highly efficient and selective heterogeneous electrocatalysts due to their ultrahigh porosity and topologically diverse structures. Up to now, great progress has been achieved in the design and synthesis of highly active and selective MOF-related catalysts for electrochemical CO2 reduction reaction (CO2RR), and their corresponding reaction mechanisms have been thoroughly studied. In this review, we summarize the recent progress of applying MOFs and their derivatives in CO2RR, with a focus on the design strategies for electrocatalysts and electrolyzers. We first discussed the reaction mechanisms for different CO2RR products and introduced the commonly applied electrolyzer configurations in the current CO2RR system. Then, an overview of several categories of products (CO, HCOOH, CH4, CH3OH, and multi-carbon chemicals) generated from MOFs or their derivatives via CO2RR was discussed. Finally, we offer some insights and perspectives for the future development of MOFs and their derivatives in electrochemical CO2 reduction. We aim to provide new insights into this field and further guide future research for large-scale applications.\n",
      "  - The interest in CO2 conversion to value-added chemicals and fuels has increased in recent years as part of strategic efforts to mitigate and use the excessive CO2 concentration in the atmosphere. Much attention has been given to developing two-dimensional catalytic materials with high-efficiency CO2 adsorption capability and conversion yield. While several candidates are being investigated, MXenes stand out as one of the most promising catalysts and co-catalysts for CO2 reduction, given their excellent surface functionalities, unique layered structures, high surface areas, rich active sites, and high chemical stability. This review aims to highlight research progress and recent developments in the application of MXene-based catalysts for CO2 conversion to value-added chemicals, paying special attention to photoreduction and electroreduction. Furthermore, the underlying photocatalytic and electrocatalytic CO2 conversion mechanisms are discussed. Finally, we provide an outlook for future research in this field, including photoelectrocatalysis and photothermal CO2 reduction.\n",
      "  - The conversion of CO2 to valuable substances (methane, methanol, formic acid, etc.) by photocatalytic reduction has important significance for both the sustainable energy supply and clean environment technologies. This review systematically summarized recent progress in this field and pointed out the current challenges of photocatalytic CO2 reduction while using metal-organic frameworks (MOFs)-based materials. Firstly, we described the unique advantages of MOFs based materials for photocatalytic reduction of CO2 and its capacity to solve the existing problems. Subsequently, the latest research progress in photocatalytic CO2 reduction has been documented in detail. The catalytic reaction process, conversion efficiency, as well as the product selectivity of photocatalytic CO2 reduction while using MOFs based materials are thoroughly discussed. Specifically, in this review paper, we provide the catalytic mechanism of CO2 reduction with the aid of electronic structure investigations. Finally, the future development trend and prospect of photocatalytic CO2 reduction are anticipated.\n",
      "--------------------------------------------------\n",
      "Topic 31: 31_beliefs_climate change_support_change\n",
      "Representative Documents:\n",
      "  - People’s perceptions of climate change represent a growing concern, especially when these perceptions entail the denial of climate change. Past studies have highlighted the detrimental role of conspiracist beliefs concerning climate change regarding people’s perceptions on this matter. However, the effects of generic conspiracy beliefs and the different types of beliefs determining skepticism about climate change, as well as that of an individual’s personality, are still an open area of inquiry. Our cross-sectional study (N = 842) explored the relationships between the degree to which people hold different generic conspiracy beliefs, their personality characteristics (as defined within the Big Five taxonomy), and climate change beliefs (i.e., in its occurrence and anthropogenic causation). Results indicated common predictors of these dimensions of climate change beliefs, specifically three of the five types of generic conspiracy beliefs, extraversion, agreeability, and intellect/imagination as personality factors. While conspiracy beliefs related to personal well-being emerged as related to climate change skepticism, those in government malfeasance and information control were found to be associated with more acceptance of climate change and its anthropogenic causation. These findings reveal a mixed pattern of relationships between different conspiracist beliefs and climate change perceptions and suggest the complex psychological and ideological underpinnings of the attitudes towards climate change.\n",
      "  - Political leaders can influence public beliefs about climate change, and climate beliefs can influence climate actions. But, much is still unknown about (1) whether changes in political landscapes influence public’s climate beliefs and (2) the psychological process through which climate beliefs influence pro-environmental sentiments and actions. Achieving a better understanding these influences are the dual purposes of this paper, we investigated during the unique setting of the 2016 US presidential elections. First, we explored to what extent the American public’s belief in the anthropogenic origins and negative impacts of climate change were influenced by the 2016 US presidential election and earliest administrative days of a climate-skeptical political leader, Donald Trump. We found Trump’s influence on public climate beliefs may have increased after his election in such a way that may have polarized public climate beliefs. Compared with pre-election levels, supporters’ climate beliefs grew weaker and, further, opponents’ climate beliefs grew stronger after his election. Second, we tested a novel conditional mediation model that proposes climate beliefs interact to exert their influence on climate actions via moral behavioral sentiments. Specifically, we found people’s origin and impact climate beliefs interact to influence climate actions by activating moral sentiments about their own environmental behavior (i.e., guilt, striving to be a better person), with the particularly weak moral sentiments reported by those with both weak belief in climate change’s anthropogenic origins and its negative impacts. Moral sentiments, in turn, predicted respondents’ willingness to save energy to reduce climate change and their support for the Paris Climate Agreement. These results suggest the election of climate-skeptical political leaders can impact the public’s climate beliefs. Moreover, climate beliefs interact to influence the moral sentiments people feel about their own behavior, and consequently, influence their climate-friendly behavioral intentions and policy preferences.\n",
      "  - A growing body of research demonstrates that believing action to reduce the risks of climate change is both possible (self‐efficacy) and effective (response efficacy) is essential to motivate and sustain risk mitigation efforts. Despite this potentially critical role of efficacy beliefs, measures and their use vary wildly in climate change risk perception and communication research, making it hard to compare and learn from efficacy studies. To address this problem and advance our understanding of efficacy beliefs, this article makes three contributions. First, we present a theoretically motivated approach to measuring climate change mitigation efficacy, in light of diverse proposed, perceived, and previously researched strategies. Second, we test this in two national survey samples (Amazon's Mechanical Turk N = 405, GfK Knowledge Panel N = 1,820), demonstrating largely coherent beliefs by level of action and discrimination between types of efficacy. Four additive efficacy scales emerge: personal self‐efficacy, personal response efficacy, government and collective self‐efficacy, and government and collective response efficacy. Third, we employ the resulting efficacy scales in mediation models to test how well efficacy beliefs predict climate change policy support, controlling for specific knowledge, risk perceptions, and ideology, and allowing for mediation by concern. Concern fully mediates the relatively strong effects of perceived risk on policy support, but only partly mediates efficacy beliefs. Stronger government and collective response efficacy beliefs and personal self‐efficacy beliefs are both directly and indirectly associated with greater support for reducing the risks of climate change, even after controlling for ideology and causal beliefs about climate change.\n",
      "--------------------------------------------------\n",
      "Topic 32: 32_cloud_radiative_feedback_clouds\n",
      "Representative Documents:\n",
      "  -                Reanalysis data and radiation budget data are used to calculate the role of the atmospheric cloud radiative effect in determining the magnitude of horizontal export of energy by the tropical atmosphere. Because tropical high clouds result in net radiative heating of the atmosphere, they increase the requirement for the atmosphere to export energy from convective regions. Increases in upper-tropospheric water vapor associated with convection contribute about a fifth of the atmospheric radiative heating anomaly associated with convection. Over the warmest tropical oceans, the radiative effect of convective clouds and associated water vapor is roughly two-thirds the value of the atmospheric energy transport. Cloud radiative heating and atmospheric heat transport increase at the same rate with increasing sea surface temperature, suggesting that the increased energy export is supplied by the radiative heating associated with convective clouds. The net cloud radiative effect at the top of the atmosphere is insensitive to changes in SST over the warm pool. Principal component analysis of satellite-retrieved cloud data reveals that the insensitivity of the net cloud radiative effect to SST is the result of changes in cloud amount offsetting changes in cloud optical thickness and cloud-top height. While increasing upward motion makes the cloud radiative effect more negative, that decrease is offset by reductions in outgoing longwave radiation owing to increases in water vapor.\n",
      "  -                Using five climate model simulations of the response to an abrupt quadrupling of CO2, the authors perform the first simultaneous model intercomparison of cloud feedbacks and rapid radiative adjustments with cloud masking effects removed, partitioned among changes in cloud types and gross cloud properties. Upon CO2 quadrupling, clouds exhibit a rapid reduction in fractional coverage, cloud-top pressure, and optical depth, with each contributing equally to a 1.1 W m−2 net cloud radiative adjustment, primarily from shortwave radiation. Rapid reductions in midlevel clouds and optically thick clouds are important in reducing planetary albedo in every model. As the planet warms, clouds become fewer, higher, and thicker, and global mean net cloud feedback is positive in all but one model and results primarily from increased trapping of longwave radiation. As was true for earlier models, high cloud changes are the largest contributor to intermodel spread in longwave and shortwave cloud feedbacks, but low cloud changes are the largest contributor to the mean and spread in net cloud feedback. The importance of the negative optical depth feedback relative to the amount feedback at high latitudes is even more marked than in earlier models. The authors show that the negative longwave cloud adjustment inferred in previous studies is primarily caused by a 1.3 W m−2 cloud masking of CO2 forcing. Properly accounting for cloud masking increases net cloud feedback by 0.3 W m−2 K−1, whereas accounting for rapid adjustments reduces by 0.14 W m−2 K−1 the ensemble mean net cloud feedback through a combination of smaller positive cloud amount and altitude feedbacks and larger negative optical depth feedbacks.\n",
      "  -  This study proposes a novel technique for computing cloud feedbacks using histograms of cloud fraction as a joint function of cloud-top pressure (CTP) and optical depth (τ). These histograms were generated by the International Satellite Cloud Climatology Project (ISCCP) simulator that was incorporated into doubled-CO2 simulations from 11 global climate models in the Cloud Feedback Model Intercomparison Project. The authors use a radiative transfer model to compute top of atmosphere flux sensitivities to cloud fraction perturbations in each bin of the histogram for each month and latitude. Multiplying these cloud radiative kernels with histograms of modeled cloud fraction changes at each grid point per unit of global warming produces an estimate of cloud feedback. Spatial structures and globally integrated cloud feedbacks computed in this manner agree remarkably well with the adjusted change in cloud radiative forcing. The global and annual mean model-simulated cloud feedback is dominated by contributions from medium thickness (3.6 &lt; τ ≤ 23) cloud changes, but thick (τ &gt; 23) cloud changes cause the rapid transition of cloud feedback values from positive in midlatitudes to negative poleward of 50°S and 70°N. High (CTP ≤ 440 hPa) cloud changes are the dominant contributor to longwave (LW) cloud feedback, but because their LW and shortwave (SW) impacts are in opposition, they contribute less to the net cloud feedback than do the positive contributions from low (CTP &gt; 680 hPa) cloud changes. Midlevel (440 &lt; CTP ≤ 680 hPa) cloud changes cause positive SW cloud feedbacks that are 80% as large as those due to low clouds. Finally, high cloud changes induce wider ranges of LW and SW cloud feedbacks across models than do low clouds. \n",
      "--------------------------------------------------\n",
      "Topic 33: 33_satellite_merra_reanalyses_reanalysis\n",
      "Representative Documents:\n",
      "  - Continuous satellite-derived cloud records now extend over three decades, and are increasingly used for climate applications. Certain applications, such as trend detection, require a clear understanding of uncertainty as it relates to establishing statistical significance. The use of reanalysis products as sources of ancillary data could be construed as one such source of uncertainty, as there has been discussion regarding the suitability of reanalysis products for trend detection. Here we use three reanalysis products: Climate Forecast System Reanalysis (CFSR), Modern Era Retrospective Analysis for Research and Applications (MERRA) and European Center for Medium range Weather Forecasting (ECMWF) ERA-Interim (ERA-I) as sources of ancillary data for the Pathfinder Atmospheres Extended/Advanced Very High Resolution Radiometer (PATMOS-x/AVHRR) Satellite Cloud Climate Data Record (CDR), and perform inter-comparisons to determine how sensitive the climatology is to choice of ancillary data source. We find differences among reanalysis fields required for PATMOS-x processing, which translate to small but not insignificant differences in retrievals of cloud fraction, cloud top height and cloud optical depth. The retrieval variability due to choice of reanalysis product is on the order of one third the size of the retrieval uncertainty, making it a potentially significant factor in trend detection. Cloud fraction trends were impacted the most by choice of reanalysis while cloud optical depth trends were impacted the least. Metrics used to determine the skill of the reanalysis products for use as ancillary data found no clear best choice for use in PATMOS-x. We conclude use of reanalysis products as ancillary data in the PATMOS-x/AVHRR Cloud CDR do not preclude its use for trend detection, but for that application uncertainty in reanalysis fields should be better represented in the PATMOS-x retrieval uncertainty.\n",
      "  -                Reanalysis products produced at the various centers around the globe are utilized for many different scientific endeavors, including forcing land surface models and creating surface flux estimates. Here, flux tower observations of temperature, wind speed, precipitation, downward shortwave radiation, net surface radiation, and latent and sensible heat fluxes are used to evaluate the performance of various reanalysis products [NCEP–NCAR reanalysis and Climate Forecast System Reanalysis (CFSR) from NCEP; 40-yr European Centre for Medium-Range Weather Forecasts (ECMWF) Re-Analysis (ERA-40) and ECMWF Interim Re-Analysis (ERA-Interim) from ECMWF; and Modern-Era Retrospective Analysis for Research and Applications (MERRA) and Global Land Data Assimilation System (GLDAS) from the Goddard Space Flight Center (GSFC)]. To combine the biases and standard deviation of errors from the separate stations, a ranking system is utilized. It is found that ERA-Interim has the lowest overall bias in 6-hourly air temperature, followed closely by MERRA and GLDAS. The variability in 6-hourly air temperature is again most accurate in ERA-Interim. ERA-40 is found to have the lowest overall bias in latent heat flux, followed closely by CFSR, while ERA-40 also has the lowest 6-hourly sensible heat bias. MERRA has the second lowest and is close to ERA-40. The variability in 6-hourly precipitation is best captured by GLDAS and ERA-Interim, and ERA-40 has the lowest precipitation bias. It is also found that at monthly time scales, the bias term in the reanalysis products are the dominant cause of the mean square errors, while at 6-hourly and daily time scales the dominant contributor to the mean square errors is the correlation term. Also, it is found that the hourly CFSR data have discontinuities present due to the assimilation cycle, while the hourly MERRA data do not contain these jumps.\n",
      "  -                The Advanced Very High Resolution Radiometer (AVHRR) outgoing longwave radiation (OLR) product, which NOAA has been operationally generating since 1979, is a very long data record that has been used in many applications, yet past studies have shown its limitations and several algorithm-related deficiencies. Ellingson et al. have developed the multispectral algorithm that largely improved the accuracy of the narrowband-estimated OLR as well as eliminated the problems in AVHRR. NOAA has been generating High Resolution Infrared Radiation Sounder (HIRS) OLR operationally since September 1998. In recognition of the need for a continuous and long OLR data record that would be consistent with the earth radiation budget broadband measurements in the National Polar-orbiting Operational Environmental Satellite System (NPOESS) era, and to provide a climate data record for global change studies, a vigorous reprocessing of the HIRS radiance for OLR derivation is necessary.               This paper describes the development of the new HIRS OLR climate dataset. The HIRS level 1b data from the entire Television and Infrared Observation Satellite N-series (TIROS-N) satellites have been assembled. A new radiance calibration procedure was applied to obtain more accurate and consistent HIRS radiance measurements. The regression coefficients of the HIRS OLR algorithm for all satellites were rederived from calculations using an improved radiative transfer model. Intersatellite calibrations were performed to remove possible discontinuity in the HIRS OLR product from different satellites. A set of global monthly diurnal models was constructed consistent with the HIRS OLR retrievals to reduce the temporal sampling errors and to alleviate an orbital-drift-induced artificial trend. These steps significantly improved the accuracy, continuity, and uniformity of the HIRS monthly mean OLR time series. As a result, the HIRS OLR shows a comparable stability as in the Earth Radiation Budget Satellite (ERBS) nonscanner OLR measurements.               HIRS OLR has superb agreement with the broadband observations from Earth Radiation Budget Experiment (ERBE) and Clouds and the Earth’s Radiant Energy System (CERES) in the ENSO-monitoring regions. It shows compatible ENSO-monitoring capability with the AVHRR OLR. Globally, HIRS OLR agrees with CERES with an accuracy to within 2 W m−2 and a precision of about 4 W m−2. The correlation coefficient between HIRS and CERES global monthly mean is 0.997. Regionally, HIRS OLR agrees with CERES to within 3 W m−2 with precisions better than 3 W m−2 in most places. HIRS OLR could be used for constructing climatology for applications that plan to use NPOESS ERBS and previously used AVHRR OLR observations. The HIRS monthly mean OLR data have high accuracy and precision with respect to the broadband observations of ERBE and CERES. It can be used as an independent validation data source. The uniformity and continuity of HIRS OLR time series suggest that it could be used as a reliable transfer reference for the discontinuous broadband measurements from ERBE, CERES, and ERBS.\n",
      "--------------------------------------------------\n",
      "Topic 34: 34_laser_patients_co2 laser_treatment\n",
      "Representative Documents:\n",
      "  -                 Background                The appearance of skin scars is known as one of the main side effects of skin burns. Stromal vascular fraction (SVF), as a rich source of cell populations with tissue regeneration properties, plays an important role in the healing of skin lesions. Fractional CO2 lasers have occupied a special place in treating skin lesions, particularly skin scars, since their introduction. Our study aimed to compare the combination of SVF and fractional CO2 laser with fractional CO2 laser alone in the treatment of burn scars.                              Method                This double-blind clinical trial study was conducted on ten patients with burn scars that were treated three times with a fractional CO2 laser at site of burn lesions, and one of the two areas studied was randomly injected with SVF. Two months after completion of the procedure, patients' scars were assessed using the Vancouver scar scale (VSS), biometric criteria, and physician and patient satisfaction ratings.                              Results                The results confirmed a significant improvement in VSS, cutometry, R7 criteria, complete density sonography, and skin density sonography in the fractional CO2 laser-treated group. The VSS criteria, epidermal thickness sonography, complete density sonography, and skin density sonography in the group treated with the combination of fractional CO2 laser and SVF also showed significant improvement. The VSS criteria and melanin index of Mexameter in the group treated with SVF in combination with fractional CO2 laser were significantly better than the group treated with fractional CO2 laser alone. Also, physician and patient satisfaction in the group treated with SVF injection in combination with fractional CO2 laser was significantly higher than the other group.                              Conclusion                The results confirm the efficacy of SVF injection in combination with fractional CO2 laser in the treatment of burn scars and can be considered as a treatment option for better management of these lesions.                Trial registration: The study protocol was retrospectively registered at Iranian Registry of Clinical Trials with code: IRCT20210515051307N1, Registration date: 2021-11-14, URL: https://www.irct.ir/trial/56337.              \n",
      "  - BACKGROUND          Scar is one of the most common complications for patients with cleft lip. Fractional CO2 laser is an effective method to improve the appearance of scars. However, there are no published articles about the optimal time for applying.                      OBJECTIVE            To determine the optimal time to apply a fractional CO2 laser for the treatment of postsecondary repair scars in patients with cleft lip.                                METHODS            Forty-two patients with linear scarring after cleft lip repair were recruited from November 2021 to October 2022. A single-blind, randomized, controlled cohort study was conducted to examine the impact of fractional CO2 laser treatment compared with conventional conservative treatment. Thirty patients started laser treatment at 1 month (n = 10), 3 months (n = 10), and 6 months (n = 10) postoperatively, and 12 patients were in the control group. Each patient was treated with high-energy low-density fractional CO2 laser treatment 3 times at an interval of 1 month. The Vancouver Scar Scale (VSS) was used for scar evaluation to determine vascularity, pigmentation, pliability, and height.                                RESULTS            The VSS scores decreased significantly after laser treatment (p &lt; .05), with the most significant improvement in scars in the group that started treatment 1 month after the surgery.                                CONCLUSION            Early postoperative fractional CO2 laser treatment of cleft lip scars is more effective than later treatment.          \n",
      "  - SummaryBackgroundFractional CO2 laser and platelet‐rich plasma (PRP) treatments have been used in the treatment of acne scars. However, an objective method of assessment has been lacking.ObjectiveTo evaluate the efficacy of CO2 laser versus the combination of PRP and fractional CO2 laser in treatment of acne scar.Patients and methodsThirty patients with atrophic acne scar lesions were included in this study. Patients were randomized to receive fractional CO2 laser therapy to one side of the face while the other side of the face was treated with fractional CO2 laser followed by intradermal PRP injection. Follow‐up using the skin analysis camera system and photography was done for three months.ResultsA dramatic improvement was observed in the scar depth on both sides of the face. However, the combined fractional CO2 laser and PRP showed more significant improvement. Improvements in the scar appearance and skin texture were reported by the patients. Although 70% of our patients were of a dark skin type, no hyperpigmentation was reported.ConclusionThe combined use of fractional CO2 laser and PRP achieved better results. It reduced the downtime of the fractional CO2 laser. The use of the skin analysis camera provided an objective assessment of the results.\n",
      "--------------------------------------------------\n",
      "Topic 35: 35_oil_co2_injection_permeability\n",
      "Representative Documents:\n",
      "  - SummaryCarbon dioxide (CO2) flooding is a common method for enhancing oil recovery in conventional and tight sandstone reservoirs. Nevertheless, CO2 flooding suitability for shale oil reservoirs with low permeability, low porosity, and rich organic matter (kerogen) remains controversial. In this study, the kerogen effects on the flow and enhanced oil recovery (EOR) behavior of oil in shale cores during CO2 flooding were investigated using nuclear magnetic resonance (NMR). The effects of injection pressure, temperature, and injected pore volume (PV) on the EOR properties of shale cores were considered. Moreover, the flow mechanism of oil displacement by CO2 flooding in shale was discussed by measuring the oil content variations in different core sections. The recovery was lower for the shale cores than for the tight sandstone cores; moreover, the shale oil recovery increased with increased injection pressure, temperature, and injected PV. The recovery was approximately 30% even after 7 PV of CO2 flooding at 18 MPa and 45°C. During the CO2 flooding process, the oil near the core inlet flowed more easily than that near the outlet, indicating CO2oil miscible fluid formation near the inlet, hampering the displacement of further saturated oil in the core. The kerogen presence in shale reduced the oil mobility and substantially decreased the oil recovery owing to the strong interactions between kerogen and oil. High injection pressure and injected PV increased the oil-in-shale flow performance and enhanced the shale oil recovery in CO2 flooding to a certain extent.\n",
      "  - The Chang 7 shale oil reservoir has low natural energy and is both tight and highly heterogeneous, resulting in significant remaining oil after depletion development. CO2 huff and puff (huff-n-puff) is an effective way to take over from depletion development. Numerous scholars have studied and analyzed the CO2 huff-n-puff mechanism and parameters based on laboratory core sample huff-n-puff experiments. However, experimental procedures are not comprehensive, leading to more general studies of some mechanisms, and existing CO2 huff-n-puff experiments struggle to reflect the effect of actual reservoir heterogeneity due to the limited length of the experimental core samples. In this paper, CO2 huff-n-puff laboratory experiments were performed on short (about 5 cm) and long (about 100 cm) core samples from the Chang 7 shale oil reservoir, and the microscopic pore fluid utilization in the short samples was investigated using a nuclear magnetic resonance (NMR) technique. We then analyzed and discussed the seven controlling factors of CO2 huff-n-puff and their recovery-enhancing mechanisms. The experimental results show that the cumulative recovery increased with the number of huff-n-puff cycles, but the degree of cycle recovery decreased due to the limitation of the differential pressure of the production. The significant increase in recovery after the CO2 mixed-phase drive was achieved by increasing the minimum depletion pressure as well as the gas injection amount. The soaking time was adjusted appropriately to ensure that the injected energy was thoroughly utilized; too short or too long a soaking time was detrimental. The pressure depletion rate was the main factor in the CO2 huff-n-puff effect in shale. If the pressure depletion rate was very high, the effective permeability loss was larger. In the CO2 huff-n-puff process of the Chang 7 shale oil reservoir, the improvement in oil recovery was mainly contributed to by mesopores and small pores. The huff-n-puff experiments using long cores could better characterize the effect of heterogeneity on the huff-n-puff effect than short cores.\n",
      "  - This work is devoted to CO2 Huff-n-Puff studies on heavy oil. Oil recovery for heavy oil reservoirs is sufficiently small in comparison with conventional reservoirs, and, due to the physical limitation of oil flow through porous media, a strong need for better understanding of tertiary recovery mechanisms of heavy oil exists. Notwithstanding that the idea of Huff-n-Puff gas injection technology for enhanced oil recovery has existed for dozens of years, there is still no any precise methodology for evaluating the applicability and efficiency of this technology in heavy oil reservoirs. Oil recovery factor is a question of vital importance for heavy oil reservoirs. In this work, we repeated Huff-n-Puff tests more than three times at five distinct pressure points to evaluate the applicability and efficiency of CO2 Huff-n-Puff injection to the heavy oil reservoirs. Additionally, the most critical factor that affects oil recovery in gas injection operation is the condition of miscibility. Experimental data allowed to distinguish the mixing zone of the light fractions of studied heavy oil samples. The experimental results showed that the pressure increase in the Huff-n-Puff injection process does not affect the oil recovery when the injection pressure stays between miscibility pressure of light components of oil and minimum miscibility pressure. It was detected that permeability decreases after Huff-n-Puff CO2 tests.\n",
      "--------------------------------------------------\n",
      "Topic 36: 36_science_agu_scientists_statement\n",
      "Representative Documents:\n",
      "  - The Bush administration has a problematic relationship with climate science research and the U.S. Climate Change Science Program (CCSP), the program through which federal agencies coordinate support for research on climate and global change. The administration has acted to impede forthright communication of the state of climate science and its implications for society, particularly at the points at which key scientifically‐based assessments of climate change touch on the arenas of policy‐making and research planning.The administration essentially has suppressed a major study, the National Assessment of Climate Change Impacts, which was produced by an independent team of scientists with the support of the federal research program [National Assessment Synthesis Team, 2000, 2001; Piltz, 2005; Thacker, 2005a; Thacker, 2005b] (http://www.usgcrp.gov/usgcrp/nacc/). In its place, the administration has substituted a set of 21 prospective synthesis reports on disparate topics, under a process in which drafts by lead authors will undergo final review at a political level prior to being published as government documents (described at http://www.climatescience.gov).\n",
      "  - The Bush administration's draft strategic plan for the federal government's Climate Change Science Program (CCSP) represents a good start, but it requires substantial improvements to the science, and to the program management, according to a review issued by the U.S. National Research Council on 26 February.CCSP Director James Mahoney promised an improved final plan—likely in April—which incorporates many of the concerns raised by the NRC and by others who have commented on it. The draft, released on 11 November 2002, is a first attempt to chart a course for the CCSP That program incorporates the decade‐long, Congressionally‐mandated U.S. Global Change Research Program, and the administration's Climate Change Research Initiative.\n",
      "  - The U.S. Climate Change Science Program issued a draft strategic plan for the Climate Change Science Program on 11 November. The plan, which provides a synthesis and update on the Bush Administration's thinking and direction on dealing with climate change, includes sections on the administration's Climate Change Research Initiative and the U.S. Global Change Research Program, as well as dozens of lists of climate science research needs and potential research products.The plan was released in advance of a major Washington, D.C. workshop for scientists and stakeholders on 3–5 December, which will examine the draft plan.\n",
      "--------------------------------------------------\n",
      "Topic 37: 37_rcp_future_rcp8_streamflow\n",
      "Representative Documents:\n",
      "  - Water resources are highly dependent on climatic variations. The quantification of climate change impacts on surface water availability is critical for agriculture production and flood management. The current study focuses on the projected streamflow variations in the transboundary Mangla Dam watershed. Precipitation and temperature changes combined with future water assessment in the watershed are projected by applying multiple downscaling techniques for three periods (2021–2039, 2040–2069, and 2070–2099). Streamflows are simulated by using the Soil and Water Assessment Tool (SWAT) for the outputs of five global circulation models (GCMs) and their ensembles under two representative concentration pathways (RCPs). Spatial and temporal changes in defined future flow indexes, such as base streamflow, average flow, and high streamflow have been investigated in this study. Results depicted an overall increase in average annual flows under RCP 4.5 and RCP 8.5 up until 2099. The maximum values of low flow, median flow, and high flows under RCP 4.5 were found to be 55.96 m3/s, 856.94 m3/s, and 7506.2 m3/s and under RCP 8.5, 63.29 m3/s, 945.26 m3/s, 7569.8 m3/s, respectively, for these ensembles GCMs till 2099. Under RCP 4.5, the maximum increases in maximum temperature (Tmax), minimum temperature (Tmin), precipitation (Pr), and average annual streamflow were estimated as 5.3 °C, 2.0 °C, 128.4%, and 155.52%, respectively, up until 2099. In the case of RCP 8.5, the maximum increase in these hydro-metrological variables was up to 8.9 °C, 8.2 °C, 180.3%, and 181.56%, respectively, up until 2099. The increases in Tmax, Tmin, and Pr using ensemble GCMs under RCP 4.5 were found to be 1.95 °C, 1.68 °C and 93.28% (2021–2039), 1.84 °C, 1.34 °C, and 75.88%(2040–2069), 1.57 °C, 1.27 °C and 72.7% (2070–2099), respectively. Under RCP 8.5, the projected increases in Tmax, Tmin, and Pr using ensemble GCMs were found as 2.26 °C, 2.23 °C and 78.65% (2021–2039), 2.73 °C, 2.53 °C, and 83.79% (2040–2069), 2.80 °C, 2.63 °C and 67.89% (2070–2099), respectively. Three seasons (spring, winter, and autumn) showed a remarkable increase in streamflow, while the summer season showed a decrease in inflows. Based on modeling results, it is expected that the Mangla Watershed will experience more frequent extreme flow events in the future, due to climate change. These results indicate that the study of climate change’s impact on the water resources under a suitable downscaling technique is imperative for proper planning and management of the water resources.\n",
      "  - Climate change plays a pivotal role in the hydrological dynamics of tributaries in the upper Blue Nile basin. The understanding of the change in climate and its impact on water resource is of paramount importance to sustainable water resources management. This study was designed to reveal the extent to which the climate is being changed and its impacts on stream flow of the Gumara watershed under the Representative Concentration Pathway (RCP) climate change scenarios. The study considered the RCP 2.6, RCP 4.5, and RCP 8.5 scenarios using the second-generation Canadian Earth System Model (CanESM2). The Statistical Downscaling Model (SDSM) was used for calibration and projection of future climatic data of the study area. Soil and Water Assessment Tool (SWAT) model was used for simulation of the future stream flow of the watershed. Results showed that the average temperature will be increasing by 0.84 °C, 2.6 °C, and 4.1 °C in the end of this century under RCP 2.6, RCP 4.5, and RCP 8.5 scenarios, respectively. The change in monthly rainfall amount showed a fluctuating trend in all scenarios but the overall annual rainfall amount is projected to increase by 8.6%, 5.2%, and 7.3% in RCP 2.6, RCP 4.5, and RCP 8.5, respectively. The change in stream flow of Gumara watershed under RCP 2.6, RCP 4.5, and RCP 8.5 scenarios showed increasing trend in monthly average values in some months and years, but a decreasing trend was also observed in some years of the studied period. Overall, this study revealed that, due to climate change, the stream flow of the watershed is found to be increasing by 4.06%, 3.26%, and 3.67%under RCP 2.6, RCP 4.5, and RCP 8.5 scenarios, respectively.\n",
      "  - Global climate change is becoming an increasingly important issue that threatens the imperiled planet. Quantifying the impact of climate change on the streamflow has been an essential task for the proper management of water resources to mitigate this impact. This study aims to evaluate the skill of an artificial neural network (ANN) method in downscaling precipitation, maximum temperature, and minimum temperature and assess the potential impacts of climate change on the streamflow in the Wabash River Basin of the Midwestern United States (U.S.) using the Soil and Water Assessment Tool (SWAT). A statistical downscaling technique based on an ANN method was employed to estimate precipitation and temperature at a higher resolution. The downscaled climate projections from five general circulation models (GCMs) under the three representative concentration pathway (RCP) scenarios (i.e., RCP2.6, RCP4.5, and RCP8.5) for the periods of 2026–2050 and 2075–2099 as well as the historical period were incorporated into the SWAT model to assess the potential impact of climate change on the Wabash River regime. Calibration and validation of the SWAT model indicated the streamflow simulations matched the observed results very well. The ANN method successfully reproduced the observed maximum/minimum temperature and precipitation; however, bias in precipitation was observed in regard to the frequency distribution. Compared with the simulated streamflow in the historical period, the predicted streamflow based on the RCP scenarios showed an obvious decreasing trend, where the annual streamflows will be decreased by 13.00%, 17.59%, and 6.91% in the midcentury periods and 25.29%, 27.61%, and 15.04% in the late-century periods under the RCP2.6, RCP4.5, and RCP8.5 scenarios, respectively. Climate warming dominated the streamflow decrease under the RCP2.6 and RCP4.5 scenarios. By contrast, under RCP8.5, the streamflow was affected by the joint actions of changes in temperature and precipitation.\n",
      "--------------------------------------------------\n",
      "Topic 38: 38_power_cycle_exergy_co2\n",
      "Representative Documents:\n",
      "  - The comparative performance study is carried out for 500 MW Supercritical (SupC) Oxy-Coal Combustion (OCC) and Air-Coal Combustion (ACC) power plants with membrane-based CO2 capture at the fixed furnace temperature. The proposed configurations are modelled using a computer-based analysis software 'Cycle-Tempo' at different operating conditions, and the detailed thermodynamic study is done by considering Energy, Exergy, and Environmental (3-E) analysis. The result shows that the net energy and exergy efficiencies of ACC power plants with CO2 capture are about 35.07 % and 30.88 %, respectively, which are about 6.44 % and 5.77 % points, respectively higher than that of OCC power plant. Auxiliary power consumption of OCC based power plant is almost 1.97 times more than that of the ACC based plant due to huge energy utilization in the Air Separation Unit (ASU) of OCC plant which leads to performance reduction in OCC plant. However, environmental benefit of OCC based power plant is more than that of ACC based power plant with respect to CO2 emission. OCC plant emits about 0.164 kg/kWh of CO2 which is approximately 16.75 times lower than the CO2 emission in ACC based power plant. It is also analyzed that the performance of the CO2 Capture Unit (CCU) for the OCC based plant is about 3.65 times higher than the ACC based power plant due to higher concentration of CO2 (nearly 80.63%) in the flue gas emitting from OCC plant. The study also reveals that the auxiliary power consumption per kg of CO2 capture of the OCC based plant is about 0.142 kWh/kg, which is approximately 0.06 times lower than the ACC based plant. The higher performance of the OCC based power plant is found at lower value of flue gas recirculation due to the fact that reduction in exergy destruction at the mixing zone of the combustor is higher than the increase in exergy destruction of the heat exchangers at higher furnace exit temperature. But the metallurgical temperature limit of boiler tube materials restricts the use of the higher value of furnace temperature. OCC based power plant with CO2 capture can be preferred over ACC based plant with CO2 capture due to higher environmental benefits towards mitigating CO2, the key greenhouse gas on earth in spite of exhibiting lesser energy and exergy efficiencies.\n",
      "  - The European electric power industry has undergone considerable changes over the past two decades as a result of more stringent laws concerning environmental protection along with the deregulation and liberalization of the electric power market. However, the pressure to deliver solutions in regard to the issue of climate change has increased dramatically in the last few years and has given rise to the possibility that future natural gas-fired combined cycle (NGCC) plants will also be subject to CO2 capture requirements. At the same time, the interest in combined cycles with their high efficiency, low capital costs, and complexity has grown as a consequence of addressing new challenges posed by the need to operate according to market demand in order to be economically viable. Considering that these challenges will also be imposed on new natural gas-fired power plants in the foreseeable future, this study presents a new process concept for natural gas combined cycle power plants with CO2 capture. The simulation tool IPSEpro is used to model a 400 MW single-pressure NGCC with post-combustion CO2 capture using an amine-based absorption process with monoethanolamine. To improve the costs of capture, the gas turbine GE 109FB is utilizing exhaust gas recirculation, thereby, increasing the CO2 content in the gas turbine working fluid to almost double that of conventional operating gas turbines. In addition, the concept advantageously uses approximately 20% less steam for solvent regeneration by utilizing preheated water extracted from heat recovery steam generator. The further recovery of heat from exhaust gases for water preheating by use of an increased economizer flow results in an outlet stack temperature comparable to those achieved in combined cycle plants with multiple-pressure levels. As a result, overall power plant efficiency as high as that achieved for a triple-pressure reheated NGCC with corresponding CO2 removal facility is attained. The concept, thus, provides a more cost-efficient option to triple-pressure combined cycles since the number of heat exchangers, boilers, etc., is reduced considerably.\n",
      "  - For developing a sustainable power system, the key is to maximize the use of available resources with a minimal impact on the environment. One technique for achieving this is exhaust heat recovery. In this paper, three gas turbine exhaust heat recovery supercritical carbon dioxide combined power cycles are presented. They are combined gas turbine-recompression cycle, combined gas turbine-preheating cycle, and combined gas turbine-simple regenerative cycle. For all the cycles, thermodynamic models are developed and the influence of varying mass flow rates, compression ratio, and mass split/recompression percentages in different components of all three cycles are investigated. Using genetic algorithm, exergetic optimization is done to find the optimal configuration for each cycle. The reduction in CO2 emissions in presented cycles against fossil fuel power cycles is also assessed. Additionally, a comparison with a simple gas turbine (SGT) and an air bottoming combined cycle (ABC) is presented. The results indicate that owing to exhaust exergy recovery, there is a significant improvement in the energetic and exergetic performance of combined gas turbine-supercritical CO2 power cycles compared to that of SGT and ABC. The sum of exergy destruction and exergy loss in the combined cycles is lower as compared to the sum in SGT. The reduction in losses compared to SGT is 22.89% in the case of the combined gas turbine recompression cycle and 35.8% in the case of the combined gas turbine preheating cycle (CGTPHC). Moreover, the energetic and exergetic performances of the bottoming supercritical CO2 recompression cycles (BRECs) are better than those of the bottoming supercritical CO2 preheating cycle owing to lower exergy destruction in the components of BREC. As a result of comparative analysis based on the exergetic performance and environmental impact, the CGTPHC is selected as an appropriate option for gas turbine exhaust exergy recovery.\n",
      "--------------------------------------------------\n",
      "Topic 39: 39_rainfall_trend_trends_mann\n",
      "Representative Documents:\n",
      "  -                Global warming and climate variability are emerging as the foremost environmental problems in the 21st century, particularly in developing countries. Ethiopia is one of the countries located in the sub-Sahara region and climate variability has a significant impact on the economy of the country. The aim of this study is to characterize annual and seasonal rainfall and annual temperature variability, and to measure trends on both the spatial and the temporal scale for ten selected stations in the Tana basin region, Ethiopia. The Mann–Kendall test and Sen's slope estimator were used to assess trends and variability of rainfall and temperature. The spatial distribution of rainfall and temperature was determined using the inverse distance weighted technique. Results indicated that the amount of rainfall decreased for the majority of the stations. The annual rainfall showed significant decreasing trends with a magnitude ranging from −5.92 mm/year at Injibara to −9.74 mm/year in Wegera. However, a positive trend of annual rainfall was observed at Addis Zemen (1.81 mm/year). The minimum, maximum and mean temperatures have increased significantly for most of the stations. An increasing trend of annual maximum temperature was obtained between 1980 and 2015; an increase of 1.08°C was observed.\n",
      "  - Climate change can have an influence on rainfall that significantly affects the magnitude frequency of floods and droughts. Therefore, the analysis of the spatiotemporal distribution, variability, and trends of rainfall over the Mahi Basin in India is an important objective of the present work. Accordingly, a serial autocorrelation, coefficient of variation, Mann–Kendall (MK) and Sen’s slope test, innovative trend analysis (ITA), and Pettitt’s test were used in the rainfall analysis. The outcomes were derived from the monthly precipitation data (1901–2012) of 14 meteorology stations in the Mahi Basin. The serial autocorrelation results showed that there is no autocorrelation in the data series. The rainfall statistics denoted that the Mahi Basin receives 94.8% of its rainfall (821 mm) in the monsoon period (June–September). The normalized accumulated departure from the mean reveals that the annual and monsoon rainfall of the Mahi Basin were below average from 1901 to 1930 and above average from 1930 to 1990, followed by a period of fluctuating conditions. Annual and monsoon rainfall variations increase in the lower catchment of the basin. The annual and monsoon rainfall trend analysis specified a significant declining tendency for four stations and an increasing tendency for 3 stations, respectively. A significant declining trend in winter rainfall was observed for 9 stations under review. Likewise, out of 14 stations, 9 stations denote a significant decrease in pre-monsoon rainfall. Nevertheless, there is no significant increasing or decreasing tendency in annual, monsoon, and post-monsoon rainfall in the Mahi Basin. The Mann–Kendall test and innovative trend analysis indicate identical tendencies of annual and seasonal rainfall on the basin scale. The annual and monsoon rainfall of the basin showed a positive shift in rainfall after 1926. The rainfall analysis confirms that despite spatiotemporal variations in rainfall, there are no significant positive or negative trends of annual and monsoon rainfall on the basin scale. It suggests that the Mahi Basin received average rainfall (867 mm) annually and in the monsoon season (821 mm) from 1901 to 2012, except for a few years of high and low rainfall. Therefore, this study is important for flood and drought management, agriculture, and water management in the Mahi Basin.\n",
      "  - This study investigated the trends and variability of seasonal and annual rainfall and temperature data over southern Ethiopia using time series analysis for the period 1983–2016. Standard Anomaly Index (SAI), Coefficient of Variation (CV), Precipitations Concentration Index (PCI), and Standard Precipitation Index (SPI) were used to examine rainfall variability and develop drought indices over southern Ethiopia. Temporal changes of rainfall trends over the study period were detected using Mann Kendall (MK) trend test and Sen’s slope estimator. The results showed that the region experienced considerable rainfall variability and change that resulted in extended periods of drought and flood events within the study period. Results from SAI and SPI indicated an inter-annual rainfall variability with the proportions of years with below and above normal rainfall being estimated at 56% and 44% respectively. Results from the Mann Kendall trend test indicated an increasing trend of annual rainfall, Kiremt (summer) and Bega (dry) seasons whereas the Belg (spring) season rainfall showed a significant decreasing trend (p &lt; 0.05). The annual rate of change for mean, maximum and minimum temperatures was found to be 0.042 °C, 0.027 °C, and 0.056 °C respectively. The findings from this study can be used by decision-makers in taking appropriate measures and interventions to avert the risks posed by changes in rainfall and temperature variability including extremes in order to enhance community adaptation and mitigation strategies in southern Ethiopia.\n",
      "--------------------------------------------------\n",
      "Topic 40: 40_laser_cutting_welding_beam\n",
      "Representative Documents:\n",
      "  - For joining of thick steel plates, commonly arc welding and partially laser-arc hybrid welding are used. Both techniques offer individual disadvantages besides their advantages. Arc welding processes are typically characterized by low welding speeds, high heat inputs, high distortions, and high filler material consumptions. Laser-arc hybrid welding processes are limited to weldable material thicknesses regarding weld imperfections as well as the ability to bridge gaps. Therefore, the investigations presented are about high-power diode laser beam welding of steel with plate thicknesses t between 15 and 30 mm using output powers PL of up to 60 kW and welding speeds v between 0.5 and 1.0 m/min. The welding experiments contain butt welds by using weld backing materials. Among other things, influence of energy per unit length (laser beam power PL, welding speed v), focal position z, and plate thickness t are analyzed for different reproducible processes. The evaluation of weld seams includes visual inspection, metallographic analyses regarding geometric characteristics, and weld imperfections as well as radiographic inspections. The investigations show achievable qualities and characteristics of the weld seams depending on the plate thickness t by using high-power diode laser beam sources. Weld seams on plates with thicknesses t of 15 and 22 mm were welded without cracks or other weld imperfections according to metallographic analyses and radiographic testing by using a laser beam power PL of 40 kW and the suitable process parameters developed. As a result, relatively high plate thicknesses t can be welded in a single layer with high quality as well as comparatively high welding speed v.\n",
      "  - During laser material processing such as laser welding or cutting, it is known that the whole laser power is not only absorbed in or transmitted through the interaction zone, but a significant percentage is also reflected back to the laser source. Some publications analyzing the laser welding process showed a clear correlation between the reflected laser power and the result of the process. In this report, the authors analyze the information content of back reflected laser light during the high-power CO2-laser cutting of metal sheets. For this purpose, laser reflections are detected coaxially via a scraper-mirror online during laser cutting with a high time resolution. For different materials (mild steel, stainless steel, aluminum) and thicknesses (1 and 3 mm), a detailed spatial analysis on where the laser beam is reflected from (cutting front or workpiece surface) will be given. The spatial analysis of the reflected laser light shows that only 10% is reflected from the cutting front in the kerf. The main part (&amp;gt;90%) is reflected from the overlap zone of the laser beam with the workpiece surface outside the cutting kerf. Therefore, the signal strongly depends on the surface roughness of the treated material. It will be shown that, as expected, reflective surfaces with little roughness show higher CO2-laser reflections than rough surfaces with a higher level of roughness. Furthermore, the fraction of back reflected laser light increases with higher cutting feed rate which can be explained with a larger overlapping zone of the CO2-laser beam with the workpiece surface in front of the cutting kerf. In addition, the back reflection signal also strongly depends on the position of the focal plane with respect to the workpiece surface. This relationship can be used to measure the absolute position of the focal plane in-process as well as detecting an undesired focus shift during laser cutting.\n",
      "  - This paper presents an investigation into the effect of the laser cutting   parameters on the heat affected zone in CO2 laser cutting of AISI 304   stainless steel. The mathematical model for the heat affected zone was   expressed as a function of the laser cutting parameters such as the laser   power, cutting speed, assist gas pressure and focus position using the   artificial neural network. To obtain experimental database for the   artificial neural network training, laser cutting experiment was planned as   per Taguchi?s L27 orthogonal array with three levels for each of the cutting   parameter. Using the 27 experimental data sets, the artificial neural   network was trained with gradient descent with momentum algorithm and the   average absolute percentage error was 2.33%. The testing accuracy was then   verified with 6 extra experimental data sets and the average predicting   error was 6.46%. Statistically assessed as adequate, the artificial neural   network model was then used to investigate the effect of the laser cutting   parameters on the heat affected zone. To analyze the main and interaction   effect of the laser cutting parameters on the heat affected zone, 2-D and   3-D plots were generated. The analysis revealed that the cutting speed had   maximum influence on the heat affected zone followed by the laser power,   focus position and assist gas pressure. Finally, using the Monte Carlo   method the optimal laser cutting parameter values that minimize the heat   affected zone were identified.\n",
      "--------------------------------------------------\n",
      "Topic 41: 41_warming_past_climate_ocean\n",
      "Representative Documents:\n",
      "  - Links between stratospheric wind patterns and ground-based climate offer hope of improved long-range weather forecasting and provide a possible explanation for some conspicuous climate trends of the past few decades.\n",
      "  - Models suggest that dramatic changes in the ocean circulation are responsible for abrupt climate changes during the last ice age and may possibly alter the relative climate stability of the last 10,000 years.\n",
      "  - The paleoclimate record makes it clear that rapid climate shifts of the 20th century are only a subset of possible climate system behavior that might occur in the absence of glacial conditions, and that climatic surprises could be a challenge for society even in the absence of significant greenhouse warming.\n",
      "--------------------------------------------------\n",
      "Topic 42: 42_richness_species_diversity_species richness\n",
      "Representative Documents:\n",
      "  - Understanding the spatial scales at which environmental factors drive species richness patterns is a major challenge in ecology. Due to the trade‐off between spatial grain and extent, studies tend to focus on a single spatial scale, and the effects of multiple environmental variables operating across spatial scales on the pattern of local species richness have rarely been investigated.Here, we related variation in local species richness of ground beetles, landbirds and small mammals to variation in vegetation structure and topography, regional climate, biome diversity and glaciation history for 27 sites across the USA at two different spatial grains.We studied the relative influence of broad‐scale (landscape) environmental conditions using variables estimated at the site level (climate, productivity, biome diversity and glacial era ice cover) and fine‐scale (local) environmental conditions using variables estimated at the plot level (topography and vegetation structure) to explain local species richness. We also examined whether plot‐level factors scale up to drive continental scale richness patterns. We used Bayesian hierarchical models and quantified the amount of variance in observed richness that was explained by environmental factors at different spatial scales.For all three animal groups, our models explained much of the variation in local species richness (85%–89%), but site‐level variables explained a greater proportion of richness variance than plot‐level variables. Temperature was the most important site‐level predictor for explaining variance in landbirds and ground beetles richness. Some aspects of vegetation structure were the main plot‐level predictors of landbird richness. Environmental predictors generally had poor explanatory power for small mammal richness, while glacial era ice cover was the most important site‐level predictor.Relationships between plot‐level factors and richness varied greatly among geographical regions and spatial grains, and most relationships did not hold when predictors were scaled up to the continental scale. Our results suggest that the factors that determine richness may be highly dependent on spatial grain, geography, and animal group. We demonstrate that instead of artificially manipulating the resolution to study multiscale effects, a hierarchical approach that uses fine grain data at broad extents could help solve the issue of scale selection in environment‐richness studies.\n",
      "  - Many factors affect the distribution of species richness. This study examines the relative influence of habitat heterogeneity, climate, human disturbance, and spatial structure on the species‐richness distribution of terrestrial vertebrates (amphibians, reptiles, birds and mammals) in mainland Spain. The results indicate that spatial structure and environment exert similar influences on species richness. For all four taxa, species richness increases southward and northward, being lower in the center of the country, when controlled for other variables. This may be the result of a peninsular effect, as found in other studies, and reflect the importance of historical events on species richness in the Iberian Peninsula. Climate is more important than habitat heterogeneity in determining species richness. Temperature is positively correlated with amphibian, reptile, and bird species richness, while mammalian species richness is highest at intermediate temperatures. This effect is stronger in ectotherms than among endotherms, perhaps reflecting physiological differences. Precipitation positively correlates with bird and mammalian species richness, but has no effect on ectotherm species richness. Amphibian species richness increases with altitudinal range, and bird species richness with habitat diversity. Human population density is positively correlated with bird and mammalian species richness, but does not affect ectotherm species richness, while amphibian and bird species richness is highest at moderate levels of human land alteration (farmland). However, unexplained variance remains, and we discuss that the effects of environmental variables on species richness may vary geographically, causing different effects to be obscured on a national scale, diminishing the explanatory power of environmental variables.\n",
      "  - AimAt large spatial extents, the species richness of high‐level taxa is generally strongly positively correlated with temperature and precipitation, and consistently so across space and time. Here, we test whether this richness–climate relationship is driven by systematic associations between climate and characteristics of the geographical ranges of individual species. Specifically, we test the hypotheses that spatial variations in richness are driven by variations in species mean range size, climatic niche‐breadth, climatic range filling, frequency distribution of climatic niche position and/or frequency distribution of extant climatic conditions.LocationThe Americas.MethodsWe tested hypothetical effects of climatically constrained ranges on species richness using the breeding ranges of 3277 birds and 1659 mammals. We tallied species richness in 104‐km2 quadrats in the Americas as well as summary statistics describing the geographical ranges and climatic niches of the species occurring in each quadrat. We then used regression models to relate species richness to those characteristics.ResultsWe found that species mean range size, climatic niche‐breadth and range filling were generally, but inconsistently, negatively related to species richness. As predicted, species richness per quadrat increased with the number of species having their climatic niches centred in the climatic conditions of the quadrats and with the geographical extent of those conditions, although these relationships were relatively weak.Main conclusionThe richness–climate relationship appears to be largely decoupled from systematic variations in the characteristics of species climatic niches. Species generally have larger geographical ranges, wider climatic niches and higher range filling in species‐poor areas, each of which, all else being equal, should generate a richness–climate relationship the inverse of what we generally observe in nature. More species have their ranges centred on warm, wet and common climatic conditions. However, temperature and precipitation variables themselves explain more of the variance in species richness than the measured characteristics of species climatic niches.\n",
      "--------------------------------------------------\n",
      "Topic 43: 43_trends_precipitation_snow_extremes\n",
      "Representative Documents:\n",
      "  - Humans experience climate variability and climate change primarily through changes in weather at local and regional scales. One of the most effective means to track these changes is through detailed analysis of meteorological data. In this work, monthly and seasonal trends in recent winter climate of the northeastern United States (NE‐US) are documented. Snow cover and snowfall are important components of the region's hydrological systems, ecosystems, infrastructure, travel safety, and winter tourism and recreation. Temperature, snowfall, and snow depth data were collected from the merged United States Historical Climate Network (USHCN) and National Climatic Data Center Cooperative Network (COOP) data set for the months of December through March, 1965–2005. Monthly and seasonal time series of snow‐covered days (snow depth &gt;2.54 cm) are constructed from daily snow depth data. Spatial coherence analysis is used to address data quality issues with daily snowfall and snow depth data, and to remove stations with nonclimatic influences from the regional analysis. Monthly and seasonal trends in mean, minimum, and maximum temperature, total snowfall, and snow‐covered days are evaluated over the period 1965–2005, a period during which global temperature records and regional indicators exhibit a shift to warmer climate conditions. NE‐US regional winter mean, minimum, and maximum temperatures are all increasing at a rate ranging from 0.42° to 0.46°C/decade with the greatest warming in all three variables occurring in the coldest months of winter (January and February). The regional average reduction in number of snow‐covered days in winter (−8.9 d/decade) is also greatest during the months of January and February. Further analysis with additional regional climate modeling is required to better investigate the causal link between the increases in temperature and reduction in snow cover during the coldest winter months of January and February. In addition, regionally averaged winter snowfall has decreased by about 4.6 cm/decade, with the greatest decreases in snowfall occurring in December and February. These results have important implications for the impacts of regional climate change on the northeastern United States hydrology, natural ecosystems, and economy.\n",
      "  -                A physically based hydrology model is used to produce time series for the period 1916–2003 of evapotranspiration (ET), runoff, and soil moisture (SM) over the western United States from which long-term trends are evaluated. The results show that trends in ET in spring and summer are determined primarily by trends in precipitation and snowmelt that determine water availability. From April to June, ET trends are mostly positive due primarily to earlier snowmelt and earlier emergence of snow-free ground, and secondarily to increasing trends in spring precipitation. From July to September trends in ET are more strongly influenced by precipitation trends, with the exception of areas (most notably California) that receive little summer precipitation and have experienced large changes in snowmelt timing. Trends in the seasonal timing of ET are modest, but during the period 1947–2003 when temperature trends are large, they reflect a shift of ET from midsummer to early summer and late spring. As in other studies, it is found that runoff is occurring earlier in spring, a trend that is related primarily to increasing temperature, and is most apparent during 1947–2003. Trends in the annual runoff ratio, a variable critical to western water management, are determined primarily by trends in cool season precipitation, rather than changes in the timing of runoff or ET. It was found that the signature of temperature-related trends in runoff and SM is strongly keyed to mean midwinter [December–February (DJF)] temperatures. Areas with warmer winter temperatures show increasing trends in the runoff fraction as early as February, and colder areas as late as June. Trends toward earlier spring SM recharge are apparent and increasing trends in SM on 1 April are evident over much of the region. The 1 July SM trends are less affected by snowmelt changes and are controlled more by precipitation trends.\n",
      "  - ABSTRACTObservational analyses of changing climate extremes over the West Africa region have been limited by the availability of long and high‐quality datasets. To help address this gap, a climate extremes indices workshop was held in the Gambia in December 2011 with participants from 14 West African countries. The resulting analysis utilized 15 annual indices derived from observed daily temperatures and 10 annual indices derived from observed daily precipitation. The analysis was conducted for 166 meteorological stations in 13 countries for 2 periods: 1960–2010 and 1981–2010. The analyses of trends in the annual mean temperature indices have identified statistically significant increases of 0.16 °C/decade and 0.28 °C/decade for mean annual maximum and mean annual minimum temperatures, respectively, averaged over all available land stations in the region during the last 50 years. The seasonal‐temperature‐related indices show significant patterns of warming in all seasons. The annual mean of daily minimum temperature has increased more than the annual mean of daily maximum temperature leading to a decreasing trend in the diurnal temperature range. Warm days and warm nights have become more frequent, and cold days and cold nights have become less frequent. The analyses of precipitation‐based indices indicate spatially non‐coherent changes throughout the study area with few statistically significant trends over the longer period. Exceptions to this are the simple daily intensity index and maximum 5‐day precipitation, which show significant increasing regional trends over both the shorter and longer periods. Additionally, over the recent period (1981–2010) most of the precipitation related indices show significant trends towards wetter conditions. However, this period of increased rainfall follows a decade of significantly drier conditions in the region – it is not clear whether the recent upward trends reflect the ‘recovery’ from this long drought period or represents a long‐term response to warming.\n",
      "--------------------------------------------------\n",
      "Topic 44: 44_catalysts_catalyst_ni_catalytic\n",
      "Representative Documents:\n",
      "  - The role of ZrO2 as different components in Ni-based catalysts for CO2 reforming of methane (CRM) has been investigated. The 10 wt.% Ni supported catalysts were prepared with ZrO2 as a support using a co-impregnation method. As a promoter (1 wt.% ZrO2) and a coactive component (10 wt.% ZrO2), the catalysts with ZrO2 were synthesized using a co-impregnation method. To evaluate the effect of the interaction, the Ni catalyst with ZrO2 as a coactive component was prepared by a sequential impregnation method. The results revealed that the activity, the selectivity, and the anti-coking ability of the catalyst depend upon the ZrO2 content, the Ni-ZrO2 interaction, basicity, and oxygen mobility of each catalyst resulting in different Ni dispersion and oxygen transfer pathway from ZrO2 to Ni. According to the characterization and catalytic activation results, the Ni catalyst with low ZrO2 content (as a promoter) presented highest selectivity toward CO owning to the high number of weak and moderate basic sites that enhance the CO2 activation-dissociation. The lowest activity (CH4 conversion ≈ 40% and CO2 conversion ≈ 39%) with the relatively high quantity of total coke formation (the weight loss of the spent catalyst in TGA curve ≈ 22%) of the Ni catalyst with ZrO2 as a support is ascribed to the lowest Ni dispersion due to the poor Ni-ZrO2 interaction and less oxygen transfer from ZrO2 to the deposited carbon on the Ni surface. The effect of a poor Ni-ZrO2 interaction on the catalytic activity was deducted by decreasing ZrO2 content to 10 wt.% (as a coactive component) and 1 wt.% (as a promoter). Although Ni catalysts with 1 wt.% and 10 wt.% ZrO2 provided similar oxygen mobility, the lack of oxygen transfer to coke during CRM process on the Ni surface was still indicated by the growth of carbon filament when the catalyst was prepared by co-impregnation method. When the catalyst was prepared by a sequential impregnation, the intimate interaction of Ni and ZrO2 for oxygen transfer was successfully developed through a ZrO2-Al2O3 composite. The interaction in this catalyst enhanced the catalytic activity (CH4 conversion ≈ 54% and CO2 conversion ≈ 50%) and the oxygen transport for carbon oxidation (the weight loss of the spent catalyst in TGA curve ≈ 7%) for CRM process. The Ni supported catalysts with ZrO2 as a promoter prepared by co-impregnation and with ZrO2 as a coactive component prepared by a sequential impregnation were tested in combined steam and CO2 reforming of methane (CSCRM). The results revealed that the ZrO2 promoter provided a greater carbon resistance (coke = 1.213 mmol·g−1) with the subtraction of CH4 and CO2 activities (CH4 conversion ≈ 28% and CO2 conversion ≈ %) due to the loss of active sites to the H2O activation-dissociation. Thus, the H2O activation-dissociation was promoted more efficiently on the basic sites than on the vacancy sites in CSCRM.\n",
      "  - Mesoporous Ni-based catalysts with Ni confined in nanochannels are widely used in CO2 methanation. However, when Ni loadings are high, the nanochannels are easily blocked by nickel particles, which reduces the catalytic performance. In this work, three-dimensional mesoporous Ni-CeO2-CSC catalysts with high Ni loadings (20−80 wt %) were prepared using a colloidal solution combustion method, and characterized by nitrogen adsorption–desorption, X-ray diffraction (XRD), transmission electron microscopy (TEM) and H2 temperature programmed reduction (H2-TPR). Among the catalysts with different Ni loadings, the 50% Ni-CeO2-CSC with 50 wt % Ni loading exhibited the best catalytic performance in CO2 methanation. Furthermore, the 50% Ni-CeO2-CSC catalyst was stable for 50 h at 300° and 350 °C in CO2 methanation. The characterization results illustrate that the 50% Ni-CeO2-CSC catalyst has Ni particles smaller than 5 nm embedded in the pore walls, and the Ni particles interact with CeO2. On the contrary, the 50% Ni-CeO2-CP catalyst, prepared using the traditional coprecipitation method, is less active and selective for CO2 methanation due to the larger size of the Ni and CeO2 particles. The special three-dimensional mesoporous embedded structure in the 50% Ni-CeO2-CSC can provide more metal–oxide interface and stabilize small Ni particles in pore walls, which makes the catalyst more active and stable in CO2 methanation.\n",
      "  - Carbon dioxide methanation was carried out over Ni-based catalysts on different supports and chelating ligands in microreactors. To investigate the influence of chelating ligands and supports, the Ni catalysts were prepared using different support such as CeO2, Al2O3, SiO2, and SBA-15 by a citric acid (CA)-assisted impregnation method. The properties of the developed catalysts were studied by X-ray diffraction (XRD), Transmission electron microscope (TEM), and X-ray photoelectron spectroscopy (XPS) measurement, and the results show that the addition of CA in the impregnation solution improved the dispersion, refines the particle size, and enhanced the interaction of nickel species. The catalytic performance of the developed Ni catalysts were evaluated by CO2 methanation in microreactors in the temperature range of 275 °C–375 °C under 12.5 bar pressure. All the catalysts exhibit high CO2 conversion and extremely high selectivity to methane. However, the catalysts prepared via CA-assisted method exhibited excellent activity and stability, compared with Ni catalysts prepared by a conventional impregnation method, which could be attributed to highly dispersed nickel particles with strong metal–support interaction. The activity of CO2 methanation followed the order of Ni/CeO2-CA &gt; Ni/SBA-15-CA &gt; Ni/Al2O3-CA &gt; Ni/SiO2-CA &gt; Ni/CeO2. The Ni/CeO2 catalysts have also been prepared using different chelating ligands such as ethylene glycol (EG), sucrose (S), oxalic acid (OA) and ethylene diamine tetra acidic acid (EDTA). Among the tested catalysts prepared with different support and chelating ligands, the Ni/CeO2 catalyst prepared via CA-assisted method gave superior catalytic performance and it could attain 98.6% of CO2 conversion and 99.7% methane selectivity at 325 °C. The partial reduction of the CeO2 support generates more surface oxygen vacancies and results in a high CO2 conversion and methane selectivity compared with other catalysts. The addition of CA as promoter favored the synergistic effect of Ni and support, which led to high dispersion, controls the size, and stabilizes the Ni nanoparticles. Furthermore, the Ni/CeO2-CA catalyst yields high CO2 conversion in a time-on-stream study due to the ability of preventing the carbon deposition and sintering of Ni particles under the applied reaction conditions. However, the Ni/Al2O3-CA and Ni/SBA-15-CA catalysts showed stable performance for 100 h of time on stream.\n",
      "--------------------------------------------------\n",
      "Topic 45: 45_firms_disclosure_corporate_companies\n",
      "Representative Documents:\n",
      "  - Despite the importance of the Carbon Disclosure Project (CDP), the question of how firms' voluntary carbon disclosure influences capital markets and shareholder value remains unanswered. Using the event study methodology with a sample of firms from the CDP Korea 2008 and 2009, this paper investigates market responses to firms' voluntary carbon information disclosure. The results suggest that the market is likely to respond negatively to firms' carbon disclosure, implying that investors tend to perceive carbon disclosure as bad news and thus are concerned about potential costs facing firms for addressing global warming. In addition, the study examines the moderating effect of frequent carbon communication on the relationship between carbon disclosure and shareholder value. The results suggest that a firm can mitigate negative market shocks from its carbon disclosure by releasing its carbon news periodically through the media in advance of its carbon disclosure. Copyright © 2013 John Wiley &amp; Sons, Ltd and ERP Environment.\n",
      "  - PurposeThe paper aims to examine the climate change-related disclosure patterns of listed Indian firms and its impact on firm performance. Specifically, it strives to analyse the conformance of the selected firms with the recommendations of the Task Force on Climate-related Financial Disclosures (TCFD) established by the Financial Stability Board of G20 nations.Design/methodology/approachThe study conducts content analysis of the annual reports and/or sustainability reports of 22 selected firms from the energy sector for the period spanning 2018–2019 and 2019–2020 based on the four-fold recommendations of TCFD, namely, governance, strategy, risk management and target and metrics, to compute the overall and respective climate-change disclosure scores. Further, a panel data regression model is used to appraise the impact of such disclosure on the performance of the firms.FindingsThe findings of the study indicate that the disclosure level of Indian firms in the energy sector is moderate. The regression results establish a positive relation between climate change-related financial disclosure and firm performance indicating that firms can witness improved financial performance by disclosing more information on climate change.Originality/valueThis is the first study in the Indian context to evaluate the climate change-related disclosure practices of the selected firms based on the TCFD’s recommendations and to trace its association with the performance of the firms. The results of the study shall hence be of relevance for the policymakers and diverse stakeholders.\n",
      "  - PurposeThe purpose of this research is to examine the impact of external assurance on the level of voluntary corporate climate change disclosures by Finnish firms.Design/methodology/approachThe sample of this study includes 228 firm-year observations over the period 2008–2015 for listed Finnish companies that have issued sustainability reports and responded to the Carbon Disclosure Project (CDP) questionnaire at least once during the sample period. The authors conduct a panel regression analysis to study the afore-mentioned linkage. In addition, the Tobit regression model is also estimated to check the robustness of our findings.FindingsThe findings suggest that assurance has a highly significant positive impact on the level of corporate climate change disclosures even after controlling for the effect of a number of control variables. Moreover, among the control variables, firm size and asset age are found to have significant effect on the extent of carbon emissions disclosure. Furthermore, the additional analysis reveals that the type of assurance providers (accounting firms vs non-accounting firms) and the type of financial auditors (Big4 financial auditors vs non-Big4 financial auditors) do not influence the level of climate change disclosure of assured companies.Research limitations/implicationsThis research is subject to certain limitations. First, the source of the data used in this research is the CDP database which has limitations in that it is a voluntary disclosure process where all the observations collected are self-reported by the responding firms. This may bias the reported findings. Second, our sample includes only listed companies and hence the results might have limited explanatory capacity for unlisted firms.Practical implicationsBy using the results of this research, corporate managers will be able to reduce the information asymmetry between various stakeholders and them through disclosure of accurate, reliable and credible environmental information. Such disclosures will, in turn, allow socially responsible investors to choose eco-friendly investments and will thus enable them to make appropriate investment decisions.Originality/valueResearch on the external assurance-corporate climate change disclosure nexus is scarce. This study addresses this gap in the nonfinancial disclosure assurance literature by demonstrating that external assurance increases the level of voluntary corporate climate change disclosure. Drawing on stakeholder-agency theory, this study views external assurance as a monitoring structure that potentially curbs the monitoring problem between corporate managers and other stakeholders and increases the amount of climate change disclosures making a possible avenue for the reduction of the information asymmetry between them.\n",
      "--------------------------------------------------\n",
      "Topic 46: 46_ann_models_error_neural\n",
      "Representative Documents:\n",
      "  - To ensure continued food security and economic development in Africa, it is very important to address and adapt to climate change. Excessive dependence on rainfed agricultural production makes Africa more vulnerable to climate change effects. Weather information and services are essential for farmers to more effectively survive the increasing occurrence of extreme weather events due to climate change. Weather information is important for resource management in agricultural production and helps farmers plan their farming activities in advance. Machine Learning is one of the technologies used in agriculture for weather forecasting and crop disease detection among others. The objective of this study is to develop Machine Learning-based models adapted to the context of daily weather forecasting for Rainfall, Relative Humidity, and Maximum and Minimum Temperature in Senegal. In this study, we made a comparison of ten Machine Learning Regressors with our Ensemble Model. These models were evaluated based on Mean Absolute Error, Mean Squared Error, Root Mean Squared Error and Coefficient of Determination. The results show that the Ensemble Model performs better than the ten base models. The Ensemble Model results for each parameter are as follows; Relative Humidity: Mean Absolute Error was 4.0126, Mean Squared Error was 29.9885, Root Mean Squared Error was 5.4428 and Coefficient of Determination was 0.9335. For Minimum Temperature: Mean Absolute Error was 0.7908, Mean Squared Error was 1.1329, Root Mean Squared Error was 1.0515 and Coefficient of Determination was 0.9018. For Maximum Temperature: Mean Absolute Error was 1.2515, Mean Squared Error was 2.8038, Root Mean Squared Error was 1.6591 and Coefficient of Determination was 0.8205. For Rainfall: Mean Absolute Error was 0.2142, Mean Squared Error was 0.1681, Root Mean Squared Error was 0.4100 and Coefficient of Determination was 0.7733. From the present study, it has been observed that the Ensemble Model is a feasible model to be used for Rainfall, Relative Humidity, and Maximum and Minimum Temperature forecasting.\n",
      "  - This study investigates changes in river flow patterns, in the Hunza Basin, Pakistan, attributed to climate change. Given the anticipated rise in extreme weather events, accurate streamflow predictions are increasingly vital. We assess three machine learning (ML) models – artificial neural network (ANN), recurrent neural network (RNN), and adaptive fuzzy neural inference system (ANFIS) – for streamflow prediction under the Coupled Model Intercomparison Project 6 (CMIP6) Shared Socioeconomic Pathways (SSPs), specifically SSP245 and SSP585. Four key performance indicators, mean square error (MSE), root mean square error (RMSE), mean absolute error (MAE), and coefficient of determination (R2), guide the evaluation. These models employ monthly precipitation, maximum and minimum temperatures as inputs, and discharge as the output, spanning 1985–2014. The ANN model with a 3-10-1 architecture outperforms RNN and ANFIS, displaying lower MSE, RMSE, MAE, and higher R2 values for both training (MSE = 20417, RMSE = 142, MAE = 71, R2 = 0.94) and testing (MSE = 9348, RMSE = 96, MAE = 108, R2 = 0.92) datasets. Subsequently, the superior ANN model predicts streamflow up to 2100 using SSP245 and SSP585 scenarios. These results underscore the potential of ANN models for robust futuristic streamflow estimation, offering valuable insights for water resource management and planning.\n",
      "  - The scarcity of climatic data is the biggest challenge for developing countries, and the development of models for reference evapotranspiration (ET0) estimation with limited datasets is crucial. Therefore, the current investigation assessed the efficacy of four machine learning (ML) models, namely, linear regression (LR), support vector machine (SVM), random forest (RF), and neural networks (NN), to predict ET0 based on minimal climate data in comparison with the standard FAO‐56 Penman‐Monteith (PM) method. The data on daily climate parameters were collected for the period 2000−2021, including maximum and minimum temperatures (Tmax and Tmin), mean relative humidity (RH), wind speed (WS), and sunshine hours (SSH). The performance of the developed models considering different input combinations was evaluated by using several statistical performance measures. The results showed that the SVM model performed better than the other ML models during training (R2 = 0.985; mean absolute error [MAE] = 0.170 mm/day; mean square error [MSE] = 0.052 mm/day; root mean square error [RMSE] = 0.229 mm/day; mean absolute percentage error [MAPE] = 5.72%) and testing stages (R2 = 0.985; MAE = 0.168 mm/day; MSE = 0.050 mm/day; RMSE = 0.224 mm/day; MAPE = 5.91%) under full dataset scenario. The best performance of the models to estimate was with Tmax, RH, Ws, SSH, and Tmin. The results of the current study are substantial as it offers an approach to estimate ET0 in semi‐arid data‐scarce region.\n",
      "--------------------------------------------------\n",
      "Topic 47: 47_patients_hypothermia_forced air_group\n",
      "Representative Documents:\n",
      "  -  Forced-air warming is the most commonly used and effective method of active warming. A new radiant warming device (Suntouch™, Fisher and Paykel) may provide an alternative when the skin surface available for warming is limited. We conducted a randomized controlled trial to compare the efficacy of the Suntouch™ radiant warmer and forced-air warming. With ethics committee approval, 60 surgical patients having procedures anticipated to be more than two hours in duration were recruited. Patients were randomized to either radiant warming or forced-air warming. All intravenous fluids were warmed but prewarming was not used. The final intraoperative core temperatures (°C) for the radiant warming and forced-air warming groups were 36.0±0.5 and 36.4±0.6 (P=0.002) respectively. No other patient variables were significantly different. The Suntouch™ is not as effective as the forced air warming for intraoperative warming during long surgical procedures. The device may be useful when forced-air warming is not possible. \n",
      "  -                       Background:            This study aimed to evaluate the efficacy of peri-induction forced air warming to prevent inadvertent perioperative hypothermia, defined as a reduction in body temperature to &lt;36.0°C during the perioperative period, in intraoperatively warmed patients receiving major surgery lasting &gt;120 minutes.                                Methods:            In total, 130 patients scheduled for elective surgery under general anesthesia lasting &gt;120 minutes were divided into 2 groups: peri-induction warming (n = 65) and control (n = 65). Patients in the peri-induction warming group were warmed during the anesthetic induction period using a forced-air warmer set at 47°C, whereas patients in the control group were covered passively with a cotton blanket. All patients were warmed with a forced-air warmer during surgery. Body temperature was measured using a tympanic membrane thermometer in the pre- and postoperative periods and using a nasopharyngeal temperature probe during surgery. Patients were evaluated for shivering scale score, thermal comfort scale score, and satisfaction score in the post-anesthesia care unit.                                Results:            The incidence rates of intraoperative and postoperative hypothermia were lower in the peri-induction warming group than in the control group (19.0% vs 57.1%, P &lt; .001; 3.3% vs 16.9%, P = .013, respectively). Body temperature was higher in the peri-induction warming group (P &lt; .001). However, intraoperative blood loss, as well as postoperative thermal comfort scale score, shivering scale score, and patient satisfaction score, were similar between groups. Post-anesthesia care unit duration was also similar between groups.                                Conclusions:            Peri-induction active forced air warming is an effective, simple, and convenient method to prevent inadvertent perioperative hypothermia in intraoperatively warmed patients undergoing major surgery lasting &gt;120 minutes.          \n",
      "  -                       Background:            The incidence of intraoperative hypothermia is still high despite the proposal of different preventive measures during thoracoscopic surgery. This randomized control study evaluated the effects of 30-minute prewarming combined with a forced-air warming system during surgery to prevent intraoperative hypothermia in patients undergoing video-assisted thoracic surgery under general anesthesia combined with erector spinae nerve block.                                Methods:            Ninety-eight patients were randomly and equally allocated to prewarming or warming groups (n = 49 each). The primary outcome was the incidence of intraoperative hypothermia. Secondary outcomes were core temperature, irrigation and infused fluid, estimated blood loss, urine output, type of surgery, intraoperative anesthetic dosage, hemodynamics, recovery time, the incidence of postoperative shivering, thermal comfort, postoperative sufentanil consumption and pain intensity, patient satisfaction, and adverse events.                                Results:            The incidence of intraoperative hypothermia was significantly lower in the prewarming group than the warming group (12.24% vs 32.65%, P                                  = .015). Core temperature showed the highest decrease 30 minutes after surgery start in both groups; however, the rate was lower in the prewarming than in the warming group (0.31 ± 0.04°C vs 0.42 ± 0.06°C, P                                  &lt; .05). Compared with the warming group, higher core temperatures were recorded for patients in the prewarming group from T1 to T6 (P                                  &lt; .05). Significantly fewer patients with mild hypothermia were in the prewarming group (5 vs 13, P                                  = .037) and recovery time was significantly reduced in the prewarming group (P                                  &lt; .05). Although the incidence of postoperative shivering was lower in the prewarming group, it was not statistically significant (6.12% vs 18.37%, P                                  = .064). Likewise, the shivering severity was similar for both groups. Thermal comfort was significantly increased in the prewarming group, although patient satisfaction was comparable between the 2 groups (P                                  &gt; .05). No adverse events occurred associated with the forced-air warming system. Both groups shared similar baseline demographics, type of surgery, total irrigation fluid, total infused fluid, estimated blood loss, urine output, intraoperative anesthetic dosage, hemodynamics, duration of anesthesia and operation time, postoperative sufentanil consumption, and pain intensity.                                Conclusion:            In patients undergoing video-assisted thoracic surgery, prewarming for 30 minutes before the induction of anesthesia combined with a forced-air warming system may improve perioperative core temperature and the thermal comfort, although the incidence of postoperative shivering and severity did not improve.          \n",
      "--------------------------------------------------\n",
      "Topic 48: 48_rights_law_court_litigation\n",
      "Representative Documents:\n",
      "  - Is it possible to address one of the most serious dangers of the modern world, climate emergency, before the European Court of Human Rights? Although climate change can potentially impair many of the rights recognized by the European Convention on Human Rights, there has not yet been any judgment on this issue from the ECtHR. This article explores the opportunities to use ECHR human rights law to reduce climate change's effects. It discusses the relevance of the human rights framework in the subject matter illustrated with case law from the European Court of Human Rights. The paper's main goal is to establish and explain the explicit link between climate change and human rights in relation to the corresponding obligations of governments according to the standards of the ECtHR jurisprudence.\n",
      "  -                The evolving landscape of climate change litigation within human rights frameworks presents a complex challenge for courts worldwide. Recent landmark decisions by international court and treaty bodies have expanded the jurisdiction of human rights courts to address climate-related disputes. However, the most recent case law of the European Court of Human Rights (ECtHR) emphasises the delicate balance between recognising the urgency of climate action and upholding the integrity of a regional human rights system. This article explores the ECtHR’s use of the living instrument doctrine in response to climate change-related legal claims. It submits that climate change cases highlight the circumscribed role of the European Convention on Human Rights (ECHR or the Convention) in dealing with the climate emergency and reveal the tension between addressing climate change impacts and maintaining the functioning of the European human rights system.\n",
      "  - To protect the inhabitants of The Netherlands against ‘dangerous climate change’, the Hague District Court (the ‘Court’) in the ‘climate case of the century’ (Milieudefensie v. Shell, 2021) resorted to paradoxical lex ferenda interpretations of Dutch tort law. The court found binding ‘unwritten’ corporate norms in documentation without any legal status, while it acknowledged that the corresponding multitude of demanding ‘written’ (i.e., statutory) norms are nonbinding, do not apply to private entities, and do not reflect custom. In dictating corporate climate policymaking, the court rewrote Dutch tort law, ignored its limits, and expanded it in ways that are not consistent with the Dutch Supreme Court’s rulings. Based on the proposition that CO2 emissions cause ‘dangerous’ climate change, which is not a term used by the Intergovernmental Panel on Climate Change (IPCC), the judgment is a lengthy, but in the end circular argument: there is a duty of care because emission cause danger, and emissions cause danger because there is a duty of care.Milieudefensie’s case was built chiefly on a Dutch tort law case known as the ‘Cellar Hatch’ case. In the Cellar Hatch case, the Dutch Supreme Court first articulated the endangerment doctrine that resembles Learned Hand’s negligence calculus. In Milieudefensie v. Shell, the Hague District Court applied the endangerment doctrine, but constructed a climatespecific version. To enforce the urgent CO2 emission reductions deemed scientifically necessary, the Court circumvented the logical consequences of the applying the Cellar Hatch’s endangerment doctrine by referring to human rights, consensus and the concept of ‘partial responsibility’. The judgment does not fit into the system of Dutch civil law, and reasons away all barriers to imposition of the remedy sought by Milieudefensie, including causation requirements. With the Court’s moral reconstruction of the endangerment doctrine to ‘save the planet’, the Court opened the hatch, and fell into the dark cellar, along with the entire body of Dutch tort law, democracy, the rule of law, the rights and interests of citizens and the economy.In short, based on court-made ‘unwritten’ law, the Court concocted a result-oriented mix of science, law and expanded ‘soft laws’ to find an unlawful act without duly considering its plausible lawfulness and justification, entertained a vague, multi-faceted concept of climate-related damage without carefully examining its coherence, and constructed a causal link between the act and the damage based on the act’s presumed unlawfulness. Ironically, given the way markets work, the court’s judgment may well increase CO2 emissions, and thus not have any favourable effect on the climate, but it will restrict citizen’s rights to participate in public affairs and impose a potentially large burden on the economy. Endorsing perceived consensus around a moral imperative to reduce emissions, the Court did not confirm, but merely assumed the effectiveness of the remedy and ignored its multiple adverse consequences. The reality is that to comply with the court order, in 2030, Shell could simply spin off its fossil fuel business. Regrettably, the court disposed of virtually the complete body of Dutch law to secure a pyrrhic victory for the climate movement that is likely to harm the environment.This article is published in two parts. This is part 1. Part 2 will be published in the next issue of European Energy and Environmental Law Review.Milieudefensie v. Shell, climate change, climate litigation, civil liability, tort law, customary law, duty of care, causation, public-private law interface, concept of damage, trias politica, interest balancing, legal culture\n",
      "--------------------------------------------------\n",
      "Topic 49: 49_ssw_ionospheric_stratospheric_sudden\n",
      "Representative Documents:\n",
      "  - Sudden stratospheric warming (SSW) in the winter of 2008/2009 is the strongest recorded SSW event. The enhancement in semidiurnal variation of ionospheric TEC (total electron content) with phase shift forward is shown during 22 to 27 January 2009, based on the TEC observations in Beijing (40.30°N, 116.19°E geographic, 39.73°N dip latitude). We focus on finding the reason for the TEC variation. Winds observed by an all‐sky meteor radar in the same observatory are used to study mesospheric variation. The semidiurnal solar tide in the mesosphere starts to increase before the SSW and maintains oscillation with period 16–20 days during the SSW. The semidiurnal lunar tides in TEC and wind start to increase on 17 and 15 January, respectively. Although the semidiurnal lunar tide in TEC over Beijing almost dies out on 1 February, that over equatorial ionospheric anomaly crest does not vanish until 15 February when lunar tide in wind tends to be very weak. The maximum of lunar tide in wind appears on 2 February at 96 km with amplitudes of 15 m/s and 21 m/s for zonal and meridional winds. The phase comparison shows that lunar tides in TEC and zonal wind reach their maxima at almost the same time, which is 2–4 h lag behind the meridional wind. The coupling between the mesosphere and ionosphere contributes to the semidiurnal variation of TEC through both solar and semidiurnal lunar tides. The enhancement in semidiurnal lunar tide is responsible for the TEC peak shift forward during the SSW.\n",
      "  - Observations of the Global Positioning System (GPS) total electron content (TEC) are used to study the coupling between the 2009 sudden stratospheric warming (SSW) and ionospheric perturbations. The observations reveal both migrating and nonmigrating perturbations to the semidiurnal tide in the equatorial ionization anomaly crest region that are associated with changes in electric fields induced by the tidal dynamo. In particular, a significant enhancement is observed in the nonmigrating semidiurnal westward propagating tide with zonal wavenumber 1 (SW1) in GPS TEC during the SSW. The SW1 perturbations in the low‐latitude ionosphere are found to oscillate with a similar period as planetary wave‐1 activity in the Northern Hemisphere stratosphere. This connection is attributed to the nonlinear interaction between tides and planetary waves and strongly supports the theory that planetary wave‐tide interaction is the primary mechanism coupling SSWs to ionospheric variability. Enhancements are also observed in the nonmigrating semidiurnal tide with zonal wavenumber 0 (S0) during this time period and may be related to the nonlinear interaction between the migrating semidiurnal tide and planetary wave‐2. The connection between planetary wave‐2 and S0 is, however, less clear which may be attributed to differences in the zonal mean zonal winds in the mesosphere and lower thermosphere during the times of peak planetary wave‐1 and planetary wave‐2 activity. We conclude that the changing zonal winds during SSWs play an important role in the coupling between ionospheric variability and the forcing from planetary waves of lower atmospheric origin during SSWs.\n",
      "  - A data assimilation algorithm is used to delineate the time‐dependent three‐dimensional ionospheric response to the 2009 sudden stratospheric warming (SSW) event. We use the Ionospheric Data Assimilation Four‐Dimensional (IDA4D) algorithm to study the global ionospheric response to the 2009 SSW. This is the first study to utilize global ionospheric measurements in a data assimilation framework to unambiguously characterize atmosphere‐ionosphere coupling via tidal modifications during the 2009 SSW event. Model results reveal that the dominant mode of ionospheric variability during the 2009 SSW is driven by the enhancements in westward propagating semidiurnal tide with zonal wave number 1. The IDA4D results completely characterize the tidal perturbation during the 2009 SSW for the first time and show the global 3‐D structure of the tide in total electron content (TEC) and electron density. The largest ionospheric responses were seen at low latitudes, where ionospheric plasma is extremely sensitive to the zonal electric field and susceptible to modifications by tidal winds in the lower thermosphere. The ionospheric response to the warming was characterized by an increase in TEC in the morning/early afternoon sector and a decrease during the late afternoon/evening period. The effects of coupling between the stratosphere and ionosphere were strongest between 220 km and 380 km. The IDA4D results also show a reversal of asymmetry in the equatorial ionization anomaly crests occurring several days after the peak of the 2009 SSW event. We suggest that this could be a result of the equatorial fountain effect being further modified by the summer‐to‐winter meridional neutral winds.\n",
      "--------------------------------------------------\n",
      "Topic 50: 50_anomalies_sst_pacific_enso\n",
      "Representative Documents:\n",
      "  -                Concurrent with most large El Niño events, cold sea surface temperature (SST) anomalies are observed over the western Pacific warm pool region (WPWP). Observational evidence that SST anomalies that form in the off-equatorial western Pacific during El Niño–Southern Oscillation (ENSO) cycles are forced by subsurface ocean processes equatorward of 12°N and air–sea fluxes poleward of 12°N is presented. It is demonstrated that diurnal mixing in the ocean equatorward of 12°N plays a significant role in bringing subsurface temperature anomalies to the sea surface during an El Niño event.               The role of SST anomalies equatorward of 12°N in ENSO cycles is tested in the Zebiak–Cane coupled model, modified to allow for the impact of subsurface temperatures on SSTs. This coupled model successfully simulates cold SST anomalies in the off-equatorial northwestern Pacific that are observed to occur during the warm phase of ENSO and the atmospheric response to these anomalies, which is composed of both westerlies in the central Pacific and easterlies in the far western equatorial Pacific. It is found that there is little net change in the zonal mean wind stress at the equator, suggesting that the westerlies cancel the impact of the easterlies on the basin-scale tilt of the equatorial zonal mean thermocline depth. The anomalous westerly winds in the central equatorial Pacific are found to increase the amplitude of an El Niño event directly by increasing anomalous warm zonal advection and reducing upwelling. Moreover, the off-equatorial anticyclonic wind stress associated with the cold SST anomalies during the warm phase of ENSO tends to reduce the discharge of the equatorial heat content. Thus, the coupled processes over the western Pacific warm pool can serve as a positive feedback to amplify ENSO cycles.\n",
      "  -                Two atmospheric general circulation models (AGCMs), differing in numerics and physical parameterizations, are employed to test the hypothesis that El Niño–induced sea surface temperature (SST) anomalies in the tropical Indian Ocean impact considerably the Northern Hemisphere extratropical circulation anomalies during boreal winter [January–March +1 (JFM +1)] of El Niño years. The hypothesis grew out of recent findings that ocean dynamics influence SST variations over the southwest Indian Ocean (SWIO), and these in turn impact local precipitation. A set of ensemble simulations with the AGCMs was carried out to assess the combined and individual effects of tropical Pacific and Indian Ocean SST anomalies on the extratropical circulation. To elucidate the dynamics responsible for the teleconnection, solutions were sought from a linear version of one of the AGCMs.               Both AGCMs demonstrate that the observed precipitation anomalies over the SWIO are determined by local SST anomalies. Analysis of the circulation response shows that over the Pacific–North American (PNA) region, the 500-hPa height anomalies, forced by Indian Ocean SST anomalies, oppose and destructively interfere with those forced by tropical Pacific SST anomalies. The model results validated with reanalysis data show that compared to the runs where only the tropical Pacific SST anomalies are specified, the root-mean-square error of the height anomalies over the PNA region is significantly reduced in runs in which the SST anomalies in the Indian Ocean are prescribed in addition to those in the tropical Pacific. Among the ensemble members, both precipitation anomalies over the SWIO and the 500-hPa height over the PNA region show high potential predictability. The solutions from the linear model indicate that the Rossby wave packets involved in setting up the teleconnection between the SWIO and the PNA region have a propagation path that is quite different from the classical El Niño–PNA linkage.               The results of idealized experiments indicate that the Northern Hemisphere extratropical response to Indian Ocean SST anomalies is significant and the effect of this response needs to be considered in understanding the PNA pattern during El Niño years. The results presented herein suggest that the tropical Indian Ocean plays an active role in climate variability and that accurate observation of SST there is of urgent need.\n",
      "  -                Prior to the 1976–77 climate shift (1950–76), sea surface temperature (SST) anomalies in the tropical Indian Ocean consisted of a basinwide warming during boreal fall of the developing phase of most El Niños, whereas after the shift (1977–99) they had an east–west asymmetry—a consequence of El Niño being associated with the Indian Ocean Dipole/Zonal mode. In this study, the possible impact of these contrasting SST patterns on the ongoing El Niño is investigated, using atmospheric reanalysis products and solutions to both an atmospheric general circulation model (AGCM) and a simple atmospheric model (LBM), with the latter used to identify basic processes. Specifically, analyses of reanalysis products during the El Niño onset indicate that after the climate shift a low-level anticyclone over the South China Sea was shifted into the Bay of Bengal and that equatorial westerly anomalies in the Pacific Ocean were considerably stronger. The present study focuses on determining influence of Indian Ocean SST on these changes.               A suite of AGCM experiments, each consisting of a 10-member ensemble, is carried out to assess the relative importance of remote (Pacific) versus local (Indian Ocean) SST anomalies in determining precipitation anomalies over the equatorial Indian Ocean. Solutions indicate that both local and remote SST anomalies are necessary for realistic simulations, with convection in the tropical west Pacific and the subsequent development of the South China Sea anticyclone being particularly sensitive to Indian Ocean SST anomalies. Prior to the climate shift, the basinwide Indian Ocean SST anomalies generate an atmospheric Kelvin wave associated with easterly flow over the equatorial west-central Pacific, thereby weakening the westerly anomalies associated with the developing El Niño. In contrast, after the shift, the east–west contrast in Indian Ocean SST anomalies does not generate a significant Kelvin wave response, and there is little effect on the El Niño–induced westerlies. The Linear Baroclinic Model (LBM) solutions confirm the AGCM’s results.\n",
      "--------------------------------------------------\n",
      "Topic 51: 51_extraction_extracts_extract_supercritical\n",
      "Representative Documents:\n",
      "  - Extraction process of Cucumaria frondosa japonica Semper, 1868, which are subspecies of Cucumaria frondosa (Gunnerus, 1767), were studied. It was shown that supercritical carbon dioxide extraction of holothuria was more effective than conventional solvent extraction. Step-by-step extraction with carbon dioxide followed by supercritical extraction with the addition of a co-solvent of ethanol can almost double the yields of extracts of triterpene glycosides, styrenes and carotenoids. Moreover, the fraction of triterpene glycosides practically does not contain colored impurities, in contrast to traditional ethanol extraction. The obtained extracts by HPLC in combination with tandem mass spectrometry (HPLC-MS/MS) identified 15 triterpene glycosides, 18 styrene compounds and 14 carotenoids. Supercritical extraction made it possible to obtain extracts with yields superior to conventional hexane and alcohol extracts. Moreover, such an approach with the use of supercritical fluid extraction (SFE) and subsequent profiling of metabolites can help with the study of holothuria species that are not as well studied.\n",
      "  - The essential oil extracted from Cinnamomum camphora leaves is a mixture of volatile compounds, mainly terpenes, and is widely used in medicine, perfume and chemical industries. In this study, the extraction processes of essential oil from Cinnamomum camphora leaves by steam distillation and supercritical CO2 extraction were summarized and compared, and the camphor tree essential oil was detected by GC/MS. The extraction rate of essential oil extracted by steam distillation is less than 0.5%, while that of supercritical CO2 extraction is 4.63% at 25 MPa, 45 °C and 2.5 h. GC/MS identified 21 and 42 compounds, respectively. The content of alcohols in the essential oil is more than 35%, and that of terpenoids is more than 80%. The steam extraction method can extract volatile substances with a low boiling point and more esters and epoxides; The supercritical method is suitable for extracting weak polar substances with a high alcohol content. Supercritical CO2 extraction can selectively extract essential oil components and effectively prevent oxidation and the escape of heat sensitive substances.\n",
      "  - Interest in new products from aromatic plants as medical and nutritional compounds is increasing. The aim of this work was to apply different extraction methods, including the use of supercritical carbon dioxide extraction, and to test the antioxidant activity of basil (Ocimum basilicum L.) extracts. In vitro efficacy assessments were performed using enzymatic assays. Essential oil obtained by hydrodistillation and volatile oil obtained from supercritical fluid extraction were analyzed by gas chromatography to quantify components. The total phenolic content in the extracts ranged from 35.5 ± 2.9 to 85.3 ± 8.6 mg of gallic acid equivalents and the total flavonoid content ranged from 35.5 ± 2.9 to 93.3 ± 3.9 micromole catechin equivalents per gram of dry weight of extract. All the extracts showed an antioxidant activity with 2,2-diphenyl-1-picrylhydrazyl (DPPH), 2,2-azino-bis(3-ethylbenzthiazoline-6-sulfonic acid (ABTS), and the reducing power test. Extracts obtained from methanol had a higher antioxidant capacity per the DPPH test results (IC50 = 3.05 ± 0.36 mg/mL) and the reducing power test assay 306.8 ± 21.8 μmol of trolox equivalents per gram of extract (TE/g) compared with ethanolic or supercritical fluid extracts. However, using the ABTS assay, the extract obtained by supercritical fluid extraction had a higher antioxidant capacity with an IC50 of 1.74 ± 0.05 mg/mL. Finally, the examined extracts showed practically no acetylcholinesterase (AChE) inhibitory capacity and a slight inhibitory activity against tyrosinase.\n",
      "--------------------------------------------------\n",
      "Topic 52: 52_adsorption_membranes_co2_separation\n",
      "Representative Documents:\n",
      "  - In recent years, mixed matrix membranes (MMMs) have received worldwide attention for their potential to offer superior gas permeation and separation performance involving CO2 and CH4. However, fabricating defect-free MMMs still remains as a challenge where the incorporation of fillers into MMMs has usually led to some issues including formation of undesirable interfacial voids, which may jeopardize the gas separation performance of the MMMs. This current work investigated the incorporation of zeolite RHO and silane-modified zeolite RHO (NH2–RHO) into polysulfone (PSf) based MMMs with the primary aim of enhancing the membrane’s gas permeation and separation performance. The synthesized zeolite RHO, NH2–RHO, and fabricated membranes were characterized by X-ray diffraction (XRD) analysis, Fourier transform infrared-attenuated total reflection (FTIR-ATR), thermogravimetric analysis (TGA) and field emission scanning election microscopy (FESEM). The effects of zeolite loading in the MMMs on the CO2/CH4 separation performance were investigated. By incorporating 1 wt% of zeolite RHO into the MMMs, the CO2 permeability and ideal CO2/CH4 selectivity slightly increased by 4.2% and 2.7%, respectively, compared to that of a pristine PSf membrane. On the other hand, a significant enhancement of 45% in ideal CO2/CH4 selectivity was attained by MMMs incorporated with 2 wt% of zeolite NH2-RHO compared to a pristine PSf membrane. Besides, all MMMs incorporated with zeolite NH2-RHO displayed higher ideal CO2/CH4 selectivity than that of the MMMs incorporated with zeolite RHO. By incorporating 1–3 wt% zeolite NH2-RHO into PSf matrix, MMMs without interfacial voids were successfully fabricated. Consequently, significant enhancement in ideal CO2/CH4 selectivity was enabled by the incorporation of zeolite NH2–RHO into MMMs.\n",
      "  - In this study, the Ni/KIT-6 and Ce/KIT-6 materials were prepared through the impregnation method and then amino-functionalized materials were obtained by the grafting of an amino-silane coupling agent 3-aminopropyl triethoxysilane (APTES). The samples were characterized by thermogravimetric analysis (TGA-DTA), Fourier transform infrared spectroscopy (FT-IR), X-ray diffraction, scanning electron microscopy (SEM) and nitrogen adsorption at 77 K. The study of CO2 adsorption–desorption on prepared materials was investigated using thermogravimetric analysis (TGA-DTA) coupled with mass spectrometry (MS). The influence of metal oxides on the performance of CO2 adsorption on functionalized mesoporous silica was presented. The results showed that doping the molecular sieve with cerium oxide can significantly increase the adsorption capacity of the amino-functionalized KIT-6. As the CO2 adsorbents were prepared by functionalization through grafting with APTES, the amount of amine loading is one of the important factors which improves CO2 adsorption capacity. Additionally, CO2 adsorption performance depends on the textural properties and the temperature used for the adsorption process. The maximum adsorption capacity of Ce/KIT-6 Sil is 3.66 mmol/g, which is 2.4 times higher than Ni/KIT-6 Sil. After the nine cycles of cyclic CO2 adsorption/desorption, the Ce/KIT-6 Sil still had higher adsorption capacities, indicating their good cyclical stability.\n",
      "  - Fillers play a critical role in the performance of mixed matrix membranes (MMMs). Microporous metal azolate frameworks (MAFs) are a subclass material of metal–organic frameworks (MOFs). Due to the uncoordinated nitrogen of the organic ligands, MAF-7 (SOD-[Zn(mtz)2], Hmtz = 3-methyl-1,2,4-triazole, window: d = 0.34 nm) shows excellent CO2 adsorption performance. In this work, Pebax 1657/MAF-7 MMMs were prepared by a sample solution casting method with MAF-7 particles as fillers for the first time. By means of X-ray diffraction (XRD), scanning electron microscope (SEM), infrared radiation (IR), and thermogravimetry (TG), the compositional and structural properties of the mixed matrix membrane with different filler content were analyzed. The results show that the compatibility of MAF-7 and Pebax is good with a filler content of 5 wt.%. The pure gas testing showed that mixed matrix membrane has a high ideal CO2/N2 selectivity of 124.84 together with a better CO2 permeability of 76.15 Barrer with the optimized filler content of 5 wt.%. The obtained membrane showed 323.04% enhancement in selectivity of CO2/N2 and 27.74% increase in the permeability of CO2 compared to the pristine membrane at 25 °C and 3 bar. The excellent separation performance may be due to the ligands that can afford a Lewis base active site for CO2 binding with the uniform dispersion of MAF-7 particles in Pebax and the favorable interface compatibility. The obtained membrane overcomes the Robeson’s upper bound in 2008 for CO2/N2 separation. This work provides a new strategy by utilizing MAFs as fillers with triazole ligand to enhance the gas separation performance of mixed matrix membranes.\n",
      "--------------------------------------------------\n",
      "Topic 53: 53_world_special_human_global\n",
      "Representative Documents:\n",
      "  - Climate change, air pollution, urbanization, globalization, demographic changes and changing consumption patterns affect forests and their social, cultural, ecological and economic functions, resulting in consequences for the social value of forests and for people’s livelihoods, health and quality of life [...]\n",
      "  - The evaluation of aquifer recharge is essential to make a quantitative evaluation of renewable groundwater resources required to implement proper water policies aimed at maintaining stream–aquifer interactions, guaranteeing water supply to human activities, and preserving groundwater-dependent ecosystems at different spatial and temporal scales and climate conditions [...]\n",
      "  - In the modern era of industrial revolution, urbanization, and deforestation of forest land, carbon (C) sequestration through well-known activities called “land use, land-use change and forestry (LULUCF)” could establish a win–win situation from a climate change and sustainable development perspective [...]\n",
      "--------------------------------------------------\n",
      "Topic 54: 54_disease_transmission_borne_diseases\n",
      "Representative Documents:\n",
      "  -                 Background                Climate variability influences the population dynamics of the Aedes aegypti mosquito that transmits the viruses that cause dengue, chikungunya and Zika. In recent years these diseases have grown considerably. Dengue is now the fastest-growing mosquito-transmitted disease worldwide, putting 40 per cent of the global population at risk. With no effective antiviral treatments or vaccines widely available, controlling mosquito population remains one of the most effective ways to prevent epidemics. This paper analyses the temporal and spatial dynamics of dengue in Mexico during 2000–2020 and that of chikungunya and Zika since they first appeared in the country in 2014 and 2015, respectively. This study aims to evaluate how seasonal climatological variability affects the potential risk of transmission of these mosquito-borne diseases. Mexico is among the world’s most endemic countries in terms of dengue. Given its high incidence of other mosquito-borne diseases and its size and wide range of climates, it is a good case study.                              Methods                We estimate the recently proposed mosquito-borne viral suitability index P, which measures the transmission potential of mosquito-borne pathogens. This index mathematically models how humidity, temperature and precipitation affect the number of new infections generated by a single infected adult female mosquito in a host population. We estimate this suitability index across all Mexico, at small-area level, on a daily basis during 2000–2020.                              Results                We find that the index P predicted risk transmission is strongly correlated with the areas and seasons with a high incidence of dengue within the country. This correlation is also high enough for chikungunya and Zika in Mexico. We also show the index P is sensitive to seasonal climatological variability, including extreme weather shocks.                              Conclusions                The paper shows the dynamics of dengue, chikungunya and Zika in Mexico are strongly associated with seasonal climatological variability and the index P. This potential risk of transmission index, therefore, is a valuable tool for surveillance for mosquito-borne diseases, particularly in settings with varied climates and limited entomological capacity.              \n",
      "  -           Vector-borne diseases have a worldwide distribution and are associated with a significant burden causing over one million deaths annually. Dengue and malaria are the most prevalent mosquito-borne diseases globally. Vectors transmit the infections to human and animal hosts and are the primary targets of disease control strategies. These vectors are sensitive to weather conditions, and outbreaks are associated with optimum range of temperature, precipitation and other relevant weather variables. Climate change refers to environmental changes occurring around the world as a result of human activities and is likely to be more severe towards the end of the century if climate mitigation targets are not met. Climate change is, therefore, already changing the epidemiology and distribution of these vector-borne diseases. In this review, the effect of climate change on the emergence and spread of several vector-borne diseases, with a particular focus on dengue, is explored. Additionally, the contribution of other non-climatic key factors driving disease transmission and distribution and influencing the emergence and spread of vector-borne diseases is also discussed.\n",
      "  - Climate change refers to variation in the climate of a specific region or globally over time. A change has been reported in the epidemiology of tick‐ and mosquito‐borne diseases in recent decades. Investigators have postulated that this effect may be associated with climate change. We reviewed the English‐language literature describing changes in the epidemiology of specific tick‐ and mosquito‐borne diseases, including the tick‐borne diseases of Lyme disease, tularemia, Crimean‐Congo hemorrhagic fever, Mediterranean spotted fever, and Rocky Mountain spotted fever and the mosquito‐borne diseases of dengue, malaria, West Nile virus infection, Ross River virus disease, and Barmah Forest virus disease. We postulate that the changing epidemiology of tick‐ and mosquito‐borne diseases is related to climate change.\n",
      "--------------------------------------------------\n",
      "Topic 55: 55_ice_ice sheet_sheet_ice sheets\n",
      "Representative Documents:\n",
      "  - . Modeling studies have shown that the continental-scale ice sheets in North America and Eurasia in the last glacial cycle had a large influence on the atmospheric circulation and thus yielded a climate distinctly different from the present. However, to what extent the two ice sheets influenced each others' growth trajectories remains largely unexplored. In this study we investigate how an ice sheet in North America influences the downstream evolution of the Eurasian ice sheet, using a thermomechanical ice-sheet model forced by climate data from atmospheric snapshot experiments of three distinctly different phases of the last glacial cycle: the Marine Isotope Stages 5b, 4, and 2 (Last Glacial Maximum – LGM). Owing to the large uncertainty associated with glacial changes in the Atlantic meridional overturning circulation, each atmospheric snapshot experiment was conducted using two distinctly different ocean heat transport representations. Our results suggest that changes in the North American paleo-topography may have largely controlled the zonal distribution of the Eurasian ice sheet. In the MIS4 and LGM experiments, the Eurasian ice sheet migrates westward towards the Atlantic sector – largely consistent with geological data and contemporary ice-sheet reconstructions – due to a low wave number stationary wave response, which yields a cooling in Europe and a warming in northeastern Siberia. The expansion of the North American ice sheet between MIS4 and the LGM amplifies the Siberian warm anomaly, which limits the glaciation there and may therefore help explain the progressive westward migration of the Eurasian ice sheet in this time period. The ocean heat transport only has a small influence on the stationary wave response to the North American glacial topography; however, because temperature anomalies have a smaller influence on an ice sheet's ablation in a colder climate than in a warmer one, the impact of the North American glacial topography on the Eurasian ice-sheet evolution is reduced for colder surface conditions in the North Atlantic. While the Eurasian ice sheet in the MIS4 and the LGM experiments appears to be in equilibrium with the simulated climate conditions, the MIS5b climate forcing is too warm to grow an ice sheet in Eurasia. First-order sensitivity experiments suggest that the MIS5b ice sheet was established during preceding colder stages.\n",
      "  - The Last Glacial Maximum extent of the North American Ice Sheets is well constrained empirically but has proven to be challenging to simulate with coupled Climate‐Ice Sheet models. Coupled Climate‐Ice Sheet models are often too computationally expensive to sufficiently explore uncertainty in input parameters, and it is unlikely that values calibrated to reproduce modern ice sheets will reproduce the known extent of the ice at the Last Glacial Maximum. To address this, we run an ensemble with a coupled Climate‐Ice Sheet model (FAMOUS‐ice), simulating the final stages of growth of the last North American Ice Sheets' maximum extent. Using this large ensemble approach, we explore the influence of numerous uncertain ice sheet albedo, ice sheet dynamics, atmospheric, and oceanic parameters on the ice sheet extent. We find that ice sheet albedo parameters determine the majority of uncertainty when simulating the Last Glacial Maximum North American Ice Sheets. Importantly, different albedo parameters are needed to produce a good match to the Last Glacial Maximum North American Ice Sheets than have previously been used to model the contemporary Greenland Ice Sheet due to differences in cloud cover over ablation zones. Thus, calibrating coupled climate‐ice sheet models on one ice sheet may produce strong biases when the model is applied to a new domain.\n",
      "  - . It is now widely acknowledged that past Northern Hemisphere ice sheets covering Canada and northern Europe at the Last Glacial Maximum (LGM) exerted a strong influence on climate by causing changes in atmospheric and oceanic circulations. In turn, these changes may have impacted the development of the ice sheets themselves through a combination of different feedback mechanisms. The present study is designed to investigate the potential impact of the North American ice sheet on the surface mass balance (SMB) of the Eurasian ice sheet driven by simulated changes in the past glacial atmospheric circulation. Using the LMDZ5 atmospheric circulation model, we carried out 12 experiments under constant LGM conditions for insolation, greenhouse gases and ocean. In these experiments, the Eurasian ice sheet is removed. The 12 experiments differ in the North American ice-sheet topography, ranging from a white and flat (present-day topography) ice sheet to a full-size LGM ice sheet. This experimental design allows the albedo and the topographic impacts of the North American ice sheet onto the climate to be disentangled. The results are compared to our baseline experiment where both the North American and the Eurasian ice sheets have been removed. In summer, the sole albedo effect of the American ice sheet modifies the pattern of planetary waves with respect to the no-ice-sheet case, resulting in a cooling of the northwestern Eurasian region. By contrast, the atmospheric circulation changes induced by the topography of the North American ice sheet lead to a strong decrease of this cooling. In winter, the Scandinavian and the Barents–Kara regions respond differently to the American ice-sheet albedo effect: in response to atmospheric circulation changes, Scandinavia becomes warmer and total precipitation is more abundant, whereas the Barents–Kara area becomes cooler with a decrease of convective processes, causing a decrease of total precipitation. The gradual increase of the altitude of the American ice sheet leads to less total precipitation and snowfall and to colder temperatures over both the Scandinavian and the Barents and Kara sea sectors. We then compute the resulting annual surface mass balance over the Fennoscandian region from the simulated temperature and precipitation fields used to force an ice-sheet model. It clearly appears that the SMB is dominated by the ablation signal. In response to the summer cooling induced by the American ice-sheet albedo, high positive SMB values are obtained over the Eurasian region, leading thus to the growth of an ice sheet. On the contrary, the gradual increase of the American ice-sheet altitude induces more ablation over the Eurasian sector, hence limiting the growth of Fennoscandia. To test the robustness of our results with respect to the Eurasian ice sheet state, we carried out two additional LMDZ experiments with new boundary conditions involving both the American (flat or full LGM) and high Eurasian ice sheets. The most striking result is that the Eurasian ice sheet is maintained under full-LGM North American ice-sheet conditions, but loses ~ 10 % of its mass compared to the case in which the North American ice sheet is flat. These new findings qualitatively confirm the conclusions from our first series of experiments and suggest that the development of the Eurasian ice sheet may have been slowed down by the growth of the American ice sheet, offering thereby a new understanding of the evolution of Northern Hemisphere ice sheets throughout glacial–interglacial cycles.\n",
      "--------------------------------------------------\n",
      "Topic 56: 56_laser_plasma_pulse_co2 laser\n",
      "Representative Documents:\n",
      "  - A CO2 laser system with flexible parameters was developed for fundamental research related to an extreme ultraviolet (EUV) lithography source. The laser is a master oscillator and power amplifier (MOPA) system, consisting of a master oscillator, an externally triggered plasma switch, a preamplifier, a main amplifier, and electronic synchronization units. The laser pulse duration can be varied easily from 10 to 110 ns, with a constant peak power for pulse durations from 25 to 110 ns. The MOPA laser system can also be operated in dual-oscillator mode to produce laser pulse with pulse duration as long as 200ns and a train of laser pulses with flexible interval. The divergence of the laser beam is 1.3 times the diffraction limit. The laser intensity on the target surface can be up to 8×1010 W/cm2. Utilizing this CO2 MOPA laser system, high conversion efficiency from laser to in-band (2% bandwidth) 13.5 nm EUV emission has been demonstrated over a wide range of laser pulse durations.\n",
      "  - A repeatable and flexible technique for pulse shortening of laser pulses has been applied to transversely excited atmospheric (TEA) CO2 laser pulses. The technique involves focusing the laser output onto a highly reflective metal target so that plasma is formed, which then operates as a shutter due to strong laser absorption and scattering. Precise control of the focused laser intensity allows for timing of the shutter so that different temporal portions of the pulse can be reflected from the target surface before plasma formation occurs. This type of shutter enables one to reduce the pulse duration down to ∼2 ns and to remove the low power, long duration tails that are present in TEA CO2 pulses. The transmitted energy is reduced as the pulse duration is decreased but the reflected power is ∼10 MW for all pulse durations. A simple laser heating model verifies that the pulse shortening depends directly on the plasma formation time, which in turn is dependent on the applied laser intensity. It is envisaged that this plasma shutter will be used as a tool for pulse shaping in the search for laser pulse conditions to optimize conversion efficiency from laser energy to useable extreme ultraviolet (EUV) radiation for EUV source development.\n",
      "  - The evolution of laser-induced plasma for an aluminum target in a helium ambient gas at different pressures of 100, 300, 500, 700, and 1000 mbar is numerically studied. A thermal model of laser ablation is utilized for calculation of plasma parameters which comprise heat conduction, Euler equations, Saha–Eggert equations, Knudsen layer boundary condition, mass and energy balance relations, and optical shielding effects. In addition, in order to determine the temporal parameters of aluminum's plasma, the hydrodynamic equations are computed for calculation of the plasma absorption due to inverse Bremsstrahlung and photoionization. A CO2 laser pulse at a wavelength of 10.6 μm with different pulse durations of 50 and 100 ns is irradiated on laser induced Al plasma for truncation of the transmitted CO2 laser pulse. The laser intensities irradiated on the Al sample for producing plasma and generation of a shortened pulse are considered as 1016, 1017, and 5 × 1017 W/m2. Furthermore, for validation of the theoretical calculations, some experimental results are presented. Results showed that higher helium gas pressures caused the critical density attained at earlier delay times which caused the CO2 laser beam became efficiently truncated. Moreover, it is concluded that pulse duration has an inverse relation with ambient gas pressure and laser intensity which means that the higher gas pressure or laser intensity induces less pulse duration.\n",
      "--------------------------------------------------\n",
      "Topic 57: 57_students_education_awareness_attitudes\n",
      "Representative Documents:\n",
      "  - Climate change is not a future problem, it is a significant variation of weather conditions becoming warmer, wetter or drier. It is the longer-term trend that differentiates climate change from natural weather variability. The aim of this research was to determine primary school students’ knowledge and attitudes related to climate change among primary school students (n = 473) in the Czech Republic, the United Kingdom and Portugal using a questionnaire survey. The dimensions of climate change knowledge, environmental attitudes and values, pro-environmental behaviour, and climate change attitudes were measured and analysed. The results showed gender differences in favour of girls in all the dimensions studied, except for climate change knowledge, where the results of boys and girls were comparable. In an international comparison, UK children scored higher on climate change knowledge and climate change attitudes dimensions. A multiple regression analysis showed the dimensions of nature preservation and appreciation of nature as the strongest positive predictors of pro-environmental behaviour and the dimensions of climate change knowledge and nature preservation as the strongest predictors of climate change belief. The results suggest the importance and implications of the wider societal debate on climate-related personal dimensions. The interconnectedness of environmental and climate-related topics at the primary school level is also evident.Keywords: climate change attitudes, climate change education, climate change knowledge, environmental attitudes, pro-environmental behaviour, primary school\n",
      "  - Universities play an essential role in spreading climate change awareness. However, slight information on climate change and environmental issues had been integrated into the curricula. Moreover, minimal research had been carried out to understand university role in spreading awareness, and students level of awareness and daily behaviour towards climate change, especially in developing countries. This paper aims to investigate the aforementioned issues. An experimental study was carried out on 448 undergraduate students enrolled at An-Najah National University Palestine. The study aimed to examine students’ knowledge and daily behaviour towards climate change, and the important role the university and students’ societies play in terms of spreading and enhancing awareness. The results revealed that female and male students had a non satisfactory interest level in environmental topics and activities, and gender equality did not seem to be an issue. Moreover, female students tend to have a significantly lower level of awareness on climate change compared to male students. On the other hand, being an engineering students or a member in students’ societies had a positive impact on students’ level of awareness and especially females. The results revealed that female students who are enrolled in the engineering faculty or members of students’ societies had a significantly higher level of awareness compared to female students who are enrolled in other faculties or not members of students’ societies. In general, students had a low level of awareness regardless of gender or faculty and universities should offer undergraduate students and especially female students’ opportunities to learn more about climate change by integrating climate change topics into higher education. Moreover, universities should support extracurricular activities held by student societies, and some of these activities should be directed towards environmental and climate change issues. This study entails the activities of the Mediterranean Gender Equality Community of Practice co-created by the Mediterranean Network of Engineering Schools (RMEI), where An-Najah University is an active member, with the support of the EU TARGET project entitled ’Taking a reflexive approach to gender equality at Institutional transformation’.\n",
      "  - PurposeThis paper analyzes the role that the climate change concern (CCCi) has on the willingness to accept an environmental tax. The author aims to grasp how individual general tax preferences can differ with respect to the specific (environmental) tax. He focuses attention to the Italian case since it has been argued that the potential acceptability of a carbon tax in Italy is relatively high, and this topic has been scarcely explored so far among Italian citizens (Rotaris and Danielis, 2019).Design/methodology/approachThe author conducted an online survey among 514 Italian economics students.FindingsThe CCCi positively influences the environmental tax morale (ETMi). The general tax morale (TMi) positively affects the specific (environmental) TMi. The CCCi alters individual tax preferences. The author evidenced that also subjects with low TMi turned out to be willing to pay an environmental tax if aware of the environmental issues.Research limitations/implicationsAlthough the author used a common methodology in this strand of research, he is aware that in an online survey individuals can be influenced by the self-reporting and hypothetical choice bias (see Swamy et al., 2001), that in turn can characterize their reported preferences. Moreover, even if economics university students are commonly used as a subject pool in experimental economics settings, and although several studies showed that the behavioral responses of students are largely the same as those of nonstudents in identical experiments (for a discussion see Alm, 2012; Choo et al., 2016), there is awareness that in this case, they are not taxpayers yet (Barabas and Jerit, 2010).Practical implicationsThe author’s results remark the importance of increasing climate change awareness among people to let them be more willing to pay the environmental tax, for instance through investments in sensibilization campaigns on the importance of energy source usage and climate-related topic. Then, an increase in the general TMi leads to an increase in the specific (environmental) TMi. The author’s evidence showed that people with high tax morale logically recognize the positive impact of paying an environmental tax when the CCCi increases, since the more the theme becomes important, the larger the willingness to pay the specific tax. For this reason, policymakers should carry on campaigns to increase the general level of TMi to increase the overall tax compliance level and the relative tax revenues, following the guidelines given by the Organisation for Economic Co-operation and Development (2019) to support taxpayer education programs, such as including TMi research and analysis into education programs, improving the ease of paying taxes or strengthening revenue–expenditure links to build the social contract.Social implicationsIt should be paramount to increase awareness about environmental topics among people in general and among those who are relatively tax immoral. The author’s results remark on the importance of targeting energy and environmental tax policies to groups rather than to individuals. According to this evidence, we support the use of nonmonetary tools to nudge people in the environmental transition by changing their behavior in energy use, for instance through the taxation on fuel and other nonrenewable energy resources.Originality/valueIt is the first empirical study that analyzes the impact of CCCi on the environmental TMi in Italy, in particular controlling for the role of the general willingness to pay taxes (TMi). To obtain individual attitudes toward tax payment, most of the empirical studies in behavioral economics employ international surveys. For studies across citizens living in European countries, the European Social Survey (ESS) and European Values Study (EVS) represent the most used ones (see, for instance, Martinez-Vazquez and Torgler (2009) in Spain; Torgler and Werner (2005) in Germany; Nemore and Morone (2019) in Italy). However, these surveys do not allow to study the relationship between the environmental and general TMi across the same subject pool. In fact, despite the ESS (2016) provides individual responses about the willingness to pay an environmental tax, it does not provide information about the general individual attitude toward tax payment (this information is contained only in the ESS wave of 2004, hence referring to a different subject pool). On the contrary, each wave of the EVS (i.e. 2008, 2017) provides information about the general individual attitude toward tax payment, but this survey does not provide a question regarding the willingness to pay an environmental tax. Therefore, to obtain information about the willingness to pay both general and environmental taxes, across the same subject pool, it is needed to carry out a survey.\n",
      "--------------------------------------------------\n",
      "Topic 58: 58_development_resilience_adaptation_health\n",
      "Representative Documents:\n",
      "  - This article summarises a recent virtual meeting organised by the Oxford University Clinical Research Unit in Vietnam on the topic of climate change and health, bringing local partners, faculty and external collaborators together from across the Wellcome and Oxford networks. Attendees included invited local and global climate scientists, clinicians, modelers, epidemiologists and community engagement practitioners, with a view to setting priorities, identifying synergies and fostering collaborations to help define the regional climate and health research agenda. In this summary paper, we outline the major themes and topics that were identified and what will be needed to take forward this research for the next decade. We aim to take a broad, collaborative approach to including climate science in our current portfolio where it touches on infectious diseases now, and more broadly in our future research directions. We will focus on strengthening our research portfolio on climate-sensitive diseases, and supplement this with high quality data obtained from internal studies and external collaborations, obtained by multiple methods, ranging from traditional epidemiology to innovative technology and artificial intelligence and community-led research. Through timely agenda setting and involvement of local stakeholders, we aim to help support and shape research into global heating and health in the region.\n",
      "  - Climate change is one of today's major challenges, and among the causes of population movement and international migration. Climate migrants impact health systems and how their ability to respond and adapt to their needs and patterns.  To date, the resilience of health systems in the context of climate change has barely been explored. The purpose of this article is to show the importance of studying the relationship between climate change, migration, and the resilience of health systems from an interdisciplinary perspective. Resilience is an old concept, notably in the field of psychology, and is increasingly applied to the study of health systems. Yet, no research has analysed the resilience of health systems in the context of climate change. While universal health coverage is a major international goal, little research to date focused on the existing links between climate, migration, health systems and resilience. We propose an interdisciplinary approach relying on the concept of health system resilience to study adaptive and transformative strategies to articulate climate change, migration and health systems.\n",
      "  - Climate change is one of today's major challenges, among the causes of population movements and international migration. Climate migrants impact health systems and how they respond and adapt to their needs and patterns. But to date, the resilience of health systems in the context of climate change has been little explored. The purpose of this article is to show the importance of studying, from an interdisciplinary perspective, the relationships between climate change, migration, and the resilience of health systems. Resilience is an old concept, notably in the field of psychology, and is increasingly applied to the study of health systems. Yet, no research has analysed the resilience of health systems in the context of climate change. While universal health coverage is a major international goal, little research has to date focused on the existing links between climate, migration, health systems and resilience. We propose an interdisciplinary approach relying on the concept of health system resilience to study adaptive and transformative strategies to articulate climate change, migration and health systems.\n",
      "--------------------------------------------------\n",
      "Topic 59: 59_flowering_phenological_phenology_species\n",
      "Representative Documents:\n",
      "  - Organisms across the globe are experiencing shifts in phenological events as a result of ongoing climate change. Recently, a variety of novel methods have been applied in order to fill gaps in the phenological data set, in which records often have a patchy temporal, spatial, and/or taxonomic resolution. Here, I tested whether changes in flowering phenology could be detected through the months of flowering stated in 11 guides to the Swedish flora published over a period of 220 yr (1798–2018), focussing on 241 plant species (approximately 8% of the Swedish flora), and accounting for the large increase in herbarium records that have occurred over the same period. Despite the coarse, monthly scale of flowering times reported, historical floras and wildflower guides may hold potential to fill temporal and taxonomic gaps in the plant phenological data set. However, factors other than climate may also influence any apparent phenological shifts over time. Here, flowering was found to start earlier (0.49 d/decade), end later (0.71 d/decade), and carry on longer (1.19 d/decade), with flowering length also associated with increases in the regional temperature anomaly during the 20th century (0.11 months/°C). First flowering occurring earlier in 71% of species (14% showing a significant negative trend), 68% of species ceased flowering later (20%), and 80% flowered for longer (29%). Detected phenological shifts also appeared to be related to species’ flowering seasonality. Later‐flowering species were found to flower later and for longer, while increasing temperatures appeared to drive stronger responses both in flowering onset in early‐flowering species and in flowering cessation in later‐flowering species. Although potential issues exist regarding the largely unknown ways by which authors have determined flowering times and the coarseness of the data, historical floras may be a useful resource in phenological and climate change research, with the potential to both identify and compare the broad climatic responses of a region’s entire flora over long time periods, as well as filling gaps in an otherwise patchy data set.\n",
      "  - The timing of phenological events is highly sensitive to climate change, and may influence ecosystem structure and function. Although changes in flowering phenology among species under climate change have been reported widely, how species‐specific shifts will affect phenological synchrony and community‐level phenology patterns remains unclear. We conducted a manipulative experiment of warming and precipitation addition and reduction to explore how climate change affected flowering phenology at the species and community levels in an alpine meadow on the eastern Tibetan Plateau. We found that warming advanced the first and last flowering times differently and with no consistent shifts in flowering duration among species, resulting in the entire flowering period of species emerging earlier in the growing season. Early‐flowering species were more sensitive to warming than mid‐ and late‐flowering species, thereby reducing flowering synchrony among species and extending the community‐level flowering season. However, precipitation and its interactions with warming had no significant effects on flowering phenology. Our results suggest that temperature regulates flowering phenology from the species to community levels in this alpine meadow community, yet how species shifted their flowering timing and duration in response to warming varied. This species‐level divergence may reshape flowering phenology in this alpine plant community. Decreasing flowering synchrony among species and the extension of community‐level flowering seasons under warming may alter future trophic interactions, with cascading consequences to community and ecosystem function.\n",
      "  - Flowering phenology is very sensitive to climate and with increasing global warming the flowering time of plants is shifting to earlier or later dates. Changes in flowering times may affect species reproductive success, associated phenological events, species synchrony, and community composition. Long‐term data on phenological events can provide key insights into the impacts of climate on phenology. For Australia, however, limited data availability restricts our ability to assess the impacts of climate change on plant phenology. To address this limitation other data sources must be explored such as the use of herbarium specimens to conduct studies on flowering phenology. This study uses herbarium specimens for investigating the flowering phenology of five dominant and commercially important Eucalyptus species of south‐eastern Australia and the consequences of climate variability and change on flowering phenology. Relative to precipitation and air humidity, mean temperature of the preceding 3 months was the most influential factor on the flowering time for all species. In response to a temperature increment of 1°C, a shift in the timing of flowering of 14.1–14.9 days was predicted for E. microcarpa and E. tricarpa while delays in flowering of 11.3–15.5 days were found for E. obliqua, E. radiata and E. polyanthemos. Eucalyptus polyanthemos exhibited the greatest sensitivity to climatic variables. The study demonstrates that herbarium data can be used to detect climatic signals on flowering phenology for species with a long flowering duration, such as eucalypts. The robust relationship identified between temperature and flowering phenology indicates that shifts in flowering times will occur under predicted climate change which may affect reproductive success, fitness, plant communities and ecosystems.\n",
      "--------------------------------------------------\n",
      "Topic 60: 60_heat_cycle_heat transfer_pressure\n",
      "Representative Documents:\n",
      "  - A gas cooler is one of the important parts of a carbon dioxide (CO2) heat pump water heater, and it must meet the needs of not only pressurization but also heat transfer. It is important to study gas coolers. In this paper, a heat exchanger with a spiral channel is studied. ANSYS CFX software was used to analyze the flow and heat transfer characteristics of the heat exchanger (single-plate model). The influences of the cooling pressure of CO2, the mass flux of CO2, the mass flux of water and the channel radius of CO2 are discussed. In this paper, the results show that the cooling pressure of CO2, the mass flux of CO2 and the channel radius of CO2 all have a large influence on the local heat transfer coefficient: with an increase in the cooling pressure of CO2, the peak value of the heat transfer coefficient of CO2 decreases and the average heat transfer coefficient decreases; with an increase in the mass flux of CO2, the peak value of the heat transfer coefficient of CO2 increases and the average heat transfer coefficient increases; and with a decrease in the channel radius of CO2, the peak value of the heat transfer coefficient of CO2 increases. The water mass flux has only a slight effect on heat transfer, and the lower cooling pressure of CO2 corresponds to a higher peak heat transfer coefficient, which can reach 27.5 kW∙m−2∙K−1 at 9 MPa.\n",
      "  - The supercritical CO2 is used as working fluid for power system cycle. This paper presents thermodynamic performance analysis results on supercritical CO2 Brayton cycle. Based on the assumptions of the relevant initial parameters, the mathematical models of compressor, turbine, recuperator and heater are constructed, and the thermal efficiency of regenerative Brayton cycle and recompression Brayton cycle are calculated and analyzed. The results reveal that the efficiency of the recompression cycle is higher than that of the simple regenerative cycle. The effects of inlet temperature, inlet pressure of the main compressor and inlet temperature, inlet pressure of the turbine on the thermodynamic performance of the recompression cycle are studied, and the influencing mechanism is explained. The results show that the cycle efficiency decreases with the increase of the inlet temperature of the main compressor. There exists an optimum inlet pressure in the main compressor to maximize the cycle efficiency. The cycle efficiency of the system increases with the increase of the inlet temperature and pressure of the turbine. When the inlet temperature of the turbine exceeds 600?, the thermal efficiency of the cycle can reach more than 50%.\n",
      "  - Using supercritical CO2 as a heat transfer fluid in microchannel receivers is a promising alternative for tower concentrating solar power plants. In this paper, the heat transfer and flow characteristics of supercritical CO2 in microchannels at high temperature are investigated by numerical simulations. The effects of microchannel structure, mass flow rate, heat flux, pressure, inlet temperature and radiation are analyzed and discussed. The results show that higher mass flow rate obtains poorer heat transfer performance with larger flow resistance of supercritical CO2 in microchannels at high temperature. The fluid and wall temperatures, average heat transfer coefficient and pressure drop all increase nearly linearly with the increases in heat flux and inlet temperature in the high-temperature region. Moreover, high pressure contributes to great hydraulic performance with approximate thermal performance. The effect of radiation on thermal performance is more pronounced than that on hydraulic performance. Furthermore, the optimized structures of inlet and outlet headers, as well as those of the multichannel in the microchannels, are proposed to obtain good temperature uniformity in the microchannels with relatively low pressure drop. The results given in the current study can be conducive to the design and application of microchannel receivers with supercritical CO2 as a heat transfer fluid in the third generation of concentrating solar power plants.\n",
      "--------------------------------------------------\n",
      "Topic 61: 61_health_search_scoping_systematic\n",
      "Representative Documents:\n",
      "  - ObjectivesWe aimed to develop a systematic synthesis of systematic reviews of health impacts of climate change, by synthesising studies’ characteristics, climate impacts, health outcomes and key findings.DesignWe conducted an overview of systematic reviews of health impacts of climate change. We registered our review in PROSPERO (CRD42019145972). No ethical approval was required since we used secondary data. Additional data are not available.Data sourcesOn 22 June 2019, we searched Medline, Cumulative Index to Nursing and Allied Health Literature (CINAHL), Embase, Cochrane and Web of Science.Eligibility criteriaWe included systematic reviews that explored at least one health impact of climate change.Data extraction and synthesisWe organised systematic reviews according to their key characteristics, including geographical regions, year of publication and authors’ affiliations. We mapped the climate effects and health outcomes being studied and synthesised major findings. We used a modified version of A MeaSurement Tool to Assess systematic Reviews-2 (AMSTAR-2) to assess the quality of studies.ResultsWe included 94 systematic reviews. Most were published after 2015 and approximately one-fifth contained meta-analyses. Reviews synthesised evidence about five categories of climate impacts; the two most common were meteorological and extreme weather events. Reviews covered 10 health outcome categories; the 3 most common were (1) infectious diseases, (2) mortality and (3) respiratory, cardiovascular or neurological outcomes. Most reviews suggested a deleterious impact of climate change on multiple adverse health outcomes, although the majority also called for more research.ConclusionsMost systematic reviews suggest that climate change is associated with worse human health. This study provides a comprehensive higher order summary of research on health impacts of climate change. Study limitations include possible missed relevant reviews, no meta-meta-analyses, and no assessment of overlap. Future research could explore the potential explanations between these associations to propose adaptation and mitigation strategies and could include broader sociopsychological health impacts of climate change.\n",
      "  - Background: Effective and rapid actions are required to achieve global goals for climate change mitigation, and there is an opportunity to ensure that the actions taken are also positive for human health. However, little is known about the relative magnitude of the health co-benefits that can be achieved from mitigation actions, so robust and comprehensive syntheses of the evidence on the nature and effects of relevant actions are required. This paper presents a protocol for an interdisciplinary and cross-sectoral umbrella review of systematic reviews, synthesising modelled and empirical evidence on such actions. Methods: Nine bibliographic databases will be searched, capturing literature across a wide range of disciplines and sectors. Unique records retrieved by the searches will be screened by two independent reviewers. The quality of all the included systematic reviews will be assessed using A MeaSurement Tool to Assess Systematic Reviews (AMSTAR) 2 critical appraisal tool. Data will be extracted on methodological and thematic characteristics of the reviews, nature of the actions, and their effects on greenhouse gas emission reduction, health, and its determinants, as well as any other reported effects and interactions across different actions. Results: Narrative and quantitative synthesis methods will be used to create a typology of relevant actions, map pathways to their impacts on health, compare the magnitude of health and greenhouse gas (GHG) emission reduction impacts by selected characteristics of the actions and the nature of the evidence, as well as to identify gaps in evidence syntheses. Conclusion: This review will identify the most effective actions for global climate change mitigation and health based on the best available scientific evidence.   This protocol has been registered in PROSPERO, Reg No.: CRD42021239292.\n",
      "  - Background: Effective and rapid actions are required to achieve global goals for climate change mitigation, and there is an opportunity to ensure that the actions taken are also positive for human health. However, little is known about the relative magnitude of the health co-benefits that can be achieved from mitigation actions, so robust and comprehensive syntheses of the evidence on the nature and effects of relevant actions are required. This paper presents a protocol for an interdisciplinary and cross-sectoral umbrella review of systematic reviews, synthesising modelled and empirical evidence on such actions. Methods: Nine bibliographic databases will be searched, capturing literature across a wide range of disciplines and sectors. Unique records retrieved by the searches will be screened by two independent reviewers. The quality of all the included systematic reviews will be assessed using A MeaSurement Tool to Assess Systematic Reviews (AMSTAR) 2 critical appraisal tool. Data will be extracted on methodological and thematic characteristics of the reviews, nature of the actions, and their effects on greenhouse gas emission reduction, health, and its determinants, as well as any other reported effects and interactions across different actions. Results: Narrative and quantitative synthesis methods will be used to create a typology of relevant actions, map pathways to their impacts on health, compare the magnitude of health and greenhouse gas (GHG) emission reduction impacts by selected characteristics of the actions and the nature of the evidence, as well as to identify gaps in evidence syntheses. Conclusion: This review will identify the most effective actions for global climate change mitigation and health based on the best available scientific evidence.   This protocol has been registered in PROSPERO, Reg No.: CRD42021239292.\n",
      "--------------------------------------------------\n",
      "Topic 62: 62_water_hydrological_river_catchment\n",
      "Representative Documents:\n",
      "  - . Currently, climate change is a major concern around the world, especially because of the uncertainty associated with its possible consequences for society. Among them, fluvial alterations can be highlighted in basins whose flows depend on groundwater discharges and snowmelt. This is the case of the headwaters of the Tagus River basin, whose water resources, besides being essential for water uses within this basin, are susceptible to being transferred to the Segura River basin (both basins are in the Iberian Peninsula). This work studies the possible effects that the latest climate change scenarios may have on this transfer, one of the most important ones in southern Europe. In the first place, the possible alterations of the water cycle of the donor basin were estimated. To do this, a hydrological model was calibrated. Then, with this model, three climatic scenarios were simulated, one without climate change and two projections under climate change (Representative Concentration Pathways 4.5 (RCP 4.5) and 8.5 (RCP 8.5)). The results of these three hydrological modelling scenarios were used to determine the possible flows that could be transferred from the Tagus River basin to the Segura River basin, by simulating the water resource exploitation system of the Tagus headwaters. The calibrated hydrological model predicts, for the simulated climate change scenarios, important reductions in the snowfalls and snow covers, the recharge of aquifers, and the available water resources. So, the headwaters of the Tagus River basin would lose part of its natural capacity for regulation. These changes in the water cycle for the climate change scenarios used would imply a reduction of around 70 %–79 % in the possible flows that could be transferred to the Segura basin, with respect to a scenario without climate change. The loss of water resources for the Segura River basin would mean, if no alternative measures were taken, an economic loss of EUR 380–425 million per year, due principally to decreased agricultural production.\n",
      "  - The Tagus River basin is an ultimately important water source for hydropower production, urban and agricultural water supply in Spain and Portugal. Growing electricity and water supply demands, over‐regulation of the river and construction of new dams, as well as large inter‐basin and intra‐basin water transfers aggravated by strong natural variability of climate in the catchment, have already imposed significant pressures on the river. The substantial reduction of discharge is observed already now, and projected climatic change is expected to alter the water budget of the catchment further.In this study, we address the effects of projected climate change on the water resources availability in the Tagus River basin and influence of potential changes on hydropower generation of the three important reservoirs in the basin. The catchment‐scale, process‐based eco‐hydrological model soil and water integrated model was set up, calibrated and validated for the entire Tagus River basin, taking into account 15 large reservoirs in the catchment. The future climate projections were selected from those generated within the Inter‐Sectoral Impact Model Intercomparison Project. They include five bias‐corrected climatic datasets for the region, obtained from global circulation model runs under two emissions scenario – moderate and extreme ones – and covered the whole century. The results show a strong agreement among model runs in projecting substantial decrease of discharge of the Tagus River discharge and, consequently, a strong decrease in hydropower production under both future climate scenarios. Copyright © 2016 John Wiley &amp; Sons, Ltd.\n",
      "  - The use of check dams is a common strategy to reduce soil erosion in the Mediterranean headwaters. However, the effects of these control works on water flow rates and sediment yields have been scarcely investigated under possible scenarios of climate and land-use changes. On this regard, the use of hydrological models, such as SWAT, provide reliable hydrological predictions under variable environmental conditions. To fill this gap, this study has evaluated the effectiveness of check dams on the hydrological response of a forest headwater in Calabria (Southern Italy) in comparison with an unregulated subcatchment with very similar environmental conditions. In this regard, the effects of different combined scenarios of climate change (through three GCMs and two RCPs applied to a time period of the next 80 years) and land use (forest, pasture, and cropland) on water flow rates and sediment yields in the two headwaters were analysed using the SWAT model. The SWAT model was first calibrated in a third headwater with very similar climatic, soil, and land-use conditions, and this verification showed a satisfactory prediction capacity of water flow rate. The water flow rate prediction capacity of the model was satisfactory (coefficients of determination and efficiency of Nash and Sutcliffe equal to 0.71 and 0.67, respectively, and percent bias of 14.9%). No significant differences were detected for the water flow rates and sediment yields between the two subcatchments (with or without check dams) among the different land-use and climate change scenarios. This was linked to the low hydrological response of both headwaters to the forcing actions, which influenced the low effectiveness of the control works. SWAT estimated higher values of both mean and maximum values of water flow rates and sediment yields under RCP2.6 compared with RCP8.5. Both water flow rates and sediment yields were predicted to be very low under all climate and land-use scenarios. The regulated headwater with check dams was predicted to always produce more runoff and erosion compared with the subcatchment without check dams. The increases were predicted to be up to 60% for the maximum flow rate and 30–35% for the sediment yield in forest land use under RCP2.6. Although there was a limitation in this study due to the lack of validation of the erosion data (due to unavailable records of sediment yield), this study demonstrated how the use of check dams in headwater catchments may be not effective for soil conservation purposes several decades after their installation in Mediterranean semiarid areas, where the water flow and erosion rate are limited.\n",
      "--------------------------------------------------\n",
      "Topic 63: 63_ozone_pm2_o3_emissions\n",
      "Representative Documents:\n",
      "  - We use a global chemical transport model (GEOS‐Chem) driven by a general circulation model (NASA Goddard Institute for Space Studies GCM) to investigate the effects of 2000–2050 global change in climate and emissions (the Intergovernmental Panel on Climate Change A1B scenario) on the global tropospheric ozone budget and on the policy‐relevant background (PRB) ozone in the United States. The PRB ozone, defined as the ozone that would be present in U.S. surface air in the absence of North American anthropogenic emissions, has important implications for setting national air quality standards. We examine separately and then together the effects of changes in climate and anthropogenic emissions of ozone precursors. We find that the 2000–2050 change in global anthropogenic emissions of ozone precursors increases the global tropospheric ozone burden by 17%. The 2000–2050 climate change increases the tropospheric ozone burden by 1.6%, due mostly to lightning in the upper troposphere, and also increases global tropospheric OH by 12%. In the lower troposphere, by contrast, climate change generally decreases the background ozone. The 2000–2050 increase in global anthropogenic emissions of ozone precursors increases PRB ozone by 2–6 ppb in summer; the maximum effect is found in April (3–7 ppb). The summertime PRB ozone decreases by up to 2 ppb with 2000–2050 climate change, except over the Great Plains, where it increases slightly as a result of increasing soil NOx emission. Climate change cancels out the effect of rising global anthropogenic emissions on the summertime PRB ozone in the eastern United States, but there is still a 2–5 ppb increase in the west.\n",
      "  - . We present the chemistry-climate model UMCAM in which a relatively detailed tropospheric chemical module has been incorporated into the UK Met Office's Unified Model version 4.5. We obtain good agreements between the modelled ozone/nitrogen species and a range of observations including surface ozone measurements, ozone sonde data, and some aircraft campaigns.  Four 2100 calculations assess model responses to projected changes of anthropogenic emissions (SRES A2), climate change (due to doubling CO2), and idealised climate change-associated changes in biogenic emissions (i.e. 50% increase of isoprene emission and doubling emissions of soil-NOx). The global tropospheric ozone burden increases significantly for all the 2100 A2 simulations, with the largest response caused by the increase of anthropogenic emissions. Climate change has diverse impacts on O3 and its budgets through changes in circulation and meteorological variables. Increased water vapour causes a substantial ozone reduction especially in the tropical lower troposphere (&gt;10 ppbv reduction over the tropical ocean). On the other hand, an enhanced stratosphere-troposphere exchange of ozone, which increases by 80% due to doubling CO2, contributes to ozone increases in the extratropical free troposphere which subsequently propagate to the surface. Projected higher temperatures favour ozone chemical production and PAN decomposition which lead to high surface ozone levels in certain regions. Enhanced convection transports ozone precursors more rapidly out of the boundary layer resulting in an increase of ozone production in the free troposphere. Lightning-produced NOx increases by about 22% in the doubled CO2 climate and contributes to ozone production.  The response to the increase of isoprene emissions shows that the change of ozone is largely determined by background NOx levels: high NOx environment increases ozone production; isoprene emitting regions with low NOx levels see local ozone decreases, and increase of ozone levels in the remote region due to the influence of PAN chemistry. The calculated ozone changes in response to a 50% increase of isoprene emissions are in the range of between −8 ppbv to 6 ppbv. Doubling soil-NOx emissions will increase tropospheric ozone considerably, with up to 5 ppbv in source regions.                    \n",
      "  - . Because tropospheric ozone is both a greenhouse gas and harmful air pollutant, it is important to understand how anthropogenic activities may influence its abundance and distribution through the 21st century. Here, we present model simulations performed with the chemistry–climate model SOCOL, in which spatially disaggregated chemistry and transport tracers have been implemented in order to better understand the distribution and projected changes in tropospheric ozone. We examine the influences of ozone precursor emissions (nitrogen oxides (NOx), carbon monoxide (CO) and volatile organic compounds (VOCs)), climate change (including methane effects) and stratospheric ozone recovery on the tropospheric ozone budget, in a simulation following the climate scenario Representative Concentration Pathway (RCP) 6.0 (a medium-high, and reasonably realistic climate scenario). Changes in ozone precursor emissions have the largest effect, leading to a global-mean increase in tropospheric ozone which maximizes in the early 21st century at 23% compared to 1960. The increase is most pronounced at northern midlatitudes, due to regional emission patterns: between 1990 and 2060, northern midlatitude tropospheric ozone remains at constantly large abundances: 31% larger than in 1960. Over this 70-year period, attempts to reduce emissions in Europe and North America do not have an effect on zonally averaged northern midlatitude ozone because of increasing emissions from Asia, together with the long lifetime of ozone in the troposphere. A simulation with fixed anthropogenic ozone precursor emissions of NOx, CO and non-methane VOCs at 1960 conditions shows a 6% increase in global-mean tropospheric ozone by the end of the 21st century, with an 11 % increase at northern midlatitudes. This increase maximizes in the 2080s and is mostly caused by methane, which maximizes in the 2080s following RCP 6.0, and plays an important role in controlling ozone directly, and indirectly through its influence on other VOCs and CO. Enhanced flux of ozone from the stratosphere to the troposphere as well as climate change-induced enhancements in lightning NOx emissions also increase the tropospheric ozone burden, although their impacts are relatively small. Overall, the results show that under this climate scenario, ozone in the future is governed largely by changes in methane and NOx; methane induces an increase in tropospheric ozone that is approximately one-third of that caused by NOx. Climate impacts on ozone through changes in tropospheric temperature, humidity and lightning NOx remain secondary compared with emission strategies relating to anthropogenic emissions of NOx, such as fossil fuel burning. Therefore, emission policies globally have a critical role to play in determining tropospheric ozone evolution through the 21st century.                    \n",
      "--------------------------------------------------\n",
      "Topic 64: 64_cultivars_yield_genotypes_fruit\n",
      "Representative Documents:\n",
      "  - Rice is an important cereal and drought stress is a critical abiotic stress that negatively influences the performance and productivity of rice crop, particularly under a changing climate scenario. The objectives of this study were to evaluate the impacts of drought stress on grain productivity and water use efficiency of rice cultivars and to assess the genotypic variability among the tested cultivars. Two irrigation treatments including a control and drought stress were applied to the experiments during 2018–2019 and 2019–2020. The statistical evaluation included a comparison of means, genotypic and phenotypic coefficients of variation, path analysis, correlation assessment, hierarchical clustering of tested cultivars and principal component analysis. The results indicated that drought stress negatively affected the grain productivity of the rice cultivars. The grain productivity of the cultivars decreased, ranging between 21–45% and 21–52% in the first and second season, respectively. Similarly, water use efficiency was significantly decreased ranging between 7–53% and 21–55% during the first and the second season, respectively. The broad-sense heritability for grain productivity was differed under control and drought stress treatment, indicating that the chances of the transfer of grain-productivity-related traits could be affected during selection for stress tolerance. The correlation assessment indicated that the intensity of association among the evaluated parameters was higher under the control treatment. A maximum direct effect was observed by water consumption (1.76) under control whereas, by water use efficiency (1.09) under drought stress treatment on grain productivity in path analysis. Considering the water use efficiency as a desired trait for selection in path analysis, a maximum direct effect was observed by grain productivity under the control (0.68) and under drought treatment (0.88). Hom Pathum and Pathum Thani−1 were identified as highly tolerant cultivars in the hierarchical clustering and principal component analysis. It was concluded that the results obtained for the assessment of drought stress on grain productivity, water use efficiency and genotypic variability among these cultivars could be utilized in selection program for stress tolerance and the stress tolerant cultivars could be used for sustaining grain productivity to reduce the impacts of climate change.\n",
      "  - Drought stress is the most important production constraint in maize (Zea mays L.), especially in rainfed agriculture. To improve productivity of rainfed maize, the development of hybrids with tolerance to drought stress is an important objective in maize breeding programs. The present study was undertaken to identify maize hybrids that perform better under drought-stress and drought-free conditions by using various selection indices. These selection indices were calculated on the basis of yield (t ha–1) performance of hybrids measured under drought stress and optimum environments. A set of 38 cultivars was evaluated at 10 environments (representing five each of drought stress and optimum growing conditions). The average reduction in grain yield due to drought stress was 52%. Effects of genotype, environment and their interaction were significant sources of variation in determining grain yield, respectively explaining 5.0–7.4%, 55.0–60.2% and 12.0–15.0% of total variation in yield under drought-stress and drought-free conditions. Of eight selection indices considered for study, three indices such as harmonic mean, geometric mean, and stress tolerance index were identified as suitable for selection of genotypes capable of performing well both under drought-stress and drought-free environments. Drought response index and drought resistance index were found useful in identifying hybrids that performed better under drought stress. Stress susceptibility index was negatively correlated with yield measured under drought stress. Stress susceptibility index could be used as selection index but only in combination with yield performance data under water-deficit conditions in order to identify drought-tolerant hybrids with reasonable productivity. Test weight, shelling percentage, days to maturity, and ear girth were found to be useful traits for improving yield performance across diverse environments. Cultivation of identified drought-tolerant hybrids would be useful to enhance maize productivity in drought-stress environments.\n",
      "  - In the Mediterranean region, grain yield of durum wheat is frequently limited by both high temperature and drought during grain filling. A total of six sets of paired trials, including 18 durum experimental lines and two durum and bread wheat landraces, were conducted in the field under three moderate (no stress), warm (stress) and cold (stress) climate conditions and two different water regimes [i.e. rain-fed (terminal stress) and two supplemental irrigations (no stress)] conditions for two cropping seasons (2005–06 and 2006–07) in Iran. Several stress indices (i.e. drought, heat, and cold) obtained from grain yield data under different climate and water regime conditions were used to analyse relationships between genotypic grain yield data of 20 genotypes and their tolerance to different stresses. The additive main effect and multiplicative interaction (AMMI) analysis was also used to capture a large portion of the genotype by environment (GE) interaction sum of squares and to separate main and interaction effects. The combined ANOVA revealed significant differences between locations, water regimes (rain-fed v. irrigation) and their effects in discriminating among the genotypes. The genotypic yields in both rain-fed and irrigated conditions were positively associated (P &lt; 0.01) at the moderate and warm locations; but were adversely correlated (P &lt; 0.05) at cold locations, suggesting that a high-yield potential under two supplemental irrigations does not necessarily result in improved yield under rain-fed conditions. The results verified that grain yield increased in response to irrigation, but some genotypes were more sensitive to environmental differences depending on year and location. Relative reduction of grain yield due to drought was a promising trait to improve drought tolerance indirectly in warm and moderate locations. Estimates of broad-sense heritability also varied with climate conditions. Based on principal component analysis (PCA), the different stress indices tended to discriminate genotypes in dissimilar fashions. The results also indicate that it was possible to identify superior genotypes based on single and multiple abiotic stresses (drought, heat and cold). The genotypes G4 and G5 had general tolerance to the three abiotic stresses while the G19 and G15 were tolerant to drought and cold stresses and G18 and G17 were tolerant to heat stress. According to AMMI biplot analysis, the genotypes G4 and G9 were the best in terms of both mean yield and minimal GE interaction, indicating that selecting for improved yield may increase yield in a wide range of environments.\n",
      "--------------------------------------------------\n",
      "Topic 65: 65_emissions_mitigation_carbon_reductions\n",
      "Representative Documents:\n",
      "  -  The availability of atmospheric carbon dioxide is the sine qua non for all plant growth and thence for all marine and terrestrial life forms. The purpose of this paper is to show that proposed reductions in anthropogenic emissions of carbon dioxide (CO2) to below the level of observed annual incremental biospheric absorption of those emissions would reduce the growth of the basic feedstock of all life forms. Agronomists have for long known and demonstrated in controlled experiments both in greenhouses and in field studies the dramatic impact of increases in its level on crop yields. These studies have all been local. The regression analysis here of historic data on global food production shows it may well be more dependent on increases in the availability of atmospheric carbon dioxide (henceforth written as [CO2]) than on changes in fertilizer consumption and global mean temperature (GMT). This implies that if the drastic reductions in total anthropogenic emissions of CO2 to be sought at Copenhagen (December 2009) are adopted and applied, they will, even if they aim at only a 60% reduction on the 2000 global level by 2050, bring emissions to below the incremental volume of their biospheric absorption. That could seriously imperil growth of global food production. We show how in its role as a fertilizer that raises global Net Primary Productivity (NPP), increases in [CO2] have a natural negative feedback mechanism that offsets a large proportion of growing emissions: more [CO2] causes more plant growth, but more plant growth takes up more CO2 thus limiting the further rise. This contrasts with the unproven positive feedback assumed in all models deployed by the IPCC whereby, allegedly, rising [CO2] will result in falling biospheric absorption and ever larger increases in [CO2]. We show there is no sign in the observations since 1958 of “saturation” of the capacity of the planet to continue absorbing more than half of all anthropogenic emissions of CO2, so there is no evidence for the IPCC's positive feedback. Biospheric absorption of increases in anthropogenic CO2 emissions would only have to increase from the average 57% of all anthropogenic emissions from 1958 to 2008 to 60% to achieve the likely Copenhagen 60% emissions reduction target. The rapid growth of absorption of total anthropogenic emissions to over 6% p.a. between 1997 and 2006 relative to total emissions growth at 2.6% p.a. over that period (Le Quéré 2008) confirms this manner of attaining the Copenhagen target is easily attainable—and helps to explain the growth of food production at rates in excess of global population growth. It also limited the growth rate of aggregate [CO2] between 1958 and 2008 to only 0.41% p.a. Our results show that with warming in the absence of growing carbon fertilization, agricultural production could be less by more than 10% by 2080 than at present (2007: Table 5.8). That means starvation for most of a global population likely then to be at least 50% larger than now. \n",
      "  - This paper analyses the emissions and cost impacts of mitigation of non-CO2 greenhouse gases (GHGs) at a global level, in scenarios aimed at meeting a range of long-term temperature goals (LTTGs). The study combines an integrated assessment model (TIAM-Grantham) representing CO2 emissions (and their mitigation) from the fossil fuel combustion and industrial sectors, coupled with a model covering non-CO2 emissions (GAINS), using the latest global warming potentials from the Intergovernmental Panel on Climate Change’s Fifth Assessment Report. We illustrate that in general non-CO2 mitigation measures are less costly than CO2 mitigation measures, with the majority of their abatement potential achievable at US2005$100/tCO2e or less throughout the 21st century (compared to a marginal CO2 mitigation cost which is already greater than this by 2030 in the most stringent mitigation scenario). As a result, the total cumulative discounted cost over the period 2010–2100 (at a 5% discount rate) of limiting global average temperature change to 2.5 °C by 2100 is $48 trillion (about 1.6% of cumulative discounted GDP over the period 2010–2100) if only CO2 from the fossil fuel and industrial sectors is targeted, whereas the cost falls to $17 trillion (0.6% of GDP) by including non-CO2 GHG mitigation in the portfolio of options—a cost reduction of about 65%. The criticality of non-CO2 mitigation recommends further research, given its relatively less well-explored nature when compared to CO2 mitigation.\n",
      "  - &lt;div&gt;In the United States (USA), transportation is the largest single source of                    greenhouse gas (GHG) emissions, representing 27% of total GHGs emitted in 2020.                    Eighty-three percent of these came from road transport, and 57% from light-duty                    vehicles (LDVs). Internal combustion engine (ICE) vehicles, which still form the                    bulk of the United States (US) fleet, struggle to meet climate change targets.                    Despite increasingly stringent regulatory mechanisms and technology                    improvements, only three US states have been able to reduce their transport                    emissions to the target of below 1990 levels. Fifteen states have made some                    headway to within 10% of their 1990 baseline. Largely, however, it appears that                    current strategies are not generating effective results.&lt;/div&gt;                &lt;div&gt;Current climate-change mitigation measures in road transport tend to be                    predominantly technological. One of the most popular measures in the USA is                    fleet electrification, receiving regulatory and fiscal encouragement from 45 US                    states and federal bills. However, zero-emission vehicles (ZEVs) might not be                    the climate change panacea for the transport sector. ZEVs are facing adoption                    issues ranging from affordability, equity, and charging infrastructure to                    vehicle class availability limitations. Despite increasing sales, US electric                    vehicle (EV) adoption has been behind the curve with a current market                    penetration of 4.5%. Outside of ZEVs, emission reduction in the US road                    transport sector has been sluggish.&lt;/div&gt;                &lt;div&gt;In road transport, which contributes the bulk of traffic-related air pollution                    (TRAP), there are clear gaps between policy targets, technology-based                    expectations, and actual results. For a sector that is struggling to meet                    climate change targets, broadening its scope of climate change mitigation                    measures for road transport would be useful. Driver behavior may be an                    underexplored strategy.&lt;/div&gt;                &lt;div&gt;Eco-driving is a known strategy and has been attributed to reducing TRAP by up to                    50% (through nontechnological means) in various studies in the USA and across                    the world. If technological eco-driving measures are included, they can improve                    fuel economy in excess of 100%. But the extent to which it is included in driver                    education and licensing protocols in US states is unclear.&lt;/div&gt;                &lt;div&gt;This study, therefore, evaluates eco-driving in state-sponsored non-commercial                    Driving License Manuals (DLMs). Provisions in state DLMs were assessed based on                    the &lt;i&gt;intent&lt;/i&gt; of the prescribed practices (collision safety,                    environmental exposure, or both), the &lt;i&gt;extent&lt;/i&gt; to which these                    were included, and the &lt;i&gt;strength&lt;/i&gt; of the recommended mechanisms                    (prescriptive or regulatory). The scores were converted into Grades A–D.&lt;/div&gt;                &lt;div&gt;The results are revealing. Despite thirty-three US states (66%) with extant                    climate change commitments, almost the same percentage (62%) of states received                    a “D” grade and entirely omitted to mention driver influence on fuel consumption                    and emissions. Only five states (10%) received an “A” grade with substantive                    eco-driving measures in their DLMs. There is thus significant scope for                    eco-driving content in DLMs, which can range from the state’s communicating                    climate change commitments to how drivers influence fuel consumption through                    their driving practices to empowering drivers with strategies they can adopt to                    save fuel and money and reduce emissions.&lt;/div&gt;                &lt;div&gt;This inclusion has the potential to improve vehicular fuel economy and help                    states meet their climate change goals. Driver education is the first step.                    Eco-driving principles can be further bolstered through subsequent inclusion in                    the driver training and testing phases of driver licensing.&lt;/div&gt;\n",
      "--------------------------------------------------\n",
      "Topic 66: 66_mitigation_emissions_ghg_bioenergy\n",
      "Representative Documents:\n",
      "  - SummaryUnder the Kyoto Protocol, the European Union is committed to a reduction in CO2 emissions to 92% of baseline (1990) levels during the first commitment period (2008–2012). The Kyoto Protocol allows carbon emissions to be offset by demonstrable removal of carbon from the atmosphere. Thus, land‐use/land‐management change and forestry activities that are shown to reduce atmospheric CO2 levels can be included in the Kyoto targets. These activities include afforestation, reforestation and deforestation (article 3.3 of the Kyoto Protocol) and the improved management of agricultural soils (article 3.4). In this paper, we estimate the carbon mitigation potential of various agricultural land‐management strategies and examine the consequences of European policy options on carbon mitigation potential, by examining combinations of changes in agricultural land‐use/land‐management. We show that no single land‐management change in isolation can mitigate all of the carbon needed to meet Europe's climate change commitments, but integrated combinations of land‐management strategies show considerable potential for carbon mitigation. Three of the combined scenarios, one of which is an optimal realistic scenario, are by themselves able to meet Europe's emission limitation or reduction commitments. Through combined land‐management scenarios, we show that the most important resource for carbon mitigation in agriculture is the surplus arable land. We conclude that in order to fully exploit the potential of arable land for carbon mitigation, policies will need to be implemented to allow surplus arable land to be put into alternative long‐term land‐use. Of all options examined, bioenergy crops show the greatest potential for carbon mitigation. Bioenergy crop production also shows an indefinite mitigation potential compared to other options where the mitigation potential is finite. We suggest that in order to exploit fully the bioenergy option, the infrastructure for bioenergy production needs to be significantly enhanced before the beginning of the first Kyoto commitment period in 2008. It is not expected that Europe will attempt to meet its climate change commitments solely through changes in agricultural land‐use. A reduction in CO2‐carbon emissions will be key to meeting Europe's Kyoto targets, and forestry activities (Kyoto Article 3.3) will play a major role. In this study, however, we demonstrate the considerable potential of changes in agricultural land‐use and ‐management (Kyoto Article 3.4) for carbon mitigation and highlight the policies needed to promote these agricultural activities. As all sources of carbon mitigation will be important in meeting Europe's climate change commitments, agricultural carbon mitigation options should be taken very seriously.\n",
      "  - Meeting climate change mitigation targets by 2050, as outlined in international pledges, involves determining optimal strategies for forest management, wood supply, the substitution of greenhouse gas‐intensive materials and energy sources, and wood product disposal. Our study quantified the cumulative mitigation potential by 2050 of the forest sector in the province of Quebec, Canada, using several alternative strategies and assessed under what circumstances the sector could contribute to the targets. We used the Carbon Budget Model of the Canadian Forest Sector to project ecosystems emissions and sequestration of seven alternative and one baseline (business‐as‐usual [BaU]) forest management scenarios over the 2018–2050 period. Three baskets of wood products were used in a Harvested Wood Products model to predict wood product emissions. The mitigation potential was determined by comparing the cumulative CO2e budget of each alternative scenario to the BaU. The proportion of methane emissions from landfills (RCH4%) and the required displacement factor (RDF) to achieve mitigation benefits were assessed both independently and jointly. The fastest and most efficient way to improve mitigation outcomes of the forest sector of Quebec is to reduce end‐of‐life methane emissions from wood products. By reducing methane emissions, the RDF for achieving mitigation benefits through intensification strategies can be reduced from 1.2–2.3 to 0–0.9 tC/tC, thus reaching the current provincial mean DF threshold (0.9). Both a reduction and an increase in the harvested volume have the potential to provide mitigation benefits with adequate RCH4% and RDF. Increased carbon sequestration in ecosystems, innovations in long‐lived wood products, and optimal substitution in markets offer potential avenues for the forest sector to contribute to mitigation benefits but are subject to significant uncertainties. Methane emission reduction at the end of wood product service life is emerging as a valuable approach to enhance mitigation benefits of the forest sector.\n",
      "  - . The potential of forests and the forest sector to mitigate greenhouse gas (GHG) emissions is widely recognized, but challenging to quantify at a national scale. Forests and their carbon (C) sequestration potential are affected by management practices, where wood harvesting transfers C out of the forest into products, and subsequent regrowth allows further C sequestration. Here we determine the mitigation potential of the 2.3 × 106 km2 of Canada's managed forests from 2015 to 2050 using the Carbon Budget Model of the Canadian Forest Sector (CBM-CFS3), a harvested wood products (HWP) model that estimates emissions based on product half-life decay times, and an account of emission substitution benefits from the use of wood products and bioenergy. We examine several mitigation scenarios with different assumptions about forest management activity levels relative to a base case scenario, including improved growth from silvicultural activities, increased harvest and residue management for bioenergy, and reduced harvest for conservation. We combine forest management options with two mitigation scenarios for harvested wood product use involving an increase in either long-lived products or bioenergy uses. Results demonstrate large differences among alternative scenarios, and we identify potential mitigation scenarios with increasing benefits to the atmosphere for many decades into the future, as well as scenarios with no net benefit over many decades. The greatest mitigation impact was achieved through a mix of strategies that varied across the country and had cumulative mitigation of 254 Tg CO2e in 2030, and 1180 Tg CO2e in 2050. There was a trade-off between short-term and long-term goals, in that maximizing short-term emissions reduction could reduce the forest sector's ability to contribute to longer-term objectives. We conclude that (i) national-scale forest sector mitigation options need to be assessed rigorously from a systems perspective to avoid the development of policies that deliver no net benefits to the atmosphere, (ii) a mix of strategies implemented across the country achieves the greatest mitigation impact, and (iii) because of the time delays in achieving carbon benefits for many forest-based mitigation activities, future contributions of the forest sector to climate mitigation can be maximized if implemented soon.\n",
      "--------------------------------------------------\n",
      "Topic 67: 67_corrosion_steel_corrosion rate_carbon steel\n",
      "Representative Documents:\n",
      "  - Summary               The corrosion behavior of 3% Cr steel is tested by a high-temperature/high-pressure autoclave. The corrosion environment is categorized into CO2-alone and CO2/H2S conditions. At 90°C, with the addition of H2S to the CO2, the surface corrosion condition improved greatly, and the corrosion rates declined compared with the CO2-alone condition. Under CO2/H2S condition, with an increasing CO2/H2S partial-pressure ratio, the corrosion rate reached a peak value at pCO2/pH2S = 100, and then declined. Through the analysis of the corrosion products of the samples in different conditions by scanning electron microscope (SEM), EDS, and X-ray-diffraction (XRD) methods, it was found that the inner film is finer and denser than the outer scale. The partial-pressure ratio of H2S corrosion regime should be between 10 and 100 and is not the previous 200.               Introduction Corrosion has wide-ranging implications for the integrity of materials used in the petroleum industry. The implication of CO2 corrosion can be viewed in terms of its effect on capital and operational expenditures and health, safety, and the environment (Kermani and Harrop 1996),which brings huge losses and poses security threats to the development of oil and gas (Minxu et al. 2002; Kinsella et al. 1998). Medium Cr-containing steels showed improved corrosion resistance compared with carbon steel and lower cost than 13% Cr steel (Ueda and Takabe 2002; Muraki et al. 2002; Nose et al. 2001). The effect of medium chromium-additions was attributed to the formation of chromium enriched corrosion products (e.g., observed on 3% Cr steel). Steels alloyed with 3% Cr or more were found to show improved corrosion performance over Cr-free steel by a factor of two or more (Nose et al. 2001). The corrosion becomes complicated when H2S is added into the CO2 corrosion system. The current research should focus on the formation mechanism of the corrosion product film, properties of corrosion product of different structures, and protection to the matrix. The corrosion experiment that has been carried out with 3% Cr tubular steel in pure CO2 and CO2/H2S environments. The results would be to supplement the CO2/H2S corrosion theory of 3% Cr steel and provide theoretical basis for the proper selection of the tubing and casing in oil and gas fields.\n",
      "  - The influence of surface roughness on the static corrosion behavior of J55 carbon steel in CO2-containing geothermal water environment was investigated with respect to average corrosion rate, morphology, chemical composition, corrosion depth, and the cross section of corrosion products. The influence of surface roughness on the CO2 corrosion of J55 carbon steel was then proposed based on the understanding of corrosion at 65 °C. The results show that the static corrosion rate of J55 carbon steel in CO2-containing geothermal water increases with increasing surface roughness. The surface roughness of J55 carbon steel increases 5.3-fold and the CO2 corrosion rate increases by 1.4-fold under different exposure times. The static corrosion rate of J55 carbon steel in CO2-containing geothermal water changes with exposure time. The corrosion rate of J55 carbon steel decreases with the increase in exposure time, and there is little change in the corrosion rate after immersion for 2 days. At the initial stage of corrosion, the corrosion rate of J55 carbon steel was mainly affected by surface roughness. The greater the roughness, the greater the corrosion driving force and the corrosion reaction surface area and therefore the greater the corrosion rate of J55 carbon steel. After immersion for 2 days, a continuous corrosion product layer was formed on the surface of J55 carbon steel and the corrosion rate was mainly affected by the corrosion product layer. The corrosion products of J55 carbon steel are not altered by surface roughness in a CO2-containing geothermal water environment. The corrosion products of J55 carbon steel are FeCO3 and a minute amount of CaCO3.\n",
      "  - The initial corrosion behavior of 20# steel under the condition of gas–liquid (CO2/aqueous solution) two-phase bubble flow was studied through weight loss, scanning electron microscopy, energy-dispersive X-ray spectroscopy, and X-ray photoelectron spectroscopy. The results showed that the corrosion rate decreased rapidly when the corrosion time was less than 3 h, increased rapidly, even to 19.4% of the initial corrosion rate, when the corrosion time was from 3 h to 5 h, and then decreased slowly to about 63% of the initial corrosion rate after the corrosion time exceeded 5 h under different CO2 pressure conditions. The corrosion happened first at the defects area with a high activity such as the cross points of scratches, gradually formed corrosion pits, and then extended around until the corrosion products covered the whole pipe wall surface. At the beginning stage of the corrosion process, the corrosion products were composed of acicular corrosion products and a small number of flocculent corrosion products and formed the corrosion product layer with micro-cracks. With the extension of the corrosion time, the spherical corrosion particles started to form on the initial corrosion product layer’s surface and gradually covered the initial corrosion product layer completely. The whole corrosion product layer with dual-structure characteristics formed. The inner corrosion product sub-layer was composed of initial corrosion products with columnar characteristics from the cross-section perspective, and the outer corrosion product sub-layer was composed of spherical corrosion products that were relatively dense. There was no obvious interface between the inner columnar sub-layer and the dense outer sub-layer. As time went on, the corrosion product particles with a broccoli shape characteristic formed on the dual-structure corrosion product layer’s surface and finally formed the outermost layer of the whole corrosion product layer. In the end, the whole corrosion product layer with three sub-layers formed, namely, the columnar bottom sub-layer, the relatively dense middle sub-layer, and the surface dense sub-layer composed of particles with a broccoli shape. The main components of the corrosion products were Fe, C, and O, and the main phases of the corrosion products were Fe3C, FeCO3, Fe3O4, Fe2O3, and FeOOH.\n",
      "--------------------------------------------------\n",
      "Topic 68: 68_health_community_science_research\n",
      "Representative Documents:\n",
      "  - Public health departments have important roles to play in addressing the local health impacts of climate change, yet are often not well prepared to do so. The Climate and Health Program (CHP) at the Centers for Disease Control and Prevention (CDC) created the Building Resilience Against Climate Effects (BRACE) framework in 2012 as a five-step planning framework to support public health departments and their partners to respond to the health impacts of climate change. CHP has initiated a process to revise the framework to address learnings from a decade of experience with BRACE and advances in the science and practice of addressing climate and health. The aim of this manuscript is to describe the methodology for revising the BRACE framework and the expected outputs of this process. Development of the revised framework and associated guidance and tools will be guided by a multi-sector expert panel, and finalization will be informed by usability testing. Planned revisions to BRACE will (1) be consistent with the vision of Public Health 3.0 and position health departments as “chief health strategists” in their communities, who are responsible for facilitating the establishment and maintenance of cross-sector collaborations with community organizations, other partners, and other government agencies to address local climate impacts and prevent further harm to historically underserved communities; (2) place health equity as a central, guiding tenet; (3) incorporate greenhouse gas mitigation strategies, in addition to its previous focus on climate adaptation; and (4) feature a new set of tools to support BRACE implementation among a diverse set of users. The revised BRACE framework and the associated tools will support public health departments and their partners as they strive to prevent and reduce the negative health impacts of climate change for everyone, while focusing on improving health equity.\n",
      "  -             Context:            Human health is threatened by climate change. While the public health workforce is concerned about climate change, local health department (LHD) administrators have reported insufficient knowledge and resources to address climate change. Minigrants from state to LHDs have been used to promote a variety of local public health initiatives.                                Objective:            To describe the minigrant approach used by state health departments implementing the Centers for Disease Control and Prevention's (CDC's) Building Resilience Against Climate Effects (BRACE) framework, to highlight successes of this approach in promoting climate change preparedness at LHDs, and to describe challenges encountered.                                Design:            Cross-sectional survey and discussion.                                Intervention:            State-level recipients of CDC funding issued minigrants to local public health entities to promote climate change preparedness, adaptation, and resilience.                                Main Outcome Measures:            The amount of funding, number of LHDs funded per state, goals, selection process, evaluation process, outcomes, successes, and challenges of the minigrant programs.                                Results:            Six state-level recipients of CDC funding for BRACE framework implementation awarded minigrants ranging from $7700 to $28 500 per year to 44 unique local jurisdictions. Common goals of the minigrants included capacity building, forging partnerships with entities outside of health departments, incorporating climate change information into existing programs, and developing adaptation plans. Recipients of minigrants reported increases in knowledge, engagement with diverse stakeholders, and the incorporation of climate change content into existing programs. Challenges included addressing climate change in regions where the topic is politically sensitive, as well as the uncertainty about the long-term sustainability of local projects beyond the term of minigrant support.                                Conclusions:            Minigrants can increase local public health capacity to address climate change. Jurisdictions that wish to utilize minigrant mechanisms to promote climate change adaptation and preparedness at the local level may benefit from the experience of the 6 states and 44 local health programs described.          \n",
      "  - Public health departments are on the frontlines of protecting vulnerable groups and working to eliminate health disparities through prevention interventions, disease surveillance and community education. Exploration of the roles national, state and local health departments (LHDs) play in advancing climate change planning and actions to protect public health is a developing arena of research. This paper presents insights from local public health departments in California, USA on how they addressed the barriers to climate adaptation planning with support from the California Department of Public Health’s Office of Health Equity Climate Change and Health Equity Section (OHE), which administers the California Building Resilience Against Climate Effects Project (CalBRACE). With support from the U.S. Centers for Disease Control and Prevention (CDC) Climate-Ready States and Cities Initiative (CRSCI), CalBRACE initiated an adaptation project to seed climate planning and actions in county health departments. In this study, we compared the barriers and strategies of twenty-two urban and rural LHDs and explored potential options for climate change adaptation in the public health framework. Using key informant interviews and document reviews, the results showed how engagement with CalBRACE’s Local Health Department Partnership on Climate Change influenced the county departments’ ability to overcome barriers to adaptation through the diversification of funding sources, the leveraging strategic collaborations, extensive public education and communication campaigns, and the development of political capital and champions. The lessons learned and recommendations from this research may provide pathways and practices for national, state and local level health departments to collaborate in developing protocols and integrating systems to respond to health-related climate change impacts, adaptation and implementation.\n",
      "--------------------------------------------------\n",
      "Topic 69: 69_enso_precipitation_oscillation_north\n",
      "Representative Documents:\n",
      "  - In much of North America, variables such as temperature, precipitation, snowpack and streamflow are modulated by modes of large‐scale ocean‐atmosphere variability such as the Pacific Decadal Oscillation (PDO), El Niño‐Southern Oscillation (ENSO) and the Pacific North American Pattern (PNA). In this study, we test the hypothesis that the influence of these modes on air temperature and precipitation in British Columbia (BC), Canada, can be explained in relation to changes in frequencies of synoptic‐scale circulation types. A catalogue of 13 circulation types was derived by classifying daily mean sea‐level pressure (MSLP) grids from 1948 to 2003. The grids cover BC and the North Pacific and were subjected to a standard pattern recognition algorithm employing principal component analysis followed by cluster analysis on the component scores. The circulation types are generally associated with distinctive patterns of precipitation and air temperature anomalies across BC. Multiple linear regressions for selected stations in BC using the type frequencies as predictors explain up to 75% of the variance of mean winter temperature and 65% of winter precipitation. The frequencies of most circulation types vary significantly between the different phases of ENSO, PDO and PNA in a manner consistent with the temperature anomalies associated with those modes and, to a lesser extent, with the more complex precipitation anomalies. In addition, however, average temperatures and precipitation amounts for some circulation types differ systematically between phases of ENSO and PDO. Subsequent analysis revealed distinct differences among ENSO and PDO phases in the upper‐level circulation patterns associated with some surface types. A major part of the teleconnections can be explained through variations in the frequencies of synoptic‐scale circulation types, but systematic within‐type variability, particularly with PDO and PNA, can additionally influence the surface climate. Copyright © 2005 Royal Meteorological Society.\n",
      "  -  Extratropical cyclones are responsible for many of the high-impact weather events over the United States, including extreme cold, extreme high wind, and extreme heavy precipitation. In this study, impacts from the variations of the cyclone (or storm-track) activity on these extreme events are examined through composites based on map-averaged cyclone activity. Increased cyclone activity enhances the frequency of extreme cold and high wind events over much of the United States, and impacts extreme precipitation around the Ohio River valley. These impacts are largely due to a changing of the tail of the distribution rather than a shifting of the mean. To systematically study these impacts, three singular value decomposition (SVD) analyses have been conducted, each one between the cyclone activity and one kind of extreme event frequency. All three SVD leading modes represent a pattern of overall increase or decrease of storm tracks over the United States. The average of the time series of these leading modes is highly correlated with the observed map-averaged storm track and strongly associated with the Pacific–North America (PNA) pattern and El Niño–Southern Oscillation (ENSO). However, composites based on either the PNA pattern or ENSO do not show as strong impacts as the map-averaged storm track. A second common SVD mode is found that correlates weakly with the North Pacific mode and is likely to be largely due to internal variability. Finally, the potential impacts of projected storm-track change on the frequency of extreme events are examined, indicating that the projected storm-track decrease over North America may give rise to some reduction in the frequency of extreme events. \n",
      "  -                The probability of climate extremes is strongly affected by atmospheric circulation. This study quantifies the worldwide influence of three major modes of circulation on station-based indices of intense precipitation: the El Niño–Southern Oscillation, the Pacific interdecadal variability as characterized by the North Pacific index (NPI), and the North Atlantic Oscillation–Northern Annular Mode. The study examines which stations show a statistically significant (5%) difference between the positive and negative phases of a circulation regime. Results show distinct regional patterns of response to all these modes of climate variability; however, precipitation extremes are most substantially affected by the El Niño–Southern Oscillation. The effects of the El Niño–Southern Oscillation are seen throughout the world, including in India, Africa, South America, the Pacific Rim, North America, and, weakly, Europe. The North Atlantic Oscillation has a strong, continent-wide effect on Eurasia and affects a small, but not negligible, percentage of stations across the Northern Hemispheric midlatitudes. This percentage increases slightly if the Northern Annular Mode index is used rather than the NAO index. In that case, a region of increase in intense precipitation can also be found in Southeast Asia. The NPI influence on precipitation extremes is similar to the response to El Niño, and strongest in landmasses adjacent to the Pacific. Consistently, indices of more rare precipitation events show a weaker response to circulation than indices of moderate extremes; the results are quite similar, but of opposite sign, for negative anomalies of the circulation indices.\n",
      "--------------------------------------------------\n",
      "Topic 70: 70_forcing_warming_ocean_aerosol\n",
      "Representative Documents:\n",
      "  - In an influential and interesting study, Stevens (2015) suggested that the global and also Northern Hemispheric warming during the early industrial period implies that the effective radiative forcing [Formula: see text] by anthropogenic aerosols in the year 2000 compared to 1850 cannot be more negative than −1.0 W m−2. Here results from phase 5 of the Coupled Model Intercomparison Project are analyzed and it is shown that there is little relationship between [Formula: see text] and the warming trend in the early industrial period in comprehensive climate models. In particular, some models simulate a warming in the early industrial period despite a strong (very negative) [Formula: see text]. The reason for this difference in results is that the global-mean log-linear scaling of [Formula: see text] with anthropogenic sulfur dioxide emissions introduced and used by Stevens tends to produce a substantially larger aerosol forcing compared to climate models in the first half of the twentieth century, when SO2emissions were concentrated over smaller regions. In turn, it shows smaller (less negative) [Formula: see text] in the recent period with comparatively more widespread SO2emissions.\n",
      "  -                A linearized energy-balance model for global temperature is formulated, featuring a scale-invariant long-range memory (LRM) response and stochastic forcing representing the influence on the ocean heat reservoir from atmospheric weather systems. The model is parameterized by an effective response strength, the stochastic forcing strength, and the memory exponent. The instrumental global surface temperature record and the deterministic component of the forcing are used to estimate these parameters by means of the maximum-likelihood method. The residual obtained by subtracting the deterministic solution from the observed record is analyzed as a noise process and shown to be consistent with a long-memory time series model and inconsistent with a short-memory model. By decomposing the forcing record in contributions from solar, volcanic, and anthropogenic activity one can estimate the contribution of each to twentieth-century global warming. The LRM model is applied with a reconstruction of the forcing for the last millennium to predict the large-scale features of Northern Hemisphere temperature reconstructions, and the analysis of the residual also clearly favors the LRM model on millennium time scale. The decomposition of the forcing shows that volcanic aerosols give a considerably greater contribution to the cooling during the Little Ice Age than the reduction in solar irradiance associated with the Maunder Minimum in solar activity. The LRM model implies a transient climate response in agreement with IPCC projections, but the stronger response on longer time scales suggests replacing the notion of equilibrium climate sensitivity by a time scale–dependent sensitivity.\n",
      "  - Kretzschmar et al., in a comment in 2017, use the spread in the output of aerosol–climate models to argue that the models refute the hypothesis (presented in a paper by Stevens in 2015) that for the mid-twentieth-century warming to be consistent with observations, then the present-day aerosol forcing, [Formula: see text] must be less negative than −1 W m−2. The main point of contention is the nature of the relationship between global SO2emissions and [Formula: see text] In contrast to the concave (log-linear) relationship used by Stevens and in earlier studies, whereby [Formula: see text] becomes progressively less sensitive to SO2emissions, some models suggest a convex relationship, which would imply a less negative lower bound. The model that best exemplifies this difference, and that is most clearly in conflict with the hypothesis of Stevens, does so because of an implausible aerosol response to the initial rise in anthropogenic aerosol precursor emissions in East and South Asia—already in 1975 this model’s clear-sky reflectance from anthropogenic aerosol over the North Pacific exceeds present-day estimates of the clear-sky reflectance by the total aerosol. The authors perform experiments using a new (observationally constrained) climatology of anthropogenic aerosols to further show that the effects of changing patterns of aerosol and aerosol precursor emissions during the late twentieth century have, for the same global emissions, relatively little effect on [Formula: see text] These findings suggest that the behavior Kretzschmar et al. identify as being in conflict with the lower bound in Stevens arises from an implausible relationship between SO2emissions and [Formula: see text] and thus provides little basis for revising this lower bound.\n",
      "--------------------------------------------------\n",
      "Topic 71: 71_nema___\n",
      "Representative Documents:\n",
      "  -                     \n",
      "  -                     \n",
      "  - nema\n",
      "--------------------------------------------------\n",
      "Topic 72: 72_food_countries_agriculture_climate change\n",
      "Representative Documents:\n",
      "  - Global food security is a worldwide concern. Food insecurity is a significant threat to poverty and hunger eradication goals. Agriculture is one of the focal points in the global policy agenda. Increases in agricultural productivity through the incorporation of technological advances or expansion of cultivable land areas have been pushed forward. However, production growth has slowed in many parts of the world due to various endemic challenges, such as decreased investment in agricultural research, lack of infrastructure in rural areas, and increasing water scarcity. Climate change adversities in agriculture and food security are increasing. Recently, the COVID-19 pandemic has severely affected global food supply chains. Economic and social instability from the pandemic contribute to long-term disturbances. Additionally, conflicts such as war directly affect agriculture by environmental degradation, violence, and breaches of national and international trade agreements. A combination of food security and climate change challenges along with increased conflicts among nations and post-COVID-19 social and economic issues bring bigger and more serious threats to agriculture. This necessitates the strategic design of policies through multifaceted fields regarding food systems. In this comprehensive review, we explore how these three challenging factors, COVID-19, climate change, and conflicts, are interrelated, and how they affect food security. We discuss the impact of these issues on the agricultural sector, plus possible ways of preventing or overcoming such adverse effects.\n",
      "  - Increasing world human population, declining reserves of cheaply extracted fossil fuels, scarcity of supplies of fresh water and climatic instability will put tremendous pressure on world rangelands as the 21st century progresses. It is expected that the human population of the world will increase by 40% by 2050 but fossil fuel and reserves of fresh water will be drastically reduced. Avoiding food shortages and famine could be a major world challenge within the next 10 years. Under these conditions, major changes in policies relating to economic growth and use of natural resources seem essential. Stabilisation of the human population, development of clean and renewable energy, enhanced supplies of water and its quality, increased livestock production, and changed land-use policies, that minimise agricultural land losses to development and fragmentation, will all be needed to avoid declining living conditions at the global level. The health and productivity of rangelands will need to receive much more emphasis as they are a primary source of vital ecosystem services and products essential to human life. Changes in tax policies by developed, affluent countries, such as the United States, Australia and Canada, are needed that emphasise saving and conservation as opposed to excessive material consumption and land development. Extreme levels of debt and chronic deficits in trade by the United States and European Union countries need to be moderated to avoid a devastating collision of debt, depletion of natural resources, and environmental degradation. Over the next 10 years, livestock producers of the rangelands will benefit from a major increase in demand and prices for meat. Rapidly increasing demand for meat in China and other Asian countries is driving this trend. Rangeland managers, however, will also likely encounter greater climatic, financial, biological and political risks. Higher interest rates, higher production costs and higher annual variability in forage resources are major challenges that will confront rangeland managers in the years ahead. Under these conditions, a low risk approach to livestock production from rangelands is recommended that involves conservative stocking, use of highly adapted livestock, and application of behavioural knowledge of livestock to efficiently use forage resources.\n",
      "  - Water-related impacts due to change in climatic conditions ranging from water scarcity to intense floods and storms are increasing in developing countries like Pakistan. Water quality and waterborne diseases like hepatitis, cholera, typhoid, malaria and dengue fever are increasing due to chaotic urbanization, industrialization, poor hygienic conditions, and inappropriate water management. The morbidity rate is high due to lack of health care facilities, especially in developing countries. Organizations linked to the Government of Pakistan (e.g., Ministry of Environment, Ministry of Climate Change, Planning and Development, Ministry of Forest, Irrigation and Public Health, Pakistan Meteorological Department, National Disaster Management, Pakistan Agricultural Research Centre, Pakistan Council for Research in Water Resources, and Global Change Impact Study Centre), United Nation organizations, provincial government departments, non-governmental organizations (e.g., Global Facility and Disaster Reduction), research centers linked to universities, and international organizations (International Institute for Sustainable Development, Food and Agriculture, Global Climate Fund and World Bank) are trying to reduce the water-related impacts of climate change, but due to lack of public awareness and health care infrastructure, the death rate is steadily increasing. This paper critically reviews the scientific studies and reports both at national and at international level benefiting generalists concerned with environmental and public health challenges. The article underlines the urgent need for water conservation, risk management, and the development of mitigation measures to cope with the water-related impacts of climate change on agriculture and subsequently on public health. Novel solutions and bioremediation methods have been presented to control environmental pollution and to promote awareness among the scientific community. The focus is on diverse strategies to handle the forthcoming challenges associated with water resources management.\n",
      "--------------------------------------------------\n",
      "Topic 73: 73_patients_etco2_arterial_mmhg\n",
      "Representative Documents:\n",
      "  -             Background:            The advent of highly sensitive End-Tidal CO2 (ETCO2) sensors allows effective monitoring of intubated patients in many emergency care settings, including EMS. Previous work has explored the use of ETCO2 monitoring in non-intubated patients with sensors placed in the nares. However, nothing is known about the effect of passive oxygen delivery [nasal cannula (NC) or non-rebreather mask (NRB)] on ETCO2 measurement.                                Objective:            To compare ETCO2 measurements in non-intubated Traumatic Brain Injury (TBI) patients receiving O2 via NC vs NRB in the prehospital setting.                                Methods:            A subset of major TBI cases (CDC Barell Matrix Type-1) in the Excellence in Prehospital Injury Care (EPIC) TBI Study (NIH/NINDS-1R01NS071049; ClinicalTrials.gov-NCT01339702) were evaluated 4/13-3/17). Non-intubated cases from 6 EMS agencies providing monitor data (Philips MRx) were included when continuous ETCO2 data were available. Statistics: Two-tailed t test, α = 0.05.                                Results:            The 104 included cases had median age of 50.5 (range: 9-91; male: 67%). 39 (37.5%) received O2 via NC and 65 (62.5%) via NRB. Mean ETCO2: NC cases: 27.7 mmHg (95% CI: 25.7, 29.8); NRB: 30.0 (28.1, 31.8; p=0.132). There were also no significant differences among the mean lowest recorded values (p=0.449) or the mean highest values (p=0.275).                                Conclusion:            We believe this is the first report comparing ETCO2 values based upon the method of passive O2 delivery in non-intubated patients. The minor differences between NC vs NRB-oxygenated patients was neither statistically nor clinically significant. This is surprising since: 1) the O2 flow rates and 2) the open-air (NC) vs mask (NRB) delivery methods are so dramatically different. Future study is needed to identify the clinical implications of using noninvasive ETCO2 measurement as a tool for monitoring ventilatory status and changes in non-intubated TBI (and other) patients.                                          \n",
      "  -             Background:            End-Tidal CO2 (ETCO2) monitoring is valuable in the management of traumatic brain injury (TBI). In intubated patients it helps prevent hyper/over-ventilation. In non-intubated patients, placing a sensor in the nares allows accurate monitoring of respiratory rate and has other promising uses (e.g. monitoring ETCO2 trends in worsening TBI, COPD, etc).                                Study Objective:            To identify how accurately EMS providers document ETCO2, we compared the values recorded in EMS patient care records (PCR) to monitor data in non-intubated TBI patients.                                Methods:            Cases from 6 EMS agencies reporting continuous monitor data (Philips MRx) in the EPIC Study (NIH 1R01NS071049) were evaluated (4/13-3/17). All ETCO2 data available for this post-hoc review were displayed and accessible to the EMS providers during care. Concordance was defined in two ways (for both highest and lowest ETCO2): ≤5 and ≤3 mmHg difference between the monitor data and PCR-documented values.                                Results:            106 cases were included [median age: 47 (range: 9-91), 66% male]. The figure shows concordance between PCR documentation and monitor data for both the lowest and highest recorded ETCO2 values.                                Conclusion:            The            highest            PCR-recorded vs monitor ETCO2 values had excellent concordance for a difference ≤5 mmHg (85.9%) and it was good (76.4%) even when defined at the limits of instrument precision (≤3 for ETCO2 compared to actual pCO2). However, for            lowest            ETCO2, concordance was very poor (only 42.5% for ≤5). The failure to accurately document low ETCO2 in a “passive-ventilation” setting may also have significant implications for improving ventilatory care among intubated patients because identifying and correcting hypocapnia/hyperventilation in actively-ventilated cases is extraordinarily important. The low concordance rates may be due to the emphasis on discreet, intermittent vital sign documentation rather than ongoing identification and documentation of significant ETCO2 variation.                                          \n",
      "  -             Background:            Little is known in humans about the physiological effects of the combination of automated Head-Up cardiopulmonary resuscitation CPR, active compression-decompression CPR and an impedance threshold device (ITD). This new approach, termed AHUP-CPR, improves perfusion of vital organs and lowers intracranial pressure compared with conventional (C)CPR in animal models of cardiac arrest. This study tested the hypothesis that AHUP-CPR treatment would increase end tidal CO2 (ETCO2), a circulation surrogate, more than C-CPR in out-of-hospital cardiac arrest (OHCA) patients.                                Method:            Prospective before-after interventional study of witnessed OHCA patients. C-CPR and AHUP-CPR were performed by firefighters who measured ETCO2. AHUP-CPR was delivered using a LUCAS AD (5 cm of compression and 3 cm active decompression) (Stryker Medical, USA), an EleGARD Patient Positioning System (AdvancedCPR Solutions, USA), and an ITD (ResQPOD-16, Zoll, USA). The study was performed in the greater Grenoble France region in four different fire stations. The primary endpoint was the measurement of maximum EtCO2 during CPR. Results are presented as mean ± standard deviation.                                Results:            Baseline characteristics (age, sex, arrest location, initial rhythm, bystander CPR, witnessed) were not statistically different between groups.EtCO2 was higher for patients treated with AHUP-CPR (n=63) compared to the C-CPR (n=59) (41±18 vs. 30.2 mmHg, p&lt;0.001). This difference was significant for shockable (45±13 vs. 34±12 mmHg, p=0.03) and non-shockable (40±19 vs. 28±13 mmHg, p=0.004) rhythms, respectively. The calculated difference between the maximum and first recorded ETCO2 values was 6.3 ± 20.4 in the C-CPR arm versus 21.1 ± 20.6 in the AHUP-CPR group (P&lt;0.001). A total of 29% (n=18) of the AHUP patients vs. 22 % (n=13) were admitted alive to the hospital (P=0.34).                                Conclusion:            Results from this first prospective clinical trial on AHUP-CPR demonstrated that ETCO2 values were significantly higher after AHUP-CPR versus C-CPR, regardless of the presenting rhythm. Using ETCO2 as a surrogate for circulation, these findings confirm animal studies showing AHUP-CPR provides significantly more vital organ blood flow to patients in OHCA compared with C-CPR.          \n",
      "--------------------------------------------------\n",
      "Topic 74: 74_distribution_suitable_maxent_species\n",
      "Representative Documents:\n",
      "  - An increase in atmospheric greenhouse gases necessitates the use of species distribution models (SDMs) in modeling suitable habitats and projecting the impact of climate change on the future range shifts of the species. The present study is based on the BIOMOD ensemble approach to map the currently suitable habitats and predict the impact of climate change on the niche shift of Valeriana wallichii. We also studied its niche dynamics using the ecospat package in R software. Values of the area under curve (AUC) and true skill statistics (TSS) were highly significant (&gt;0.9), which shows that the model has run better. From 19 different bioclimatic variables, only 8 were retained after correlation, among which bio_17 (precipitation of driest quarter), bio_1 (annual mean temperature), and bio_12 (annual mean precipitation) received the highest gain. Under future climate change, the suitable habitats will be significantly contracted by −94% (under representative concentration pathway RCP 8.5 for 2070) and −80.22% (under RCP 8.5 for 2050). There is a slight increase in habitat suitability by +16.69% (RCP 4.5 for 2050) and +8.9% (RCP 8.5 for 2050) under future climate change scenarios. The equivalency and similarity tests of niche dynamics show that the habitat suitability for current and future climatic scenarios is comparable but not identical. Principal Component Analysis (PCA) analysis shows that climatic conditions will be severely affected between current and future scenarios. From this study, we conclude that the habitats of Valeriana wallichii are highly vulnerable to climate shifts. This study can be used to alleviate the threat to this plant by documenting the unexplored populations, restoring the degraded habitats through rewilding, and launching species recovery plans in the natural habitats.\n",
      "  -                Climate change impacts on tropical forests and tree species have been documented as changes in distribution, growing period, phenology, habitat, productivity, species composition, and migration. This study attempts to assess the current and future habitat suitability distribution of two dominant species of Central India, teak (Tectona grandis Linn. f.) and sal (Shorea robusta Gaertn. f.) using a maximum entropy (MaxEnt) model to predict species occurrences by finding the distribution that has the most spread. The future suitable habitat ranges of the species were modeled for two time periods (2050 and 2070) and two representative concentration pathways (RCP 2.6 and 8.5). Representative concentration pathways are scenarios that describe alternative trajectories for carbon dioxide emissions and the resulting atmospheric concentration from 2000 to 2100. We collected and modeled the spatially well-dispersed species occurrence points of teak and sal. The results suggested an increase in suitable habitat range for teak and a decrease for sal for both time periods and RCPs. Furthermore, the jackknife analysis identified temperature and precipitation seasonality as the major variables that influence the distribution of teak. In the case of sal, minimum temperature makes the maximum contribution to distribution changes. The suitable silvicultural strategies for forest management are proposed based on the future distribution of species in relation to the climate variables responsible for the change in their distribution range. These findings and strategies will help forest departments build future management plans for teak and sal forest with a focus on minimizing the impact of climate change.               Study Implications: Our study used maximum entropy (MaxEnt) modeling to understand the impact of changing climate on the distribution of teak and sal forests of central India and to propose future silvicultural strategies. The study used MaxEnt model for two time periods and two climate change scenarios at highest resolution. An increase in future suitable habitat for teak and a decrease for sal is predicted by the model. Temperature for teak and precipitation for sal were identified as the major influencing climatic variables. We recommend forest and other related government departments to commission focused research to understand the changing patterns of species with climate change and design appropriate silviculture strategies for effective management.\n",
      "  - Climate change, as an emerging phenomenon, has led to changes in the distribution, movement, and even risk of extinction of various wildlife species and this has raised concerns among conservation biologists. Different species have two options in the face of climate change, either to adopt or follow their climatic niche to new places through the connectivity of habitats. The modeling of interpatch landscape communications can serve as an effective decision support tool for wildlife managers. This study was conducted to assess the effects of climate change on the distribution and habitat connectivity of the endangered subspecies of Asian black bear (Ursus thibetanus gedrosianus) in the southern and southeastern Iran. The presence points of the species were collected in Provinces of Kerman, Hormozgan, and Sistan-Baluchestan. Habitat modeling was done by the Generalized Linear Model, and 3 machine learning models including Maximum Entropy, Back Propagation based artificial Neural Network, and Support Vector Machine. In order to achieve the ensemble model, the results of the mentioned models were merged based on the method of “accuracy rate as weight” derived from their validation. To construct pseudo-absence points for the use in the mentioned models, the Ensemble model of presence-only models was used. The modeling was performed using 15 habitat variables related to climatic, vegetation, topographic, and anthropogenic parameters. The three general circulation models of BCC-CSM1, CCSM4, and MRI-CGCM3 were selected under the two scenarios of RCP2.6 and RCP8.5 by 2070. To investigate the effect of climate change on the habitat connections, the protected areas of 3 provinces were considered as focal nodes and the connections between them were established based on electrical circuit theory and Pairwise method. The true skill statistic was employed to convert the continuous suitability layers to binary suitable/unsuitable range maps to assess the effectiveness of the protected areas in the coverage of suitable habitats for the species. Due to the high power of the stochastic forest model in determining the importance of variables, this method was used. The results showed that presence/absence models were successful in the implementation and well distinguished the points of presence and pseudo-absence from each other. Based on the random forests model, the variables of Precipitation of Driest Quarter, Precipitation of Coldest Quarter, and Temperature Annual Range have the greatest impact on the habitat suitability. Comparing the modeling findings to the realities of the species distribution range indicated that the suitable habitats are located in areas with high humidity and rainfall, which are mostly in the northern areas of Bandar Abbas, south of Kerman, and west and south of Sistan-Baluchestan. The area of suitable habitats, in the MRI-CGCM3 (189731 Km2) and CCSM4 (179007 Km2) models under the RCP2.6 scenario, is larger than the current distribution (174001 Km2). However, in terms of the performance of protected areas, the optimal coverage of the species by the boundary of the protected areas, under each of the RCP2.6 and RCP8.5 scenarios, is less than the present time. According to the electric circuit theory, connecting the populations in the protected areas of Sistan-Baluchestan province to those in the northern Hormozgan and the southern Kerman would be based on the crossing through the heights of Sistan-Baluchestan and Hormozgan provinces and the plains between these heights would be the movement pinch points under the current and future scenarios. Populations in the protected areas of Kerman have higher quality patch connections than that of the other two provinces. The areas such as Sang-e_Mes, Kouh_Shir, Zaryab, and Bahr_Aseman in Kerman Province and Kouhbaz and Geno in Hormozgan Province can provide suitable habitats for the species in the distribution models. The findings revealed that the conservation of the heights along with the caves inside them could be a protective priority to counteract the effects of climate change on the species.\n",
      "--------------------------------------------------\n",
      "Topic 75: 75_policy_policies_governments_state\n",
      "Representative Documents:\n",
      "  - Organized business interests often seek to block public interest regulations. But whether firms oppose regulation depends on institutional context. We argue that, in federal systems, sub‐national policies and politics can have a home state effect on firms' national policy preferences and the lobbying coalitions they join. State policies that force firms to absorb regulatory cost can reduce the marginal cost of national policies, leading to preference shifts. In addition, firms regulated at the state level have incentives to strategically align with their state governments to avoid future regulatory cost. We test our argument in the context of U.S. climate politics, matching original data on the positions of electric utilities toward the Clean Power Plan and data on ad hoc coalition membership with data measuring state policy stringency and state government positions. Quantitative evidence is consistent with hypotheses: both state policies and state politics influence utilities' positions on national climate policy. Qualitative evidence from elite interviews helps clarify the roles of different mechanisms. Our findings underscore the importance of sub‐national governments in shaping national lobbying coalitions.\n",
      "  - The United States is experiencing growing impacts of climate change but currently receives a limited policy response from its national leadership. Within this policy void, many state governments are stepping up and taking action on adaptation planning. Yet we know little about why some states adopt State Adaptation Plans (SAPs), while others do not. This article investigates factors that predict the emergence of SAPs, both in terms of policy adoption and policy intensity (goal ambitiousness). Applying the diffusion of innovation theory, I consider the relative influence of internal state characteristics, regional pressures, and test for conditional effects between government ideologies and severity of the problem. The results show interesting differences between predictors that influence policy adoption and ambitiousness. States are more motivated to adopt a policy when faced with greater climate vulnerability, have more liberal citizenry, and where governments have crossed policy hurdles by previously passing mitigation plans. The intensity of policies and goal setting, moreover, is more likely to be driven by interest group politics and diffuse through policy learning or sharing information among neighboring states in Environmental Protection Agency regions. These findings support an emerging scholarship that uses more complex dependent variables in policy analysis. These variables have the potential to differentiate symbolic from substantive policies and capture finer information about predictors of importance.\n",
      "  - Understanding how preferences for public policy instruments shape policy support helps policymakers to design policies that begin to tackle large‐scale and complex problems, such as climate change. Climate change policies generate both local and global costs and benefits, which affect the public's policy preferences. In this article we investigate the role of perceived conditional cooperation and distributive concerns on climate policy attitude formation. We identify a range of climate policies and test public opinion for adoption of these policies at different scales of government. The important theoretical distinction is the scale‐driven distributional nature of policy costs and benefits as well as concerns regarding the cooperation of other actors. We use data from Sweden and a conjoint experimental design where we vary level of government, type of policy, and the targeted group. We find evidence that people support policies when costs are shared broadly. We also find that support for climate policy is conditional on expected policy adoption by other units of government at various scales. This implies that unpopular climate policies might be more popular if the funding structure of the policy allows for binding policy and that the cost‐sharing is taking place at higher levels of government.\n",
      "--------------------------------------------------\n",
      "Topic 76: 76_species_sdms_models_predictions\n",
      "Representative Documents:\n",
      "  - Forecasting the effects of climate change on species and populations is a fundamental goal of conservation biology, especially for montane endemics which seemingly are under the greatest threat of extinction given their association with cool, high elevation habitats. Species distribution models (also known as niche models) predict where on the landscape there is suitable habitat for a species of interest. Correlative niche modeling, the most commonly employed approach to predict species' distributions, relies on correlations between species' localities and current environmental data. This type of model could spuriously forecast less future suitable habitat because species' current distributions may not adequately represent their thermal tolerance, and future climate conditions may not be analogous to current conditions. We compared the predicted distributions for three montane species ofPlethodonsalamanders in the southern Appalachian Mountains of North America using a correlative modeling approach and a mechanistic model. The mechanistic model incorporates species‐specific physiology, morphology and behavior to predict an annual energy budget on the landscape. Both modeling approaches performed well at predicting the species' current distributions and predicted that all species could persist in habitats at higher elevation through 2085. The mechanistic model predicted more future suitable habitat than the correlative model. We attribute these differences to the mechanistic approach being able to model shifts in key range‐limiting biological processes (changes in surface activity time and energy costs) that the correlative approach cannot. Choice of global circulation model (GCM) contributed significantly to distribution predictions, with a tenfold difference in future suitability based on GCM, indicating that GCM variability should be either directly included in models of species distributions or, indirectly, through the use of multi‐model ensemble averages. Our results indicate that correlative models are over‐predicting habitat loss for montane species, suggesting a critical need to incorporate mechanisms into forecasts of species' range dynamics.\n",
      "  - Rapid global change has increased interest in developing ways to identify suitable refugia for species of conservation concern. Correlative and mechanistic species distribution models (SDMs) represent two approaches to generate spatially‐explicit estimates of climate vulnerability. Correlative SDMs generate distributions using statistical associations between environmental variables and species presence data. In contrast, mechanistic SDMs use physiological traits and tolerances to identify areas that meet the conditions required for growth, survival and reproduction. Correlative approaches assume modeled environmental variables influence species distributions directly or indirectly; however, the mechanisms underlying these associations are rarely verified empirically. We compared habitat suitability predictions between a correlative‐only SDM, a mechanistic SDM and a correlative framework that incorporated mechanistic layers (‘hybrid models'). Our comparison focused on green salamanders Aneides aeneus, a priority amphibian threatened by climate change throughout their disjunct range. We developed mechanistic SDMs using experiments to measure the thermal sensitivity of resistance to water loss (ri) and metabolism. Under current climate conditions, correlative‐only, hybrid and mechanistic SDMs predicted similar overlap in habitat suitability; however, mechanistic SDMs predicted habitat suitability to extend into regions without green salamanders but known to harbor many lungless salamanders. Under future warming scenarios, habitat suitability depended on climate scenario and SDM type. Correlative and hybrid models predicted a 42% reduction or 260% increase in area considered to be suitable depending on the climate scenario. In mechanistic SDMs, energetically suitable habitat declined with both climate scenarios and was driven by the thermal sensitivity of ri. Our study indicates that correlative‐only and hybrid approaches produce similar predictions of habitat suitability; however, discrepancies can arise for species that do not occupy their entire fundamental niche, which may hold consequences of conservation planning of threatened species.\n",
      "  - Species distribution models (SDMs) correlate species occurrences with environmental predictors, and can be used to forecast distributions under future climates. SDMs have been criticized for not explicitly including the physiological processes underlying the species response to the environment. Recently, new methods have been suggested to combine SDMs with physiological estimates of performance (physiology‐SDMs). In this study, we compare SDM and physiology‐SDM predictions for select marine species in the Mediterranean Sea, a region subjected to exceptionally rapid climate change. We focused on six species and created physiology‐SDMs that incorporate physiological thermal performance curves from experimental data with species occurrence records. We then contrasted projections of SDMs and physiology‐SDMs under future climate (year 2100) for the entire Mediterranean Sea, and particularly the ‘warm’ trailing edge in the Levant region. Across the Mediterranean, we found cross‐validation model performance to be similar for regular SDMs and physiology‐SDMs. However, we also show that for around half the species the physiology‐SDMs substantially outperform regular SDM in the warm Levant. Moreover, for all species the uncertainty associated with the coefficients estimated from the physiology‐SDMs were much lower than in the regular SDMs. Under future climate, we find that both SDMs and physiology‐SDMs showed similar patterns, with species predicted to shift their distribution north‐west in accordance with warming sea temperatures. However, for the physiology‐SDMs predicted distributional changes are more moderate than those predicted by regular SDMs. We conclude, that while physiology‐SDM predictions generally agree with the regular SDMs, incorporation of the physiological data led to less extreme range shift forecasts. The results suggest that climate‐induced range shifts may be less drastic than previously predicted, and thus most species are unlikely to completely disappear with warming climate. Taken together, the findings emphasize that physiological experimental data can provide valuable supplemental information to predict range shifts of marine species.\n",
      "--------------------------------------------------\n",
      "Topic 77: 77_xco2_co2_haze_emissions\n",
      "Representative Documents:\n",
      "  - The COVID-19 pandemic has led to ongoing reductions in economic activity and anthropogenic emissions. Beijing was particular badly affected by lockdown measures during the early months of the COVID-19 pandemic. It has significantly reduced the CO2 emission and toxic air pollution (CO and NO2). We use column-averaged dry-air mole fractions of CO2 and CO (XCO2 and XCO) observed by a ground-based EM27/SUN Fourier transform spectrometer (FTS), the tropospheric NO2 column observed by MAX-DOAS and satellite remote sensing data (GOSAT and TROPOMI) to investigate the variations in anthropogenic CO2 emission related to COVID-19 lockdown in Beijing. The anomalies describe the spatio-temporal enhancement of gas concentration, which relates to the emission. Anomalies in XCO2 and XCO, and XNO2 (ΔXCO2, ΔXCO, and ΔXNO2) for ground-based measurements were calculated from the diurnal variability. Highly correlated daily XCO and XCO2 anomalies derived from FTS time series data provide the ΔXCO to ΔXCO2 ratio (the correlation slope). The ΔXCO to ΔXCO2 ratio in Beijing was lower in 2020 (8.2 ppb/ppm) than in 2019 (9.6 ppb/ppm). The ΔXCO to ΔXCO2 ratio originating from a polluted area was significantly lower in 2020. The reduction in anthropogenic CO2 emission was estimated to be 14.2% using FTS data. A comparable value reflecting the slowdown in growth of atmospheric CO2 over the same time period was estimated to be 15% in Beijing from the XCO2 anomaly from GOSAT, which was derived from the difference between the target area and the background area. The XCO anomaly from TROPOMI is reduced by 8.7% in 2020 compared with 2019, which is much smaller than the reduction in surface air pollution data (17%). Ground-based NO2 observation provides a 21.6% decline in NO2. The NO2 to CO2 correlation indicates a 38.2% decline in the CO2 traffic emission sector. Overall, the reduction in anthropogenic CO2 emission relating to COVID-19 lockdown in Beijing can be detected by the Bruker EM27/SUN Fourier transform spectrometer (FTS) and MAX-DOAS in urban Beijing.\n",
      "  - The continuing increase in atmospheric CO2 concentration caused by anthropogenic CO2 emissions significantly contributes to climate change driven by global warming. Satellite measurements of long-term CO2 data with global coverage improve our understanding of global carbon cycles. However, the sensitivity of the space-borne measurements to anthropogenic emissions on a regional scale is less explored because of data sparsity in space and time caused by impacts from geophysical factors such as aerosols and clouds. Here, we used global land mapping column averaged dry-air mole fractions of CO2 (XCO2) data (Mapping-XCO2), generated from a spatio-temporal geostatistical method using GOSAT and OCO-2 observations from April 2009 to December 2020, to investigate the responses of XCO2 to anthropogenic emissions at both global and regional scales. Our results show that the long-term trend of global XCO2 growth rate from Mapping-XCO2, which is consistent with that from ground observations, shows interannual variations caused by the El Niño Southern Oscillation (ENSO). The spatial distributions of XCO2 anomalies, derived from removing background from the Mapping-XCO2 data, reveal XCO2 enhancements of about 1.5–3.5 ppm due to anthropogenic emissions and seasonal biomass burning in the wintertime. Furthermore, a clustering analysis applied to seasonal XCO2 clearly reveals the spatial patterns of atmospheric transport and terrestrial biosphere CO2 fluxes, which help better understand and analyze regional XCO2 changes that are associated with atmospheric transport. To quantify regional anomalies of CO2 emissions, we selected three representative urban agglomerations as our study areas, including the Beijing-Tian-Hebei region (BTH), the Yangtze River Delta urban agglomerations (YRD), and the high-density urban areas in the eastern USA (EUSA). The results show that the XCO2 anomalies in winter well capture the several-ppm enhancement due to anthropogenic CO2 emissions. For BTH, YRD, and EUSA, regional positive anomalies of 2.47 ± 0.37 ppm, 2.20 ± 0.36 ppm, and 1.38 ± 0.33 ppm, respectively, can be detected during winter months from 2009 to 2020. These anomalies are slightly higher than model simulations from CarbonTracker-CO2. In addition, we compared the variations in regional XCO2 anomalies and NO2 columns during the lockdown of the COVID-19 pandemic from January to March 2020. Interestingly, the results demonstrate that the variations of XCO2 anomalies have a positive correlation with the decline of NO2 columns during this period. These correlations, moreover, are associated with the features of emitting sources. These results suggest that we can use simultaneously observed NO2, because of its high detectivity and co-emission with CO2, to assist the analysis and verification of CO2 emissions in future studies.\n",
      "  - Anthropogenic carbon dioxide (CO2) emissions from bottom-up inventories have high uncertainties due to the usage of proxy data in creating these inventories. To evaluate bottom-up inventories, satellite observations of atmospheric CO2 with continuously improved accuracies have shown great potential. In this study, we evaluate the consistency and uncertainty of four gridded CO2 emission inventories, including CHRED, PKU, ODIAC, and EDGAR that have been commonly used to study emissions in China, using GOSAT and OCO-2 satellite observations of atmospheric column-averaged dry-air mole fraction of CO2 (XCO2). The evaluation is carried out using two data-driven approaches: (1) quantifying the correlations of the four inventories with XCO2 anomalies derived from the satellite observations; (2) comparing emission inventories with emissions predicted by a machine learning-based model that considers the nonlinearity between emissions and XCO2. The model is trained using long-term datasets of XCO2 and emission inventories from 2010 to 2019. The result shows that the inconsistencies among these four emission inventories are significant, especially in areas of high emissions associated with large XCO2 values. In particular, EDGAR shows a larger difference to CHRED over super-emitting sources in China. The differences for ODIAC and EDGAR, when compared with the machine learning-based model, are higher in Asia than those in the USA and Europe. The predicted emissions in China are generally lower than the inventories, especially in megacities. The biases depend on the magnitude of inventory emissions with strong positive correlations with emissions (R2 is larger than 0.8). On the contrary, the predicted emissions in the USA are slightly higher than the inventories and the biases tend to be random (R2 is from 0.01 to 0.5). These results indicate that the uncertainties of gridded emission inventories of ODIAC and EDGAR are higher in Asian countries than those in European and the USA. This study demonstrates that the top-down approach using satellite observations could be applied to quantify the uncertainty of emission inventories and therefore improve the accuracy in spatially and temporally attributing national/regional totals inventories.\n",
      "--------------------------------------------------\n",
      "Topic 78: 78_selection_plasticity_populations_thermal\n",
      "Representative Documents:\n",
      "  - Evolutionary adaptation as a response to climate change is expected for fitness‐related traits affected by climate and exhibiting genetic variance. Although the relationship between warmer spring temperature and earlier timing of reproduction is well documented, quantifications and predictions of the impact of global warming on natural selection acting on phenology in wild populations remain rare. If global warming affects fitness in a similar way across individuals within a population, or if fitness consequences are independent of phenotypic variation in key‐adaptive traits, then no evolutionary response is expected for these traits.Here, we quantified the selection pressures acting on laying date during a 24‐year monitoring of blue tits in southern Mediterranean France, a hot spot of climate warming. We explored the temporal fluctuation in annual selection gradients and we determined its temperature‐related drivers.We first investigated the month‐specific warming since 1970 in our study site and tested its influence on selection pressures, using a model averaging approach. Then, we quantified the selection strength associated with temperature anomalies experienced by the blue tit population.We found that natural selection acting on laying date significantly fluctuated both in magnitude and in sign across years. After identifying a significant warming in spring and summer, we showed that warmer daily maximum temperatures in April were significantly associated with stronger selection pressures for reproductive timing. Our results indicated an increase in the strength of selection by 46% for every +1°C anomaly.Our results confirm the general assumption that recent climate change translates into strong selection favouring earlier breeders in passerine birds. Our findings also suggest that differences in fitness among individuals varying in their breeding phenology increase with climate warming. Such climate‐driven influence on the strength of directional selection acting on laying date could favour an adaptive response in this trait, since it is heritable.\n",
      "  -                 Background                Present-day climate change has altered the phenology (the timing of periodic life cycle events) of many plant and animal populations worldwide. Some of these changes have been adaptive, leading to an increase in population fitness, whereas others have been associated with fitness decline. Representing short-term responses to an altered weather regime, hitherto observed changes are largely explained by phenotypic plasticity. However, to track climatically induced shifts in optimal phenotype as climate change proceeds, evolutionary capacity in key limiting climate- and fitness-related traits is likely to be crucial. In order to produce realistic predictions about the effects of climate change on species and populations, a main target for conservation biologists is thus to assess the potential of natural populations to respond by these two mechanisms. In this study we use a large 15-year dataset on an ectotherm model, the Swedish sand lizard (Lacerta agilis), to investigate how higher spring temperature is likely to affect oviposition timing in a high latitude population, a trait strongly linked to offspring fitness and survival.                              Results                With an interest in both the short- and potential long-term effect of rising temperatures, we applied a random regression model, which yields estimates of population-level plasticity and among-individual variation in the average, as well as the plastic, response to temperature. Population plasticity represents capacity for short-term adjustments whereas variation among individuals in a fitness-related trait indicates an opportunity for natural selection and hence for evolutionary adaptation. The analysis revealed both population-level plasticity and individual-level variation in average laying date. In contrast, we found no evidence for variation among females in their plastic responses to spring temperature, which could demonstrate a similarity in responses amongst females, but may also be due to a lack of statistical power to detect such an effect.                              Conclusion                Our findings indicate that climate warming may have positive fitness effects in this lizard population through an advancement of oviposition date. This prediction is consistent over shorter and potentially also longer time scales as the analysis revealed both population-level plasticity and individual-level variation in average laying date. However, the genetic basis for this variation would have to be examined in order to predict an evolutionary response.              \n",
      "  - Synopsis               Janzen's hypothesis (JH) posits that low thermal variation selects for narrow physiological tolerances, and thus small species distributional ranges and high species turnover along tropical elevational gradients. Although this hypothesis has been intensely revisited, it does not explain how many tropical species may exhibit broad distributions, encompassing altitudinal gradients. Moreover, the physiological responses of tropical species remain largely unknown, limiting our understanding on how they respond to climate variation. To fill these knowledge gaps, we tested a major component of JH, the climate variability hypothesis (CVH), which predicts broader thermal tolerance breadth (Tbr = CTmax – CTmin) with broader temperature variation. Specifically, we sampled populations of five amphibian species distributed in two mountain ranges in Brazil's Atlantic Forest to test how CTmin and CTmax vary along elevational gradients. Since both thermal and water balance traits are pivotal to the evolutionary history of amphibians, we also measured rates of dehydration and rehydration and their relations with thermal tolerances. We found that broader temperature variation with increasing altitude did not always lead to broader Tbr, since changes in CTmin and CTmax were species-specific. In addition, we found that water balance did not show consistent variation with altitude, also with low correlations between hydric and thermal traits. While we also found that highland populations are at lower risk of thermal stress than lowland counterparts, both are living far from their upper thermal limits. As a consequence of intraspecific variation in physiological traits and spatial variation in climate along altitude, responses to climate variation in tropical amphibian species were context-dependent and heterogeneous. Together with recent studies showing thermal tolerances of some tropical amphibians comparable to temperate taxa, our findings highlight that several responses to climate variation in tropical species may not conform to predictions made by either the CVH or other important hypotheses concerning physiological variation. This reinforces the need to overcome geographical bias in physiological data to improve predictions of climate change impacts on biodiversity.               (Portuguese ) Resumo A Hipótese de Janzen (JH) postula que a baixa variação térmica seleciona tolerâncias fisiológicas estreitas e, portanto, amplitudes restritas de distribuição das espécies e alta substituição de espécies ao longo de gradientes altitudinais tropicais. Embora intensamente revisitada, essa hipótese não explica como espécies tropicais podem exibir amplas distribuições geográficas, abrangendo gradientes altitudinais. Além disso, as respostas fisiológicas das espécies tropicais permanecem amplamente desconhecidas, limitando nossa compreensão sobre como elas respondem à variação climática. Para preencher essas lacunas de conhecimento, testamos um componente importante da JH, a Hipótese de Variabilidade Climática (CVH), que prevê uma maior amplitude de tolerância térmica (Tbr = CTmax – CTmin) quando a variação da temperatura ambiental é mais ampla. Especificamente, amostramos populações de cinco espécies de anfíbios distribuídas em duas cadeias montanhosas na Mata Atlântica do Brasil para testar como CTmin e CTmax variam ao longo de gradientes de altitude. Dado que parâmetros térmicos e do balanço hídrico são fundamentais para a história evolutiva dos anfíbios, também medimos as taxas de desidratação e reidratação e suas relações com as tolerâncias térmicas. Encontramos que uma variação de temperatura ambiental mais ampla com o aumento da altitude nem sempre conduz a uma Tbr mais ampla, uma vez que as mudanças em CTmin e CTmax foram espécie-específicas. Além disso, encontramos que o balanço hídrico não apresentou variação consistente com a mudança de altitude, e que as correlações entre parâmetros hídricos e térmicos foram baixas. Embora populações das maiores altitudes apresentaram menor risco de estresse térmico do que populações da mesma espécie em altitudes menores, ambas estão vivendo longe de seus limites térmicos superiores. Em consequência da variação intraespecífica em parâmetros fisiológicos e variação espacial no clima ao longo da altitude, as respostas à variação climática em espécies de anfíbios tropicais foram contexto-dependentes e heterogêneas. Juntamente com estudos recentes indicando tolerâncias térmicas de alguns anfíbios tropicais comparáveis a de táxons temperados, nossas descobertas destacam que várias respostas à variação climática em espécies tropicais podem não estar de acordo com as previsões feitas pela CVH ou outras hipóteses importantes sobre a variação fisiológica. Isso reforça a necessidade de superar o viés geográfico em dados fisiológicos para aperfeiçoar previsões dos impactos das mudanças climáticas sobre a biodiversidade.               (Spanish ) Resumen La hipótesis de Janzen (JH) postula que la baja variación térmica selecciona tolerancias fisiológicas estrechas y, por lo tanto, rangos de distribución de especies restringidos con alta rotación de especies a lo largo de gradientes de elevación tropicales. Aunque esta hipótesis ha sido intensamente discutida, no explica cómo várias especies tropicales pueden exhibir distribuciones amplias, abarcando gradientes altitudinales. Además, las respuestas fisiológicas de las especies tropicales siguen siendo bastante desconocidas, lo que limita la comprensión de cómo responden a la variación climática. Para llenar estos vacíos de conocimiento, examinamos un componente importante de JH, la Hipótesis de Variabilidad Climática (CVH), que predice mayor amplitud de tolerancia térmica (Tbr = CTmax – CTmin) cuando la variación de temperatura es más amplia. Específicamente, tomamos muestras de poblaciones de cinco especies de anfibios distribuidas en dos cadenas montañosas en el Bosque Atlántico de Brasil para verificar cómo CTmin y CTmax varían a lo largo de este gradiente de elevación. Dado que los rasgos de equilibrio térmico y hídrico son fundamentales para la historia evolutiva de los anfibios, también medimos las tasas de deshidratación y rehidratación y sus relaciones con las tolerancias térmicas. Encontramos que una variación de temperatura más amplia con el aumento de la altitud no siempre conduce a una Tbr más amplia, ya que los cambios en CTmin y CTmax son específicos de la especie. Además, encontramos que el balance hídrico no muestra variación consistente con la altitud, con bajas correlaciones también entre los rasgos hídricos y térmicos. Si bien las poblaciones de las tierras altas tienen un menor riesgo de estrés térmico que las contrapartes de las tierras bajas, ambas se encuentran lejos de sus límites térmicos superiores. Como consecuencia de la variación intraespecífica en los rasgos fisiológicos y la variación espacial en el clima a lo largo de la altitud, las respuestas a la variación climática en las especies de anfibios tropicales fueron dependientes del contexto y heterogéneas. Junto con estudios recientes que muestran tolerancias térmicas de algunos anfibios tropicales comparables a los taxones de zonas templadas, nuestros hallazgos resaltan que varias respuestas a la variación climática en especies tropicales pueden no ajustarse a las predicciones hechas por el CVH u otras hipótesis importantes sobre la variación fisiológica. Esto refuerza la necesidad de superar el sesgo geográfico en los datos fisiológicos para mejorar las predicciones de los impactos del cambio climático en la biodiversidad.\n",
      "--------------------------------------------------\n",
      "Topic 79: 79_agricultural_find_trade_yields\n",
      "Representative Documents:\n",
      "  - We investigate the effect of crop price and climate variables on rainfed corn and soybean yields and acreage in the United States using a large panel dataset for the 1977–2007 period. Instrumental variables are used to control for endogeneity of prices in yield and acreage regressions, while allowing for spatially auto‐correlated errors. We find that an increase in corn price has a statistically significant positive impact on corn yield, but the effect of soybean price on soybean yields is not statistically significant. The estimated price elasticities of corn yield and acreage are 0.23 and 0.45, respectively. Of the increase in corn supply caused by an increase in corn price, we find that 33.8% is due to price‐induced yield enhancement and 66.2% is due to price‐induced acreage expansion. We also find that the impact of climate change on corn production ranges from −7% to −41% and on soybean ranges from −8% to −45%, depending on the climate change scenarios, time horizon, and global climate models used to predict climate change. We show that the aggregate net impact of omitting price variables is an overestimation of the effect of climate change on corn yield by up to 9% and on soybean yield by up to 15%.\n",
      "  - This paper explores the interplay between the biophysical and economic geographies of climate change impacts on agriculture. It does so by bridging the extensive literature on climate impacts on yields and physical productivity in global crop production, with the literature on the role of adaptation through international trade in determining the consequences of climate change impacts. Unlike previous work in this area, instead of using a specific crop model or a set of models, we employ a statistical meta‐analysis that encompasses all studies available to the IPCC‐AR5 report. This permits us to isolate specific elements of the spatially heterogeneous biophysical geography of climate impacts, including the role of initial temperature, differential patterns of warming, and varying crop responses to warming across the globe. We combine these climate impact estimates with the Global Trade Analysis Project model of global trade in order to estimate the national welfare changes that are decomposed into three components: the direct (biophysical impact) contribution to welfare, the terms of trade effect, and the allocative efficiency effect. We find that when we remove the spatial variation in climate impacts, the terms of trade impacts are cut in half. Given the inherent heterogeneity of climate impacts in agriculture, this points to the important role of trade in distributing the associated welfare impacts. When we allow the biophysical impacts to vary across the empirically estimated uncertainty range taken from the meta‐analysis, we find that the welfare consequences are highly asymmetric, with much larger losses at the low end of the yield distribution. This interaction between the magnitude and heterogeneity of biophysical climate shocks and their welfare effects highlight the need for detailed representation of both in projecting climate change impacts.\n",
      "  - International trade increases connections and dependencies between countries, weaving a network of global supply chains. Agricultural commodity trade has implications for crop producers, consumers, crop prices, water and land uses, and other human systems. Interconnections among these systems are not always easy to observe when external impacts penetrate across multiple sectors. To better understand the interactions of non-linear and globally coupled agricultural-bioenergy-water systems under the broader economy, we introduce systematic perturbations in two dimensions, one human (restrictions on agricultural trade) and the other physical (climate impacts on crop yields). We explore these independently and in combination to distinguish the consequences of individual perturbation and interactive effects in long-term projections. We show that most regions experience larger changes in cereal consumption due to cereal import dependency constraints than due to the impacts of climate change on agricultural yields. In the scenario where all regions ensure an import dependency ratio of zero, the global trade of cereals decreases ~50% in 2050 compared to the baseline, with smaller decreases in cereal production and consumption (4%). The changes in trade also impact water and bioenergy: global irrigation water consumption increases 3% and corn ethanol production decreases 7% in 2050. Climate change results in rising domestic prices and declining consumption of cereal crops in general, while the import dependency constraint exacerbates the situation in regions which import more cereals in the baseline. The individual and interactive effects of trade perturbations and climate change vary greatly across regions, which are also affected by the regional ability to increase agricultural production through intensification or extensification.\n",
      "--------------------------------------------------\n",
      "Topic 80: 80_learning_machine_detection_machine learning\n",
      "Representative Documents:\n",
      "  - Identifying accident patterns is one of the most vital research foci of driving analysis. Environmental or safety applications and the growing area of fleet management all benefit from accident detection contributions by minimizing the risk vehicles and drivers are subject to, improving their service and reducing overhead costs. Some solutions have been proposed in the past literature for automated accident detection that are mainly based on traffic data or external sensors. However, traffic data can be difficult to access, while external sensors can end up being difficult to set up and unreliable, depending on how they are used. Additionally, the scarcity of accident detection data has limited the type of approaches used in the past, leaving in particular, machine learning (ML) relatively unexplored. Thus, in this paper, we propose a ML framework for automated car accident detection based on mutimodal in-car sensors. Our work is a unique and innovative study on detecting real-world driving accidents by applying state-of-the-art feature extraction methods using basic sensors in cars. In total, five different feature extraction approaches, including techniques based on feature engineering and feature learning with deep learning are evaluated on the strategic highway research program (SHRP2) naturalistic driving study (NDS) crash data set. The main observations of this study are as follows: (1) CNN features with a SVM classifier obtain very promising results, outperforming all other tested approaches. (2) Feature engineering and feature learning approaches were finding different best performing features. Therefore, our fusion experiment indicates that these two feature sets can be efficiently combined. (3) Unsupervised feature extraction remarkably achieves a notable performance score.\n",
      "  - . Glaciers across the globe react to the changing climate. Monitoring the transformation of glaciers is essential for projecting their contribution to global mean sea level rise. The delineation of glacier-calving fronts is an important part of the satellite-based monitoring process. This work presents a calving-front extraction method based on the deep learning framework nnU-Net, which stands for no new U-Net. The framework automates the training of a popular neural network, called U-Net, designed for segmentation tasks. Our presented method marks the calving front in synthetic aperture radar (SAR) images of glaciers. The images are taken by six different sensor systems. A benchmark dataset for calving-front extraction is used for training and evaluation. The dataset contains two labels for each image. One label denotes a classic image segmentation into different zones (glacier, ocean, rock, and no information available). The other label marks the edge between the glacier and the ocean, i.e., the calving front. In this work, the nnU-Net is modified to predict both labels simultaneously. In the field of machine learning, the prediction of multiple labels is referred to as multi-task learning (MTL). The resulting predictions of both labels benefit from simultaneous optimization. For further testing of the capabilities of MTL, two different network architectures are compared, and an additional task, the segmentation of the glacier outline, is added to the training. In the end, we show that fusing the label of the calving front and the zone label is the most efficient way to optimize both tasks with no significant accuracy reduction compared to the MTL neural-network architectures. The automatic detection of the calving front with an nnU-Net trained on fused labels improves from the baseline mean distance error (MDE) of 753±76 to 541±84 m. The scripts for our experiments are published on GitHub (https://github.com/ho11laqe/nnUNet_calvingfront_detection, last access: 20 November 2023). An easy-access version is published on Hugging Face (https://huggingface.co/spaces/ho11laqe/nnUNet_calvingfront_detection, last access: 20 November 2023).                    \n",
      "  - The emissions of greenhouse gases, such as carbon dioxide, into the biosphere have the consequence of warming up the planet, hence the existence of climate change. Sentiment analysis has been a popular subject and there has been a plethora of research conducted in this area in recent decades, typically on social media platforms such as Twitter, due to the proliferation of data generated today during discussions on climate change. However, there is not much research on the performances of different sentiment analysis approaches using lexicon, machine learning and hybrid methods, particularly within this domain-specific sentiment. This study aims to find the most effective sentiment analysis approach for climate change tweets and related domains by performing a comparative evaluation of various sentiment analysis approaches. In this context, seven lexicon-based approaches were used, namely SentiWordNet, TextBlob, VADER, SentiStrength, Hu and Liu, MPQA, and WKWSCI. Meanwhile, three machine learning classifiers were used, namely Support Vector Machine, Naïve Bayes, and Logistic Regression, by using two feature extraction techniques, which were Bag-of-Words and TF–IDF. Next, the hybridization between lexicon-based and machine learning-based approaches was performed. The results indicate that the hybrid method outperformed the other two approaches, with hybrid TextBlob and Logistic Regression achieving an F1-score of 75.3%; thus, this has been chosen as the most effective approach. This study also found that lemmatization improved the accuracy of machine learning and hybrid approaches by 1.6%. Meanwhile, the TF–IDF feature extraction technique was slightly better than BoW by increasing the accuracy of the Logistic Regression classifier by 0.6%. However, TF–IDF and BoW had an identical effect on SVM and NB. Future works will include investigating the suitability of deep learning approaches toward this domain-specific sentiment on social media platforms.\n",
      "--------------------------------------------------\n",
      "Topic 81: 81_damages_mortality_exposure_billion\n",
      "Representative Documents:\n",
      "  - The U.S. Southwest is projected to experience increasing aridity due to climate change. We quantify the resulting impacts on ambient dust levels and public health using methods consistent with the Environmental Protection Agency's Climate Change Impacts and Risk Analysis framework. We first demonstrate that U.S. Southwest fine (PM2.5) and coarse (PM2.5‐10) dust levels are strongly sensitive to variability in the 2‐month Standardized Precipitation‐Evapotranspiration Index across southwestern North America. We then estimate potential changes in dust levels through 2099 by applying the observed sensitivities to downscaled meteorological output projected by six climate models following an intermediate (Representative Concentration Pathway 4.5, RCP4.5) and a high (RCP8.5) greenhouse gas concentration scenario. By 2080–2099 under RCP8.5 relative to 1986–2005 in the U.S. Southwest: (1) Fine dust levels could increase by 57%, and fine dust‐attributable all‐cause mortality and hospitalizations could increase by 230% and 360%, respectively; (2) coarse dust levels could increase by 38%, and coarse dust‐attributable cardiovascular mortality and asthma emergency department visits could increase by 210% and 88%, respectively; (3) climate‐driven changes in dust concentrations can account for 34–47% of these health impacts, with the rest due to increases in population and baseline incidence rates; and (4) economic damages of the health impacts could total $47 billion per year additional to the 1986–2005 value of $13 billion per year. Compared to national‐scale climate impacts projected for other U.S. sectors using the Climate Change Impacts and Risk Analysis framework, dust‐related mortality ranks fourth behind extreme temperature‐related mortality, labor productivity decline, and coastal property loss.\n",
      "  - BackgroundThe most direct way in which climate change is expected to affect public health relates to changes in mortality rates associated with exposure to ambient temperature. Many countries worldwide experience annual heat-related and cold-related deaths associated with current weather patterns. Future changes in climate may alter such risks. Estimates of the likely future health impacts of such changes are needed to inform public health policy on climate change in the UK and elsewhere.MethodsTime-series regression analysis was used to characterise current temperature-mortality relationships by region and age group. These were then applied to the local climate and population projections to estimate temperature-related deaths for the UK by the 2020s, 2050s and 2080s. Greater variability in future temperatures as well as changes in mean levels was modelled.ResultsA significantly raised risk of heat-related and cold-related mortality was observed in all regions. The elderly were most at risk. In the absence of any adaptation of the population, heat-related deaths would be expected to rise by around 257% by the 2050s from a current annual baseline of around 2000 deaths, and cold-related mortality would decline by 2% from a baseline of around 41 000 deaths. The cold burden remained higher than the heat burden in all periods. The increased number of future temperature-related deaths was partly driven by projected population growth and ageing.ConclusionsHealth protection from hot weather will become increasingly necessary, and measures to reduce cold impacts will also remain important in the UK. The demographic changes expected this century mean that the health protection of the elderly will be vital.\n",
      "  - Mortality due to extreme temperatures is one of the most worrying impacts of climate change. In this analysis, we use historic mortality and temperature data from 106 cities in the United States to develop a model that predicts deaths attributable to temperature. With this model and projections of future temperature from climate models, we estimate temperature‐related deaths in the United States due to climate change, changing demographics, and adaptation. We find that temperature‐related deaths increase rapidly as the climate warms, but this is mainly due to an expanding and aging population. For global average warming below 3°C above pre‐industrial levels, we find that climate change slightly reduces temperature‐related mortality in the U.S. because the reduction of cold‐related mortality exceeds the increase in heat‐related deaths. Above 3°C warming, whether the increase in heat‐related deaths exceeds the decrease in cold‐related deaths depends on the level of adaptation. Southern U.S. cities are already well adapted to hot temperatures and the reduction of cold‐related mortality drives overall lower mortality. Cities in the Northern U.S. are not well adapted to high temperatures, so the increase in heat‐related mortality exceeds the reduction in cold‐related mortality. Thus, while the total number of climate‐related mortality may not change much, climate change will shift mortality in the U.S. to higher latitudes.\n",
      "--------------------------------------------------\n",
      "Topic 82: 82_tipping_dynamical_system_systems\n",
      "Representative Documents:\n",
      "  - Based on the theory of “snapshot/pullback attractors”, we show that important features of the climate change that we are observing can be understood by imagining many replicas of Earth that are not interacting with each other. Their climate systems evolve in parallel, but not in the same way, although they all obey the same physical laws, in harmony with the chaotic-like nature of the climate dynamics. These parallel climate realizations evolving in time can be considered as members of an ensemble. We argue that the contingency of our Earth’s climate system is characterized by the multiplicity of parallel climate realizations rather than by the variability that we experience in a time series of our observed past. The natural measure of the snapshot attractor enables one to determine averages and other statistical quantifiers of the climate at any instant of time. In this paper, we review the basic idea for climate changes associated with monotonic drifts, and illustrate the large number of possible applications. Examples are given in a low-dimensional model and in numerical climate models of different complexity. We recall that systems undergoing climate change are not ergodic, hence temporal averages are generically not appropriate for the instantaneous characterization of the climate. In particular, teleconnections, i.e. correlated phenomena of remote geographical locations are properly characterized only by correlation coefficients evaluated with respect to the natural measure of a given time instant, and may also change in time. Physics experiments dealing with turbulent-like phenomena in a changing environment are also worth being interpreted in view of the attractor-based ensemble approach. The possibility of the splitting of the snapshot attractor to two branches, near points where the corresponding time-independent system undergoes bifurcation as a function of the changing parameter, is briefly mentioned. This can lead in certain climate-change scenarios to the coexistence of two distinct sub-ensembles representing dramatically different climatic options. The problem of pollutant spreading during climate change is also discussed in the framework of parallel climate realizations.\n",
      "  -  We explore cosmological perturbations in a modified Gauss–Bonnet [Formula: see text] gravity, using a [Formula: see text] covariant formalism. In such a formalism, we define gradient variables to get perturbed linear evolution equations. We transform these linear evolution equations into ordinary differential equations using a spherical harmonic decomposition method. The obtained ordinary differential equations are time-dependent and then transformed into redshift-dependent. After these transformations, we analyze energy-density perturbations for two fluid systems, namely, for a Gauss–Bonnet field-dust system and for a Gauss–Bonnet field-radiation system for three different pedagogical [Formula: see text] models: trigonometric, exponential and logarithmic. For the Gauss–Bonnet field-dust system, energy-density perturbations decay with increase in redshift for all the three models. For the Gauss–Bonnet field-radiation system, the energy-density perturbations decay with increase in redshift for all of the three [Formula: see text] models for long wavelength modes whereas for short wavelength modes, the energy-density perturbations decay with increasing redshift for the logarithmic and exponential [Formula: see text] models and oscillate with decreasing amplitude for the trigonometric [Formula: see text] model. \n",
      "  - The gravity or reactive bundle energy is the outlet of the morphogenetic impact, known as “BIG BANG”, creating a bounded ordered/structured universe along with the solar system, including the EARTH-world with its human race. Post-impact, the huge kinetic energy is spread into stellar bodies associated with the light flux under strong mutual connections or gravitational bundle. Einstein’s general relativity theory including the gravitational field can be expressed under a condensed tensor formulation asE  R − Rg =  Twhere E defines the geometry via a curved space-time structure (R) over the gravity field (1/2Rg), embedded in a matter distribution T The fundamental (ten non-linear partial differential) equations of the gravitational field are a kind of the space-time machine using the curvature of a four-dimensional space-time to engender the gravity field carrying away material structures. Gravity according to the curved space-time theory is not seen as a gravitational force, but it manifests itself in the relativistic form of the space-time curvature needing the constancy of the light speed. But the constant light velocity makes the tidal wave/pulsating energy, a characteristic of solar energy, impossible. The Einstein’s field equation, expressed in terms of tensor formulation along with the constant light speed postulate, needs two special space-time tensors (curvature and torsion) in 4 dimensions, where for the simplicity the torsion/twist tensor is less well approximated (Bianchi identity) leading to a constant/frozen gravity (twist-free gravity).The non-zero torsion tensor plays a significant physical role in the planetary dynamics as a finest gear of a planet, where its spinning rotation is directly connected to the own work and space-time structure (or clock), controlled by light fluctuations (or tidal effect of gravity). The spin correction of Einstein’s gravitational field refers to the curvature-torsion effect coupled with fluctuating light speed. The mutual curvature-torsion bundle self-sustained by the quantum fluctuations of light speed engenders helical gravitational wave fields of a quantum nature where bodies orbit freely in the light speed field (cosmic wind). In contrast to the Einstein’s field equation describing a gravitational frozen field, a quantum tidal gravity model is proposed in the paper.\n",
      "--------------------------------------------------\n",
      "Topic 83: 83_rainfall_products_bias_performance\n",
      "Representative Documents:\n",
      "  - Consistent time series rainfall datasets are important in performing climate trend analyses and agro-hydrological modeling. However, temporally consistent ground-based and long-term observed rainfall data are usually lacking for such analyses, especially in mountainous and developing countries. In the absence of such data, satellite-derived rainfall products, such as the Climate Hazard Infrared Precipitations with Stations (CHIRPS) and Global Precipitation Measurement Integrated Multi-SatellitE Retrieval (GPM-IMERG) can be used. However, as their performance varies from region to region, it is of interest to evaluate the accuracy of satellite-derived rainfall products at the basin scale using ground-based observations. In this study, we evaluated and demonstrated the performance of the three-run GPM-IMERG (early, late, and final) and CHIRPS rainfall datasets against the ground-based observations over the Ziway Lake Basin in Ethiopia. We performed the analysis at monthly and seasonal time scales from 2000 to 2014, using multiple statistical evaluation criteria and graphical methods. While both GPM-IMERG and CHIRPS showed good agreement with ground-observed rainfall data at monthly and seasonal time scales, the CHIRPS products slightly outperformed the GPM-IMERG products. The study thus concluded that CHIRPS or GPM-IMERG rainfall data can be used as a surrogate in the absence of ground-based observed rainfall data for monthly or seasonal agro-hydrological studies.\n",
      "  - The spatial and temporal scale of rainfall datasets is crucial in modeling hydrological processes. Recently, open-access satellite precipitation products with improved resolution have evolved as a potential alternative to sparsely distributed ground-based observations, which sometimes fail to capture the spatial variability of rainfall. However, the reliability and accuracy of the satellite precipitation products in simulating streamflow need to be verified. In this context, the objective of the current study is to assess the performance of three rainfall datasets in the prediction of daily and monthly streamflow using Soil and Water Assessment Tool (SWAT). We used rainfall data from three different sources: Climate Hazards Group InfraRed Rainfall with Station data (CHIRPS), Climate Forecast System Reanalysis (CFSR) and observed rain gauge data. Daily and monthly rainfall measurements from CHIRPS and CFSR were validated using widely accepted statistical measures, namely, correlation coefficient (CC), root mean squared error (RMSE), probability of detection (POD), false alarm ratio (FAR), and critical success index (CSI). The results showed that CHIRPS was in better agreement with ground-based rainfall at daily and monthly scale, with high rainfall detection ability, in comparison with the CFSR product. Streamflow prediction across multiple watersheds was also evaluated using Kling-Gupta Efficiency (KGE), Nash-Sutcliffe Efficiency (NSE) and Percent BIAS (PBIAS). Irrespective of the climatic characteristics, the hydrologic simulations of CHIRPS showed better agreement with the observed at the monthly scale with the majority of the NSE values ranging between 0.40 and 0.78, and KGE values ranging between 0.62 and 0.82. Overall, CHIRPS outperformed the CFSR rainfall product in driving SWAT for streamflow simulations across the multiple watersheds selected for the study. The results from the current study demonstrate the potential of CHIRPS as an alternate open access rainfall input to the hydrologic model.\n",
      "  - Climate models are basic tools to obtain reliable estimates of future climate change and its effects on the water resources and agriculture in given basin. However, all climate models are not equally valuable for all areas. Therefore, determining the most appropriate climate model for a specific study area is essential. This study examines the performance of 10 CORDEX-AFRICA-220 Regional Climate Models (RCMs), three downscaling institutional based ensembles mean (Reg ensemble, CCLM ensemble and REMOO ensemble) and the multi-model ensemble mean. The models were evaluated based on their ability in replicating the seasonal and annual rainfall, minimum and maximum temperature and inter-annual variability for the period of 1986–2005 using statistical metrics such as BIAS, Root Mean Square Error (RMSE), Pearson correlation coefficient (r), coefficient of variation (CV), Kling Gupta Efficiency (KGE) and Taylor diagram. The findings indicated that HadREMOO, MPI-Reg4-7, HadReg4-7, Reg ensemble, and multi-model ensemble mean performed relatively better in representing the mean annual observed rainfall at the Adiramets, Debarik Ketema, Niguse Maystebri, and Zarima stations, respectively. Whereas, NorESM-CCLM, MPI-CCLM, NorESM-Reg4-7, and NorESM-REMOO exhibited a weak performance in reproducing the observed mean annual rainfall at the Adiramets, Debarik Ketema Niguse, Maystebri, and Zarima stations, respectively. Similarly, RCMs generally capture the mean annual maximum temperature of climatic stationsof Zarima subbasin well. Specifically, the MPI-Reg4-7 simulation performs well in representing the mean annual observed maximum temperature at Adiramets and Maytsebri stations, while the Debarik and Ketema Niguse stations exhibit superior performance in the HadReg4-7 simulation and the Zarima station shows better representation in the CCLM ensemble simulations. The majority of the model simulations exhibit good representation of mean annual minimum temperature at Adiramets, Debarik, and Zarima stations. Specifically, CanESM-RCM, HadReg4-7, REMOOensemble, multi-model ensemble, and Regensemble simulations perform better at Adiramets, Debarik, Ketema niguse, Maystebri and Zarima stations respectively. This suggests that these models may have biases or shortcomings in capturing the temperature values in the subbasin. Furthermore, NorESM-CCLM at Adiramets, Ketema niguse, and Zarima stations, NorESM-REMOO at Debarik station, and HadReg4-7 at Maystebri station demonstrate poor performance in representing the observed mean minimum temprature. Majority of the RCMs, all institutional based ensemble means and the multi-model ensemble mean simulations overestimate the observed mean annual rainfall of the Zarima subbasin with minimum bias of 0.02 mm at Ketema niguse HadReg4-7and maximum bias of 2.81 mm at Maytsebri MPI-CCLM simulation. Similarly, HadReg4-7 simulation of Ketama Niguse MPI-CCLM showed a minimum 0.02 mm and Maytsebri simulation kiremit season mean rainfall showed a maximum bias of and 2.99 mm. Regarding mean annual and kiremit season maximum and minimum temperature of the Zarima subbasin were overestimated by majority of the simulation and the ensemble means. The correlation (r) of observed and model simulated mean annual and kiremit season rainfall was strong (0.60–0.79) and very strong (0.80–0.99) in the majority of the simulations except Ketema niguse station mean annual and kiremit season rainfall simulations of MPI-REMOO, NorESM-Reg4-7; Debarik station kiremit season rainfall of NorESM-CCLM and NorESM-REMOO, MPI-Reg4-7 and MPI-REMOO, which showed moderate correlation. The performance of the RCMs, institutional based ensemble means and multi-model ensemble mean were different in statistical metrics (BIAS, RMSE, r, CV and KGE) and Taylor diagram. Among the simulations and ensemble means, the multi-model ensemble mean was superiors in two or more of statistical metrics at each station of the Zarima subbasin except Maytsebri station kiremit season rainfall, where the CCLM ensemble was better. Consistently, the Taylor diagram showed that the multi-model ensemble was better in the replication of the areal annual and kiremit season rainfall, maximum and minimum temperature of the subbasin. This finding evidenced that selecting the best RCMs and ensemble mean is necessary for climate projection and climate change impact assessment study.\n",
      "--------------------------------------------------\n",
      "Topic 84: 84_research_originality_design methodology_methodology\n",
      "Representative Documents:\n",
      "  - PurposeThe purpose of this paper is to examine how past experiences in implementing disaster risk reduction (DRR) activities can be harnessed to conceptualise effective and appropriate climate change adaptation (CCA) programs in Indonesia. The authors propose a conceptual framework for integrating DRR and CCA in managing climate‐related risks and explain the need for joint implementation.Design/methodology/approachThe study is conducted through review and analysis of academic, government and non‐government literature to determine the Indonesian experience in integrating DRR and CCA. Interviews were conducted with 26 DRR and CCA stakeholders in Indonesia.FindingsThe authors make three propositions in this paper. First, there needs to be a re‐orientation of the institutional arrangements for DRR and CCA, to increase the effectiveness of planning and implementation. Second, DRR and CCA activities needed to be stronger supported at the local level, with a specific aim to reduce the underlying causes of vulnerability of communities at risk. Third, non‐government organisations play a very important role in integrating DRR and CCA through community‐based initiatives.Research limitations/implicationsWhile this paper focuses specifically on Indonesia, the findings are relevant to other countries with similar geographical and socio‐economic conditions, as they are likely to face similar challenges.Practical implicationsThe paper provides practical suggestions on what steps government actors, at all political levels, can do to support the integration of DRR and CCA planning and implementation activities in Indonesia.Originality/valueThe paper is one of the first to document progress in integrating DRR and CCA in Indonesia.\n",
      "  - PurposeThis research investigated Australian property valuers' identification and consideration of physical climate change risks in valuation practice.Design/methodology/approachThirty Australian valuer members of the Australian Property Institute from a variety of specialisations were interviewed. The semi-structured interviews explored climate change risks and the extent of risk investigation and consideration in valuation practice. The analysis utilised the Moser and Luers (2008) climate risk preparedness framework as a lens to evaluate current valuation practice in Australia.FindingsThe analysis reflects that while physical risks are easily identified and engaged with by valuers, correspondingly, there is a lack of understanding of and engagement with, climate change risks. This supports the need for better information sources and guidance to inform valuers of climate change risks and the development of specific mechanisms for the consideration of such risks to be included in valuation processes, practices and reports.Research limitations/implicationsThe research was limited by its sample size and qualitative approach. Therefore, the research is not a representative opinion of the Australian profession; however, the analysis provides the perspective of a range of valuers from across Australia with different valuation specialisations.Practical implicationsThis research has established that valuers have the potential to be prepared to address climate change in their professional capacity, as described by Moser and Luers (2008). However, they are constrained by information communication, access and detail and subsequent market awareness of information on climate change risk exposure on properties. There is a need for further support, guidance, information and tools, as well as awareness-raising, to enable valuers to accurately identify and reflect all risks affecting a property in the process of valuation.Originality/valueThis research provides the first investigation into the consideration of climate change in valuation practice. Property stakeholders—owners, investors, financiers and occupiers—are escalating their climate change risk analysis and reporting for property portfolios and organisations. This research suggests that valuers also need to be aware of the changing dynamics of market reporting and decision-making related to climate change risks to ensure appropriate reflection in valuation practice.\n",
      "  - PurposeThe purpose of this research is to investigate Australian property valuers' identification and consideration of physical risks to properties in valuation practice. The research further explores valuers' considerations of climate change-related risks.Design/methodology/approachThe research approach comprised an online survey of Australian valuers who were members of the Australian Property Institute. The online survey included structured and unstructured questions to explore types and extent of risk investigations in valuation practice.FindingsThe analysis reflects that while valuers easily identified and engaged with physical risks, there is a lack of understanding of, and engagement with, climate change risks. This supports the need for better information sources and guidance to inform valuers of climate change risksper se, as well as the development of specific mechanisms for consideration of such risks to be included in valuation processes, practices and reports.Research limitations/implicationsThe research is limited by the small sample size achieved due to the timing of the survey deployment, which occurred during the first wave of COVID-19 lockdowns in Australia. Thus, the findings are not necessarily representative of the Australian valuation profession, but they do provide indications of current approaches to risk identification in practice and the need for more guidance in relation to climate change risks.Practical implicationsThis research identifies that more support, guidance, information and tools, as well as awareness-raising, are required to enable valuers to accurately identify all risks affecting a property.Originality/valueThe research provides a snapshot of current understandings of physical risk identification in valuation practice. As investors and other organisations integrate and build up their analysis of climate risks to their portfolios and organisations, this research indicates that valuers also need to be aware of changing market assessment of physical and climate risks associated with property for consideration in valuation.\n",
      "--------------------------------------------------\n",
      "Topic 85: 85_health_kidney_disease_heat\n",
      "Representative Documents:\n",
      "  -             Purpose of review            Geographically localized areas with a high prevalence of kidney disease exist currently in several regions of the world. Although the exact cause is unclear, environmental exposures accelerated by climate change, particularly heat exposure and ground water contamination, are hypothesized as putative risk factors. Aiming to inform investigations of water-related exposures as risk factors for kidney disease, we excavate the history of major water sources in three regions that are described as hotspots of kidney disease: the low-lying coastal regions in El Salvador and Nicaragua, the dry central region in Sri Lanka, and the Central Valley of California.                                Recent findings            Historic data indicate that these regions have experienced water scarcity to which several human-engineered solutions were applied; these solutions could be hypothesized to increase residents’ exposure to putative kidney toxins including arsenic, fluoride, pesticides, and cyanobacteria. Combined with heat stress experienced in context of climate change, there is potential for multistressor effects on kidney function. Climate change will also amplify water scarcity, and even if regional water sources are not a direct risk factor for development of kidney disease, their scarcity will complicate the treatment of the relatively larger numbers of persons with kidney disease living in these hotspots.                                Summary            Nephrologists and kidney disease researchers need to engage in systematic considerations of environmental exposures as potential risk factors for kidney disease, including water sources, their increasing scarcity, and threats to their quality due to changing climate.          \n",
      "  -                Climate change should be of special concern for the nephrologist, as the kidney has a critical role in protecting the host from dehydration, but it is also a favorite target of heat stress and dehydration. Here we discuss how rising temperatures and extreme heat events may affect the kidney. The most severe presentation of heat stress is heat stroke, which can result in severe electrolyte disturbance and both acute and chronic kidney disease (CKD). However, lesser levels of heat stress also have multiple effects, including exacerbating kidney disease and precipitating cardiovascular events in subjects with established kidney disease. Heat stress can also increase the risk for kidney stones, cause multiple electrolyte abnormalities and induce both acute and chronic kidney disease. Recently there have been multiple epidemics of CKD of uncertain etiology in various regions of the world, including Mesoamerica, Sri Lanka, India and Thailand. There is increasing evidence that climate change and heat stress may play a contributory role in these conditions, although other causes, including toxins, could also be involved. As climate change worsens, the nephrologist should prepare for an increase in diseases associated with heat stress and dehydration.\n",
      "  - The worldwide increase in temperature has resulted in a marked increase in heat waves (heat extremes) that carries a markedly increased risk for morbidity and mortality. The kidney has a unique role not only in protecting the host from heat and dehydration but also is an important site of heat-associated disease. Here we review the potential impact of global warming and heat extremes on kidney diseases. High temperatures can result in increased core temperatures, dehydration, and blood hyperosmolality. Heatstroke (both clinical and subclinical whole-body hyperthermia) may have a major role in causing both acute kidney disease, leading to increased risk of acute kidney injury from rhabdomyolysis, or heat-induced inflammatory injury to the kidney. Recurrent heat and dehydration can result in chronic kidney disease (CKD) in animals and theoretically plays a role in epidemics of CKD developing in hot regions of the world where workers are exposed to extreme heat. Heat stress and dehydration also has a role in kidney stone formation, and poor hydration habits may increase the risk for recurrent urinary tract infections. The resultant social and economic consequences include disability and loss of productivity and employment. Given the rise in world temperatures, there is a major need to better understand how heat stress can induce kidney disease, how best to provide adequate hydration, and ways to reduce the negative effects of chronic heat exposure.\n",
      "--------------------------------------------------\n",
      "Topic 86: 86_water_basin_scenarios_future\n",
      "Representative Documents:\n",
      "  - To investigate the impacts of climate and land use changes on hydrology, the Don catchment in Yorkshire, UK, was selected. A physically based distributed catchment‐scale (DiCaSM) model was applied. The model simulates surface runoff, groundwater recharge and drought indicators such as soil moisture deficit SMD, wetness index WI and reconnaissance drought index RDI. The model's goodness of fit using the Nash–Sutcliffe efficiency factor was &gt;91% for the calibration period (2011–2012) and 83% for the validation period (1966–2012). Under different climate change scenarios, the greatest decrease in stream flow and groundwater recharge was projected under medium‐ and high‐emission scenarios. Climate change scenarios projected an increase in evapotranspiration and SMD, especially in the latter half of the current century.Increasing the woodland area had the most significant impact, reducing stream flow by 17% and groundwater recharge by 22%. Urbanization could lead to increase in stream flow and groundwater recharge. The climate change impact on stream flow and groundwater recharge was more significant than land use change. Drought indices SMD, WI and RDI projected an increase in the severity and frequency of drought events under future climatic change, especially under high‐emission scenarios. © 2020 John Wiley &amp; Sons, Ltd.\n",
      "  - This study evaluates hydrology and hydrological extremes under future climate change scenarios. The climate change scenarios were developed from multiple Global Circulation Models (GCMs), Representative Concentration Pathway (RCP) scenarios, and statistical downscaling techniques. To ensure hydrological model robustness, the Soil Water Assessment Tool (SWAT) was calibrated and validated using the Differential Split Sample Test (DSST) approach. The model was also calibrated and validated at the multi-gauges of the watershed. Future climate change scenarios revealed a reduction in precipitation (in the order of −9.1% to 4.9%) and a consistent increase in maximum temperature (0.34°C to 4.10°C) and minimum temperature (−0.15 °C to 3.7°C) in different climate model simulations. The climate change scenarios triggered a reduction of surface runoff and streamflow and a moderate increase in evapotranspiration. Future climate change scenarios projected a decrease in high flow (Q5) and low flow (Q95). A higher reduction of Q5 and annual minimum flow is also simulated in future climate scenarios, whereas an increase in annual maximum flow is simulated in climate change scenarios developed from the RCP8.5 emission scenario. The study suggests optimal water management structures which can reduce the effect of change in high and low flows.\n",
      "  - Pakistan is currently facing physical and economic water scarcity issues that are further complicated by the rapid increase in its population and by climate change. Many studies have focused on the physical water scarcity using hydrological modeling and the measurement of the impact of climate change on water resources in the Upper Indus Basin (UIB). However, few studies have concentrated on the importance of the economic water scarcity, that is, the water management issue under the looming impacts of climate change and the population explosion of Pakistan. The purpose of this study is to develop a management strategy which helps to achieve water security and sustainability in the Upper Indus Basin (UIB) with the help of different socio-economic and climate change scenarios using WEAP (Water Evaluation and Planning) modeling. The streamflow data of five sub-basins (Gilgit, Hunza, Shigar, Shyok, and Astore) and the entire Upper Indus Basin (UIB) were calibrated (2006–2010) and validated (2011–2014) in the WEAP model. The coefficient of determination and Nash Sutcliffe values for the calibration period ranged from 0.81–0.96. The coefficient of determination and the Nash Sutcliffe values for the validation period ranged from 0.85–0.94. After the development of the WEAP model, the analysis of the unmet water demand and percent coverage of the water demand for the period of 2006–2050 was computed. Different scenarios were generated for external driving factors (population growth, urbanization, and living standards) and the impact of climate change to evaluate their effect on the current water supply system. The results indicated that the future unmet water demand is likely to reach 134 million cubic meters (mcm) by the year 2050 and that the external driving factors are putting more pressure on the supply service. This study further explores the importance of proposed dams (likely to be built until 2025) by WAPDA (Water and Power Development Authority). These dams will decrease the unmet water demand by 60% in the catchment. The water demands under four scenarios (the reference, moderate future-1, moderate future-2, and management scenarios) were compared. The management scenario analysis revealed that 80% of the water demand coverage could be achieved by the year 2023, which could help in developing sustainable water governance for the catchment.\n",
      "--------------------------------------------------\n",
      "Topic 87: 87_utilities_energy_electric_customers\n",
      "Representative Documents:\n",
      "  - As a growing number of electric utilities across the United States are tasked with delivering clean energy, distributed energy resources (DERs) are poised to play a pivotal role in making this transition cost‐effective and equitable while keeping the electric grid safe and reliable. DERs can range from larger, utility‐sited applications—such as energy storage in utility substations or community solar—to smaller, customer‐sited applications, such as rooftop solar photovoltaics (PV) or smart devices enrolled in utility demand response programs. Key emerging roles for DERs in grid operations include the balancing of intermittent renewables (e.g., bulk solar PV and wind generation), managing changes in electric power demand through cost‐effective and flexible approaches (e.g., charging electric vehicles from on‐site renewable sources), and significantly contributing to utility clean energy and resiliency objectives.\n",
      "  - Taken at face value, peak load management involves controlling or influencing the time of day when electricity is used in homes, businesses, and public facilities. The desire to reduce peak electricity use has been based on the availability of generation resources and their associated costs. During periods of high electricity demand, retail energy providers, including distribution utilities, purchase power from generation sources that are less efficient than baseload generation resources such as hydro, nuclear, or coal. Operating the electrical grid has never been simple, but today the balance of supply and demand is getting more complex. On the supply side, the increasing penetration of renewable and distributed energy sources, such as solar and wind power, makes peak load management more complex. These sources are inherently intermittent, meaning that power generation cannot always be scheduled to meet demand. Additionally, electrification of the buildings and transportation sectors is changing the load profiles of customers and the regions of a distribution utility's service area. Yet, the rise of distributed energy resources (DERs), such as rooftop solar and battery storage, has created both opportunities and challenges for grid operators. Peak load management is rapidly evolving from past practices, with new use cases, economic drivers, hardware and software, and information technologies playing an increasingly important role. A cleaner energy future, while critical to our society and the environment, is not without increasing cost pressures, economic risks, and reliability challenges from extreme weather events. While we know where we are going, it is not exactly clear how we will get there. Nonetheless, the emphasis on peak load management will only increase in scale and sophistication. To better predict and prepare for the rapidly changing energy landscape, this editorial discusses the past and present state of peak load management and how it might be evolving into more flexible load management.\n",
      "  - Distributed Energy Resources (DERs) are a primary driver requiring utilities to become more digitalized. DERs are disrupting traditional distribution utility business models, creating new opportunities in the way utilities and customers generate electricity, manage load, and finance and procure resources. With more than 33 states having clean energy action plans and a majority of Americans in all 50 states supporting the actions to move the country toward 100 percent clean energy generation by 2035, utilities are being called upon to support investment in DERs. DER capacity is expected to grow through both FERC Order 2222, which would enable DER aggregators to participate in wholesale electricity markets, and in support of electric vehicles infrastructure development. The rise of DERs in response to decarbonization and clean energy goals provides an opportunity for both utilities and developers to improve grid reliability and improve the load profile on the distribution grid. The increased penetration of DERs continues to foster greater customer participation in meeting their loads while increasing pressure on utilities to interconnect and derive value from DERs and grid‐edge assets. These complexities require a significant shift in thinking and paves the way for industry leaders to think digitally.\n",
      "--------------------------------------------------\n",
      "Topic 88: 88_research_bibliometric_publications_papers\n",
      "Representative Documents:\n",
      "  - Affected by global warming, the frequency of crop pests and diseases have increased, causing huge losses to agricultural production. To better grasp the development and trends of research on the effects of climate change on crop pests and diseases, the literature on the impact of climate change on crop pests and diseases published from 1990 to 2021 in the Web of Science (WOS) core collection database was used. This study explores the literature characteristics and hotspot evolution through the bibliometric visualization analysis software COOC, VOSviewer, and CiteSpace, with a view to identifying the changing characteristics and trends of research changes in this field. The results showed that the number of literature on the impact of climate change on crop pests and diseases increased rapidly. The main fields involved include environmental sciences, ecology, and agronomy. Papers in these fields mainly published in journals, such as PLos One, Forest Ecology and Management, and Frontiers in Plant Science. The country with the highest number of publications was the United States, followed by China and Australia. The most prolific authors in the top 20 are research scholars from China. The first author of the top 20 highly cited papers was from the United States. It was found that that current research on the impact of climate change on crop pests and diseases mainly focuses on agricultural production and food safety. Modelling and crop growth has maintained steady development. At present, research in this field mainly focuses on pest management strategies under the impact of climate change, the response of single species, and the complex ecological mechanisms behind the response. This study provides unique insights into the research field of the impact of climate change on crop pests and diseases and provides a reference direction for future research development in this field.\n",
      "  -                 Purpose                Vegetation is a typical sensitive indicator of climate change, and therefore provides theoretical and valuable information for addressing issues arising from climate change including improving soil ecosystem services. Exploring how vegetation responses to climate change has become one of major hotspots of research. However, few scholars have performed bibliometric analyses of this field. This study investigated the current research activities and the trend developments of vegetation responses to climate change.                              Materials and methods                We conducted a quantitative bibliometric analysis of 2,310 publications on vegetation responses to climate change from 1991 to 2021 retrieved in the Web of Science Core Collection. The analysis comprised significant journals, disciplines, and scholars, as well as partnerships between countries and institutions, keyword co-occurrence and burst analysis. The bibliometric analysis tools, Histcite, Vosviewer, CiteSpace software, and R (Bibliometrix package), were applied.                              Results and discussion                The related publications on vegetation responses to climate change had been increasing exponentially in the past 30 years and its total global cited score reached its peak in 2010. The USA and China were the leading countries, with the Chinese Academy of Sciences having the highest number of publications and citations. The scholars who had the most citations were Allen CD, Bresears DD, and Running SW. Six research clusters were generated by keywords co-occurrence analysis, including impact, response, CO2, growth, climate change, and vegetation. These clusters represented the current research topics that highlighted the responses of vegetation to climate change, the manifestation of its impact, and coping strategies. In future research on vegetation, the emphasis is expected to be placed on “human activities” and “N2O emission”.                              Conclusion                This study has performed a comprehensive and systematic and quantitative analysis of the publications on the responses of vegetation to climate change. The results reveal the characteristics, development patterns, and research trends of studies on vegetation activity in response to climate change, which sheds new insights into understanding the relationship between soil and climate.              \n",
      "  - Climate change has increased the vulnerability of many communities and ecosystems, including those on islands. This study evaluates the patterns of scientific publication and visualises network connections between countries and keywords by presenting four sets of bibliometric analyses of publications related to “climate change and vulnerability”, “climate change and island”, “vulnerability and island”, and “vulnerability, climate change, and island”, as obtained from the Scopus database. Based on the combinations of keywords in the article, the study retrieved 1768 documents for “climate change and vulnerability”, 501 documents for “climate change and island”, 270 documents for “vulnerability and island”, and 37 documents for “vulnerability, climate change, and island” for further analysis using various tools. Microsoft Excel was used to conduct the frequency analysis, and Harzing’s Publish or Perish and VOSviewer were used for the citation metrics analysis and data visualisation, respectively. The results are reported using standard bibliometric indicators, such as the annual growth of publications, publications by subject, prolific authors, most active institutions, active journals, highly cited articles, co-authorship by countries, and co-occurrence keyword analysis. The findings revealed that there has been continuous growth in the number of publications on all four research topics since the first publication, and the main subject found on Scopus for all topics in Environmental Science. For “climate change and vulnerability”, the most productive author is James D. Ford, and the most active journal is Climatic Change. The most-cited document has received 3243 citations. Meanwhile, for “climate change and islands”, the most productive author and most active journals are Patrick D. Nunn and Regional Environmental Change, respectively, while the most cited document has received 285 citations. Subsequently, the most productive authors for “vulnerability and island” and “climate change, vulnerability, and island” received 627 citations and 154 citations, respectively. The country with the most links and highest total link strength was the United States of America, according to co-occurrence analysis between countries. Current themes are discussed, and future possible research is suggested based on the clustering of the keywords. Among the clusters that emerged from the network visualisations are those focused on the ecosystem, adaptation, water resources, human and health risk assessments, coastal vulnerability and management, and agricultural and resource management. This study will benefit policymakers, researchers, environmental practitioners, and the public because it provides a comprehensive overview of existing research, potential research directions, and the current state of knowledge on the topic, allowing a better understanding of the research landscape.\n",
      "--------------------------------------------------\n",
      "Topic 89: 89_species_habitat_conservation_areas\n",
      "Representative Documents:\n",
      "  - In a world where changes in land cover and climate happen faster than ever due to the expansion of human activities, narrowly distributed species are predicted to be the first to go extinct. Studies projecting species extinction in tropical regions consider either habitat loss or climate change as drivers of biodiversity loss but rarely evaluate them together. Here, the contribution of these two factors to the extinction risk of narrowly distributed species (with ranges smaller than 10,000 km2) of seed plants endemic to a fifth-order watershed in Brazil (microendemics) is assessed. We estimated the Regional Climate Change Index (RCCI) of these watersheds (areas with microendemics) and projected three scenarios of land use up to the year 2100 based on the average annual rates of habitat loss in these watersheds from 2000 to 2014. These scenarios correspond to immediate conservation action (scenario 1), long-term conservation action (scenario 2), and no conservation action (scenario 3). In each scenario, areas with microendemics were classified into four classes: (1) areas with low risk, (2) areas threatened by habitat loss, (3) areas threatened by climate change, and (4) areas threatened by climate change and habitat loss. We found 2,354 microendemic species of seed plants in 776 areas that altogether cover 17.5% of Brazil. Almost 70% (1,597) of these species are projected to be under high extinction risk by the end of the century due to habitat loss, climate change, or both, assuming that these areas will not lose habitat in the future due to land use. However, if habitat loss in these areas continues at the prevailing annual rates, the number of threatened species is projected to increase to more than 85% (2,054). The importance of climate change and habitat loss as drivers of species extinction varies across phytogeographic domains, and this variation requires the adoption of retrospective and prospective conservation strategies that are context specific. We suggest that tropical countries, such as Brazil, should integrate biodiversity conservation and climate change policies (both mitigation and adaptation) to achieve win-win social and environmental gains while halting species extinction.\n",
      "  - The ability of species to shift their distributions in response to climate change may be impeded by lack of suitable climate or habitat between species’ current and future ranges. We examined the potential for climate and forest cover to limit the movement of bird species among sites of biodiversity importance in the Albertine Rift, East Africa, a biodiversity hotspot. We forecasted future distributions of suitable climate for 12 Albertine Rift endemic bird species using species distribution models based on current climate data and projections of future climate. We used these forecasts alongside contemporary forest cover and natal dispersal estimates to project potential movement of species over time. We identified potentially important pathways for the bird species to move among 30 important bird and biodiversity areas (IBAs) that are both currently forested and projected to provide suitable climate over intervening time periods. We examined the relative constraints imposed by availability of suitable climate and forest cover on future movements.The analyses highlighted important pathways of potential dispersal lying along a north‐south axis through high elevation areas of the Albertine Rift. Both forest availability and climate suitability were projected to influence bird movement through these landscapes as they are affected by future climate change. Importantly, forest cover and areas projected to contain suitable climate in future were often dissociated in space, which could limit species’ responses to climate change. A lack of climatically suitable areas was a far greater impediment to projected movement among IBAs than insufficient forest cover. Although current forest cover appears sufficient to facilitate movement of bird species in this region, protecting the remaining forests in areas also projected to be climatically suitable for species to move through in the future should be a priority for adaptation management.\n",
      "  - \t\t\t\t\t\t\t\t\tContext\t\t\t\t\tThe impacts of climate change on the climate envelopes, and hence, distributions of species, are of ongoing concern for biodiversity worldwide. Knowing where climate refuge habitats will occur in the future is essential to conservation planning. The koala (Phascolarctos cinereus) is recognised by the International Union for Conservation of Nature (IUCN) as a species highly vulnerable to climate change. However, the impact of climate change on its distribution is poorly understood.\t\t\t\t\t\t\t\t\t\t\t\t\tAims\t\t\t\t\tWe aimed to predict the likely shifts in the climate envelope of the koala throughout its natural distribution under various climate change scenarios and identify potential future climate refugia.\t\t\t\t\t\t\t\t\t\t\t\t\tMethods\t\t\t\t\tTo predict possible future koala climate envelopes we developed bioclimatic models using Maxent, based on a substantial database of locality records and several climate change scenarios.\t\t\t\t\t\t\t\t\t\t\t\t\tKey results\t\t\t\t\tThe predicted current koala climate envelope was concentrated in south-east Queensland, eastern New South Wales and eastern Victoria, which generally showed congruency with their current known distribution. Under realistic projected future climate change, with the climate becoming increasingly drier and warmer, the models showed a significant progressive eastward and southward contraction in the koala’s climate envelope limit in Queensland, New South Wales and Victoria. The models also indicated novel potentially suitable climate habitat in Tasmania and south-western Australia.\t\t\t\t\t\t\t\t\t\t\t\t\tConclusions\t\t\t\t\tUnder a future hotter and drier climate, current koala distributions, based on their climate envelope, will likely contract eastwards and southwards to many regions where koala populations are declining due to additional threats of high human population densities and ongoing pressures from habitat loss, dog attacks and vehicle collisions. In arid and semi-arid regions such as the Mulgalands of south-western Queensland, climate change is likely to compound the impacts of habitat loss, resulting in significant contractions in the distribution of this species.\t\t\t\t\t\t\t\t\t\t\t\t\tImplications\t\t\t\t\tClimate change pressures will likely change priorities for allocating conservation efforts for many species. Conservation planning needs to identify areas that will provide climatically suitable habitat for a species in a changing climate. In the case of the koala, inland habitats are likely to become climatically unsuitable, increasing the need to protect and restore the more mesic habitats, which are under threat from urbanisation. National and regional koala conservation policies need to anticipate these changes and synergistic threats. Therefore, a proactive approach to conservation planning is necessary to protect the koala and other species that depend on eucalypt forests.\t\t\t\t\t\t\t\n",
      "--------------------------------------------------\n",
      "Topic 90: 90_reaction_catalytic_carboxylation_catalyst\n",
      "Representative Documents:\n",
      "  - Catalytic reductive coupling of two electrophiles and one unsaturated bond represents an economic and efficient way to construct complex skeletons, which is dominated by transition-metal catalysis via two electron transfer. Herein, we report a strategy of visible-light photoredox-catalyzed successive single electron transfer, realizing dearomative arylcarboxylation of indoles with CO2. This strategy avoids common side reactions in transition-metal catalysis, including ipso-carboxylation of aryl halides and β-hydride elimination. This visible-light photoredox catalysis shows high chemoselectivity, low loading of photocatalyst, mild reaction conditions (room temperature, 1 atm) and good functional group tolerance, providing great potential for the synthesis of valuable but difficultly accessible indoline-3-carboxylic acids. Mechanistic studies indicate that the benzylic radicals and anions might be generated as the key intermediates, thus providing a direction for reductive couplings with other electrophiles, including D2O and aldehyde.\n",
      "  - Photoredox-mediated umpolung strategy provides an alternative pattern for functionalization of carbonyl compounds. However, general approaches towards carboxylation of carbonyl compounds with CO2remain scarce. Herein, we report a strategy for visible-light photoredox-catalyzed umpolung carboxylation of diverse carbonyl compounds with CO2by using Lewis acidic chlorosilanes as activating/protecting groups. This strategy is general and practical to generate valuable α-hydroxycarboxylic acids. It works well for challenging alkyl aryl ketones and aryl aldehydes, as well as for α-ketoamides and α-ketoesters, the latter two of which have never been successfully applied in umpolung carboxylations with CO2(to the best of our knowledge). This reaction features high selectivity, broad substrate scope, good functional group tolerance, mild reaction conditions and facile derivations of products to bioactive compounds, including oxypheonium, mepenzolate bromide, benactyzine, and tiotropium. Moreover, the formation of carbon radicals and carbanions as well as the key role of chlorosilanes are supported by control experiments.\n",
      "  - Electrochemical catalytic reductive cross couplings are powerful and sustainable methods to construct C−C bonds by using electron as the clean reductant. However, activated substrates are used in most cases. Herein, we report a general and practical electro-reductive Ni-catalytic system, realizing the electrocatalytic carboxylation of unactivated aryl chlorides and alkyl bromides with CO2. A variety of unactivated aryl bromides, iodides and sulfonates can also undergo such a reaction smoothly. Notably, we also realize the catalytic electrochemical carboxylation of aryl (pseudo)halides with CO2avoiding the use of sacrificial electrodes. Moreover, this sustainable and economic strategy with electron as the clean reductant features mild conditions, inexpensive catalyst, safe and cheap electrodes, good functional group tolerance and broad substrate scope. Mechanistic investigations indicate that the reaction might proceed via oxidative addition of aryl halides to Ni(0) complex, the reduction of aryl-Ni(II) adduct to the Ni(I) species and following carboxylation with CO2.\n",
      "--------------------------------------------------\n",
      "Topic 91: 91_growth_radial growth_tree_radial\n",
      "Representative Documents:\n",
      "  - Improved understanding of the responses of stem radial growth to climates is necessary for modeling and predicting the response of forest ecosystems to future climate change. We used dendrochronological methods to study climate effects on the radial growth of a subalpine deciduous conifer, Larix potaninii. Tree-ring residual chronologies were developed for five sites at the upper distributional limits in the Central Hengduan Mountains, Southwestern China. Redundancy analysis and response function were used to compare inter-annual variability in growth sensitivity among the chronologies and to identity key climatic factors controlling tree radial growth. The results showed that both precipitation and temperature influenced tree growth, and response patterns were consistent for five chronologies. During the current year’s early growing season (Tmean in May and Tmax in June), temperature positively affected the radial growth of L. potaninii, while September Tmin and October precipitation in the previous year and May and June precipitation in the current year all had negative impacts on its radial growth. L. potaninii growth appeared to be mainly limited by photothermal conditions in May and June. In the context of increasing CO2 concentrations accompanied with warmer temperatures, future climate change would likely stimulate the radial growth of L. potaninii in Central Hengduan Mountain.\n",
      "  - It is important to explore the responses of radial tree growth in different regions to understand growth patterns and to enhance forest management and protection with climate change. We constructed tree ring width chronologies of Picea crassifolia from different regions of the Qilian Mountains of northwest China. We used Pearson correlation and moving correlation to analyze the main climate factors limiting radial growth of trees and the temporal stability of the growth–climate relationship, while spatial correlation is the result of further testing the first two terms in space. The conclusions were as follows: (1) Radial growth had different trends, showing an increasing followed by a decreasing trend in the central region, a continuously increasing trend in the eastern region, and a gradually decreasing trend in the isolated mountain. (2) Radial tree growth in the central region and isolated mountains was constrained by drought stress, and tree growth in the central region was significantly negatively correlated with growing season temperature. Isolated mountains showed a significant negative correlation with mean minimum of growing season and a significant positive correlation with total precipitation. (3) Temporal dynamic responses of radial growth in the central region to the temperatures and SPEI (the standardized precipitation evapotranspiration index) in the growing season were unstable, the isolated mountains to total precipitation was unstable, and that to SPEI was stable. The results of this study suggest that scientific management and maintenance plans of the forest ecosystem should be developed according to the response and growth patterns of the Qinghai spruce to climate change in different regions of the Qilian Mountains.\n",
      "  - The climate changed from warm-dry to warm-wet during the 1960s in northwest China. However, the effects of climate change on the response of radial growth from different age-class trees have been unclear. We assessed the age-effect radial growth responses in three age-classes (ml-old: ≥200 years, ml-middle: 100–200 years and ml-young: &lt;100 years) of Schrenk spruce (Picea schrenkiana Fisch. et Mey.) in the eastern Tianshan Mountains. The primary conclusions were as follows: the developed chronologies of the three age-class trees contained significant climate information and exhibited high similarity as shown by calculating the statistical parameter characteristics and Gleichlaufigkeit index. The three age-class trees were consistent for annual variation trends of radial growth under climate change, showing similar fluctuations, tree-ring width chronology trends, time trends of cumulative radial growth, and basal area increment. In addition, the old and middle trees were found to be more sensitive to climate variability by analyzing Pearson correlations between radial growth from three age-class trees and climate factors. As a result, the drought caused by reduced total precipitation and higher mean temperature was a limiting factor of tree radial growth, and the trees with ages of up to 100 years were more suitable for studies on the growth-climate relationships. Thus, the studies on age-effect radial growth responses of Schrenk spruce can help not only in understanding the adaptive strategies of different-age trees to climate change, but also provide an accurate basis for climate reconstruction.\n",
      "--------------------------------------------------\n",
      "Topic 92: 92_growth_spruce_tree_fir\n",
      "Representative Documents:\n",
      "  -                Norway spruce (Picea abies [L.] Karst.) and silver fir (Abies alba Mill.) are main tree species of Central Europe that are currently highly vulnerable in times of global climate change. The research deals with the effect of climate and air pollution on radial growth of silver fir and Norway spruce in mixed age-varied (56 – 146 years) forests in the Jeseníky Protected Landscape Area, the Czech Republic. The objectives were to evaluate biodiversity, structure and production, specifically interaction of radial growth of fir and spruce to air pollution (SO2, NOX, tropospheric ozone) and climatic factors (precipitation, air temperature). Concentration of SO2 and NOX had negative effect on radial growth of fir, while radial growth of spruce was more negatively influenced by tropospheric ozone. Fir showed higher variability in radial growth and was more sensitive to climatic factors compared to spruce. On the other hand, fir was relatively adaptable tree species that regenerated very well when the pressure of stress factors subsided (air pollution load, Caucasian bark beetle, frost damage). Low temperature was a limiting factor of radial growth in the study mountainous area, especially for fir. Fir was significantly sensitive to late frost, respectively, spruce to winter desiccation and spring droughts with synergism of air pollution load. Generally, older forest stands were more negatively influenced by air pollution load and climatic extremes compared to young trees.\n",
      "  - Douglas-fir (Pseudotsuga menziesii (Mirb.) Franco) is a non-native tree species in Slovenia with the potential to partially replace Norway spruce in our native forests. Compared to spruce, it has several advantages in terms of volume growth, wood quality and tolerance to drought. This is important given the changing climate in which spruce is confronted with serious problems caused by increasing temperatures and drought stress. At three sites (one on non-carbonate bedrock and deep soils, and two on limestone with soil layers of varying depths), 20 Douglas-fir and 20 spruce per site were sampled in order to compare their radial growth response to climate and drought events. The radial growth of Douglas-fir exceeds that of spruce by about 20% on comparable sites. It is more responsive to climate than spruce. Above-average temperatures in February and March have a significant positive effect on the radial growth of Douglas-fir. In recent decades, above-average summer precipitation has also had a positive influence on the radial growth of Douglas-fir. Compared to spruce, Douglas-fir is less sensitive to extreme drought events. Our results indicate that Douglas-fir may be a good substitute for spruce in semi-natural managed forest stands in Slovenia. The planting of Douglas-fir should be allowed in Slovenian forests, but the proportion of it in forest stands should be kept lower than is the case with spruce today.\n",
      "  - Research Highlights: In Central Europe, Douglas fir became more responsive to summer drought in recent years. Background and Objectives: Until now, Douglas fir has been considered a tree species resistant to drought. However, how Douglas fir will be able to cope with the increasing frequency and intensity of summer heat waves remains a question. The long-term variability in the climate response of Douglas fir in Central European conditions has not been fully explored. The aim of the study was to identify climatic factors controlling the stem radial growth of Douglas fir and Norway spruce, and to examine the temporal changes in tree responses to key climatic variables related to drought stress. Materials and Methods: We analysed the pattern of the climate–growth relationship of Douglas fir and Norway spruce, growing in mixed stands distributed between 260 and 600 m above sea level, which corresponds with the altitudinal zone of intensive spruce dieback in the Czech Republic. Nine-site tree-ring-width chronologies were developed for each tree species. Pointer year analysis and correlation analysis in combination with principal component analysis were used to identify climatic factors limiting their growth. Moving correlation function was computed to assess temporal changes of the climate–growth relationship. Results: In the entire 1961–2015 period, growth of both species was positively related to summer precipitation. The response to temperature differed between species. While spruce was negatively affected by the temperatures in summer months, the increments of Douglas fir were positively correlated with the temperatures in February and March. However, moving correlation analysis revealed recently increasing sensitivity to summer temperatures also for Douglas fir. Higher responsiveness of Douglas fir to drought was also revealed by the increasing frequency of negative pointer years in the 2003–2015 period. Conclusions: The recommendations of Douglas fir as a suitable alternative tree species for declining spruce stands at lower altitudes must be regarded with caution.\n",
      "--------------------------------------------------\n",
      "Topic 93: 93_warming_species_seedling_plant\n",
      "Representative Documents:\n",
      "  - Winter underpins key ecological processes, such as dormancy loss and seedling emergence. Enhanced warm spells, together with warming are occurring and will continue in the future. The consequences of these climate phenomena on germination were investigated among co‐occurring woody plants, whose seeds are bird‐dispersed in autumn and require cold stratification for spring emergence.Seeds from nine common southeastern USA plants were collected in autumn. We verified that seeds of the study species required cold stratification for dormancy loss. We then examined the following aspects in the laboratory or field: effect of warm spells during cold stratification on germination, effect of a warm spell during winter on seed survival and germination phenology, and effect of warming from autumn dispersal through winter dormancy loss on timing of germination.While no consistent effects of warm spells were found in the laboratory on quantity of germination, warm spells advanced spring field germination for several species. Some species germinated during cold stratification and during warm spells, especially extreme spells, in the laboratory. In the field, about half of Lonicera maackii seedlings that emerged with a warm spell died by late winter. With warming from autumn through spring, laboratory germination shifted from spring to predominately autumn for some species.With precocious germination during warm spells or germination phenology shifts, two scenarios are possible. Seedlings may die during winter, reducing the size of the soil seed bank and number of emergents, or they would survive in warmer winters, which would give them a competitive advantage over spring‐emerging seedlings.\n",
      "  - The high diversity and abundance of vascular epiphytes in tropical montane cloud forest is associated with frequent cloud immersion, which is thought to protect plants from drought stress. Increasing temperature and rising cloud bases associated with climate change may increase epiphyte drought stress, leading to species and biomass loss. We tested the hypothesis that warmer and drier conditions associated with a lifting cloud base will lead to increased mortality and/or decreased recruitment of epiphyte ramets, altering species composition in epiphyte mats. By using a reciprocal transplant design, where epiphyte mats were transplanted across an altitudinal gradient of increasing cloud immersion, we differentiated between the effects of warmer and drier conditions from the more general prediction of niche theory that transplanting epiphytes in any direction away from their home elevation should result in reduced performance. Effects differed among species, but effects were generally stronger and more negative for epiphytes in mats transplanted down slope from the highest elevation, into warmer and drier conditions, than for epiphyte mats transplanted from other elevations. In contrast, epiphytes from lower elevations showed greater resistance to drought in all treatments. Epiphyte community composition changed with elevation, but over the timescale of the experiment there were no consistent changes in species composition. Our results suggest some epiphytes may show resistance to climate change depending on the environmental and evolutionary context. In particular, sites where high rainfall makes cloud immersion less important for epiphyte water-balance, or where occasional drought has previously selected for drought-resistant taxa, may be less adversely affected by predicted climate changes.\n",
      "  - The high diversity and abundance of vascular epiphytes in tropical montane cloud forest is associated with frequent cloud immersion, which is thought to protect plants from drought stress. Increasing temperature and rising cloud bases associated with climate change may increase epiphyte drought stress, leading to species and biomass loss. We tested the hypothesis that warmer and drier conditions associated with a lifting cloud base will lead to increased mortality and/or decreased recruitment of epiphyte ramets, altering species composition in epiphyte mats. By using a reciprocal transplant design, where epiphyte mats were transplanted across an altitudinal gradient of increasing cloud immersion, we differentiated between the effects of warmer and drier conditions from the more general prediction of niche theory that transplanting epiphytes in any direction away from their home elevation should result in reduced performance. Ramet mortality increased, recruitment decreased, and population size declined for epiphytes in mats transplanted down slope from the highest elevation, into warmer and drier conditions, but epiphytes from lower elevations showed greater resistance to drought in all treatments. Epiphyte community composition changed with elevation, but over the timescale of the experiment there were no consistent changes in species composition. Our results suggest some epiphytes may show resistance to climate change depending on the environmental context, although if climate change results in consistently drier conditions and higher cloud bases, biomass loss and shifting species composition in epiphyte communities is likely.\n",
      "--------------------------------------------------\n",
      "Topic 94: 94_cement_curing_carbonation_concrete\n",
      "Representative Documents:\n",
      "  - This study aims to develop highly durable, mineral carbonation-based, resource-recycling, secondary cement products based on supercritical carbon dioxide (CO2) curing as part of carbon capture utilization technology that permanently fixes captured CO2. To investigate the basic characteristics of secondary cement products containing concrete sludge waste (CSW) as the main materials after supercritical CO2 curing, the compressive strengths of the paste and mortar (fabricated by using CSW as the main binder), ordinary Portland cement, blast furnace slag powder, and fly ash as admixtures were evaluated to derive the optimal mixture for secondary products. The carbonation curing method that can promote the surface densification (intensive CaCO3 formation) of the hardened body within a short period of time using supercritical CO2 curing was defined as “Lean Carbonation”. The optimal curing conditions were derived by evaluating the compressive strength and durability improvement effects of applying Lean Carbonation to secondary product specimens. As a result of the experiment, for specimens subjected to Lean Carbonation, compressive strength increased by up to 12%, and the carbonation penetration resistance also increased by more than 50%. The optimal conditions for Lean Carbonation used to improve compressive strength and durability were found to be 35 °C, 80 bar, and 1 min.\n",
      "  - The application of CO2 curing on sludge ceramsite may improve its mechanical properties, and then increase the corresponding corrosion resistance. In this study, the influence of CO2-cured sludge ceramsite on the strength and long-term properties of cement concrete is investigated. CO2 curing time ranges from 0 h to 2 d. The cylinder compressive strength and water absorption rate of CO2-cured sludge ceramsite are first determined. Additionally, the flexural and compressive strengths, the chloride permeability and the freeze—thaw damage, as well as the corresponding thermal conductivity of cement concrete, are tested. Furthermore, the corrosion resistance of reinforcement inner-sludge-ceramsite cement concrete is measured. Finally, the scanning electron microscope photos of sludge ceramsite are obtained. Results show that the cylinder compressive strength of CO2-cured sludge ceramsite is 15.1, ~34.2% higher than that of sludge ceramsite. Meanwhile, the water absorption rate of CO2-cured sludge ceramsite is 39.6, ~82.4% higher than that of sludge ceramsite. The compressive strength and the flexural strength of cement concrete with CO2-cured sludge ceramsite are 11.4 and 18.7, ~21.6% and ~31.5% higher than the cement concrete with sludge ceramsite, respectively. The resistance of NaCl freeze—thaw cycles, determined by comparing the mass loss rate and the loss rates of mechanical strengths, is effectively improved by CO2 curing, while the thermal conductivity of cement concrete is decreased by CO2 curing. The corrosion resistance of inner reinforcement is improved by the application of CO2 curing on sludge ceramsite.\n",
      "  - In this paper, the mechanical properties (the flexural strength, compressive strength and the drying shrinkage rate) of CO2-cured alkali-activated compound mineral admixtures (blast furnace slag powder (BFS) and fly ash (FA)) are investigated. In addition, the corresponding chloride ion mobility coefficient is measured. Additionally, the freeze–thaw cycles with an NaCl concentration of 3% is studied. Thermogravimetric analysis and scanning electron microscopy are applied in analyzing the mechanical properties. The curing ages of the alkali-activated compound mineral admixtures are 1 day, 3 days and 28 days. Results show that the mechanical strengths are decreased by the addition of FA and increased by the increasing curing age and CO2 curing. The maximum reducing rates of flexural and compressive strengths by FA are 47.6% and 42.3%. Meanwhile, the corresponding increasing rates by CO2 curing are 26.5% and 23.1%, respectively. The improving effect of alkali-activated BFS by CO2 curing is higher than that of FA. Furthermore, the drying shrinkage rate is increased by the increasing dosages of BFS, the increasing curing ages and CO2 curing. Additionally, CO2 curing and the increasing dosage of BFS leads to decreasing the chloride ion mobility coefficient. Finally, CO2 curing and the addition of BFS can effectively improve the resistance of NaCl freeze–thaw cycles. The compactness of the hydration products is improved by the addition of BFS and the roughness of hydration products is increased by CO2 curing.\n",
      "--------------------------------------------------\n",
      "Topic 95: 95_wastewater_treatment_removal_sludge\n",
      "Representative Documents:\n",
      "  -                Constructed wetlands as a treatment system are widely explored in different climate conditions and established to be effective in pollution removal from water environment. This study aims to demonstrate the performance of pilot-scale subsurface flow constructed wetland for storm water treatment in Latvia. The catchment basin was located in a farmyard of agricultural area and storm water was collected from the impermeable pavements. Storm water was accumulated in an open pond and periodically pumped above the filter part of the subsurface flow constructed wetland. Grab samples were collected once or twice per month at the inlet and outlet of the treatment system during a period of 73 months from year 2014 to 2020. Water quality parameters as nitrate nitrogen (NO3-N), ammonium nitrogen (NH4–N), total nitrogen (TN), orthophosphate phosphorus (PO4-P), and total phosphorus (TP), total suspended solids (TSS), biochemical oxygen demand (BOD5) and chemical oxygen demand (COD) were monitored. Water level at the inlet structure was automatically measured and flow rate was calculated based on the Manning equation for partially filled circular pipes. Results showed the reduction of average concentrations for all parameters during the study period. However, in some sampling cases concentrations increased at the outlet of the treatment system and can be explained by influencing factors of farming and maintenance. The treatment efficiency of NO3-N, NH4-N, TN, PO4-P, TP, TSS, BOD5 and COD concentrations was 17 %, 68 %, 55 %, 78 %, 80 %, 57 %, 80 % and 74 %, respectively. The study site demonstrated a potential to improve water quality in the long term.\n",
      "  - This paper reports the results of an investigation into the influence of precipitation and air temperature on the efficiency of pollutant removal processes and effluent pollutant concentrations in a one-stage constructed wetland with subsurface vertical flow. We studied an on-site constructed wetland system that used Phragmites australis for the treatment of domestic wastewater. The system was located in central Europe, in the south-east of Poland, in a temperate climate zone with transitional features. Physico-chemical analyses of influent and effluent wastewater, as well as measurements of precipitation and air temperature were carried out in the years 2001–2010. It was shown that the pollutant removal efficiency of the treatment plant was significantly higher in the growing season than outside the growing season (the mean efficiency is usually a few percent higher but generally this parameter is highly varied). This indicated that temperature determined the efficiency of the wastewater treatment. We found that the amount of precipitation affected the concentration of pollutants in the effluent. The more rainfall there was, the lower the content of pollutants in the effluent from the treatment plant, which demonstrated that rainwater diluted the concentrations of pollutants in the treated wastewater—thus improving the efficiency of the wastewater treatment plant.\n",
      "  -                Pharmaceutical wastewater biological treatment plants are stressed with multi-component wastewater and unexpected variations in wastewater flow, composition and toxicity. To avoid operational problems and reduced wastewater treatment efficiency, accurate monitoring of influent toxicity on activated sludge microorganisms is essential. This paper outlines how to predict highly toxic streams, which should be avoided, using measurements of biochemical oxygen demand (BOD), if they are made in a wide range of initial concentration. The results indicated that wastewater containing multivalent Al3+ cations showed a strong toxic effect on activated sludge biocenosis irrespectively of dilutions, while toxicity of phenol and formaldehyde containing wastewater decreased considerably with increasing dilution. Activated sludge microorganisms were not sensitive to wastewater containing halogenated sodium salts (NaCl, NaF) and showed high treatment capacity of saline wastewater. Our findings confirm that combined indicators of contamination, such as chemical oxygen demand (COD), alone do not allow evaluating potential toxic influence of wastewater. Obtained results allow identifying key inhibitory substances in pharmaceutical wastewater and evaluating potential impact of new wastewater streams or increased loading on biological treatment system. Proposed method is sensitive and cost effective and has potential for practical implementation in multiproduct pharmaceutical wastewater biological treatment plants.\n",
      "--------------------------------------------------\n",
      "Topic 96: 96_cloud_clouds_optical_cloud fraction\n",
      "Representative Documents:\n",
      "  -                The sensitivity of the reflection of shortwave radiation over the Southern Ocean to the cloud properties there is estimated using observations from a suite of passive and active satellite instruments in combination with radiative transfer modeling. A composite cloud property observational data description is constructed that consistently incorporates mean cloud liquid water content, ice water content, liquid and ice particle radius information, vertical structure, vertical overlap, and spatial aggregation of cloud water as measured by optical depth versus cloud-top pressure histograms. The observational datasets used are Moderate Resolution Imaging Spectroradiometer (MODIS) effective radius filtered to mitigate solar zenith angle bias, the Multiangle Imaging Spectroradiometer (MISR) cloud-top height–optical depth (CTH–OD) histogram, the liquid water path from the University of Wisconsin dataset, and ice cloud properties from CloudSat. This cloud database is used to compute reflected shortwave radiation as a function of month and location over the ocean from 40° to 60°S, which compares well with observations of reflected shortwave radiation. This calculation is then used to test the sensitivity of the seasonal variation of shortwave reflection to the observed seasonal variation of cloud properties. Effective radius decreases during the summer season, which results in an increase in reflected solar radiation of 4–8 W m−2 during summer compared to what would be reflected if the effective radius remained constant at its annual-mean value. Summertime increases in low cloud fraction similarly increase the summertime reflection of solar radiation by 9–11 W m−2. In-cloud liquid water path is less in summertime, causing the reflected solar radiation to be 1–4 W m−2 less.\n",
      "  -                This study evaluates the performances of seven single-column models (SCMs) by comparing simulated cloud fraction with observations at the Atmospheric Radiation Measurement Program (ARM) Southern Great Plains (SGP) site from January 1999 to December 2001. Compared with the 3-yr mean observational cloud fraction, the ECMWF SCM underestimates cloud fraction at all levels and the GISS SCM underestimates cloud fraction at levels below 200 hPa. The two GFDL SCMs underestimate lower-to-middle level cloud fraction but overestimate upper-level cloud fraction. The three Community Atmosphere Model (CAM) SCMs overestimate upper-level cloud fraction and produce lower-level cloud fraction similar to the observations but as a result of compensating overproduction of convective cloud fraction and underproduction of stratiform cloud fraction. Besides, the CAM3 and CAM5 SCMs both overestimate midlevel cloud fraction, whereas the CAM4 SCM underestimates. The frequency and partitioning analyses show a large discrepancy among the seven SCMs: Contributions of nonstratiform processes to cloud fraction production are mainly in upper-level cloudy events over the cloud cover range 10%–80% in SCMs with prognostic cloud fraction schemes and in lower-level cloudy events over the cloud cover range 15%–50% in SCMs with diagnostic cloud fraction schemes. Further analysis reveals different relationships between cloud fraction and relative humidity (RH) in the models and observations. The underestimation of lower-level cloud fraction in most SCMs is mainly due to the larger threshold RH used in models. The overestimation of upper-level cloud fraction in the three CAM SCMs and two GFDL SCMs is primarily due to the overestimation of RH and larger mean cloud fraction of cloudy events plus more occurrences of RH around 40%–80%, respectively.\n",
      "  - This study provides an assessment of low cloud properties retrieved from CloudSat, MODIS (Moderate Resolution Imaging Spectroradiometer), and Cloud‐Aerosol Lidar and Infrared Pathfinder Satellite Observation with the goal of exposing biases that hinder meaningful comparisons with the simulated cloud properties in global climate models (GCMs). Being pertinent to GCM comparisons, CloudSat is the only satellite that can provide the vertical structure of cloud water and ice content from space. Biases in CloudSat low cloud properties are found to be tied to problems involving cloud detection and algorithm retrieval failures related to precipitation and strict cloud screening procedures. We show that MODIS and CloudSat cloud liquid water path (LWP) data agree when carefully screened for lack of precipitation but significantly depart in precipitating clouds due to rain water contamination of LWP in the CloudSat retrieval algorithm. The presence of drizzle and rain (occurring about 20% of the time) is associated with different mean LWP, mean particle sizes, and optical depths of all low clouds and therefore the radiative properties of the oceanic low clouds. Another more significant source of the LWP bias stems from the apparent lack of cloud detection. On average, the Cloud Profiling Radar misses clouds with adequate liquid and ice water retrievals as detected by MODIS in approximately 45% of warm clouds with the bulk of the bias occurring in clouds below 1 km in the so‐called “ground clutter zone.” By incorporating additional sensors such as MODIS, the following results suggest that this LWP bias can be greatly reduced.\n",
      "--------------------------------------------------\n",
      "Topic 97: 97_gene_genes_expression_mutant\n",
      "Representative Documents:\n",
      "  - Chlamydomonas reinhardtii acclimates to CO2-limiting stress by inducing a set of genes for a carbon-concentrating mechanism (CCM). This set includes the gene Cah1, which encodes a periplasmic carbonic anhydrase. Although physiological aspects of CO2 response have been extensively studied, regulatory components, such as transcription factors involved in the acclimation, have not been well described in eukaryotic microalgae. Using an arylsulfatase gene driven by the Cah1 promoter, a regulatory mutant of Cah1 was isolated and named lcr1 (for low-CO2 stress response). The photosynthetic affinity for inorganic carbon of lcr1 was reduced compared with that of wild-type cells. Expression of three low-CO2-inducible genes, Cah1, Lci1, and Lci6, were regulated by LCR1 as shown by cDNA array and RNA gel blot analyses. The Lcr1 gene encodes a protein of 602 amino acids containing a single Myb domain, which binds to the Cah1-promoter region. Expression of Lcr1 was induced by lowering CO2 levels and controlled by the regulatory factor CCM1. These results suggest that LCR1 transmits the low CO2 signal to at least three CO2-responsive genes and then fully induces CCM.\n",
      "  - The c-fes proto-oncogene encodes a 92-kd protein tyrosine kinase whose expression is restricted largely to myeloid and endothelial cells in adult mammals. A 13.2-kilobase (kb) humanc-fes genomic fragment was previously shown to containcis-acting element(s) sufficient for a locus control function in bone marrow macrophages. Locus control regions (LCRs) confer transgene expression in mice that is integration site independent, copy number dependent, and similar to endogenous murine messenger RNA levels. To identify sequences required for this LCR,c-fes transgenes were analyzed in mice. Myeloid-cell–specific, deoxyribonuclease-I–hypersensitive sites localized to the 3′ boundary of exon 1 and intron 3 are required to confer high-level transgene expression comparable to endogenous c-fes, independent of integration site. We define a minimal LCR element as DNA sequences (nucleotides +28 to +2523 relative to the transcription start site) located within intron 1 to intron 3 of the human locus. When this 2.5-kb DNA fragment was linked to a c-fes complementary DNA regulated by its own 446–base-pair promoter, integration-site–independent, copy-number–dependent transcription was observed in myeloid cells in transgenic mice. Furthermore, this 2.5-kb cassette directed expression of a heterologous gene (enhanced green fluorescent protein) exclusively in myeloid cells. The c-fes regulatory unit represents a novel reagent for targeting gene expression to macrophages and neutrophils in transgenic mice.\n",
      "  - The c-fes proto-oncogene encodes a 92-kd protein tyrosine kinase whose expression is restricted largely to myeloid and endothelial cells in adult mammals. A 13.2-kilobase (kb) humanc-fes genomic fragment was previously shown to containcis-acting element(s) sufficient for a locus control function in bone marrow macrophages. Locus control regions (LCRs) confer transgene expression in mice that is integration site independent, copy number dependent, and similar to endogenous murine messenger RNA levels. To identify sequences required for this LCR,c-fes transgenes were analyzed in mice. Myeloid-cell–specific, deoxyribonuclease-I–hypersensitive sites localized to the 3′ boundary of exon 1 and intron 3 are required to confer high-level transgene expression comparable to endogenous c-fes, independent of integration site. We define a minimal LCR element as DNA sequences (nucleotides +28 to +2523 relative to the transcription start site) located within intron 1 to intron 3 of the human locus. When this 2.5-kb DNA fragment was linked to a c-fes complementary DNA regulated by its own 446–base-pair promoter, integration-site–independent, copy-number–dependent transcription was observed in myeloid cells in transgenic mice. Furthermore, this 2.5-kb cassette directed expression of a heterologous gene (enhanced green fluorescent protein) exclusively in myeloid cells. The c-fes regulatory unit represents a novel reagent for targeting gene expression to macrophages and neutrophils in transgenic mice.\n",
      "--------------------------------------------------\n",
      "Topic 98: 98_strain_production_coli_acid\n",
      "Representative Documents:\n",
      "  -                       Background            Succinic acid is a building-block chemical which could be used as the precursor of many industrial products. The dissolved CO2 concentration in the fermentation broth could strongly regulate the metabolic flux of carbon and the activity of phosphoenolpyruvate (PEP) carboxykinase, which are the important committed steps for the biosynthesis of succinic acid by Actinobacillus succinogenes. Previous reports showed that succinic acid production could be promoted by regulating the supply of CO2 donor in the fermentation broth. Therefore, the effects of dissolved CO2 concentration and MgCO3 on the fermentation process should be investigated. In this article, we studied the impacts of gaseous CO2 partial pressure, dissolved CO2 concentration, and the addition amount of MgCO3 on succinic acid production by Actinobacillus succinogenes ATCC 55618. We also demonstrated that gaseous CO2 could be removed when MgCO3 was fully supplied.                                Results            An effective CO2 quantitative mathematical model was developed to calculate the dissolved CO2 concentration in the fermentation broth. The highest succinic acid production of 61.92 g/L was obtained at 159.22 mM dissolved CO2 concentration, which was supplied by 40 g/L MgCO3 at the CO2 partial pressure of 101.33 kPa. When MgCO3 was used as the only CO2 donor, a maximal succinic acid production of 56.1 g/L was obtained, which was just decreased by 7.03% compared with that obtained under the supply of gaseous CO2 and MgCO3.                                Conclusions            Besides the high dissolved CO2 concentration, the excessive addition of MgCO3 was beneficial to promote the succinic acid synthesis. This was the first report investigating the replaceable of gaseous CO2 in the fermentation of succinic acid. The results obtained in this study may be useful for reducing the cost of succinic acid fermentation process.          \n",
      "  -                 Background                Methanol is increasingly gaining attraction as renewable carbon source to produce specialty and commodity chemicals, as it can be generated from renewable sources such as carbon dioxide (CO2). In this context, native methylotrophs such as the yeast Komagataella phaffii (syn Pichia pastoris) are potentially attractive cell factories to produce a wide range of products from this highly reduced substrate. However, studies addressing the potential of this yeast to produce bulk chemicals from methanol are still scarce. 3-Hydroxypropionic acid (3-HP) is a platform chemical which can be converted into acrylic acid and other commodity chemicals and biopolymers. 3-HP can be naturally produced by several bacteria through different metabolic pathways.                              Results                In this study, production of 3-HP via the synthetic β-alanine pathway has been established in K. phaffii for the first time by expressing three heterologous genes, namely panD from Tribolium castaneum, yhxA from Bacillus cereus, and ydfG from Escherichia coli K-12. The expression of these key enzymes allowed a production of 1.0 g l−1 of 3-HP in small-scale cultivations using methanol as substrate. The addition of a second copy of the panD gene and selection of a weak promoter to drive expression of the ydfG gene in the PpCβ21 strain resulted in an additional increase in the final 3-HP titer (1.2 g l−1). The 3-HP-producing strains were further tested in fed-batch cultures. The best strain (PpCβ21) achieved a final 3-HP concentration of 21.4 g l−1 after 39 h of methanol feeding, a product yield of 0.15 g g−1, and a volumetric productivity of 0.48 g l−1 h−1. Further engineering of this strain aiming at increasing NADPH availability led to a 16% increase in the methanol consumption rate and 10% higher specific productivity compared to the reference strain PpCβ21.                              Conclusions                Our results show the potential of K. phaffii as platform cell factory to produce organic acids such as 3-HP from renewable one-carbon feedstocks, achieving the highest volumetric productivities reported so far for a 3-HP production process through the β-alanine pathway.              \n",
      "  -                 Background                A representative hydrogen-oxidizing bacterium Cupriavidus necator H16 has attracted much attention as hosts to recycle carbon dioxide (CO2) into a biodegradable polymer, poly(R)-3-hydroxybutyrate (PHB). Although C. necator H16 has been used as a model PHB producer, the PHB production rate from CO2 is still too low for commercialization.                              Results                Here, we engineer the carbon fixation metabolism to improve CO2 utilization and increase PHB production. We explore the possibilities to enhance the lithoautotrophic cell growth and PHB production by introducing additional copies of transcriptional regulators involved in Calvin Benson Bassham (CBB) cycle. Both cbbR and regA-overexpressing strains showed the positive phenotypes for 11% increased biomass accumulation and 28% increased PHB production. The transcriptional changes of key genes involved in CO2—fixing metabolism and PHB production were investigated.                              Conclusions                The global transcriptional regulator RegA plays an important role in the regulation of carbon fixation and shows the possibility to improve autotrophic cell growth and PHB accumulation by increasing its expression level. This work represents another step forward in better understanding and improving the lithoautotrophic PHB production by C. necator H16.              \n",
      "--------------------------------------------------\n",
      "Topic 99: 99_turbine_fluid_supercritical_sco2\n",
      "Representative Documents:\n",
      "  - Turbine as a key power unit is vital to the novel supercritical carbon dioxide cycle (sCO2-BC). At the same time, the turbine design and optimization process for the sCO2-BC is complicated, and its relevant investigations are still absent in the literature due to the behavior of supercritical fluid in the vicinity of the critical point. In this regard, the current study entails a multifaceted approach for designing and optimizing a radial turbine system for an 8 MW sCO2 power cycle. Initially, a base design of the turbine is calculated utilizing an in-house radial turbine design and analysis code (RTDC), where sharp variations in the properties of CO2 are implemented by coupling the code with NIST’s Refprop. Later, 600 variants of the base geometry of the turbine are constructed by changing the selected turbine design geometric parameters, i.e., shroud ratio (rs4r3), hub ratio (rs4r3), speed ratio (νs) and inlet flow angle (α3) and are investigated numerically through 3D-RANS simulations. The generated CFD data is then used to train a deep neural network (DNN). Finally, the trained DNN model is employed as a fitting function in the multi-objective genetic algorithm (MOGA) to explore the optimized design parameters for the turbine’s rotor geometry. Moreover, the off-design performance of the optimized turbine geometry is computed and reported in the current study. Results suggest that the employed multifaceted approach reduces computational time and resources significantly and is required to completely understand the effects of various turbine design parameters on its performance and sizing. It is found that sCO2-turbine performance parameters are most sensitive to the design parameter speed ratio (νs), followed by inlet flow angle (α3), and are least receptive to shroud ratio (rs4r3). The proposed turbine design methodology based on the machine learning algorithm is effective and substantially reduces the computational cost of the design and optimization phase and can be beneficial to achieve realistic and efficient design to the turbine for sCO2-BC.\n",
      "  -                Highly compact and efficient design makes inward flow radial (IFR) turbine a preferred choice for kilowatt scale supercritical CO2 (sCO2) power blocks. The influence of geometric design parameters on sCO2 turbine performance differs from gas turbines because of their small size, high rotational speeds, and lower viscous losses. The paper presents a computational fluid dynamics (CFD) study for a 100 kW IFR turbine to arrive at optimal geometric design parameters—axial length, outlet-to-inlet radius ratio, number of rotor blades, and velocity ratio, and understand their influence on the turbine's performance. The results are compared with well-established gas turbine correlations in the specific speed range of 0.2 to 0.8 to understand the implications on sCO2 IFR turbines. The analysis shows significant variations in the optimal values of design parameters when compared with gas turbines. It is found that sCO2 turbines require fewer blades and higher velocity ratios for optimal performance. The maximum turbine efficiency (∼82%) is achieved at a lower specific speed of ∼0.4 compared to a gas turbine with specific speed varying between 0.55 and 0.65. Additionally, higher negative incidence angles in the range of −50 deg to −55 deg are required at high specific speeds to counter the Coriolis effect in the rotor passage. The paper presents the variation of stator, rotor, and exit kinetic energy losses with specific speeds. The cumulative losses are found to be minimum at the specific speed of ∼0.4.\n",
      "  -                The balance piston seal in multiple-stage centrifugal compressors and axial turbines sustains the largest pressure drop through the machines and therefore plays an important role in successful full load operation at high rotational speed. This is especially true for power dense turbomachines in supercritical CO2 power cycles that generate or expend higher fluid pressures (above the critical value 7.3 MPa) and density (close to water 1000 kg/m3), because the fluid forces generated by the balance piston seals are directly proportional to the fluid density and the pressure drop across the seal. This paper presents a comprehensive assessment and comparison on the leakage and rotordynamic performance of three types of annular gas seals for application in a 14 MW supercritical CO2 turbine. These three seals represent the main seal types used in high-speed rotating machines at the balance piston location in efforts to limit internal leakage flow and achieve rotordynamic stability, including a labyrinth seal (LABY), a fully partitioned pocket damper seal (FPDS), and a hole-pattern damper seal (HPS). These three seals were designed to have the same sealing clearance and similar axial lengths. To enhance the seal net damping capability at high inlet preswirl condition, a straight swirl brake was also designed and employed at seal entrance for each type seal to reduce the seal inlet preswirl velocity. Numerical results of leakage flow rates, rotordynamic force coefficients, cavity dynamic pressure, and swirl velocity developments were analyzed and compared for three seal designs at high positive inlet preswirl (in the direction of shaft rotation), using a proposed transient computational fluid dynamic (CFD)-based perturbation method based on the multiple-frequency elliptical-orbit rotor whirling model and the mesh deformation technique. To take into account of real gas effect with high accuracy, a table look-up procedure based on the National Institute of Standards and Technology reference fluid properties database was implemented, using an in-house code, for the fluid properties of CO2 in both supercritical and subcritical conditions. Results show that the inlet swirl brake can significantly reduce the preswirl velocity at seal entrance, lowering the effective damping crossover frequency fco (or even fco = 0) to maximize the full operational frequency range of the machines. In stability analysis phase of a MW-scale supercritical CO2 turbine/compressor, the seal stiffness effects on the rotor mode shape must be evaluated carefully, where the seal stiffness is sufficiently large (comparable to the bearing stiffness). From a rotordynamic viewpoint, the HPS seal with entrance swirl brake is a better seal concept for the balance piston seal in supercritical CO2 turbomachinery, which possesses the largest positive effective damping throughout the entire subsynchronous frequency range.\n",
      "--------------------------------------------------\n",
      "Topic 100: 100_carbon_carbon cycle_feedback_climate carbon\n",
      "Representative Documents:\n",
      "  - The terrestrial carbon cycle plays a critical role in determining levels of atmospheric CO2 that result from anthropogenic carbon emissions. Elevated atmospheric CO2 is thought to stimulate terrestrial carbon uptake, through the process of CO2 fertilization of vegetation productivity. This negative carbon cycle feedback results in reduced atmospheric CO2 growth, and has likely accounted for a substantial portion of the historical terrestrial carbon sink. However, the future strength of CO2 fertilization in response to continued carbon emissions and atmospheric CO2 rise is highly uncertain. In this paper, the ramifications of CO2 fertilization in simulations of future climate change are explored, using an intermediate complexity coupled climate–carbon model. It is shown that the absence of future CO2 fertilization results in substantially higher future CO2 levels in the atmosphere, as this removes the dominant contributor to future terrestrial carbon uptake in the model. As a result, climate changes are larger, though the radiative effect of higher CO2 on surface temperatures in the model is offset by about 30% due to reduced positive dynamic vegetation feedbacks; that is, the removal of CO2 fertilization results in less vegetation expansion in the model, which would otherwise constitute an important positive surface albedo‐temperature feedback. However, the effect of larger climate changes has other important implications for the carbon cycle – notably to further weaken remaining carbon sinks in the model. As a result, positive climate–carbon cycle feedbacks are larger when CO2 fertilization is absent. This creates an interesting synergism of terrestrial carbon cycle feedbacks, whereby positive (climate–carbon cycle) feedbacks are amplified when a negative (CO2 fertilization) feedback is removed.\n",
      "  -                Coupled climate–carbon models have shown the potential for large feedbacks between climate change, atmospheric CO2 concentrations, and global carbon sinks. Standard metrics of this feedback assume that the response of land and ocean carbon uptake to CO2 (concentration–carbon cycle feedback) and climate change (climate–carbon cycle feedback) combine linearly. This study explores the linearity in the carbon cycle response by analyzing simulations with an earth system model of intermediate complexity [the University of Victoria Earth System Climate Model (UVic ESCM)]. The results indicate that the concentration–carbon and climate–carbon cycle feedbacks do not combine linearly to the overall carbon cycle feedback. In this model, the carbon sinks on land and in the ocean are less efficient when exposed to the combined effect of elevated CO2 and climate change than to the linear combination of the two. The land accounts for about 80% of the nonlinearity, with the ocean accounting for the remaining 20%. On land, this nonlinearity is associated with the different response of vegetation and soil carbon uptake to climate in the presence or absence of the CO2 fertilization effect. In the ocean, the nonlinear response is caused by the interaction of changes in physical properties and anthropogenic CO2. These findings suggest that metrics of carbon cycle feedback that postulate linearity in the system’s response may not be adequate.\n",
      "  -                Perturbations to the carbon cycle could constitute large feedbacks on future changes in atmospheric CO2 concentration and climate. This paper demonstrates how carbon cycle feedback can be expressed in formally similar ways to climate feedback, and thus compares their magnitudes. The carbon cycle gives rise to two climate feedback terms: the concentration–carbon feedback, resulting from the uptake of carbon by land and ocean as a biogeochemical response to the atmospheric CO2 concentration, and the climate–carbon feedback, resulting from the effect of climate change on carbon fluxes. In the earth system models of the Coupled Climate–Carbon Cycle Model Intercomparison Project (C4MIP), climate–carbon feedback on warming is positive and of a similar size to the cloud feedback. The concentration–carbon feedback is negative; it has generally received less attention in the literature, but in magnitude it is 4 times larger than the climate–carbon feedback and more uncertain. The concentration–carbon feedback is the dominant uncertainty in the allowable CO2 emissions that are consistent with a given CO2 concentration scenario. In modeling the climate response to a scenario of CO2 emissions, the net carbon cycle feedback is of comparable size and uncertainty to the noncarbon–climate response. To quantify simulated carbon cycle feedbacks satisfactorily, a radiatively coupled experiment is needed, in addition to the fully coupled and biogeochemically coupled experiments, which are referred to as coupled and uncoupled in C4MIP. The concentration–carbon and climate–carbon feedbacks do not combine linearly, and the concentration–carbon feedback is dependent on scenario and time.\n",
      "--------------------------------------------------\n",
      "Topic 101: 101_energy_vehicles_waste_charging\n",
      "Representative Documents:\n",
      "  -  A major challenge for modern waste management lies in a smart integration of waste-to-energy installations in local energy systems in such a way that the energy efficiency of the waste-to-energy plant is optimized and that the energy contained in the waste is, therefore, optimally utilized. The extent of integration of thermal waste treatment processes into regular energy supply systems plays a major role with regard to climate control. In this research, the specific waste management situation looked at scenarios aiming at maximizing the energy recovery from waste ( i.e. actual scenario and waste-to-energy process with 75% energy efficiency [22.5% electricity, 52.5% heat]) yield greenhouse gas emission savings due to the fact that more greenhouse gas emissions are avoided in the energy sector than caused by the various waste treatment processes. Comparing dedicated waste-to-energy-systems based on the combined heat and power (CHP) process with concepts based on sole electricity production, the energy efficiency proves to be crucial with regard to climate control. This underlines the importance of choosing appropriate sites for waste-to-energy-plants. This research was looking at the effect with regard to the climate impact of various waste management scenarios that could be applied alternatively by a private waste management company in Austria. The research is, therefore, based on a specific set of data for the waste streams looked at (waste characteristics, logistics needed, etc.). Furthermore, the investigated scenarios have been defined based on the actual available alternatives with regard to the usage of treatment plants for this specific company. The standard scenarios for identifying climate impact implications due to energy recovery from waste are based on the respective marginal energy data for the power and heat generation facilities/industrial processes in Austria. \n",
      "  - The regulation of vehicular CO2 emissions determines the permissible emissions of vehicles in units of g CO2/km. However, these values only partially provide adequate information because they characterize only the vehicle but not the emission of the associated energy supply technology system. The energy needed for the motion of vehicles is generated in several ways by the energy industry, depending on how the vehicles are driven. These methods of energy generation consist of different series of energy source conversions, where the last technological step is the vehicle itself, and the result is the motion. In addition, sustainability characterization of vehicles cannot be determined by the vehicle’s CO2 emissions alone because it is a more complex notion. The new approach investigates the entire energy technology system associated with the generation of motion, which of course includes the vehicle. The total CO2 emissions and the resulting energy efficiency have been determined. For this, it was necessary to systematize (collect) the energy supply technology lines of the vehicles. The emission results are not given in g CO2/km but in g CO2/J, which is defined in the paper. This new method is complementary to the European Union regulative one, but it allows more complex evaluations of sustainability. The calculations were performed based on Hungarian data. Finally, using the resulting energy efficiency values, the emission results were evaluated by constructing a sustainability matrix similar to the risk matrix. If only the vehicle is investigated, low CO2 emissions can be achieved with vehicles using internal combustion engines. However, taking into consideration present technologies, in terms of sustainability, the spread of electric-only vehicles using renewable energies can result in improvement in the future. This proposal was supported by the combined analysis of the energy-specific CO2 emissions and the energy efficiency of vehicles with different power-driven systems.\n",
      "  - The main sources of greenhouse gas emissions and air pollution from the transport sector are diesel- and gasoline-powered passenger cars. The combustion of large amounts of conventional fuels by cars contributes to a significant release of various compounds into the atmosphere, such as solid particles, nitrogen oxides, carbon monoxide, and carbon dioxide. In order to reduce these pollutants in places of their high concentration (especially in urban agglomerations), the use of ecological means of transport for daily driving is highly recommended. Electric vehicles (EV) are characterized by ecological potential due to their lack of direct emissions and low noise. However, in Poland and many other countries, electricity production is still based on fossil fuels which can significantly influence the indirect emissions of carbon dioxide into the atmosphere associated with battery charging. Thus, indirect emissions from electric cars may be comparable or even higher than direct emissions related to the use of traditional cars. Therefore, the aim of the work was to analyze the amount of carbon dioxide emissions associated with the use of electric vehicles for daily driving (City, Sedan, SUV) and their impact on the environment on a local and global scale. Based on the assumed daily number of kilometers driven by the vehicle and the collected certified catalog data (Car Info Nordic AB), the direct emissions generated by the internal combustion engines (ICE) were calculated for specific cars. These values were compared to the indirect emissions related to the source of electricity generation, for the calculation of which the CO2 emission coefficient for a particular energy source and energy mix was used, as well as reference values of electricity generation efficiency in a given combustion installation, in accordance with the KOBiZE (The National Centre for Emissions Management) and European Union regulation. Indirect emissions generated from non-renewable fuels (lignite, hard coal, natural gas, diesel oil, heating oil, municipal waste) and renewable emissions (wind energy, solar energy, hydro energy, biomass, biogas) were considered. The results indicated that for the Polish case study, indirect carbon dioxide emission associated with the daily driving of EV (distance of 26 km) ranges 2.49–3.28 kgCO2∙day−1. As a result, this indirect emission can be even higher than direct emissions associated with ICE usage (2.55–5.64 kgCO2∙day−1).\n",
      "--------------------------------------------------\n",
      "Topic 102: 102_data_user_web_metadata\n",
      "Representative Documents:\n",
      "  -                For users of climate services, the ability to quickly determine the datasets that best fit one’s needs would be invaluable. The volume, variety, and complexity of climate data makes this judgment difficult. The ambition of CHARMe (Characterization of metadata to enable high-quality climate services) is to give a wider interdisciplinary community access to a range of supporting information, such as journal articles, technical reports, or feedback on previous applications of the data. The capture and discovery of this “commentary” information, often created by data users rather than data providers, and currently not linked to the data themselves, has not been significantly addressed previously. CHARMe applies the principles of Linked Data and open web standards to associate, record, search, and publish user-derived annotations in a way that can be read both by users and automated systems. Tools have been developed within the CHARMe project that enable annotation capability for data delivery systems already in wide use for discovering climate data. In addition, the project has developed advanced tools for exploring data and commentary in innovative ways, including an interactive data explorer and comparator (“CHARMe Maps”), and a tool for correlating climate time series with external “significant events” (e.g., instrument failures or large volcanic eruptions) that affect the data quality. Although the project focuses on climate science, the concepts are general and could be applied to other fields. All CHARMe system software is open-source and released under a liberal license, permitting future projects to reuse the source code as they wish.\n",
      "  - Emerging developments in geographic information systems and distributed computing offer a roadmap towards an unprecedented spatial data infrastructure in the climate sciences. Key to this are the standards developments for digital geographic information being led by the International Organisation for Standardisation (ISO) technical committee on geographic information/geomatics (TC211) and the Open Geospatial Consortium (OGC). These, coupled with the evolution of standardised web services for applications on the internet by the World Wide Web Consortium (W3C), mean that opportunities for both new applications and increased interoperability exist. These are exemplified by the ability to construct ISO‐compliant data models that expose legacy data sources through OGC web services. This paper concentrates on the applicability of these standards to climate data by introducing some examples and outlining the challenges ahead. An  data model is developed, based on ISO standards, and applied to a range of climate data –both observational and modelled. An OGC Web Map Server interface is constructed for numerical weather prediction (NWP) data stored in legacy data files. A W3C web service for remotely accessing gridded climate data is illustrated. Challenges identified include the following: first, both the ISO and OGC specifications require extensions to support climate data. Secondly, OGC services need to fully comply with W3C web services, and support complex access control. Finally, to achieve real interoperability, broadly accepted community‐based semantic data models are required across the range of climate data types. These challenges are being actively pursued, and broad data interoperability for the climate sciences appears within reach. Copyright © 2005 Royal Meteorological Society.\n",
      "  - The Bayech basin is located in southwestern Tunisia, a highly prone region to flooding risks. The Bayech basin is characterized by wadis that adopt a wide, sometimes ill-defined bed, often intersected by low-lying areas, resulting in a semi-endoreismo, greatly disrupting the flow regimes. The Bayech basin drains the slopes of the Nementchas and Tebessa mountains in Algeria, collecting water from the Medjen Bel Abbes plain in its middle course before crossing the Gafsa djebls chain at the Gafsa gap. In this basin, flooding is generally caused by high-intensity storms and is often relatively limited in extent. The slope shape and soil type can promote rapid surface runoff during intense rainfall. Therefore, the purpose of creating a web application, labeled ClimInonda, is to respond to a critical need of readily available information on climatic, environmental, and land use data collected in this basin and its morphometric characteristics using recent methods. The application consists of three essential components: the front-end, back-end, and database. The front-end focuses on the user interface, allowing users to interact with the application’s features. It communicates with the back-end through Hypertext Transfer Protocol requests for data processing and retrieval. The back-end handles the server-side operations, processes requests, and provides responses by retrieving data from the database. The database stores and manages the application’s data, ensuring integrity and efficient access. This modular architecture ensures a user-friendly interface, seamless data processing, and reliable data storage. Visualizations can include different types of data, such as satellite imagery, weather data, and terrain data, and can be displayed using various techniques, such as heat maps, contour maps, and 3D models, by providing easy-to-understand visualizations. ClimInonda is an application developed to expand upon existing platforms by providing a suite of exploratory data analysis features, including the ability to calculate the total precipitation depth recorded for any period, interpolate the annual recurrence interval for rainfall events, etc. A simple evaluation of the platform was performed to assess the usefulness and user satisfaction of the tool by professional users, and positive feedback was received. There is clear evidence that ClimInonda would provide the necessary basis for informed decision making by stakeholders and development agencies in arid and semi-arid Tunisia.\n",
      "--------------------------------------------------\n",
      "Topic 103: 103_aerosol_ozone_forcing_bc\n",
      "Representative Documents:\n",
      "  -                The authors simulate transient twentieth-century climate in the Goddard Institute for Space Studies (GISS) GCM, with aerosol and ozone chemistry fully coupled to one another and to climate including a full dynamic ocean. Aerosols include sulfate, black carbon (BC), organic carbon, nitrate, sea salt, and dust. Direct and BC-snow-albedo radiative effects are included. Model BC and sulfur trends agree fairly well with records from Greenland and European ice cores and with sulfur deposition in North America; however, the model underestimates the sulfur decline at the end of the century in Greenland. Global BC effects peak early in the century (1940s); afterward the BC effects decrease at high latitudes of the Northern Hemisphere but continue to increase at lower latitudes. The largest increase in aerosol optical depth occurs in the middle of the century (1940s–80s) when sulfate forcing peaks and causes global dimming. After this, aerosols decrease in eastern North America and northern Eurasia leading to regional positive forcing changes and brightening. These surface forcing changes have the correct trend but are too weak. Over the century, the net aerosol direct effect is −0.41 W m−2, the BC-albedo effect is −0.02 W m−2, and the net ozone forcing is +0.24 W m−2. The model polar stratospheric ozone depletion develops, beginning in the 1970s. Concurrently, the sea salt load and negative radiative flux increase over the oceans around Antarctica. Net warming over the century is modeled fairly well; however, the model fails to capture the dynamics of the observed midcentury cooling followed by the late century warming. Over the century, 20% of Arctic warming and snow–ice cover loss is attributed to the BC-albedo effect. However, the decrease in this effect at the end of the century contributes to Arctic cooling.               To test the climate responses to sulfate and BC pollution, two experiments were branched from 1970 that removed all pollution sulfate or BC. Averaged over 1970–2000, the respective radiative forcings relative to the full experiment were +0.3 and −0.3 W m−2; the average surface air temperature changes were +0.2° and −0.03°C. The small impact of BC reduction on surface temperature resulted from reduced stability and loss of low-level clouds.\n",
      "  - We apply our Snow, Ice, and Aerosol Radiative (SNICAR) model, coupled to a general circulation model with prognostic carbon aerosol transport, to improve understanding of climate forcing and response from black carbon (BC) in snow. Building on two previous studies, we account for interannually varying biomass burning BC emissions, snow aging, and aerosol scavenging by snow meltwater. We assess uncertainty in forcing estimates from these factors, as well as BC optical properties and snow cover fraction. BC emissions are the largest source of uncertainty, followed by snow aging. The rate of snow aging determines snowpack effective radius (re), which directly controls snow reflectance and the magnitude of albedo change caused by BC. For a reasonable re range, reflectance reduction from BC varies threefold. Inefficient meltwater scavenging keeps hydrophobic impurities near the surface during melt and enhances forcing. Applying biomass burning BC emission inventories for a strong (1998) and weak (2001) boreal fire year, we estimate global annual mean BC/snow surface radiative forcing from all sources (fossil fuel, biofuel, and biomass burning) of +0.054 (0.007–0.13) and +0.049 (0.007–0.12) W m−2, respectively. Snow forcing from only fossil fuel + biofuel sources is +0.043 W m−2 (forcing from only fossil fuels is +0.033 W m−2), suggesting that the anthropogenic contribution to total forcing is at least 80%. The 1998 global land and sea‐ice snowpack absorbed 0.60 and 0.23 W m−2, respectively, because of direct BC/snow forcing. The forcing is maximum coincidentally with snowmelt onset, triggering strong snow‐albedo feedback in local springtime. Consequently, the “efficacy” of BC/snow forcing is more than three times greater than forcing by CO2. The 1998 and 2001 land snowmelt rates north of 50°N are 28% and 19% greater in the month preceding maximum melt of control simulations without BC in snow. With climate feedbacks, global annual mean 2‐meter air temperature warms 0.15 and 0.10°C, when BC is included in snow, whereas annual arctic warming is 1.61 and 0.50°C. Stronger high‐latitude climate response in 1998 than 2001 is at least partially caused by boreal fires, which account for nearly all of the 35% biomass burning contribution to 1998 arctic forcing. Efficacy was anomalously large in this experiment, however, and more research is required to elucidate the role of boreal fires, which we suggest have maximum arctic BC/snow forcing potential during April–June. Model BC concentrations in snow agree reasonably well (r = 0.78) with a set of 23 observations from various locations, spanning nearly 4 orders of magnitude. We predict concentrations in excess of 1000 ng g−1 for snow in northeast China, enough to lower snow albedo by more than 0.13. The greatest instantaneous forcing is over the Tibetan Plateau, exceeding 20 W m−2 in some places during spring. These results indicate that snow darkening is an important component of carbon aerosol climate forcing.\n",
      "  - . The Atmospheric Chemistry and Climate Model Intercomparison Project (ACCMIP) examined the short-lived drivers of climate change in current climate models. Here we evaluate the 10 ACCMIP models that included aerosols, 8 of which also participated in the Coupled Model Intercomparison Project phase 5 (CMIP5). The models reproduce present-day total aerosol optical depth (AOD) relatively well, though many are biased low. Contributions from individual aerosol components are quite different, however, and most models underestimate east Asian AOD. The models capture most 1980–2000 AOD trends well, but underpredict increases over the Yellow/Eastern Sea. They strongly underestimate absorbing AOD in many regions. We examine both the direct radiative forcing (RF) and the forcing including rapid adjustments (effective radiative forcing; ERF, including direct and indirect effects). The models' all-sky 1850 to 2000 global mean annual average total aerosol RF is (mean; range) −0.26 W m−2; −0.06 to −0.49 W m−2. Screening based on model skill in capturing observed AOD yields a best estimate of −0.42 W m−2; −0.33 to −0.50 W m−2, including adjustment for missing aerosol components in some models. Many ACCMIP and CMIP5 models appear to produce substantially smaller aerosol RF than this best estimate. Climate feedbacks contribute substantially (35 to −58%) to modeled historical aerosol RF. The 1850 to 2000 aerosol ERF is −1.17 W m−2; −0.71 to −1.44 W m−2. Thus adjustments, including clouds, typically cause greater forcing than direct RF. Despite this, the multi-model spread relative to the mean is typically the same for ERF as it is for RF, or even smaller, over areas with substantial forcing. The largest 1850 to 2000 negative aerosol RF and ERF values are over and near Europe, south and east Asia and North America. ERF, however, is positive over the Sahara, the Karakoram, high Southern latitudes and especially the Arctic. Global aerosol RF peaks in most models around 1980, declining thereafter with only weak sensitivity to the Representative Concentration Pathway (RCP). One model, however, projects approximately stable RF levels, while two show increasingly negative RF due to nitrate (not included in most models). Aerosol ERF, in contrast, becomes more negative during 1980 to 2000. During this period, increased Asian emissions appear to have a larger impact on aerosol ERF than European and North American decreases due to their being upwind of the large, relatively pristine Pacific Ocean. There is no clear relationship between historical aerosol ERF and climate sensitivity in the CMIP5 subset of ACCMIP models. In the ACCMIP/CMIP5 models, historical aerosol ERF of about −0.8 to −1.5 W m−2 is most consistent with observed historical warming. Aerosol ERF masks a large portion of greenhouse forcing during the late 20th and early 21st century at the global scale. Regionally, aerosol ERF is so large that net forcing is negative over most industrialized and biomass burning regions through 1980, but remains strongly negative only over east and southeast Asia by 2000. Net forcing is strongly positive by 1980 over most deserts, the Arctic, Australia, and most tropical oceans. Both the magnitude of and area covered by positive forcing expand steadily thereafter.\n",
      "--------------------------------------------------\n",
      "Topic 104: 104_molecules_co2_molecule_adsorption\n",
      "Representative Documents:\n",
      "  - We studied the dissociative adsorption of CO2 to CO + O on the Cu(111), Cu(221), Cu(211), and Cu(11 5 9) surfaces by using state-of-the-art density functional theory (DFT) within a generalized gradient approximation (GGA) and van der Waals density functional (vdW-DF) calculations. The activation energy for CO2 dissociation on the flat Cu(111) surface is 1.33 eV. The activation energies on stepped and kinked surfaces are 1.06 eV, 0.67 eV, and 1.02 eV for the Cu(221), Cu(211), and Cu(11 5 9) surfaces, respectively. Even though the activation energy is 0.66 eV lower on the stepped Cu(211) surface than on the flat Cu(111) surface, we conclude that CO2 does not dissociate on “ideal” flat, stepped, or kinked Cu surfaces at low temperature. We attribute the discrepancy between our theoretical results and experimentally observed CO2 dissociation on stepped Cu surfaces below 150 K to other factors such as effects of Cu adatoms, gas phase or condensed CO2 molecules, or interaction with other gas phase molecules.\n",
      "  - A multi-scale computational methodology based on the density functional theory and molecular dynamics has been used to investigate the rheological properties of super critical CO2 with CuO nano-particle (NP). Density functional theory which treats the electron density as the central variable has been used to explore the adsorption of CO2 molecules on the two most stable CuO surfaces [i.e., (111) and (011)] at absolute zero. The results of this theory would provide valuable information to make CuO NPs with the surface where the CO2 adsorption is maximum in order to have a stronger mono-layer of adsorbed CO2 molecules on the surface of the NP which is the most crucial factor in formation of a stable nanofluid. The results show that the CO2 molecule is adsorbed more strongly on the (011) surface with an adsorption energy of −99.06 kJ/mol compared to the (111) surface. A computational methodology based on molecular dynamics has been used to evaluate the enhancement of the rheological properties of the super-critical CO2 liquid based nanofluid at different temperatures and pressures. In this scale, first, the CO2 liquid has been modeled by employing the condensed-phase optimized molecular potentials for atomistic simulation studies (COMPASS) force field potential and the fluid properties computed are in excellent agreement with the literature and experiment values. Second, the nanofluid has been modeled in order to study the enhancement of the fluid properties with the CuO NPs. The charged optimized many-body force field potential has been employed to consider the effect of the charge transferring between the NPs and liquid molecules and breaking of existing bonds and the formation of new bonds. The COMPASS force field potential is also employed for the interactions between CO2 molecules. The combination of these potentials is quite a new approach for the study of the super-critical (SC)-CO2 based nanofluid. The results show that the viscosity of the SC-CO2 is enhanced between 1.3 and 2.5 times under the temperature and pressure conditions studied.\n",
      "  - Iron sulfide minerals, including mackinawite (FeS), are relevant in origin of life theories, due to their potential catalytic activity towards the reduction and conversion of carbon dioxide (CO2) to organic molecules, which may be applicable to the production of liquid fuels and commodity chemicals. However, the fundamental understanding of CO2 adsorption, activation, and dissociation on FeS surfaces remains incomplete. Here, we have used density functional theory calculations, corrected for long-range dispersion interactions (DFT-D2), to explore various adsorption sites and configurations for CO2 on the low-index mackinawite (001), (110), and (111) surfaces. We found that the CO2 molecule physisorbs weakly on the energetically most stable (001) surface but adsorbs relatively strongly on the (011) and (111) FeS surfaces, preferentially at Fe sites. The adsorption of the CO2 on the (011) and (111) surfaces is shown to be characterized by significant charge transfer from surface Fe species to the CO2 molecule, which causes a large structural transformation in the molecule (i.e., forming a negatively charged bent CO2−δ species, with weaker C—O confirmed via vibrational frequency analyses). We have also analyzed the pathways for CO2 reduction to CO and O on the mackinawite (011) and (111) surfaces. CO2 dissociation is calculated to be slightly endothermic relative to the associatively adsorbed states, with relatively large activation energy barriers of 1.25 eV and 0.72 eV on the (011) and (111) surfaces, respectively.\n",
      "--------------------------------------------------\n",
      "Topic 105: 105_solar_system_pv_energy\n",
      "Representative Documents:\n",
      "  - The solar water heater can be integrated into future residential buildings as the main energy source, which will subsequently reduce the energy cost of water heating. An original configuration for an efficient Domestic Hot Water (DHW) storage tank is developed and experimentally evaluated under Saharan climate. This novel DHW configuration includes a hybrid (solar and electric) energy system with a flat plate solar collector coupled with an electric heater. Additionally, a phase change material (PCM) mixture that is composed of paraffin wax and animal fat with a melting temperature between 35.58 °C and 62.58 °C and latent heat between 180 and 210 kJ/kg is integrated into this novel tank configuration. The experimental results indicated that hot water production by using latent heat storage could be economically attractive. By evaluating the cost of water heating expressed in Algerian dinar per liter (DZD/L), it was found that one liter of hot water may cost around 0.1362 DZD/L (i.e., 0.00096 USD/L) compared to 0.4431 DZD/L for the conventional water heater, an average energy cost savings of 69.26%. On a yearly basis, the average energy cost savings may reach up to 80.25% if optimal tilt for the solar collector is adopted on a monthly basis. The flat plate collector may be vulnerable to convective heat transfer; therefore, other solar collectors, such as vacuum tube collectors, may provide enhanced energy performance.\n",
      "  - An innovative thermal energy storage system (TESSe2b) was retrofitted in a residential building in Cyprus with a typical Mediterranean climate. The system comprises flat-plate solar collectors, thermal energy storage tanks filled with organic phase change material, a geothermal installation consisting of borehole heat exchangers with and without phase change material and a ground source heat pump, an advanced self-learning control system, backup devices and several other auxiliary components. The thermal energy storage tanks cover the building’s needs at certain temperature ranges (10–17 °C for cooling, 38–45 °C for heating and 50–60 °C for domestic hot water). A performance evaluation was conducted by comparing the TESSe2b system with the existing conventional heating and cooling system. The systems were simulated using commercial software, and the performance of the systems and the building’s energy needs were calculated. Based on the energy quantities, an economic analysis followed. The equivalent annual primary energy consumption with the conventional system resulted in being 43335 kWh, while for the storage system, it was only 8398 kWh. The payback period for the storage system was calculated to be equal to 9.76 years. The operation of the installed storage system provided data for calculations of the seasonal performance factor and storage performance. The seasonal performance factor values were very high during June, July and August, since the TESSe2b system works very efficiently in cooling mode due to the very high temperatures that dominate in Cyprus. The measured stored thermal energy for cooling, heating and domestic hot water resulted in being 14.5, 21.9 and 6.2 kWh, respectively. Moreover, the total volume of the phase change material thermal energy storage tanks for heating and domestic hot water was calculated to be roughly several times smaller than the volume of a tank with water as a storage medium.\n",
      "  - The goal of this investigation is the thorough analysis and optimization of a solar-assisted heat pump heating unit for covering the space heating demand for a building in Athens, Greece. The novelty of the studied system is the use of a high-temperature heat pump that can operate with radiative terminal units, leading to high thermal comfort standards. The examined system includes flat-plate solar thermal collectors, an insulated thermal storage tank, auxiliary electrical thermal resistance in the tank and a high-temperature heat pump. The economic optimization indicates that the optimal design includes 35 m2 of solar thermal collectors connected with a storage tank of 2 m3 for facing the total heating demand of 6785 kWh. In this case, the life cycle cost was calculated at 22,694 EUR, the seasonal system coefficient of performance at 2.95 and the mean solar thermal efficiency at 31.60%. On the other hand, the multi-objective optimization indicates the optimum design is the selection of 50 m2 of solar field connected to a thermal tank of 3 m3. In this scenario, the life cycle cost was calculated at 24,084 EUR, the seasonal system coefficient of performance at 4.07 and the mean solar thermal efficiency at 25.33%.\n",
      "--------------------------------------------------\n",
      "Topic 106: 106_targets may missed_missed large margin_policies instead promises_may missed large\n",
      "Representative Documents:\n",
      "  - Key PointsEditors‐in‐chief of AGU journals stress urgent need for greening economyCross‐sector solutions‐based science must supplement basic researchAGU is adding solutions‐based community science journal to portfolio\n",
      "  - Looking at policies instead of promises shows that global climate targets may be missed by a large margin\n",
      "  - Looking at policies instead of promises shows that global climate targets may be missed by a large margin\n",
      "--------------------------------------------------\n",
      "Topic 107: 107_species_richness_diversity_species richness\n",
      "Representative Documents:\n",
      "  - Higher temperatures can increase metabolic rates and carbon demands of invertebrate herbivores, which may shift leaf-chewing herbivory among plant functional groups differing in C:N (carbon:nitrogen) ratios. Biotic factors influencing herbivore species richness may modulate these temperature effects. Yet, systematic studies comparing leaf-chewing herbivory among plant functional groups in different habitats and landscapes along temperature gradients are lacking. This study was conducted on 80 plots covering large gradients of temperature, plant richness and land use in Bavaria, Germany. We investigated proportional leaf area loss by chewing invertebrates (‘herbivory’) in three plant functional groups on open herbaceous vegetation. As potential drivers, we considered local mean temperature (range 8.4–18.8 °C), multi-annual mean temperature (range 6.5–10.0 °C), local plant richness (species and family level, ranges 10–51 species, 5–25 families), adjacent habitat type (forest, grassland, arable field, settlement), proportion of grassland and landscape diversity (0.2–3 km scale). We observed differential responses of leaf-chewing herbivory among plant functional groups in response to plant richness (family level only) and habitat type, but not to grassland proportion, landscape diversity and temperature—except for multi-annual mean temperature influencing herbivory on grassland plots. Three-way interactions of plant functional group, temperature and predictors of plant richness or land use did not substantially impact herbivory. We conclude that abiotic and biotic factors can assert different effects on leaf-chewing herbivory among plant functional groups. At present, effects of plant richness and habitat type outweigh effects of temperature and landscape-scale land use on herbivory among legumes, forbs and grasses.\n",
      "  - Single species forest systems often suffer from low resistance and resilience to perturbations. Consequently, fostering tree species diversity is discussed as an important management approach to address the impacts of changing climate and disturbance regimes. Yet, the effect of the spatial grain of tree species mixtures remains unknown.We asked whether increasing tree species diversity between stands (beta diversity) has the same effect as increasing tree species diversity within stands (alpha diversity) at similar overall levels of richness (gamma diversity). We conducted a multi‐model simulation experiment under climate change, applying two forest landscape models (iLand and LandClim) across two contrasting landscapes of Central Europe. We analysed the effect of different levels and configurations of diversity on the disturbance impact and the temporal stability of biomass stocks and forest structure.In general, increasing levels of diversity decreased disturbance impacts. Positive diversity effects increased with increasing severity of climate change. Beta diversity buffered disturbance impacts on landscape‐level biomass stocks more strongly than alpha diversity. The effects of the spatial configuration on forest structure were more variable. Diversity effects on temporal stability were less pronounced compared to disturbance impacts, and mixture within and between stands had comparable effects on temporal stability.Diversity effects were context‐dependent, with patterns varying between landscapes and indicators. Furthermore, we found a strong species identity effect, with increasing diversity being particularly beneficial in conifer‐dominated systems of the European Alps. The two models agreed on the effects of different levels and configurations of tree species diversity, underlining the robustness of our findings.Synthesis and application. Enhancing tree species diversity can buffer forest ecosystems against increasing levels of perturbation. Mixing tree species between stands is at least as effective as mixing tree species within stands. Given the managerial advantages of between‐stand mixtures (e.g. reduced need to control competition to maintain diversity, higher timber quality, lower logistic effort), we conclude that forest management should consider enhancing diversity at multiple spatial scales.​\n",
      "  - QuestionsWhat are the most important drivers of plant species richness (gamma‐diversity) and species turnover (beta‐diversity) in the field layer of a forest edge? Does the tree and shrub species richness structure and complexity affect the richness of forest and grassland specialist species?LocationSoutheast Sweden.MethodsWe sampled 50 forest edges with different levels of structural complexity in agricultural landscapes. In each border we recorded trees, shrubs and herb layer species in a 50‐m transect parallel with the forest. We investigated species composition and species turnover in relation to the proportions of gaps in the border and the diversity of trees and shrubs.ResultsTotal plant species richness in the field layer was mainly explained by the proportion of gaps to areas with full canopy cover and tree diversity. Increasing number of gaps promoted higher diversity of grassland specialist species within the field layer, resulting in open forest borders with the highest overall species richness. Gaps did however have a negative impact on forest species richness. Conversely, increasing forest species richness was positively related to tree diversity, but the number of grassland specialist species was negatively affected by tree diversity.ConclusionsManaging forest borders, and therefore increasing the area of semi‐open habitats in fragmented agricultural landscapes, provides future opportunities to create a network of suitable habitats for both grassland and deciduous forest specialist species. Such measures therefore have the potential to increase functional connectivity and support dispersal of species in homogeneous forest/agricultural landscapes.\n",
      "--------------------------------------------------\n",
      "Topic 108: 108_energy_emissions_electricity_co2 emissions\n",
      "Representative Documents:\n",
      "  - Waternet, the first water cycle company in the Netherlands, is responsible for drinking water treatment and distribution, wastewater collection and treatment, and water system management and control in and around Amsterdam. Waternet has the ambition to become climate neutral in 2020. To realise this ambition, measures are required to compensate for the emission of 53,000 t CO2-eq/year. Energy recovery from the water cycle looks very promising. From wastewater, ground water, surface water and drinking water, all elements of the water cycle, renewable energy can be recovered. This can be thermal energy and chemical energy. First calculations reveal that energy recovery from the water cycle in and around Amsterdam can contribute to a total reduction in greenhouse gas emissions up to 74,900 t CO2-eq/year. The challenge for the coming years is to choose robust combinations of all the possibilities to fulfil the energy demand at any time. Only then can the use of fossil fuel be abandoned and the target of becoming climate neutral in 2020 be reached.\n",
      "  - Environmentally friendly compared to other modes of transport, is still   responsi?ble for 1 billionns of CO2 emissions per year and 2.7% of total   global emissions, although it has the lowest CO2 emissions per mile. In   order to keep the world?s sur?face temperature below the critical +2 ?C,   International Maritime Organization works with alternative methods   especially in the energy efficiency design index, to increase the   productivity depending on the type and operation of the ship to reduce   current CO2 emissions each tonne per mile basis. More energy-efficient   vessels are necessary due to the increasing volume of maritime trade in   parallel to meet the growing energy demands and reduce total CO2 emissions.   Measures to reduce CO2 emissions also increase efficiency and fuel-savings.   The most significant parameter of fuel economy is the speed of the ship.   Sensitivity analysis was used to determine the ecological speed limits of   vessels in terms of minimum commercial profitability by a gradual reduction   in operating speeds. Consequently a solution methodology for the effects of   slow steaming to the global environment is presented as a CO2 emission   reduction activity under the systematic analysis of human thought.\n",
      "  - Environmentally friendly compared to other modes of transport, is still   responsi?ble for 1 billionns of CO2 emissions per year and 2.7% of total   global emissions, although it has the lowest CO2 emissions per mile. In   order to keep the world?s sur?face temperature below the critical +2 ?C,   International Maritime Organization works with alternative methods   especially in the energy efficiency design index, to increase the   productivity depending on the type and operation of the ship to reduce   current CO2 emissions each tonne per mile basis. More energy-efficient   vessels are necessary due to the increasing volume of maritime trade in   parallel to meet the growing energy demands and reduce total CO2 emissions.   Measures to reduce CO2 emissions also increase efficiency and fuel-savings.   The most significant parameter of fuel economy is the speed of the ship.   Sensitivity analysis was used to determine the ecological speed limits of   vessels in terms of minimum commercial profitability by a gradual reduction   in operating speeds. Consequently a solution methodology for the effects of   slow steaming to the global environment is presented as a CO2 emission   reduction activity under the systematic analysis of human thought.\n",
      "--------------------------------------------------\n",
      "Topic 109: 109_policy_governance_cities_adaptation\n",
      "Representative Documents:\n",
      "  - This article analyzes and compares the climate policy and transformation pathways of the forerunner cities Turku (Finland), Groningen (The Netherlands), Rostock, and Potsdam (both located in Germany). Our study combines an international comparison of cities located in three different countries with a national comparison of two German cities. This research design is based on the assumption that national context matters. We argue that the chances for scaling local experiments between cities are particularly high among matching cities, which resemble each other. Such cities have the capability to learn by matchmaking, nationally as well as internationally. All four cities are mid‐sized cities of roughly the same size located in advanced democracies in northern and continental Europe. Moreover, within their countries, all four cities have acquired the reputation of being forerunners in the area of climate policy. First, we focus on a comparison of the four cities and identify the strengths and weaknesses of their climate policies. Second, we assess the scaling potential of local experiments, in particular institutional and organizational innovations, integrative and participatory approaches, and leadership. Third, we analyze actual scaling between the two German cities, which share the same national context. More generally, we explore how matching cities can develop from local pioneers to internationally acknowledged leaders, which have the ability to upscale successful local initiatives, nationally as well as internationally.\n",
      "  - Local climate policy in Germany is embedded in a complex and dense multilevel system. While higher levels of governance confront cities with legal frameworks and regulations, they are not constrained to mere implementation of requirements from the national or supranational levels. Cities can influence and make strategic use of opportunities stemming from the multilevel structure to introduce innovative climate policy measures as best practices. Within a multilevel structure, they can engage in trans‐local action and become actors in various processes of upscaling. In this paper, we analyze the configurations of success for local climate innovations. We focus on the impact of cities' trans‐local and strategic activities within the European multilevel system in conjunction with city‐specific context conditions. The research is based on a concept‐structural framework that combines trans‐local activities and internal context conditions in a way that accounts for interactions between the two spheres. A comparison of the German cities of Darmstadt, Hagen, Offenbach, and Oldenburg indicates that configurations of strategic action in the multilevel system and beneficial local conditions explain the adoption of climate innovations. Therefore, such trans‐local action should not be understood as a sufficient condition of innovative climate policy measures, but as an enabling factor embedded in local contexts.\n",
      "  - Academic attention to local climate policy usually focuses on large-sized cities. Given the climate challenges ahead this seems unjustified. Small and medium-sized cities (SMCs) deserve scholarly attention as well. The main question is: What factors influence climate change policy and local climate actions in SMCs? In this article we present an analytical framework to analyze climate change policy and local climate actions of SMCs. The framework addresses different aspects: policy-input, -throughput, -output, -outcome, characteristics of the local environment, local action arenas, influence by higher government levels, and interaction with climate change issue networks. The framework is used to analyze and compare four case studies of SMCs in the Dutch region of Twente (two urban and two rural municipalities, and addresses both adaptation and mitigation). Results show that both ‘localist’, ‘multi-level’ and issue network membership factors influence local climate policy action. Governance modes discerned concern mostly ‘governing by authority’ and ‘self-governing’. When reflecting on the role of SMCs in climate action the study revealed the importance of local capacity building schemes issued by provincial government, inter-municipal network collaboration, and the potential for local governments to mobilize and organize citizen action.\n",
      "--------------------------------------------------\n",
      "Topic 110: 110_drug_foaming_pla_poly\n",
      "Representative Documents:\n",
      "  - Poly(D,L,-lactide-co-glycolide) (PLGA) foam samples impregnated with rutin were successfully produced by supercritical foaming processes. A number of parameters such as pressure (80–200 bar), temperature (35–55 °C), depressurization rate (5–100 bar/min), ratio lactide:glycolide of the poly(D,L,-lactide-co-glycolide) (50:50 and 75:25) were studied to determine their effect on the expansion factor and on the glass transition temperature of the polymer foams and their consequences on the release profile of the rutin entrapped in them. The impregnated foams were characterized by scanning electron microscopy, differential scanning calorimetry, and mercury intrusion porosimetry. A greater impregnation of rutin into the polymer foam pores was observed as pressure was increased. The release of rutin in a phosphate buffer solution was investigated. The controlled release tests confirmed that the modification of certain variables would result in considerable differences in the drug release profiles. Thus, five-day drug release periods were achieved under high pressure and temperature while the depressurization rate remained low.\n",
      "  - Scaffolds are advanced devices employed in tissue engineering, as they are intended to mimic the characteristics of extracellular matrices. In this respect, conjugated materials are gaining relevance in the manufacturing of the foams used for therapeutic scaffolds, since they can provide certain properties that are missing in the other polymers used to form the scaffolds. This work has, therefore, focused on the development of functional scaffolds formed by conjugated-non-conjugated polymers such as polyvinyl acetate and polypyrrole, impregnated with gallic acid as the model drug and produced by means of a supercritical CO2 foaming/impregnation process. The effects from a series of parameters such as pressure, temperature, depressurization rate, and contact time of the scaffold production process have been determined. The impregnated foams have been characterized according to their morphology, including their porosity and expansion factor, their drug loading and delivering capabilities, and their mechanical and electrical properties. The characterization of the experiments was carried out using scanning electron microscopy, liquid displacement, in vitro release, electrochemical impedance spectroscopy, and compression techniques. The results from our tests have revealed a considerable influence of all the input variables studied, as well as relevant interactions between them. Values close to 35% porosity were obtained, with a drug release of up to 10 h with a fast initial release. The best operating conditions were 353 K, 30 MPa, 0.5 MPa/min depressurization rate, and 1 h contact time. By means of the supercritical foaming/impregnation technique, scaffolds with potential in tissue engineering due to their studied properties were obtained.\n",
      "  - This article proposes a foaming method using supercritical carbon dioxide (scCO2) to obtain compostable bionanocomposite foams based on PLA and organoclay (C30B) where this bionanocomposite was fabricated by a previous hot melt extrusion step. Neat PLA films and PLA/C30B films (1, 2, and 3 wt.%) were obtained by using a melt extrusion process followed by a film forming process obtaining films with thicknesses between 500 and 600 μm. Films were further processed into foams in a high-pressure cell with scCO2 under constant conditions of pressure (25 MPa) and temperature (130 °C) for 30 min. Bionanocomposite PLA foams evidenced a closed cell and uniform cell structure; however, neat PLA presented a poor cell structure and thick cell walls. The thermal stability was significantly enhanced in the bionanocomposite foam samples by the good dispersion of nanoclays due to scCO2, as demonstrated by X-ray diffraction analysis. The bionanocomposite foams showed improved overall mechanical performance due to well-dispersed nanoclays promoting increased interfacial adhesion with the polymeric matrix. The water uptake behavior of bionanocomposite foams showed that they practically did not absorb water during the first week of immersion in water. Finally, PLA foams were disintegrated under standard composting conditions at higher rates than PLA films, showing their sustainable character. Thus, PLA bionanocomposite foams obtained by batch supercritical foaming seem to be a sustainable option to replace non-biodegradable expanded polystyrene, and they represent a promising alternative to be considered in applications such as food packaging and other products.\n",
      "--------------------------------------------------\n",
      "Topic 111: 111_data_resolution_gridded_interpolation\n",
      "Representative Documents:\n",
      "  - . Potential evapotranspiration (PET) is the water that would be lost by plants through evaporation and transpiration if water was not limited in the soil, and it is commonly used in conceptual hydrological modelling in the calculation of runoff production and hence river discharge. Future changes of PET are likely to be as important as changes in precipitation patterns in determining changes in river flows. However PET is not calculated routinely by climate models so it must be derived independently when the impact of climate change on river flow is to be assessed. This paper compares PET estimates from 12 equations of different complexity, driven by the Hadley Centre's HadRM3-Q0 model outputs representative of 1961–1990, with MORECS PET, a product used as reference PET in Great Britain. The results show that the FAO56 version of the Penman–Monteith equations reproduces best the spatial and seasonal variability of MORECS PET across GB when driven by HadRM3-Q0 estimates of relative humidity, total cloud, wind speed and linearly bias-corrected mean surface temperature. This suggests that potential biases in HadRM3-Q0 climate do not result in significant biases when the physically based FAO56 equations are used. Percentage changes in PET between the 1961–1990 and 2041–2070 time slices were also calculated for each of the 12 PET equations from HadRM3-Q0. Results show a large variation in the magnitude (and sometimes direction) of changes estimated from different PET equations, with Turc, Jensen–Haise and calibrated Blaney–Criddle methods systematically projecting the largest increases across GB for all months and Priestley–Taylor, Makkink, and Thornthwaite showing the smallest changes. We recommend the use of the FAO56 equation as, when driven by HadRM3-Q0 climate data, this best reproduces the reference MORECS PET across Great Britain for the reference period of 1961–1990. Further, the future changes of PET estimated by FAO56 are within the range of uncertainty defined by the ensemble of 12 PET equations. The changes show a clear northwest–southeast gradient of PET increase with largest (smallest) changes in the northwest in January (July and October) respectively. However, the range in magnitude of PET changes due to the choice of PET method shown in this study for Great Britain suggests that PET uncertainty is a challenge facing the assessment of climate change impact on hydrology mostly ignored up to now.\n",
      "  - Several different gridded climate data sets have recently been made available with the purpose of providing a consistent set of climatic data for many hydro‐climatic studies. Recent advances in land‐surface schemes and their implementation in fully distributed processes‐based hydrologic models have demanded even higher‐resolution gridded data. It remains, however, a challenge to identify the most reliable gridded climate data for hydrologic modelling, especially in mountainous headwater regions where there is significant spatial variability but few observing stations. Moreover, the accuracy of such climate forcing data applied to alpine headwaters directly affects the modelled hydrologic responses of the lower, downstream portions of river basins. This study evaluates the spatial and temporal differences in precipitation and temperature fields among three high‐resolution climate data sets available in Canada, namely, the North American Regional Reanalysis, the Canadian Precipitation Analysis and the thin‐plate smoothing splines (ANUSPLIN). Inter‐comparison of the quality of these data sets was undertaken for the Athabasca River basin in western Canada. The hydrologic responses of this watershed with respect to each of the three gridded climate data sets were also evaluated using the Variable Infiltration Capacity model. Results indicate that the data sets have systematic differences, which vary with regional characteristics – the largest differences being for mountainous regions. The hydrologic model simulations corresponding to those three forcing data sets also show significant differences and more with North American Regional Reanalysis than those between Canadian Precipitation Analysis and ANUSPLIN. © 2014 Her Majesty the Queen in Right of Canada. Hydrological Processes © 2014 John Wiley &amp; Sons Ltd.\n",
      "  - A key aim of the Eastern Seaboard Climate Change Initiative (ESCCI) is under-standing the effect of climate change on the eastern seaboard of Australia, and the implications for climate change adaptation in this area. The New South Wales (NSW) / Australian Capital Territory (ACT) Regional Climate Modelling project (NARCliM) has produced three dynamically downscaled reanalysis climate datasets along with 12 downscaled general circulation model (GCM) projections of current (1990–2009) and future climate. It is expected that the NARCliM dataset will be used for many climate change impact studies including water security assessment. Therefore, in this study we perform a case study investigation into the usefulness and limitations of using NARCliM data for water security assessment, using the Lower Hunter urban water supply system managed by Hunter Water Corporation. We compare streamflow and reservoir levels simulated using NARCliM rainfall and a gridded historical rainfall dataset (AWAP) and focus our analysis on the differences in the simulated streamflow and reservoir levels. We show that when raw (i.e. not bias-corrected) NARCliM rainfall and potential evapotranspiration (PET) data is used to simulate streamflow and reservoir storage levels, some of the NARCliM datasets produce unrealistic results when compared with the simulations using AWAP; for example, some NARCliM datasets simulate reservoirs at or near empty while the AWAP reservoir simulations rarely drop below 60%. The bias-corrected NARCliM rainfall (corrected to AWAP) produces estimates of streamflow and reservoir levels that have a closer, but still inconsistent, match with the streamflow and reservoir levels simulated using AWAP directly. The inconsistency between the simulations using bias-corrected rainfall and historical AWAP rainfall is potentially because while bias-correction reduces systematic deviations it does not fix temporal rainfall sequencing issues. Additionally, the NARCliM PET is not bias-corrected and using bias-corrected rainfall with uncorrected PET in hydrological models results in physical inconsistencies in the rainfall-PET relationship and simulated streamflow. We demonstrate that rainfall plays a large role in the streamflow simulations, while PET seems to play a large role in the reasonableness of the simulated reservoir dynamics by determining the evaporation losses from the reservoirs. The downscaled GCM datasets that simulate the greatest average PET for 1990–2009 show reservoirs often (unrealistically) near empty. This study highlights the need to assess the validity of all climate data for the applications required, with a focus on long-term statistics for reservoir modelling and ensuring realism and coherence across all projected variables.\n",
      "--------------------------------------------------\n",
      "Topic 112: 112_agreement_paris_international_paris agreement\n",
      "Representative Documents:\n",
      "  - Since adoption of the Kyoto Protocol under the United Nations Framework Convention on Climate Change in 1997, the international climate regime has been caught in stasis. Due to a lack of direction and clarity at the policy level and deep political divides, the evolution of the international climate regime under the United Nations Framework Convention on Climate Change (UNFCCC) had failed to catch up with the changes occurring in the real economy. The momentum created ahead of COP21 in 2015 and resulting Paris Agreement has changed this, creating a new paradigm of international climate policy, politics and cooperation that is, if implemented, capable of generating the momentum needed to accelerate the pace of change and drive transformation. This new paradigm that emerged from the Paris Agreement, demonstrates the role of the United Nations in giving voice to smaller countries to create effective positive powerful coalitions and the need to invite the outside world into the process through greater participation of cities, business, investors and other non‐state actors. We outline the main policy and political shifts that the Paris Agreement represents, and explain why this new paradigm of international climate policy, politics and cooperation is key to accelerating the pace of change and keeping the world well below 2°C, and optimally 1.5°C. WIREs Clim Change 2017, 8:e471. doi: 10.1002/wcc.471This article is categorized under:Policy and Governance &gt; International Policy Framework\n",
      "  - President Donal Trump announced the U.S. withdrawal from the 2015 Paris Agreement, and stated that the withdrawal was mainly to protect its national interests. The U.S. economic ambitions, the China factor and the intricacies of U.S domestic politics had played a major role in deciding the U.S. position on the Paris Agreement and the Kyoto Protocol of 1997. There are some who are sceptical on whether the Paris Agreement would successfully achieve its expected outcomes in the absence of U.S. participation. The objective of this study is to examine the factors that have discouraged the U.S. to partake in the international climate change agreements. An analytical framework was employed for this study that examines the insights and conceptions from the textual data, based on realism. The study concludes that the U.S. outlook on climate change had more or less adhered to the realist stance, even though realism is considered a theoretical approach with significant drawbacks, particularly when dealing with issues of climate change. Nonetheless, this study also asserts that there is a need for deeper engagement between the U.S. and the participants of the Paris Agreement to effectively tackle the issues of climate change at this moment.\n",
      "  - President Donal Trump announced the U.S. withdrawal from the 2015 Paris Agreement, and stated that the withdrawal was mainly to protect its national interests. The U.S. economic ambitions, the China factor and the intricacies of U.S domestic politics had played a major role in deciding the U.S. position on the Paris Agreement and the Kyoto Protocol of 1997. There are some who are sceptical on whether the Paris Agreement would successfully achieve its expected outcomes in the absence of U.S. participation. The objective of this study is to examine the factors that have discouraged the U.S. to partake in the international climate change agreements. An analytical framework was employed for this study that examines the insights and conceptions from the textual data, based on realism. The study concludes that the U.S. outlook on climate change had more or less adhered to the realist stance, even though realism is considered a theoretical approach with significant drawbacks, particularly when dealing with issues of climate change. Nonetheless, this study also asserts that there is a need for deeper engagement between the U.S. and the participants of the Paris Agreement to effectively tackle the issues of climate change at this moment.\n",
      "--------------------------------------------------\n",
      "Topic 113: 113_ocean_heat_sea_overturning\n",
      "Representative Documents:\n",
      "  -  Multidecadal internal climate variability centered in the North Atlantic is evident in sea surface temperatures and is assumed to be related to variations in the strength of the Atlantic meridional overturning circulation (AMOC). In this study, the extent to which variations in the AMOC may also alter hemispheric and global surface air temperature trends and ocean heat content during the past century is examined.  Forty-seven realizations of the twentieth-century climate change from two large ensembles using the Community Earth System Model (CESM) are analyzed. One of the ensembles shows a much wider spread in global mean surface air temperature between its members. This ensemble simulates diverging trends of the AMOC strength during the twentieth century. The presence and strength of deep convection in the Labrador Sea controls these trends. The AMOC strength influences the air–sea heat flux into the high-latitude ocean, where a strengthening of the AMOC leads to decreased storage of heat in the Atlantic, and a larger fraction of the heat taken up by the global ocean accumulates in the top 300 m, compared to the case of a weakening AMOC. The spread in the amount of heat stored in the global ocean below 300 m is similar across the CESM members as in a set of CMIP5 models, confirming the AMOC as a “control knob” on deep-ocean heat storage. By influencing the ocean heat uptake efficiency and by shifting the pattern of heat uptake, global surface air temperatures are significantly altered on a multidecadal time scale by AMOC variability. \n",
      "  - Ocean heat transport in the South Atlantic of a coupled climate model has been diagnosed and compared with observational estimates. The coupled model overestimates the northward heat transport in the South Atlantic. This corresponds to an underestimate of the northward flux of bottom water across World Ocean Circulation Experiment (WOCE) section A11 (the model transports less than 1 Sv compared with climatological estimates of 6 Sv). The magnitude of the southward outflow of North Atlantic deep water agrees well with observational estimates while the northward flux of surface and intermediate waters is larger than observational estimates. We show that with the correct water mass properties a realistic northward flux of bottom water across 30°S is only possible, in the climate model, if the depths of the channels linking the Argentine and Brazil basins are properly represented. We find that an increase in the northward flow of bottom water corresponds to an increase in the southward flow of deep water, rather than a reduction in the northward flux of surface and intermediate waters. This indicates that the upper and lower limb of the overturning are decoupled in the model. As a consequence, increasing the northward transport of bottom water leads to a small reduction of the northward heat transport across 30°S. The magnitude of the heat transport from the Indian to the Atlantic ocean in the model (the warm water path) is surprisingly large for a noneddy resolving model. We find that the magnitude of the Indonesian Throughflow is important in climate resolution models for determining the strength of the warm water path. However, the relative strengths of the warm and cold water paths do not significantly change the heat transported across 30°S.\n",
      "  - . A high-resolution parallel ocean model is set up to examine how the sill depth of the Atlantic connection affects circulation and water characteristics in the Mediterranean Basin. An analysis of the model performance, comparing model results with observations of the present-day Mediterranean, demonstrates its ability to reproduce observed water characteristics and circulation (including deep water formation). A series of experiments with different sill depths in the Atlantic–Mediterranean connection is used to assess the sensitivity of Mediterranean circulation and water characteristics to sill depth. Basin-averaged water salinity and, to a lesser degree, temperature rise when the sill depth is shallower and exchange with the Atlantic is lower. Lateral and interbasinal differences in the Mediterranean are, however, largely unchanged. The strength of the upper overturning cell in the western basin is proportional to the magnitude of the exchange with the Atlantic, and hence to sill depth. Overturning in the eastern basin and deep water formation in both basins, on the contrary, are little affected by the sill depth. The model results are used to interpret the sedimentary record of the Late Miocene preceding and during the Messinian Salinity Crisis. In the western basin, a correlation exists between sill depth and rate of refreshment of deep water. On the other hand, because sill depth has little effect on the overturning and deep water formation in the eastern basin, the model results do not support the notion that restriction of the Atlantic–Mediterranean connection may cause lower oxygenation of deep water in the eastern basin. However, this discrepancy may be due to simplifications in the surface forcing and the use of a bathymetry different from that in the Late Miocene. We also tentatively conclude that blocked outflow, as found in experiments with a sill depth &amp;amp;leq;10 m, is a plausible scenario for the second stage of the Messinian Salinity Crisis during which halite was rapidly accumulated in the Mediterranean. With the model setup and experiments, a basis has been established for future work on the sensitivity of Mediterranean circulation to changes in (palaeo-)bathymetry and external forcings.\n",
      "--------------------------------------------------\n",
      "Topic 114: 114_coral_reef_reefs_coral reefs\n",
      "Representative Documents:\n",
      "  - The increasing frequency of mass coral bleaching and associated coral mortality threaten the future of warmwater coral reefs. Although thermal stress is widely recognized as the main driver of coral bleaching, exposure to light also plays a central role. Future projections of the impacts of climate change on coral reefs have to date focused on temperature change and not considered the role of clouds in attenuating the bleaching response of corals. In this study, we develop temperature- and light-based bleaching prediction algorithms using historical sea surface temperature, cloud cover fraction and downwelling shortwave radiation data together with a global-scale observational bleaching dataset observations. The model is applied to CMIP6 output from the GFDL-ESM4 Earth System Model under four different future scenarios to estimate the effect of incorporating cloudiness on future bleaching frequency, with and without thermal adaptation or acclimation by corals. The results show that in the low emission scenario SSP1-2.6 incorporating clouds into the model delays the bleaching frequency conditions by multiple decades in some regions, yet the majority (&gt;70%) of coral reef cells still experience dangerously frequent bleaching conditions by the end of the century. In the moderate scenario SSP2-4.5, however, the increase in thermal stress is sufficient to overwhelm the mitigating effect of clouds by mid-century. Thermal adaptation or acclimation by corals could further shift the bleaching projections by up to 40 years, yet coral reefs would still experience dangerously frequent bleaching conditions by the end of century in SPP2-4.5. The findings show that multivariate models incorporating factors like light may improve the near-term outlook for coral reefs and help identify future climate refugia. Nonetheless, the long-term future of coral reefs remains questionable if the world stays on a moderate or higher emissions path.\n",
      "  - Ocean warming under climate change threatens coral reefs directly, through fatal heat stress to corals and indirectly, by boosting the energy of cyclones that cause coral destruction and loss of associated organisms. Although cyclone frequency is unlikely to rise, cyclone intensity is predicted to increase globally, causing more frequent occurrences of the most destructive cyclones with potentially severe consequences for coral reef ecosystems. While increasing heat stress is considered a pervasive risk to coral reefs, quantitative estimates of threats from cyclone intensification are lacking due to limited data on cyclone impacts to inform projections. Here, using extensive data from Australia's Great Barrier Reef (GBR), we show that increases in cyclone intensity predicted for this century are sufficient to greatly accelerate coral reef degradation. Coral losses on the outer GBR were small, localized and offset by gains on undisturbed reefs for more than a decade, despite numerous cyclones and periods of record heat stress, until three unusually intense cyclones over 5 years drove coral cover to record lows over &gt;1500 km. Ecological damage was particularly severe in the central‐southern region where 68% of coral cover was destroyed over &gt;1000 km, forcing record declines in the species richness and abundance of associated fish communities, with many local extirpations. Four years later, recovery of average coral cover was relatively slow and there were further declines in fish species richness and abundance. Slow recovery of community diversity appears likely from such a degraded starting point. Highly unusual characteristics of two of the cyclones, aside from high intensity, inflated the extent of severe ecological damage that would more typically have occurred over 100s of km. Modelling published predictions of future cyclone activity, the likelihood of more intense cyclones within time frames of coral recovery by mid‐century poses a global threat to coral reefs and dependent societies.\n",
      "  - Elevated ocean temperatures can cause coral bleaching, the loss of colour from reef‐building corals because of a breakdown of the symbiosis with the dinoflagellate Symbiodinium. Recent studies have warned that global climate change could increase the frequency of coral bleaching and threaten the long‐term viability of coral reefs. These assertions are based on projecting the coarse output from atmosphere–ocean general circulation models (GCMs) to the local conditions around representative coral reefs.Here, we conduct the first comprehensive global assessment of coral bleaching under climate change by adapting the NOAA Coral Reef Watch bleaching prediction method to the output of a low‐ and high‐climate sensitivity GCM. First, we develop and test algorithms for predicting mass coral bleaching with GCM‐resolution sea surface temperatures for thousands of coral reefs, using a global coral reef map and 1985–2002 bleaching prediction data. We then use the algorithms to determine the frequency of coral bleaching and required thermal adaptation by corals and their endosymbionts under two different emissions scenarios.The results indicate that bleaching could become an annual or biannual event for the vast majority of the world's coral reefs in the next 30–50 years without an increase in thermal tolerance of 0.2–1.0°C per decade. The geographic variability in required thermal adaptation found in each model and emissions scenario suggests that coral reefs in some regions, like Micronesia and western Polynesia, may be particularly vulnerable to climate change. Advances in modelling and monitoring will refine the forecast for individual reefs, but this assessment concludes that the global prognosis is unlikely to change without an accelerated effort to stabilize atmospheric greenhouse gas concentrations.\n",
      "--------------------------------------------------\n",
      "Topic 115: 115_mjo_convection_foehn_propagation\n",
      "Representative Documents:\n",
      "  -                The ability of eight climate models to simulate the Madden–Julian oscillation (MJO) is examined using diagnostics developed by the U.S. Climate Variability and Predictability (CLIVAR) MJO Working Group. Although the MJO signal has been extracted throughout the annual cycle, this study focuses on the boreal winter (November–April) behavior. Initially, maps of the mean state and variance and equatorial space–time spectra of 850-hPa zonal wind and precipitation are compared with observations. Models best represent the intraseasonal space–time spectral peak in the zonal wind compared to that of precipitation. Using the phase–space representation of the multivariate principal components (PCs), the life cycle properties of the simulated MJOs are extracted, including the ability to represent how the MJO evolves from a given subphase and the associated decay time scales. On average, the MJO decay (e-folding) time scale for all models is shorter (∼20–29 days) than observations (∼31 days). All models are able to produce a leading pair of multivariate principal components that represents eastward propagation of intraseasonal wind and precipitation anomalies, although the fraction of the variance is smaller than observed for all models. In some cases, the dominant time scale of these PCs is outside of the 30–80-day band.               Several key variables associated with the model’s MJO are investigated, including the surface latent heat flux, boundary layer (925 hPa) moisture convergence, and the vertical structure of moisture. Low-level moisture convergence ahead (east) of convection is associated with eastward propagation in most of the models. A few models are also able to simulate the gradual moistening of the lower troposphere that precedes observed MJO convection, as well as the observed geographical difference in the vertical structure of moisture associated with the MJO. The dependence of rainfall on lower tropospheric relative humidity and the fraction of rainfall that is stratiform are also discussed, including implications these diagnostics have for MJO simulation. Based on having the most realistic intraseasonal multivariate empirical orthogonal functions, principal component power spectra, equatorial eastward propagating outgoing longwave radiation (OLR), latent heat flux, low-level moisture convergence signals, and vertical structure of moisture over the Eastern Hemisphere, the superparameterized Community Atmosphere Model (SPCAM) and the ECHAM4/Ocean Isopycnal Model (OPYC) show the best skill at representing the MJO.\n",
      "  -                This study investigates the capability for simulating the Madden–Julian oscillation (MJO) in a series of atmosphere–ocean coupled and uncoupled simulations using NCEP operational general circulation models. The effect of air–sea coupling on the MJO is examined by comparing long-term simulations from the coupled Climate Forecast System (CFS T62) and the atmospheric Global Forecast System (GFS T62) models. Another coupled simulation with a higher horizontal resolution model (CFS T126) is performed to investigate the impact of model horizontal resolution. Furthermore, to examine the impact on a deep convection scheme, an additional coupled T126 run (CFS T126RAS) is conducted with the relaxed Arakawa–Schubert (RAS) scheme. The most important factors for the proper simulation of the MJO are investigated from these runs.               The empirical orthogonal function, lagged regression, and spectral analyses indicated that the interactive air–sea coupling greatly improved the coherence between convection, circulation, and other surface fields on the intraseasonal time scale. A higher horizontal resolution run (CFS T126) did not show significant improvements in the intensity and structure. However, GFS T62, CFS T62, and CFS T126 all yielded the 30–60-day variances that were not statistically distinguishable from the background red noise spectrum. Their eastward propagation was stalled over the Maritime Continent and far western Pacific. In contrast to the model simulations using the simplified Arakawa–Schubert (SAS) cumulus scheme, CFS T126RAS produced statistically significant spectral peaks in the MJO frequency band, and greatly improved the strength of the MJO convection and circulation. Most importantly, the ability of MJO convection signal to penetrate into the Maritime Continent and western Pacific was demonstrated. In this simulation, an early-stage shallow heating and moistening preconditioned the atmosphere for subsequent intense MJO convection and a top-heavy vertical heating profile was formed by stratiform heating in the upper and middle troposphere, working to increase temperature anomalies and hence eddy available potential energy that sustains the MJO. The stratiform heating arose from convective detrainment of moisture to the environment and stratiform anvil clouds. Therefore, the following factors were analyzed to be most important for the proper simulation of the MJO rather than the correct simulations of basic-state precipitation, sea surface temperature, intertropical convergence zone, vertical zonal wind shear, and lower-level zonal winds: 1) an elevated vertical heating structure (by stratiform heating), 2) a moisture–stratiform instability process (a positive feedback process between moisture and convective–stratiform clouds), and 3) the low-level moisture convergence to the east of MJO convection (through the appropriate moisture and convective–stratiform cloud processes–circulation interactions). The improved MJO simulation did improve the global circulation response to the tropical heating and may extend the predictability of weather and climate over Asia and North America.\n",
      "  - . Warm conveyor belts (WCBs) are dynamically important, strongly ascending and mostly stratiform cloud-forming airstreams in extratropical cyclones. Despite the predominantly stratiform character of the WCB's large-scale cloud band, convective clouds can be embedded in it. This embedded convection leads to a heterogeneously structured cloud band with locally enhanced hydrometeor content, intense surface precipitation and substantial amounts of graupel in the middle troposphere. Recent studies showed that embedded convection forms dynamically relevant quasi-horizontal potential vorticity (PV) dipoles in the upper troposphere. Thereby one pole can reach strongly negative PV values associated with inertial or symmetric instability near the upper-level PV waveguide, where it can interact with and modify the upper-level jet. This study analyzes the characteristics of embedded convection in the WCB of cyclone Sanchez based on WCB online trajectories from a convection-permitting simulation and airborne radar observations during the North Atlantic Waveguide and Downstream Impact Experiment (NAWDEX) field campaign (intense observation periods, IOPs, 10 and 11). In the first part, we present the radar reflectivity structure of the WCB and corroborate its heterogeneous cloud structure and the occurrence of embedded convection. Radar observations in three different sub-regions of the WCB cloud band reveal the differing intensity of its embedded convection, which is qualitatively confirmed by the ascent rates of the online WCB trajectories. The detailed ascent behavior of the WCB trajectories reveals that very intense convection with ascent rates of 600 hPa in 30–60 min occurs, in addition to comparatively moderate convection with slower ascent velocities as reported in previous case studies. In the second part of this study, a systematic Lagrangian composite analysis based on online trajectories for two sub-categories of WCB-embedded convection – moderate and intense convection – is performed. Composites of the cloud and precipitation structure confirm the large influence of embedded convection: intense convection produces very intense local surface precipitation with peak values exceeding 6 mm in 15 min and large amounts of graupel of up to 2.8 g kg−1 in the middle troposphere (compared to 3.9 mm and 1.0 g kg−1 for the moderate convective WCB sub-category). In the upper troposphere, both convective WCB trajectory sub-categories form a small-scale and weak PV dipole, with one pole reaching weakly negative PV values. However, for this WCB case study – in contrast to previous case studies reporting convective PV dipoles in the WCB ascent region with the negative PV pole near the upper-level jet – the negative PV pole is located east of the convective ascent region, i.e., away from the upper-level jet. Moreover, the PV dipole formed by the intense convective WCB trajectories is weaker and has a smaller horizontal and vertical extent compared to a previous NAWDEX case study of WCB-embedded convection, despite faster ascent rates in this case. The absence of a strong upper-level jet and the weak vertical shear of the ambient wind in cyclone Sanchez are accountable for the weak diabatic PV modification in the upper troposphere. This implies that the strength of embedded convection alone is not a reliable measure for the effect of embedded convection on upper-level PV modification and its impact on the upper-level jet. Instead, the profile of vertical wind shear and the alignment of embedded convection with a strong upper-level jet play a key role for the formation of coherent negative PV features near the jet. Finally, these results highlight the large case-to-case variability of embedded convection not only in terms of frequency and intensity of embedded convection in WCBs but also in terms of its dynamical implications.\n",
      "--------------------------------------------------\n",
      "Topic 116: 116_tornado_warnings_warning_evacuation\n",
      "Representative Documents:\n",
      "  -                Mobile home residents are known to be highly vulnerable to tornadoes and account for a considerable portion of tornado-related fatalities. The problem is partially related to the limited protection provided by the structure; however, shortcomings in preparedness and response to warnings may also play a role. This study investigated mobile home resident preparedness and responses to warnings for identifying areas where they might be more vulnerable than permanent home residents (brick and wood-frame houses). The study site was Macon County, Tennessee, which reported the highest number of fatalities during the 2008 Super Tuesday tornado outbreak. A post-disaster survey was conducted within days of the disaster, and the study group included 127 local residents: 35% mobile home (MH) residents, 61% permanent home (PH) residents, and 4% other. An unconditional exact test was used to test for statistical significance (0.05 level) because the sample was nonrandom. The MH residents were less prepared than the PH residents in all six categories evaluated. The difference was significant in having participated in a tornado drill, having a tornado-resistant shelter on the premises, and having an emergency response plan for seeking shelter. The MH residents were also less likely to follow the plan, and the difference was significant. Furthermore, the MH residents were much less likely to take shelter in a safe location. Preparedness factors that promoted higher evacuation rates among MH residents included having participated in a tornado drill, understanding the definition of a tornado warning, and having a plan for seeking shelter.\n",
      "  - Tornado warnings are currently issued an average of 13 min in advance of a tornado and are based on a warn-on-detection paradigm. However, computer model improvements may allow for a new warning paradigm, warn-on-forecast, to be established in the future. This would mean that tornado warnings could be issued one to two hours in advance, prior to storm initiation. In anticipation of the technological innovation, this study inquires whether the warn-on-forecast paradigm for tornado warnings may be preferred by the public (i.e., individuals and households). The authors sample is drawn from visitors to the National Weather Center in Norman, Oklahoma. During the summer and fall of 2009, surveys were distributed to 320 participants to assess their understanding and perception of weather risks and preferred tornado warning lead time. Responses were analyzed according to several different parameters including age, region of residency, educational level, number of children, and prior tornado experience. A majority of the respondents answered many of the weather risk questions correctly. They seemed to be familiar with tornado seasons; however, they were unaware of the relative number of fatalities caused by tornadoes and several additional weather phenomena each year in the United States. The preferred lead time was 34.3 min according to average survey responses. This suggests that while the general public may currently prefer a longer average lead time than the present system offers, the preference does not extend to the 1–2-h time frame theoretically offered by the warn-on-forecast system. When asked what they would do if given a 1-h lead time, respondents reported that taking shelter was a lesser priority than when given a 15-min lead time, and fleeing the area became a slightly more popular alternative. A majority of respondents also reported the situation would feel less life threatening if given a 1-h lead time. These results suggest that how the public responds to longer lead times may be complex and situationally dependent, and further study must be conducted to ascertain the users for whom the longer lead times would carry the most value. These results form the basis of an informative stated-preference approach to predicting public response to long (&amp;gt;1 h) warning lead times, using public understanding of the risks posed by severe weather events to contextualize lead-time demand.\n",
      "  -                Recent improvements in weather observation and monitoring have increased the precision of tornado warnings. The National Weather Service currently issues storm-based tornado warnings, and even more geographically specific warnings that include probability information are under development. At the same time, the widespread proliferation of smartphone and mobile computing technology supports the rapid dissemination of graphical weather warning information. Some broadcasters and private companies have already begun using probabilistic-style tornado warning graphics. However, the development of these new types of warnings has occurred with limited research on how users interpret probabilistic visualizations.               This study begins filling this void by examining responses to color scheme and relative position using probabilistic tornado warning designs. A survey of university students is used to measure the level of perceived fear and likelihood of protective action for a series of hypothetical warning scenarios. Central research questions investigate 1) differences in responses across warning designs, 2) clustering of extreme responses in each design, 3) trends in responses with respect to probability levels, 4) differences in responses inside versus outside the warnings, and 5) differences in responses near the edges of the warning designs. Results suggest a variety of trade-offs in viewer responses to tornado warnings based on visual design choices. These findings underscore the need for more comprehensive research on visualizations in weather hazard communication that can aid meteorologists in effectively warning the public and spur appropriate tornado protection behaviors in a timely manner.\n",
      "--------------------------------------------------\n",
      "Topic 117: 117_see_see perspective_see also_science\n",
      "Representative Documents:\n",
      "  - Changing sex ratios                      Climate-warming temperatures might be expected to affect the sex ratio of species if sex determination is temperature-dependent. Petry            et al.            show that indirect climate effects could also alter sex ratios in species in which sex is genetically determined and damage reproductive fitness (see the Perspective by Etterson and Mazer). Over four decades, sex ratios in populations of a dioecious alpine plant have shifted toward females as a result of the different water needs of the male and female plants. The lack of males has reduced the reproductive success and fitness of the females. Similar subtle differences between sexes in environmental sensitivities could eventually lead to population declines.                                Science            , this issue p.            69            ; see also p.            32          \n",
      "  - Consequences conferred at a distance                      Migratory animals have adapted to life in multiple, sometimes very different environments. Thus, they may show particularly complex responses as climates rapidly change. Van Gils            et al.            show that body size in red knot birds has been decreasing as their Arctic breeding ground warms (see the Perspective by Wikelski and Tertitski). However, the real toll of this change appears not in the rapidly changing northern part of their range but in the apparently more stable tropical wintering range. The resulting smaller, short-billed birds have difficulty reaching their major food source, deeply buried mollusks, which decreases the survival of birds born during particularly warm years.                                Science            , this issue p.            819            ; see also p.            775          \n",
      "  - Accounting for a warming ocean                      Fisheries provide food and support livelihoods across the world. They are also under extreme pressure, with many stocks overfished and poorly managed. Climate change will add to the burden fish stocks bear, but such impacts remain largely unknown. Free            et al.            used temperature-specific models and hindcasting across fish stocks to determine the degree to which warming has, and will, affect fish species (see the Perspective by Plagányi). They found that an overall reduction in yield has occurred over the past 80 years. Furthermore, although some species are predicted to respond positively to warming waters, the majority will experience a negative impact on growth. As our world warms, responsible and active management of fisheries harvests will become even more important.                                Science            , this issue p.            979            ; see also p.            930          \n",
      "--------------------------------------------------\n",
      "Topic 118: 118_reports_argue_10 1002_1002\n",
      "Representative Documents:\n",
      "  - In their comments, Schottler et al. (doi:10.1002/2015WR018482) raised concerns about our technique for deciphering climate and land use land cover (LULC) change impacts on streamflow in the upper Midwestern United States. In this reply, we further explain the underpinnings of our statistical technique and point out criticism on the procedures that Schottler et al. (doi:10.1002/2015WR018482; doi:10.1002/hyp.9738) used in their comment.\n",
      "  - This reply addresses concerns raised by Schilling (2016, doi:10.1002/2015WR018482) on Gupta et al. (2015a, doi: 10.1002/2015WR017323, 2015b, doi:10.1002/2015WR017323). To this end, we provide additional analysis of the Raccoon River flows in Iowa and show that both annual streamflow and baseflow are mainly controlled by precipitation.\n",
      "  - Rahmstorf et al. [2004], in their “critique” of Shaviv and Veizer [2003], assert that the proposed correlation between cosmic ray flux (CRF) and paleoclimate during the Phanerozoic does not “hold up under scrutiny” because its astrophysical background is based on “questionable assumptions” and circular reasoning, and because the meteoritic and terrestrial databases and statistics are manipulated.They further claim that the Shaviv and Veizer [2003] treatment of the CO2/climate relationship is not scientifically sustainable, and that the oxygen isotope record is likely a proxy of oceanic pH and not of paleotemperature. They make a host of additional assertions that cannot all be restated here.\n",
      "--------------------------------------------------\n",
      "Topic 119: 119_graphene_catalyst_oxide_oer\n",
      "Representative Documents:\n",
      "  - Anion-rich FePSe3 were successfully prepared, displaying considerable conductivity. Used as SIBs anodes without conductive agents, it showed excellent electrochemical properties at RT/LT, resulted from in situ formation of Cu–(DEGDME)n coordination.\n",
      "  - We deposit self-limiting amorphous metal oxide films via in situ superoxide generation from dimethyl formamide, yielding efficient oxygen evolution reaction (OER) catalysis and offering promise for environmentally-friendly energy technologies.\n",
      "  - We report that by engineering the intra-gap defect related energy states in GaN nanowire arrays using Mg dopants, efficient and stable overall neutral water splitting can be achieved under violet light. Overall neutral water splitting on Rh/Cr2O3 co-catalyst decorated Mg doped GaN nanowires is demonstrated with intra-gap excitation up to 450 nm. Through optimized Mg doping, the absorbed photon conversion efficiency of GaN nanowires reaches ∼43% at 375–450 nm, providing a viable approach to extend the solar absorption of oxide and non-oxide photocatalysts.\n",
      "--------------------------------------------------\n",
      "Topic 120: 120_sensory_meat_storage_treatment\n",
      "Representative Documents:\n",
      "  - The effect of gas ratio on the growth of bacteria has been well demonstrated, but some adverse effects of modified atmosphere packaging (MAP) on seafoods have also been found. To provide a better understanding of the effects of CO2 and O2 concentrations (CO2 from 40% to 100% and O2 from 0% to 30%) in MAP on the texture and protein contents and odor characteristics of salmon during cold storage, the physiochemical, microbial, and odor indicators were compared with those without treatment (CK). Generally, MAP treatments hindered the increase of microbial counts, total volatile basic nitrogen, and TCA-soluble peptides, and decreased the water-holding capacity, hardness, springiness, and sarcoplasmic and myofibrillar protein contents. The results also indicated that 60%CO2/10%O2/30%N2 was optimal and decreased the total mesophilic bacterial counts by 2.8 log cfu/g in comparison with CK on day 12. In agreement, the concentration of CO2 of 60% showed the lowest myofibrillar protein degradation, and less subsequent loss of hardness. The electronic nose characteristics analysis indicated that 60%CO2/20%O2/20%N2 and 60%CO2/10%O2/30%N2 had the best effect to maintain the original odor profiles of salmon. The correlation analysis demonstrated that microbial growth had a strong relationship with myofibrillar and sarcoplasmic protein content. It can be concluded that 60%CO2/10%O2/30%N2 displayed the best effect to achieve the goal of preventing protein degradation and odor changes in salmon fillets.\n",
      "  - With food insecurity rising dramatically in Sub-Saharan Africa, promoting the use of sorghum, cowpea and cassava flours in staple food such as bread may reduce wheat imports and stimulate the local economy through new value chains. However, studies addressing the technological functionality of blends of these crops and the sensory properties of the obtained breads are scarce. In this study, cowpea varieties (i.e., Glenda and Bechuana), dry-heating of cowpea flour and cowpea to sorghum ratio were studied for their effects on the physical and sensory properties of breads made from flour blends. Increasing cowpea Glenda flour addition from 9 to 27% (in place of sorghum) significantly improved bread specific volume and crumb texture in terms of instrumental hardness and cohesiveness. These improvements were explained by higher water binding, starch gelatinization temperatures and starch granule integrity during pasting of cowpea compared to sorghum and cassava. Differences in physicochemical properties among cowpea flours did not significantly affect bread properties and texture sensory attributes. However, cowpea variety and dry-heating significantly affected flavour attributes (i.e., beany, yeasty and ryebread). Consumer tests indicated that composite breads could be significantly distinguished for most of the sensory attributes compared to commercial wholemeal wheat bread. Nevertheless, the majority of consumers scored the composite breads from neutral to positive with regard to liking. Using these composite doughs, chapati were produced in Uganda by street vendors and tin breads by local bakeries, demonstrating the practical relevance of the study and the potential impact for the local situation. Overall, this study shows that sorghum, cowpea and cassava flour blends can be used for commercial bread-type applications instead of wheat in Sub-Saharan Africa.\n",
      "  - Due to its “generally recognized as safe status” (GRAS) and moderate treatment temperatures, non-thermal plasma (NTP) has lately been considered a suitable replacement for chemicals in the modification of food properties and for preserving food quality. One of the promising areas for the application of NTP is the treatment of wheat flour, leading to improved flour properties and product quality and consequently to higher customer satisfaction. In the present research, the German wheat flour type 550, equivalent to all-purpose flour, was treated using NTP in a rotational reactor to determine the influence of short treatment times (≤5 min) on the properties of flour (moisture and fat content, protein, starch, color, microbial activity, and enzymes), dough (visco-elastic properties, starch, wet and dry gluten, and water absorption), and baking products (color, freshness, baked volume, crumb structure, softness, and elasticity). Based on the properties of NTP, it was expected that even very short treatment times would have a significant effect on the flour particles, which could positively affect the quality of the final baking product. Overall, the experimental analysis showed a positive effect of NTP treatment of wheat flour, e.g., decreased water activity value (&lt;0.7), which is known to positively affect flour stability and product shelf life; dough stability increased (&gt;8% after 5 min. treatment); dough extensibility increased (ca. 30% after 3 min treatment); etc. Regarding the baking product, further positive effects were detected, e.g., enhanced product volume (&gt;9%), improved crumb whiteness/decreased crumb yellowness, softening of breadcrumb without a change in elasticity, and limited microorganism and enzymatic activity. Furthermore, no negative effects on the product quality were observed, even though further food quality tests are required. The presented experimental research confirms the overall positive influence of NTP treatment, even for very low treatment times, on wheat flour and its products. The presented findings are significant for the potential implementation of this technique on an industrial level.\n",
      "--------------------------------------------------\n",
      "Topic 121: 121_microalgae_biomass_co2_chlorella\n",
      "Representative Documents:\n",
      "  - Microalgae are one of the most promising sources of renewable substrates used for energy purposes. Biomass and components accumulated in their cells can be used to produce a wide range of biofuels, but the profitability of their production is still not at a sufficient level. Significant costs are generated, i.a., during the cultivation of microalgae, and are connected with providing suitable culture conditions. This study aims to evaluate the possibility of using sodium bicarbonate as an inexpensive alternative CO2 source in the culture of Chlorella vulgaris, promoting not only the increase of microalgae biomass production but also lipid accumulation. The study was carried out at technical scale using 100 L photobioreactors. Gravimetric and spectrophotometric methods were used to evaluate biomass growth. Lipid content was determined using a mixture of chloroform and methanol according to the Blight and Dyer method, while the carbon content and CO2 fixation rate were measured according to the Walkley and Black method. In batch culture, even a small addition of bicarbonate resulted in a significant (p ≤ 0.05) increase in the amount of biomass, productivity and optical density compared to non-bicarbonate cultures. At 2.0 g∙L–1, biomass content was 572 ± 4 mg·L−1, the maximum productivity was 7.0 ± 1.0 mg·L–1·d–1, and the optical density was 0.181 ± 0.00. There was also an increase in the lipid content (26 ± 4%) and the carbon content in the biomass (1322 ± 0.062 g∙dw–1), as well as a higher rate of carbon dioxide fixation (0.925 ± 0.073 g·L–1·d–1). The cultivation of microalgae in enlarged scale photobioreactors provides a significant technological challenge. The obtained results can be useful to evaluate the efficiency of biomass and valuable cellular components production in closed systems realized at industrial scale.\n",
      "  - In modern energy, various technologies for absorbing carbon dioxide from the atmosphere are being considered, including photosynthetic microalgae. An important task is to obtain maximum productivity at high concentrations of CO2 in gas–air mixtures. In this regard, the aim of the investigation is to study the effect of light intensity on the biomass growth and biochemical composition of five different microalgae strains: Arthrospira platensis, Chlorella ellipsoidea, Chlorella vulgaris, Gloeotila pulchra, and Elliptochloris subsphaerica. To assess the viability of microalgae cells, the method of cytochemical staining with methylene blue, which enables identifying dead cells during microscopy, was used. The microalgae were cultivated at 6% CO2 and five different intensities: 80, 120, 160, 200, and 245 μmol quanta·m−2·s−1. The maximum growth rate among all strains was obtained for C. vulgaris (0.78 g·L−1·d−1) at an illumination intensity of 245 µmol quanta·m−2·s−1. For E. subsphaerica and A. platensis, similar results (approximately 0.59 and 0.25 g·L−1·d−1 for each strain) were obtained at an illumination intensity of 160 and 245 µmol quanta·m−2·s−1. A decrease in protein content with an increase in illumination was noted for C. vulgaris (from 61.0 to 46.6%) and A. platensis (from 43.8 to 33.6%), and a slight increase in lipid content was shown by A. platensis (from 17.8 to 21.4%). The possibility of increasing microalgae biomass productivity by increasing illumination has been demonstrated. This result can also be considered as showing potential for enhanced lipid microalgae production for biodiesel applications.\n",
      "  - The influence of elevated CO2 concentrations on the growth and viability of various microalgae strains was studied. Arthrospira platensis, Chlorella ellipsoidea, Chlorella vulgaris, Gloeotila pulchra, and Elliptochloris subsphaerica were tested. The cultivation of microalgae was carried out at constant CO2 concentrations (0.04, 3, 6, or 9%—sequentially from lower to higher concentrations), under constant (24 h·day−1) illumination with an intensity of 74.3 µmol quanta·m−2·s−1, and a constant temperature of 23.5 ± 0.5 °C. The optical density of the microalgae biomass, pH, and the chemical composition of the culture medium were measured. Microscopy (including the cytochemical microscopic method) was conducted to monitor the state of the microalgae. The highest biomass growth rate (0.37 g·L−1·day−1), among all experiments, was achieved for Chlorella vulgaris at CO2 = 3% and for Chlorella ellipsoidea at CO2 = 6 and 9%. The lowest growth rate (0.12 g·L−1·day−1) was achieved for Arthrospira platensis at CO2 = 3 and 9%. The microscopy results showed the absence or a minimum number of dead cells of the strains under selected conditions. The ability to maintain the viability of cultures up to significant concentrations of CO2 = 9% was due to adaptation (gradual increase in CO2 concentrations in the experiments).\n",
      "--------------------------------------------------\n",
      "Topic 122: 122_isbn_978_isbn 978_paperback\n",
      "Representative Documents:\n",
      "  - Review of: Indigenous Pacific Approaches to Climate Change: Pacific Island Countries, Jenny Bryant-Tokalau (2018)               Cham: Palgrave Pivot, 111 pp.,               ISBN 978 3 319 78398 7 (hbk), £44.99                                                 Indigenous Pacific Approaches to Climate Change: Aotearoa/New Zealand, Lyn Carter (2019)               Cham: Palgrave Pivot, 106 pp.,               ISBN 978 3 319 96438 6 (hbk), £49.99                                                 Combatting Climate Change in the Pacific: The Role of Regional Organizations, Marc Williams and Duncan McDuie-Ra (2018)               London: Palgrave Macmillan, 136 pp.,               ISBN 978 3 319 88816 3 (pbk), £44.99\n",
      "  -  Reid, H. 2014: Climate Change and Human Development. London: Zed Books. X + 287 pp. £70 (Hardback), £23.99 (Paperback). ISBN: 978 1 78032 441 8 (Hardback), ISBN: 978 1 78032 440 1 (Paperback). \n",
      "  -  Bulkeley, Harriet and Newell, Peter. 2010: Governing Climate Change (Global Institutions). Abingdon and New York: Routledge. 142 pp. £18.99 paperback and e-book, £85.00 hardback. ISBN: 978-0-415-46768-1 hardback. ISBN: 978-415-46769-8 (paperback), ISBN: 978-0-203-85829-5 (e-book). \n",
      "--------------------------------------------------\n",
      "Topic 123: 123_des_du_dans_une\n",
      "Representative Documents:\n",
      "  - In recent years successful attempts have been made to develop and improve spatial modelling of mountain permafrost distribution. Work package 4 of the PACE project (Permafrost and Climate in Europe) sought to provide the essential basis not only of present‐day modelling capability, but also of future enhancements in modelling methodology. This paper briefly outlines the currently available typology of models, which involve various levels of sophistication at different spatio‐temporal scales. Appropriate models may be applied to a range of environmental issues in cold mountain areas, including engineering applications, climate‐change scenarios, large‐scale mapping, studies of surface processes or environmental concerns. Special emphasis is given here to aspects of energy exchange at the surface and within the active layer. Such energy fluxes remain poorly understood but play an essential role in process‐oriented research and sensitivity studies with respect to complex interactions and feedbacks within the system. In contrast to relatively flat permafrost areas in polar and subpolar lowlands, circulation of water and air can cause important lateral fluxes of matter and energy within coarse blocks on steep slopes and result in highly variable and sometimes extreme thermal offsets between the ground surface and the permafrost table. Measuring and numerically modelling such fluxes together with coupling time‐dependent surface and subsurface ground thermal conditions in characteristic materials (bedrock, ice‐rich debris, fine‐grained deposits) constitute the main challenge for research in the near future. Copyright © 2001 John Wiley &amp; Sons, Ltd.RÉSUMÉDans ces dernières années, des essais ont, avec succès, développé et amélioré les modélisations spatiales de la distribution du pergélisol de montagne. La quatrième partie du programme PACE (Pergélisol et Climat en Europe) a cherché à établir les bases essentielles, non seulement des possibilités actuelles de modélisation, mais aussi les améliorations méthodologique futures. Le présent article souligne brièvement la typologie couramment disponible des modèles qui comprennent plusieurs niveaux de sophistication à différentes échelles spatio‐temporelles. Des modèles appropriés peuvent être appliqués à de nombreux problèmes environnementaux, entre autres à des applications des ingénieurs, des scénarios de changement de climat, des cartographies à grande échelle, et des études des processus de surface ou environnementaux. Une attention spéciale est accordée ici aux échanges d'énergie à la surface et dans la couche active. De tels flux d'énergie restent mal compris bien qu'ils jouent un rôle essential dans la recherche des processus et dans le domaine des interactions complexes et rétroactives du système. Par opposition à ce qui se passe dans les basses terres polaires et subpolaires, les circulations de l'eau et de l'air peuvent causer des flux importants de matières et d'énergie au sein des blocs grossiers accumulés sur des pentes raides; il en résulte des échanges très variables et parfois extrêmement importants entre la surface du sol et la table du pergélisol.Mesurer et établir des modèles numériques de flux semblables dans des conditions variables de matériaux (roche en place, débris riches en glace, dépôts de granulométrie fine) et en tenant compte des conditions variables dans le temps de la température de surface et du sol, constitue le principal challenge pour la recherche dans le proche avenir Copyright © 2001 John Wiley &amp; Sons, Ltd.\n",
      "  - Recent warm winters have negatively impacted many rural Labrador residents, raising concerns over regional climate change and variability. To better understand these events, the recent temperature record was examined in detail using atmospheric reanalyses and relevant station data. In addition to quantifying seasonal and annual trends, the influence of major climate drivers is explored and their contributions to recent anomalies are estimated. The North Atlantic Oscillation (NAO) and Atlantic Multidecadal Oscillation (AMO) are identified as the dominant sources of variability, with the winter NAO producing the largest and most predictable anomalies. These drivers are associated with decadal‐scale variability in the region, including unusually cool conditions from the 1980 s through late 1990 s and a subsequent shift to warmer conditions. Removing the influence of the NAO and other climate drivers greatly reduces the magnitude of recent warm anomalies. However, temperature trends in the residual data are amplified in most seasons, with winter residual trends four times larger than the raw winter data. This suggests that climate change, previously obscured by natural variability, is exerting a significant influence on Labrador. Although climate change likely contributed relatively little to recent extreme events, it is gradually raising the probability of similar future events.Une analyse des dernières tendances climatiques observées et de leur variabilité au LabradorLes hivers chauds des dernières années ont entraîné des effets négatifs sur de nombreux résidents des régions rurales du Labrador et ont suscité des préoccupations sur les changements climatiques et la variabilité au niveau régional. Pour mieux comprendre ces événements, les relevés de température les plus récents ont fait l'objet d'un examen détaillé en tirant parti des réanalyses atmosphériques et des données des stations pertinentes. En plus de quantifier les tendances saisonnières et annuelles, une exploration de l'influence des principaux facteurs climatiques déterminants a été menée au moyen d'une estimation de leurs contributions aux anomalies récentes. Il est établi que l'oscillation nord‐atlantique (ONA) et l'oscillation atlantique multi‐décennale (OAM) constituent les principales sources de variabilité, et que c'est l'OAN de l'hiver qui est responsable des anomalies les plus importantes et prévisibles. Ces facteurs déterminants vont de pair avec la variabilité décennale dans la région, y compris les conditions anormalement fraîches enregistrées à partir des années 1980 jusqu'à la fin des années 1990, suivi d'un changement abrupt vers des conditions plus clémentes. Écarter l'influence de l'ONA et des autres facteurs climatiques déterminants réduit considérablement l'étendue des anomalies chaudes observées récemment. Il ressort des données résiduelles, une amplification des tendances de la température au cours de la plupart des saisons, avec des tendances hivernales quatre fois plus accentuées que les données de base pour l'hiver. Cela laisse entendre que les changements climatiques, masqués auparavant par la variabilité naturelle, exercent une influence notable sur le Labrador. Bien que les changements climatiques aient vraisemblablement peu contribué aux événements extrêmes récents, ils augmentent peu à peu la probabilité que de tels événements se produisent à l'avenir.\n",
      "  -  Résumé :  L’homme qui plantait des arbres, la nouvelle que Jean Giono a publiée en 1952, raconte l’histoire d’un berger solitaire qui consacre des décennies à planter inlassablement des arbres dans le sud de la France et à restaurer la vie, l’eau, la végétation et le bonheur dans une région autrefois ravagée. Des indices dissimulés dans l’histoire, moins évidents, relèvent les causes de la désolation et de la déforestation de la région aux mains de charbonniers désespérés. Même si Giono a rédigé sa nouvelle en 1952, avant que le terme « changement climatique » soit inventé, il était en parfaite harmonie avec le monde naturel et s’inquiétait des effets destructeurs attribuables à l’exploitation irresponsable de l’environnement par la population humaine. Cette histoire remarquablement visionnaire rappelle le XXIe siècle actuel avec ses sécheresses, ses incendies et ses inondations, qui font les manchettes au quotidien. Frédéric Back, environnementaliste et planteur d’arbres dévoué, a consacré six ans de sa vie à adapter l’histoire de Giono pour l’écran. La transposition de cette nouvelle à l’écran est l’objectif analytique du présent article. Sa représentation des causes et des effets des changements climatiques et de la désolation qui en découle est particulièrement intéressante. L’animation de Back est plutôt inquiétante, mais il s’arrête brusquement et propose une solution pour imaginer un monde meilleur, plus sain, une vision qui repose sur l’idée que les humains prennent soin du monde naturel et coupent court aux pratiques qui mettent la vie sur Terre en péril pour en faire des agents positifs des changements climatiques. Ainsi, dans le film, la représentation des changements climatiques n’évolue pas irrévocablement vers une catastrophe comme le font la plupart des films de fiction climatique. L’histoire de Giono en est une de rédemption, démontrée par le passage de Back d’une palette monochromatique au début du film à des scènes qui rappellent les jardins de Monet à la fin, foisonnants de couleurs, de vie et de joie. Pour comprendre le film, l'auteur aborde le militantisme environnemental tant de Giono que de Back et examine les films antérieurs de Back. \n",
      "--------------------------------------------------\n",
      "Topic 124: 124_trend_days_air temperature_poland\n",
      "Representative Documents:\n",
      "  - The study objective was to characterise biometeorological conditions during the long May weekend (1–3 May) in Poland in the period 1966–2020 and determine baric conditions causing their variability. The conducted research employed data such as air temperature, relative humidity, wind speed, and total cloudiness. The aforementioned data were collected at 12:00 UTC. In the first year of the conducted study, the Universal Thermal Climate Index (UTCI) was calculated for the period of 1–3 May in the years 1966–2020. Next, circulation conditions were analysed in the designated groups based on daily sea level atmospheric pressure values and isobaric surface height of 500 hPa. This study evidenced the occurrence of variable biometeorological conditions during the long May weekend in Poland. The lowest index values were recorded at the coast of the Baltic Sea and in Northeast Poland, and the highest in the southern and western regions. On the analysed days of May in the years 1966–2020, days classified as days with no thermal stress were recorded the most frequently, followed by days with cold stress, and days with warm stress that occurred sporadically. People planning tourist activity on the analysed days should be prepared for diverse biometeorological conditions, from those causing cold stress to those causing heat stress.\n",
      "  - Climate change is having many effects in the agricultural sector, which are being studied worldwide. Undoubtedly, warmer winters and earlier springs produce changes in frost regimes and severity that will affect the sustainability of agricultural production in the area. The Mediterranean region and the Iberian Peninsula (IP) are among the areas where the greatest impact of climate change is expected. Daily data from 68 weather stations of the IP belonging to the European Climate Assessment and Dataset (1975–2018) were used to conduct a spatiotemporal study of the frost regime. The variables calculated include the probability of three frost types according to their severity, frost day, mean absolute minimum yearly temperature, first frost day, last frost day, and frost-free period. These variables were integrated into a geographic information system, which allowed the graphical visualization of their patterns using of geostatistical interpolation techniques (kriging). Changes in frost variables were investigated using the Mann–Kendall test and Sen’s slope estimator. A general reduction in the number of frosts per year is observed (values between −0.04- and −0.8-day frosts per year), as well as an increase in the mean absolute minimum temperature (values between 0.04 and 0.10 °C per year), with very high significant trends throughout the territory. The reduction in the number of frosts is more pronounced at a higher elevation. Frost dates vary greatly due to the orographic characteristics of the IP. The generalized trend is of a significant delay of the autumn frosts (values between 0.4 and 1.06 days/year), as well as early spring frosts (between −0.429 and −1.29 days/year), and as a consequence a longer frost-free period, all changes were much stronger than those found in other regions of the world. These effects of climate change must be mitigated by modifying species, varieties, and cultivation techniques to guarantee sustainable agriculture.\n",
      "  - Evapotranspiration is an important part of the water cycle and influences, for example, water management and agricultural production. The article presents temporal and spatial changes in reference evapotranspiration (ETo) in the growing season (April–September) against the background of climatic conditions in Poland in the years 1966–2020. ETo was calculated using the Penman–Monteith method using data from 37 meteorological stations in the network of the Institute of Meteorology and Water Management‐National Research Institute. For the growing season of April–September, the average sum of ETo for Poland was 529 mm. In terms of spatial distribution, the values were lowest in northern Poland (Kołobrzeg, 480 mm; Lębork, 488 mm) and highest in the central lowlands (Warsaw, 570 mm; Poznań, 566 mm). For individual months, the average sum of ETo ranged from 53 to 63 mm in April and September to 108–112 mm in June and July. In Poland, in the years 1966–2020, ETo showed a statistically significant upward trend of 16.4 mm/10 year. This is the result of, inter alia, statistically significant increases in sunshine duration and air temperature and a decrease in relative humidity (respectively: 62 h/10 year, 0.40°C/10 year and −1%/10 year) during the growing season in Poland. Within the multiyear study period, the maximum ETo values occurred in 2018, reaching values of &gt;700 mm. At that time, Poland was under the influence of very intense anticyclonic circulation. This is confirmed by the relationship between ETo and the anticyclonic circulation index for central Poland, which is statistically significant for the 55 study years.\n",
      "--------------------------------------------------\n",
      "Topic 125: 125_deforestation_vegetation_land_amazon\n",
      "Representative Documents:\n",
      "  - This study uses offline simulations with a land surface model to explore how the future response of potential vegetation to elevated CO2 and attendant climate changes feeds back to influence surface hydrological processes. Climate changes are those projected by eight General Circulation Models (GCMs) under the SRESA1B, and the potential natural vegetation structure corresponding to the Preindustrial control and SRESA1B 2100 climate of the 8 GCMs are simulated by a dynamic global vegetation model integrated to equilibrium. For climate change forcing from each GCM, comparisons are made among three surface hydrology simulations using CLM3.0 driven with different combinations of climate forcing, atmospheric CO2 concentration, and potential natural vegetation. These simulations are designed to separate the effect of structural vegetation feedback from the combined influence of climate and CO2 changes. With the exception of the HadCM scenario, all other GCM scenarios broadly agree on the spatial patterns of structural vegetation feedbacks on surface temperature and surface water budget, although the response of soil moisture varies considerably among the GCM scenarios especially in the tropics. With the HadCM excluded, averages over the seven GCM scenarios indicate that the CO2‐induced warming in winter is stronger than in summer in the northern mid and high latitudes, and structural vegetation feedback enhances the winter warming and reduces the summer warming over a large portion of these regions; the global hydrological cycle is expected to accelerate in a warmer future climate, while the structural vegetation feedback further increases evapotranspiration in a major portion of the globe, including parts of South America, tropical Africa, Southeast Asia, and regions north of approximately 45°N, suggesting that vegetation feedback could further accelerate the hydrological cycle. Averaged over the globe, this increase in evapotranspiration due to structural vegetation feedback is equivalent to 78% of that due to climate and CO2 changes. When changes in vegetation structure are not considered, the 7‐model average response of soil moisture to climate and CO2 changes is characterized by wetter soil conditions in the northern high latitudes and parts of the midlatitudes. Structural vegetation feedback, however, causes strong midlatitude dryness both in the winter and in the summer. The impact of vegetation changes corresponding to the HadCM‐projected climate changes is markedly different, being either more extreme or in a different direction than that corresponding to the other GCMs examined. Our results are constrained by the lack of consideration for human land use changes and vegetation feedback to climate, as well as the uncertainty related to the highly disputed physiological response of ecosystems to elevated CO2. Nevertheless, this study demonstrates that climate‐ and CO2‐induced changes in potential vegetation structure substantially influence the surface hydrological processes, thus emphasizing the importance of including vegetation feedback in future climate change predictions.\n",
      "  - . Changes in forest cover have a strong effect on climate through the alteration of surface biogeophysical and biogeochemical properties that affect energy, water and carbon exchange with the atmosphere. To quantify biogeophysical and biogeochemical effects of deforestation in a consistent setup, nine Earth system models (ESMs) carried out an idealized experiment in the framework of the Coupled Model Intercomparison Project, phase 6 (CMIP6). Starting from their pre-industrial state, models linearly replace 20×106 km2 of forest area in densely forested regions with grasslands over a period of 50 years followed by a stabilization period of 30 years. Most of the deforested area is in the tropics, with a secondary peak in the boreal region. The effect on global annual near-surface temperature ranges from no significant change to a cooling by 0.55 ∘C, with a multi-model mean of -0.22±0.21 ∘C. Five models simulate a temperature increase over deforested land in the tropics and a cooling over deforested boreal land. In these models, the latitude at which the temperature response changes sign ranges from 11 to 43∘ N, with a multi-model mean of 23∘ N. A multi-ensemble analysis reveals that the detection of near-surface temperature changes even under such a strong deforestation scenario may take decades and thus longer than current policy horizons. The observed changes emerge first in the centre of deforestation in tropical regions and propagate edges, indicating the influence of non-local effects. The biogeochemical effect of deforestation are land carbon losses of 259±80 PgC that emerge already within the first decade. Based on the transient climate response to cumulative emissions (TCRE) this would yield a warming by 0.46 ± 0.22 ∘C, suggesting a net warming effect of deforestation. Lastly, this study introduces the “forest sensitivity” (as a measure of climate or carbon change per fraction or area of deforestation), which has the potential to provide lookup tables for deforestation–climate emulators in the absence of strong non-local climate feedbacks. While there is general agreement across models in their response to deforestation in terms of change in global temperatures and land carbon pools, the underlying changes in energy and carbon fluxes diverge substantially across models and geographical regions. Future analyses of the global deforestation experiments could further explore the effect on changes in seasonality of the climate response as well as large-scale circulation changes to advance our understanding and quantification of deforestation effects in the ESM frameworks.\n",
      "  - . Deforestation in Amazon is expected to decrease evapotranspiration (ET) and to increase soil moisture and river discharge under prevailing energy-limited conditions. The magnitude and sign of the response of ET to deforestation depend both on the magnitude and regional patterns of land-cover change (LCC), as well as on climate change and CO2 levels. On the one hand, elevated CO2 decreases leaf-scale transpiration, but this effect could be offset by increased foliar area density. Using three regional LCC scenarios specifically established for the Brazilian and Bolivian Amazon, we investigate the impacts of climate change and deforestation on the surface hydrology of the Amazon Basin for this century, taking 2009 as a reference. For each LCC scenario, three land surface models (LSMs), LPJmL-DGVM, INLAND-DGVM and ORCHIDEE, are forced by bias-corrected climate simulated by three general circulation models (GCMs) of the IPCC 4th Assessment Report (AR4). On average, over the Amazon Basin with no deforestation, the GCM results indicate a temperature increase of 3.3 °C by 2100 which drives up the evaporative demand, whereby precipitation increases by 8.5 %, with a large uncertainty across GCMs. In the case of no deforestation, we found that ET and runoff increase by 5.0 and 14 %, respectively. However, in south-east Amazonia, precipitation decreases by 10 % at the end of the dry season and the three LSMs produce a 6 % decrease of ET, which is less than precipitation, so that runoff decreases by 22 %. For instance, the minimum river discharge of the Rio Tapajós is reduced by 31 % in 2100. To study the additional effect of deforestation, we prescribed to the LSMs three contrasted LCC scenarios, with a forest decline going from 7 to 34 % over this century. All three scenarios partly offset the climate-induced increase of ET, and runoff increases over the entire Amazon. In the south-east, however, deforestation amplifies the decrease of ET at the end of dry season, leading to a large increase of runoff (up to +27 % in the extreme deforestation case), offsetting the negative effect of climate change, thus balancing the decrease of low flows in the Rio Tapajós. These projections are associated with large uncertainties, which we attribute separately to the differences in LSMs, GCMs and to the uncertain range of deforestation. At the subcatchment scale, the uncertainty range on ET changes is shown to first depend on GCMs, while the uncertainty of runoff projections is predominantly induced by LSM structural differences. By contrast, we found that the uncertainty in both ET and runoff changes attributable to uncertain future deforestation is low.                    \n",
      "--------------------------------------------------\n",
      "Topic 126: 126_magnetic_spin_heusler_fe\n",
      "Representative Documents:\n",
      "  - In this work, we were able to produce Co2FeSi Heusler alloy glass-covered microwires with a metallic nucleus diameter of about 4.4 µm and total sample diameter of about 17.6 μm by the Taylor–Ulitovsky Technique. This low cost and single step fabrication process allowed the preparation of up to kilometers long glass-coated microwires starting from a few grams of high purity inexpensive elements (Co, Fe and Si), for a wide range of applications. From the X-ray diffraction, XRD, analysis of the metallic nucleus, it was shown that the structure consists of a mixture of crystalline and amorphous phases. The single and wide crystalline peak was attributed to a L21 crystalline structure (5.640 Å), with a possible B2 disorder. In addition, nanocrystalline structure with an average grain size, Dg = 17.8 nm, and crystalline phase content of about 52% was obtained. The magnetic measurements indicated a well-defined magnetic anisotropy for all ranges of temperature. Moreover, soft magnetic behavior was observed for the temperature measuring range of 5–1000 K. Strong dependence of the magnetic properties on the applied magnetic field and temperature was observed. Zero field cooling and field cooling magnetization curves showed large irreversibility magnetic behavior with a blocking temperature (TB = 205 K). The in-plane magnetization remanence and coercivity showed quite different behavior with temperature, due to the existence of different magnetic phases induced from the internal stress created by the glass-coated layer. Moreover, a high Curie temperature was reported (Tc ≈ 1059 K), which predisposes this material to being a suitable candidate for high temperature spintronic applications.\n",
      "  - The structural, magnetic, and transport properties are investigated for full-Heusler alloy Co2(Cr1−xFex)Al (CCFA) thin films sputtered on thermally oxidized Si substrates at room temperature (RT). X-ray diffraction reveals that the films possess the B2 structure for x=0, decrease the atomic site ordering by substituting Fe for Cr(0.4≦x≦0.6), and form the A2 structure for x=1. Both the magnetic moment and the Curie temperature of the films increase with increasing Fe content (x), although the moment for x&amp;lt;1 is significantly smaller than that of the calculated value for the L21 structure. Magnetic tunnel junctions (MTJs) with CCFA films as either upper or bottom ferromagnetic layers are also fabricated by using metal masks. The maximum tunneling magnetoresistance (TMR) at RT for the MTJ was observed to be 19.1% for x=0.4 with the CCFA film as an upper ferromagnetic layer, despite the atomic disorder of the CCFA film. This is consistent with our previous TMR observation with the CCFA film as a bottom ferromagnetic layer, indicating that the CCFA film even with the B2 structure is a good candidate for future spintronic devices due to its disorder tolerance, high reproducibility, and large spin polarization.\n",
      "  - In this article, we studied the effect of annealing (600 °C for 1 h) and the applied magnetic field from 50 Oe to 20 kOe of Co2FeSi glass-coated microwires with ordered L21 structure prepared by Taylor–Ulitovsky technique on the magnetic behavior. The as-prepared and annealed samples show a ferromagnetic behavior at the range of measuring temperature (5 to 400 K) and magnetic field (50 Oe to 20 kOe). M–H loops of as prepared sample do not show a squared shape. Meanwhile, perfectly squared hysteresis loops have detected for the annealed sample. In addition, annealed sample shows high magnetization M/M5K ratio, coercivity, and anisotropy field, as-compared to the as-prepared one. The annealed sample shows considerable irreversibility when the magnetic behavior changes with temperature upon the applied magnetic field at 50 and 200 Oe. Such irreversibility does not found in the as-prepared sample measured at the same magnetic field due to mixed amorphous and crystalline structure. By increasing the external magnetic field higher than 200 Oe and up to 20 kOe a gradual changing in the magnetic behavior has been detected where the irreversibility disappeared at applying magnetic field about 1 kOe and the magnetic behavior is totally change by increasing the external magnetic field up to the maximum 20 kOe. The difference in the magnetic behavior of the annealed glass-coated Co2FeSi glass-coated microwires indicates the effect of internal stresses induced by the presence of the glass-coating and the annealing-induced recrystallization.\n",
      "--------------------------------------------------\n",
      "Topic 127: 127_million years_years ago_ago_million\n",
      "Representative Documents:\n",
      "  - On 25 September 2008, seismo meters operated by the Alaska Volcano Observatory (AVO) registered strong ground shaking. On the basis of previous experience with such large seismic signals, AVO personnel were able to rapidly identify the seismic event as an avalanche. Two days later, an AVO overflight of Iliamna volcano, near Alaska's Cook Inlet, confirmed that a massive chunk of glacial ice and rock had broken free from its position on the upper flanks of the volcano, generating a massive avalanche that could have buried an entire town had it occurred in a more populated area.Rapidly moving rock, ice, or debris avalanches, such as the one that occurred on Iliamna, can be highly destructive and deadly. Similar events have caused the deaths of hundreds to thousands of people [Keefer and Larsen, 2007]. In general, avalanches that move more than 1 million cubic meters of material are rare. However, a remarkable series of large avalanches recently occurred in Alaska and the Caucasus, providing a new opportunity to better understand this type of hazard. All events initiated in steep mountain slopes, involved rock and significant amounts of ice, and traveled for 10–35 kilometers.\n",
      "  - Stepping Down                      Earth's environment changed markedly over the past 5.2 million years, when a permanent ice sheet has developed in the Northern Hemisphere and the glacial cycle has changed its period from roughly every 40,000 years to the dominantly 100,000-year duration of the past half-million years. One of the biggest questions about these changes is whether they were “threshold” responses to a gradual, uniform cooling trend or whether they represent reactions to discrete episodes of cooling.            Sosdian and Rosenthal            (p.            306            ) present deep-ocean temperature records from the North Atlantic that show that the cooling happened in distinct steps, at 3 to 2.5 million years ago and at 1.2 to 0.85 million years ago. Combining their record with that of deep ocean water oxygen isotopes allowed the distinction between effects due to global cooling and ice-sheet dynamics.          \n",
      "  - From Big Fish to Big Whales                      Whales are the largest animals today, and many feed on the abundant plankton, particularly diatoms, in the oceans. Whales arose and diversified in the Cenozoic, about 30 to 40 million years ago (see the Perspective by                          Cavin                        ).            Marx and Uhen            (p.            993            ) show that their diversity parallels the diversity of diatoms and changes in ocean temperature. Whether there were large predators of plankton before whales has been enigmatic, because the fossil record during the Mesozoic (245 to 65 million years ago) is sparse.                          Friedman              et al.                        (p.            990            ) now show that a group of large fish filled this role for nearly 100 million years in the Mesozoic. Although not as large as whales, these globally distributed fish were still several meters long. Their extinction at the Cretaceous-Paleogene boundary 65.5 million years ago may have cleared the seas for the evolution of whales.          \n",
      "--------------------------------------------------\n",
      "Topic 128: 128_forecasts_downscaling_skill_downscaled\n",
      "Representative Documents:\n",
      "  -                The North American Multimodel Ensemble (NMME) forecasting system has been continuously producing seasonal forecasts since August 2011. The NMME, with its suite of diverse models, provides a valuable opportunity for characterizing forecast confidence using probabilistic forecasts. The current experimental probabilistic forecast product (in map format) presents the most likely tercile for the seasonal mean value, chosen out of above normal, near normal, or below normal categories, using a nonparametric counting method to determine the probability of each class. The skill of the 3-month-mean probabilistic forecasts of 2-m surface temperature (T2m), precipitation rate, and sea surface temperature is assessed using forecasts from the 29-yr (1982–2010) NMME hindcast database. Three forecast configurations are considered: a full six-model NMME; a “mini-NMME” with 24 members, four each from six models; and the 24-member CFSv2 alone. Skill is assessed on the cross-validated hindcasts using the Brier skill score (BSS); forecast reliability and resolution are also assessed. This study provides a baseline skill assessment of the current method of creating probabilistic forecasts from the NMME system.               For forecasts in the above- and below-normal terciles for all variables and geographical regions examined in this study, BSS for NMME forecasts is higher than BSS for CFSv2 forecasts. Niño-3.4 forecasts from the full NMME and the mini-NMME receive nearly identical BSS that are higher than BSS for CFSv2 forecasts. Even systems with modest BSS, such as T2m in the Northern Hemisphere, have generally high reliability, as shown in reliability diagrams.\n",
      "  - We assess the value of dynamical versus statistical downscaling of National Centers for Environmental Prediction's (NCEP) Climate Forecast System (CFS) winter season forecasts for seasonal hydrologic forecasting. Dynamically downscaled CFS forecasts for 1 December to 30 April of 1982–2003 were obtained from the Multi‐RCM Ensemble Downscaling (MRED) project that used multiple Regional Climate Models (RCMs) to downscale CFS forecasts. Statistical downscaling of CFS forecasts was achieved by a much simpler bias correction and spatial downscaling method. We evaluate forecast accuracy of runoff (RO), soil moisture (SM), and snow water equivalent produced by a hydrology model forced with dynamically (the MRED forecasts) and statistically downscaled CFS forecasts in comparison with predictions of those variables produced by forcing the same hydrology model with gridded observations (reference data set). Our results show that the MRED forecasts produce modest skill beyond what results from statistical downscaling of CFS. Although the improvement in hydrologic forecast skill associated with the ensemble average of the MRED forecasts (Multimodel) relative to statistical downscaled CFS forecasts is field significant for RO and SM forecasts with up to 3 months lead, the region of improvement is mainly limited to parts of the northwest and north central U.S. In general, one or more RCMs outperform the other RCMs as well as the Multimodel. Hence, we argue that careful selection of RCMs (based on their hindcast skill over any given region) is critical to improving hydrologic forecast skill using dynamical downscaling.\n",
      "  - Ongoing research by the Climate Impacts Group at the University of Washington focuses on the use of recent advances in climate research to improve streamflow forecasts at seasonal-to-interannual, decadal, and longer time scales. Seasonal-to-interannual climate forecasting capabilities have advanced significantly in the past several years, primarily because of improvements in the understanding of, and an ability to forecast, El Niño/Southern Oscillation (ENSO) at seasonal/interannual time scales, and because of better understanding of longer time scale climate phenomena like the Pacific Decadal Oscillation (PDO). These phenomena exert strong controls on climate variability along the Pacific Coast of North America.               The streamflow forecasting techniques we have developed for Pacific Northwest (PNW) rivers are based on climate forecasts that facilitate longer lead times (as much as a year) than the methods that are traditionally used for water management (maximum forecast lead times of a few months). At interannual time scales, the simplest of these techniques involves resampling meteorological data from previous years identified to be in similar climate categories as are forecast for the coming year. These data are then used to drive a hydrology model, which produces an ensemble of streamflow forecasts that are analogous to those that result from the well-known Extended Streamflow Prediction (ESP) method. This technique is a relatively simple, but effective, way of incorporating long-lead climate information into streamflow forecasts. It faithfully captures the history of observed climate variability. Its main limitation is that the sample size of observed events for some climate categories is small because of the length of the historic record. Furthermore, it is unable to capture important aspects of global change, which may interact with shorter term variations through changes in climate phenomena like ENSO and PDO. An alternative to the resampling method is to use nested regional climate models to produce the long-lead climate forecasts. Success using this approach has been hindered to some degree by the bias that is inherent in climate models, even when downscaled using regional nested modeling approaches. Adjustment or correction for this bias is central to the use of climate model output for hydrologic forecasting purposes. Approaches for dealing with climate model bias in the context of global and meso-scale are presently an area of active research. We illustrate an experimental application of the nested climate modeling approach for the Columbia River Basin, and compare it with the simpler resampling method.               At much longer time scales, changes in Columbia River flows that might be associated with global climate change are of considerable concern in the PNW, given recent Endangered Species Act listing of certain salmonid species, and the increase in water demand that is expected to follow increases in human population in the region. Many of the same general challenges associated with the spatial downscaling of climate forecasts are present in these long-range investigations. Additional uncertainties exist in the ability of climate models to predict the effects of changing greenhouse gas concentrations. These uncertainties tend to dominate the results, and lead us to use relatively simplemethods of downscaling seasonal temperature and precipitation to interpret the implications of alternative climate scenarios on PNW water resources.\n",
      "--------------------------------------------------\n",
      "Topic 129: 129_runoff_swat_streamflow_scenarios\n",
      "Representative Documents:\n",
      "  - Climate change will have a significant impact on the water cycle and will lead to severe environmental problems and disasters in humid tropical river basins. Examples include river basins in Sumatra Island, Indonesia, where the coastal lowland areas are mostly composed of peatland that is a wetland environment initially sustained by flooding from rivers. Climate change may alter the frequency and magnitude of flood inundation in these lowland areas, disturbing the peatland environment and its carbon dynamics and damaging agricultural plantations. Consequently, projecting the extent of inundation due to future flooding events is considered important for river basin management. Using dynamically downscaled climate data obtained by the Non-Hydrostatic Regional Climate Model (NHRCM), the Rainfall-Runoff-Inundation (RRI) model was applied to the Batanghari River Basin (42,960 km2) in Sumatra Island, Indonesia, to project the extent of flood inundation in the latter part of the twenty-first century. In order to obtain reasonable estimates of the extent of future flood inundation, this study compared two bias correction methods: a Quantile Mapping (QM) method and a combination of QM and Variance Scaling (VS) methods. The results showed that the bias correction obtained by the QM method improved the simulated flow duration curve (FDC) obtained from the RRI model, which facilitated comparison with the simulated FDC using reference rainfall data. However, the high spatial variability observed in daily and 15-day rainfall data remained as the spatial variation bias, and this could not be resolved by simple QM bias correction alone. Consequently, the simulated extreme variables, such as annual maximum flood inundation volume, were overestimated compared to the reference data. By introducing QM-VS bias correction, the cumulative density functions of annual maximum discharge and inundation volumes were improved. The findings also showed that flooding will increase in this region; for example, the flood inundation volume corresponding to a 20-year return period will increase by 3.3 times. River basin management measures, such as land use regulations for plantations and wetland conservation, should therefore consider increases in flood depth and area, the extents of which under a future climate scenario are presented in this study.\n",
      "  - SummaryThe objective of this research is to investigate the effect of land‐use and climate change on the volume of runoff produced and its impact on water resources. It is clear that the more accurate the assessment of runoff in the future, the better the evaluation of the impact of land‐use and climate changes on water resources. Thus, to more accurately predict water sources in the future, runoff is estimated using two Soil and Water Assessment Tool (SWAT) and SWAT‐DEEP‐IFSO models. The results showed that the SWAT‐DEEP‐IFSO model has a better estimation than the SWAT method. Because Deep Belief Network and an improved optimization algorithm called Improved Fluid Search Optimization (IFSO) algorithm have been utilized in optimizing the hybrid SWAT model that can reduce the error of runoff simulation. After selecting the best model for estimating runoff, the effect of land‐use and climate change is evaluated using different scenarios. Results show that the simulated runoff under the influence of climate and land‐use changes can impact on the average yearly and monthly runoff. These factors have a significant effect on the average yearly runoff changes and are predicted an increasing trend for average yearly runoff. But climate and land‐use changes have a different impact on the different months and for some months of the year the runoff has an increasing trend and for some months the runoff has a decreasing trend. Based on land‐use scenarios, it is found that due to the decrease in rangelands and increase in agricultural lands, there is a possibility of severe floods and drought periods in the region, which reduces the water resources of the study area.\n",
      "  - Torrents play an essential role in water resources through rainfall in arid to semi-arid mountainous regions, serving large populations worldwide, and are also crucial in maintaining the downstream environment. The natural flows (floods, ephemeral flows) in arid hill regions result in potential hydrological fluctuations caused by climate change. However, the feasibility of eventual storage in remote hilly catchments would force a more sudden change. The current study was conducted in the lower part of the Khirthar National Range in the Sindh province of Pakistan, with the aim to explore spatial runoff storage sites for sustainable development to mitigate the impacts of climate change in arid areas. In total, 83 years of precipitation data were used to estimate water availability, along with satellite imagery for LULC pre- and post-monsoon conditions, delineation of watersheds, and identification of potential runoff storage locations and return periods, using Remote Sensing (RS)/Geographical Information System (GIS) 10.5.1, HEC-HMS 3.1, and Origin Pro 9.0 for statistical approaches. The model delineated two potential watersheds: Goth Sumar, covering an area of 61.0456 km2, wherein ten cascading reservoirs were identified, and Goth Baro, covering an area of 14,236 km2, wherein two cascading reservoirs were identified. Different storage capacities were determined for the cascade-type reservoirs. The maximum live volumetric potential storage of the reservoirs varies from 0.25 to 1.32 million cubic meters (MCM) in the villages of Baro and Sumar. The return periods have been estimated at 5, 10, 20, 25, 50, and 75 years, corresponding to 12.35, 16.47, 21.43, 21.72, 25.21, and 40.53 MCM for Goth Sumar, while Goth Baro’s storage capacity has been estimated at 2.88, 3.84, 5.00, 5.06, 5.88, and 9.45 MCM, respectively. All results obtained were authenticated using accuracy assessment, validation, and sensitivity analysis. The proposed potential storage sites were recommended for a planning period of five years. The live storage capacity of the identified cascade reservoirs can be improved by raising the marginal banks and developing the spillways to control inlet and outlet flow in order to maintain internal pressure on the reservoir banks. The stored water can be used for climate-friendly agricultural activities to increase crop production and productivity. The proposed study area has extensive experience with flood irrigation systems and rainwater harvesting to sustain agriculture due to rainfall being the only water resource (WR) in the region. However, the study area has enormous potential for surface runoff WRs, especially during the rainy season (monsoon); the current 2022 monsoon is showing flooding. The modeling approaches of Remote Sensing, GIS, and HEC-HMS play an important role in delineating watershed areas, developing hydrographs, and simulating water availability for different return periods by minimizing cost and time.\n",
      "--------------------------------------------------\n",
      "Topic 130: 130_reanalysis_grace_ersst_errors\n",
      "Representative Documents:\n",
      "  - Recent studies show that data from the Gravity Recovery and Climate Experiment (GRACE) is promising for basin‐ to global‐scale water cycle research. This study provides varied assessments of errors associated with GRACE water storage estimates. Thirteen monthly GRACE gravity solutions from August 2002 to December 2004 are examined, along with synthesized GRACE gravity fields for the same period that incorporate simulated errors. The synthetic GRACE fields are calculated using numerical climate models and GRACE internal error estimates. We consider the influence of measurement noise, spatial leakage error, and atmospheric and ocean dealiasing (AOD) model error as the major contributors to the error budget. Leakage error arises from the limited range of GRACE spherical harmonics not corrupted by noise. AOD model error is due to imperfect correction for atmosphere and ocean mass redistribution applied during GRACE processing. Four methods of forming water storage estimates from GRACE spherical harmonics (four different basin filters) are applied to both GRACE and synthetic data. Two basin filters use Gaussian smoothing, and the other two are dynamic basin filters which use knowledge of geographical locations where water storage variations are expected. Global maps of measurement noise, leakage error, and AOD model errors are estimated for each basin filter. Dynamic basin filters yield the smallest errors and highest signal‐to‐noise ratio. Within 12 selected basins, GRACE and synthetic data show similar amplitudes of water storage change. Using 53 river basins, covering most of Earth's land surface excluding Antarctica and Greenland, we document how error changes with basin size, latitude, and shape. Leakage error is most affected by basin size and latitude, and AOD model error is most dependent on basin latitude.\n",
      "  -                Until recently, monthly rainfall products using the National Oceanic and Atmospheric Administration National Environmental Satellite, Data, and Information Service Office of Research and Applications Special Sensor Microwave Imager (SSM/I) rainfall algorithm have been generated on a global 2.5° × 2.5° grid. The rainfall estimates are based on a subsampled set of the full-resolution SSM/I data, with a resulting spatial density of about one-third of what is possible at SSM/I’s highest spatial resolution. The reduction in the spatial resolution was introduced in 1992 as a compromise dictated by data processing capabilities. Currently, daily SSM/I data processing at full resolution has been established and is being operated in parallel with the subsampled set. Reprocessing of the entire SSM/I time series based on the full-resolution data is plausible but requires the reprocessing of over 10 yr of retrospective data. Because the Global Precipitation Climatology Project is considering the generation of a daily 1° × 1° rainfall product, it is important that the effects of using the reduced spatial resolution be reexamined.               In this study, error due to using the reduced-resolution versus the full-resolution SSM/I data in the gridded products at 2.5° and 1° grid sizes is examined. The estimates are based on statistics from radar-derived rain data and from SSM/I data taken over the Tropical Ocean and Global Atmosphere Coupled Ocean–Atmosphere Response Experiment (TOGA COARE) radar site. SSM/I data at full resolution were assumed to provide rain estimates with 12.5-km spacing. Subsampling with spacings of 25, 37.5 (which corresponds to the present situation of ⅓° latitude–longitude spatial resolution), and 50 km were considered. For the instantaneous 2.5° × 2.5° product, the error due to subsampling, expressed as a percentage of the gridbox mean, was estimated using radar-derived data and was 6%, 10%, and 15% at these successively poorer sampling densities. For monthly averaged products on a 2.5° × 2.5° grid, it was substantially lower: 3%, 4%, and 7%, respectively. Subsampling errors for monthly averages on a 1° × 1° grid were 8%, 16%, and 23%, respectively. Estimates based on SSM/I data at full resolution gave errors that were somewhat larger than those from radar-based estimates. It was concluded that a rain product of monthly averages on a 1° × 1° grid must use the full-resolution SSM/I data. More work is needed to determine how applicable these estimates are to other areas of the globe with substantially different rain statistics.\n",
      "  -                Land surface variables, such as soil moisture, are among the most important components of memory for the climate system. A more accurate and long time series of land surface data is very important for real-time drought monitoring, for understanding land surface–atmosphere interaction, and for improving weather and climate prediction. Thus, the ultimate goal of the present work is to produce a long-term “land reanalysis” with 1) retrospective and 2) real-time update components that are both generated in a manner that remains temporally homogeneous throughout the record. As the first step of the above goal, the retrospective component is reported here. Specifically, a 51-yr (1948–98) set of hourly land surface meteorological forcing is produced and used to execute the Noah land surface model, all on the 1/8° grid of the North American Land Data Assimilation System (NLDAS). The surface forcing includes air temperature, air humidity, surface pressure, wind speed, and surface downward shortwave and longwave radiation, all derived from the National Centers for Environmental Prediction–National Center For Atmospheric Research (NCEP–NCAR) Global Reanalysis. Additionally, a newly improved precipitation analysis is used to provide realistic hourly precipitation forcing on the NLDAS grid. Some unique procedures are described and applied to yield retroactive forcing that is temporally homogeneous over the 51 yr at the spatial and temporal resolution, including a terrain height adjustment that accounts for the terrain differences between the global reanalysis and the NLDAS. The land model parameters and fixed fields are derived from existing high-resolution datasets of vegetation, soil, and orography. The land reanalysis output from the Noah land surface model consists of eight energy balance components and skin temperature, which are output at 3-hourly intervals, and 15 other variables (i.e., water balance components, surface state variables, etc.), which are output at daily intervals for the period of 1 January 1948 through 31 December 1998.               Using soil moisture observations throughout Illinois over 1984–98 as validation, an improvement in the simulated soil moisture (of the Noah model versus a forerunner leaky bucket model) is illustrated in terms of an improved annual cycle (much better phasing) and somewhat higher anomaly correlation for the anomalies, especially in central and southern Illinois. Nonetheless, considerable room for model improvement remains. For example, the simulated anomalies are overly uniform in the vertical compared to the observations, and some likely routes for model improvement in this aspect are proposed.\n",
      "--------------------------------------------------\n",
      "Topic 131: 131_sediment_incision_fan_terraces\n",
      "Representative Documents:\n",
      "  - The effects of climate change on eroding landscapes and the terrestrial sedimentary record are poorly understood. Using mountain catchment–alluvial fan systems as simple analogues for larger landscapes, a wide range of theoretical studies, numerical models and physical experiments have hypothesized that a change in precipitation rate could leave a characteristic signal in alluvial fan sediment flux, grain size and down‐system fining rate. However, this hypothesis remains largely untested in real landscapes. This study measures grain‐size fining rates from apex to toe on two alluvial fan systems in northern Death Valley, California, USA, which each have well‐exposed modern and ca 70 ka surfaces, and where the long‐term tectonic boundary conditions can be constrained. Between them, these surfaces capture a well‐constrained temporal gradient in climate. A grain‐size fining model is adapted, based on self‐similarity and selective deposition, for application to these alluvial fans. This model is then integrated with cosmogenic nuclide constraints on catchment erosion rates, and observed grain‐size fining data from two catchment‐fan systems, to estimate the change in sediment flux from canyon to alluvial fan that occurred between mid‐glacial and modern interglacial conditions. In a fan system with negligible sediment recycling, a ca 30% decrease in precipitation rate led to a 20% decrease in sediment flux and a clear increase in the down‐fan rate of fining, supporting existing landscape evolution models. Consequently, this study shows that small mountain catchments and their alluvial fan stratigraphy can be highly sensitive to orbital climate changes over &lt;105 year timescales. However, in the second fan system it is observed that this sensitivity is completely lost when sediment is remobilized and recycled over a time period longer than the duration of the climatic perturbation. These analyses offer a new approach to quantitatively reconstructing the effects of past climate changes on sedimentation, using simple grain‐size data measured in the field.\n",
      "  - Sequence‐stratigraphic models for fourth to sixth order, glacio‐eustatic sequences based only on relative sea‐level variations result in simplified and potentially false interpretations. Glacio‐eustatic sea‐level variations form only one aspect of cyclic climate variation; other aspects, such as variations in fluvial water discharge, vegetation cover, weathering and sediment supply can lead to variable sediment yield, thus adding complexity to sequence‐stratigraphic patterns normally attributed to sea‐level variations. Analogue flume models show a significant impact of water discharge on the timing and character of sequence boundaries, and on changes in the relative importance of systems tracts, as expressed in sediment volumes. Four deltas, generated under the influence of an identical sea‐level curve, and affected by different water‐discharge cycles were generated in the Eurotank facility: (1) constant discharge; (2) high‐frequency discharge variations (HFD); (3) discharge leading sea level by a quarter phase; (4) discharge lagging sea level by a quarter phase. HFD shift the parasequence stacking pattern consistently but do not alter large‐scale delta architecture. Water‐discharge changes that lead sea‐level changes result in high sediment yield during sea‐level rise and in the poor development of maximum flooding surfaces. Delta‐front erosion during sea‐level fall is expressed by multiple, small channels related to upstream avulsions, and does not result in an incised valley that efficiently routs sediment to the shelf edge. When water‐discharge changes lag sea‐level changes, sediment yield is high during falling sea level and results in rapid progradation during forced regression. Erosion from incised valleys is strong on the proximal delta top and dissipates towards the delta front. The combination of high discharge and sea‐level fall provides the most efficient mode of valley incision and sediment transport to the shelf edge. During sea‐level rise, low water discharge results in sediment starvation and well‐developed maximum flooding surfaces. Water‐discharge variations thus alter sequence‐stratigraphic patterns and provide an alternative explanation to the amplitude of sea‐level fall for generating either type 1 or 2 erosional unconformities.\n",
      "  - Many river systems in western North America retain a fluvial strath-terrace rec ord of discontinuous downcutting into bedrock through the Quaternary. Their importance lies in their use to interpret climatic events in the headwaters and to determine long-term incision rates. Terrace formation has been ascribed to changes in sediment supply and/or water discharge produced by late Quaternary climatic fluctuations. We use a one-dimensional channel- evolution model to explore whether temporal variations in sediment and water discharge can generate terrace sequences. The model includes sediment transport, vertical bedrock erosion limited by alluvial cover, and lateral valley-wall erosion. We set limits on our modeling by using data collected from the terraced Wind River basin. Two types of experiments were performed: constant- period sinusoidal input histories and variable-period inputs scaled by the marine δ18O rec ord. Our simulations indicate that strath-terrace formation requires input variability that produces a changing ratio of vertical to lateral erosion rates. Straths are cut when the channel floor is protected from erosion by sediment and are abandoned—and terraces formed—when incision can resume following sediment-cover thinning. High sediment supply promotes wide valley floors that are abandoned as sediment supply decreases. In contrast, wide valleys are promoted by low effective water discharge and are abandoned as discharge increases. Widening of the valley floors that become terraces occurs over many thousands of years. The transition from valley widening to downcutting and terrace creation occurs in response to subtle input changes affecting local divergence of sediment-transport capacity. Formation of terraces lags by several thousand years the input changes that cause their formation.Our results suggest that use of terrace ages to set limits on the timing of a specific event must be done with the knowledge that the system can take thousands of years to respond to a perturbation. The incision rate calculated in the field from the lowest terrace in these systems will likely be higher than the rate calculated by using older terraces, because the most recent fluvial response in the field is commonly downcutting associated with declining sediment input since the Last Glacial Maximum. This apparent increase in incision rates is observed in many river systems and should not necessarily be interpreted as a response to an increase in rock-uplift rate.\n",
      "--------------------------------------------------\n",
      "Topic 132: 132_phytoplankton_bloom_warming_biomass\n",
      "Representative Documents:\n",
      "  - To assess protistan grazing impact and temperature sensitivity on plankton population dynamics, we measured bulk and species-specific phytoplankton growth and herbivorous protist grazing rates in Disko Bay, West Greenland in April-May 2011. Rate estimates were made at three different temperatures in situ (0 °C), +3 °C and +6 °C over ambient. In situ Chlorophylla(Chla) doubled during the observation period to ∼12  µg ChlaL−1, with 60–97% of Chlain the &gt;20 µm size-fraction dominated by the diatom genusChaetoceros.Herbivorous dinoflagellates comprised 60–80% of microplankton grazer biomass. At in situ temperatures, phytoplankton growth or grazing by herbivorous predators &lt;200 µm was not measurable until 11 days after observations commenced. Thereafter, phytoplankton growth was on average 0.25 d−1. Phytoplankton mortality due to herbivorous grazing was only measured on three occasions but the magnitude was substantial, up to 0.58 d−1. Grazing of this magnitude removed ∼100% of primary production. In short-term temperature-shift incubation experiments, phytoplankton growth rate increased significantly (20%) at elevated temperatures. In contrast, herbivorous protist grazing and species-specific growth rates decreased significantly (50%) at +6 °C. This differential response in phytoplankton and herbivores to temperature increases resulted in a decrease of primary production removed with increasing temperature.Phaeocystisspp. abundance was negatively correlated with bulk grazing rate. Growth and grazing rates were variable but showed no evidence of an inherent, low temperature limitation. Herbivorous protist growth rates in this study and in a literature review were comparable to rates from temperate waters. Thus, an inherent physiological inhibition of protistan growth or grazing rates in polar waters is not supported by the data. The large variability between lack of grazing and high rates of primary production removal observed here and confirmed in the literature for polar waters implies larger amplitude fluctuations in phytoplankton biomass than slower, steady grazing losses of primary production.\n",
      "  - In many ecosystems, consumers respond to warming differently than their resources, sometimes leading to temporal mismatches between seasonal maxima in consumer demand and resource availability. A potentially equally pervasive, but less acknowledged threat to the temporal coherence of consumer‐resource interactions is mismatch in food quality. Many plant and algal communities respond to warming with shifts toward more carbon‐rich species and growth forms, thereby diluting essential elements in their biomass and intensifying the stoichiometric mismatch with herbivore nutrient requirements. Here we report on a mesocosm experiment on the spring succession of an assembled plankton community in which we manipulated temperature (ambient vs. +3.6°C) and presence versus absence of two types of grazers (ciliates and Daphnia), and where warming caused a dramatic regime shift that coincided with extreme stoichiometric mismatch. At ambient temperatures, a typical spring succession developed, where a moderate bloom of nutritionally adequate phytoplankton was grazed down to a clear‐water phase by a developing Daphnia population. While warming accelerated initial Daphnia population growth, it speeded up algal growth rates even more, triggering a massive phytoplankton bloom of poor food quality. Consistent with the predictions of a stoichiometric producer–grazer model, accelerated phytoplankton growth promoted the emergence of an alternative system attractor, where the extremely low phosphorus content of the abundant algal food eventually drove Daphnia to extinction. Where present, ciliates slowed down the phytoplankton bloom and the deterioration of its nutritional value, but this only delayed the regime shift. Eventually, phytoplankton also grew out of grazer control in the presence of ciliates, and the Daphnia population crashed. To our knowledge, the experiment is the first empirical demonstration of the “paradox of energy enrichment” (grazer starvation in an abundance of energy‐rich but nutritionally imbalanced food) in a multispecies phytoplankton community. More generally, our results support the notion that warming can exacerbate the stoichiometric mismatch at the plant–herbivore interface and limit energy transfer to higher trophic levels.\n",
      "  - Global warming has been shown to affect ecosystems worldwide. Warming may, for instance, disrupt plant herbivore synchrony and bird phenology in terrestrial systems, reduce primary production in oceans, and promote toxic cyanobacterial blooms in freshwater lakes. Responses of communities will not only depend on direct species‐specific temperature effects, but also on indirect effects related to bottom‐up and top‐down processes. Here, we investigated the impact of warming on freshwater phytoplankton community dynamics, and assessed the relative contribution of nutrient availability, fungal parasitism, and grazing therein. For this purpose, we performed an indoor mesocosm experiment following seasonal temperature dynamics of temperate lakes and a warmed (+4°C) scenario from early spring to late summer. We assessed phytoplankton biomass, C:N:P stoichiometry and community composition, dissolved nutrient availabilities, fungal parasite (i.e., chytrid) prevalence, and zooplankton abundance. Warming led to an overall reduction in phytoplankton biomass as well as lower C:P and N:P ratios, while phytoplankton community composition remained largely unaltered. Warming resulted in an earlier termination of the diatom spring bloom, and an epidemic of its fungal parasite ended earlier as well. Furthermore, warming advanced zooplankton phenology, leading to an earlier top‐down control on phytoplankton in the period after the spring bloom. Linear model analysis showed that most of the observed variance in phytoplankton biomass was related to seasonal temperature dynamics in combination with zooplankton abundance. Our findings showed that warming advanced grazer phenology and reduced phytoplankton biomass, thereby demonstrating how bottom‐up and top‐down related processes may shape future phytoplankton dynamics.\n",
      "--------------------------------------------------\n",
      "Topic 133: 133_lake_lakes_phytoplankton_hypolimnetic\n",
      "Representative Documents:\n",
      "  - Duration and timing of thermal stratification and the period of vertical mixing are crucial for internal chemical and biological processes of deep temperate lakes. Climatic changes induced a prolongation of thermal stratification in many lakes over the last decades. This study provides a comparative assessment of observed climate‐induced changes in thermal and limnological properties of three originally dimictic temperate lakes.We analysed 41 years of vertical sampling data of Lake Irrsee (IR), Mondsee (MO) and Hallstätter See (HA) located in the Salzkammergut lake district of Austria. We examined temperatures in surface and bottom waters, quantified changes in thermal regimes and investigated the development of hypoxia, anoxia and phosphorus concentrations of the three lakes from 1975 to 2015.Mean annual surface‐water temperatures increased substantially, whereas bottom‐water temperatures showed insignificant trends in IR and MO and a slight rising trend in HA. Resulting higher vertical temperature gradients caused stronger thermal stabilities of the lakes. Based on calculations of daily thermal stability, all three lakes showed a significant prolongation of the stratification period with +31 days (±7 days) in IR, +37 days (±7 days) in MO and +28 (±8 days) in HA. We observed greater changes in the timing of onset of stratification compared to the changes in the timing of stratification termination (IR onset −19 days versus termination +11 days, MO onset −21 days versus termination +16 days, HA onset −16 days versus termination +12 days).We found that expanding seasonal hypoxia and anoxia were correlated to prolonged seasonal stratifications and to increasing phosphorus concentrations in bottom‐water layers. However, higher phosphorus concentrations in bottom waters did not raise the lakes′ volume‐weighted total phosphorus concentrations.Under ongoing climate change, alterations in the thermal characteristics will inevitably lead to a transition of mixing regimes from a dimictic to a monomictic mixing pattern in originally ice‐covered temperate lakes. Our investigation revealed that this transition will be earlier in larger and deeper lakes.\n",
      "  - SummaryDuring recent decades, climate change and re‐oligotrophication have been affecting many lakes. Most long‐term research focuses on large North American and northern European lakes, but climate forcing south of the Alps seems to be different. Furthermore, lake restoration frequently involves smaller lakes (&lt;10 km2) that are often overlooked in long‐term limnological studies despite their importance for local stakeholders. We investigated the effects of climate change and re‐oligotrophication on the thermal structure of Lake Caldonazzo (Italy – southern Alps; area = 5.6 km2; maximum depth = 49 m) for the years 1973–2014. The lake received untreated wastewaters from its catchment until the mid‐1970s, leading to algal blooms, severe hypolimnetic anoxia and fish kills. Afterwards, local government initiated sewage removal that was completed in 1989.We used transparency, phosphorus and chlorophyll concentrations as trophic indicators, air temperature and global circulation indices as climatic indicators and epilimnion depth and temperature, hypolimnion temperature, thermocline depth and Schmidt stability as indicators of thermal structure. For these time series, we determined trend patterns and timing of change points.Epilimnetic temperatures showed an upward shift in 1985. Here, we present an alternative explanation for this observed change that generally has been attributed to global circulation indices. Epilimnetic depth continually increased until 1989, but less markedly afterwards. We suggest that until restoration continued, the increasingly deeper epilimnion absorbed the incoming heat of climate change without increasing epilimnetic temperature. After sewage removal, however, the epilimnion did not deepen enough to prevent an upward shift in epilimnetic temperature. We linked the deepening of the epilimnion to increased water transparency.Hypolimnetic temperatures showed a downward shift in 1998. Hypolimnetic cooling has been seldom observed and was in our case related to specific interactions between re‐oligotrophication, climate and lake depth. Penetration of incident solar radiation was insufficient to heat the hypolimnion (&gt;50% of lake volume), while deeper mixing released accumulated heat from the previous season and earlier stratification trapped colder water in the hypolimnion. We suggest that these combined effects resulted in a decrease in hypolimnetic temperature.Our study indicated that re‐oligotrophication mitigated the effects of climate change, but when re‐oligotrophication was no longer progressing, the effects of climate on thermal structure were perceivable. These changes were site specific and not tied to atmospheric circulation indices. Epilimnetic warming in particular will have repercussions on plankton dynamics. Management of non‐point sources of nutrients will become increasingly important to limit the eutrophication‐like effects of climate change, especially in the case of a warming epilimnion.\n",
      "  - Climate warming is causing changes in the physics of deep lakes, such as longer summer stratification, increased water column stability, reduced ice cover, and a shallower depth of winter overturns. An ultimate consequence of warming would be a transition to a different mixing regime. Here we investigate the role of physical, chemical, and biological feedback mechanisms that unfold during a shift in mixing regime, and whether these feedbacks could prompt and stabilise the new regime. Although climate, interannual temperature variation, and lake morphometry are the main determinants of a mixing regime, when climate change causes shifts in mixing regime, internal feedback mechanisms may gain in importance and modify lake ecosystem functioning.We review the role of these feedbacks in three mixing regime shifts: from polymictic to seasonally stratified, from dimictic to monomictic, and from holomictic to oligomictic or meromictic.Polymictic lakes of intermediate depth (c. 3–10 m mean depth) could experience seasonal stratification if a stratification event triggers phytoplankton blooms or dissolved organic matter release, reducing transparency and therefore further heating the surface layer. However, this feedback is only likely to have influence in small and clear lakes, it would be easily disturbed by weather conditions, and the resulting stratified state does not remain stable in the long term, as stratification is lost in winter.The ice‐albedo feedback might cause an accelerated shift from ice‐covered (dimictic) to ice‐free (monomictic) winters in sufficiently deep (mean depth 50 m or more) lakes, where temperature memory is carried over from one winter to the next. Nevertheless, there is an ongoing debate into whether this process can persist during natural weather variations and overcome self‐stabilising mechanisms such as thermal insulation by snow. The majority of studies suggest that a gradual transition from dimictic to monomictic is more likely than an abrupt transition.A shift from a holomictic to a meromictic regime can occur if anoxia is triggered by incomplete mixing and an increase in deep‐water density—through the accumulation of solutes—exceeds a density decrease by hypolimnetic warming. A shift to meromixis would strongly alter the biology of a lake and might be difficult to reverse. If solutes accumulate only minimally in the hypolimnion, an oligomictic regime is formed, in which years with complete and incomplete mixing alternate.Understanding the importance of feedback mechanisms and the role of biogeochemistry when lakes shift in mixing regime could lead to a better understanding of how climate change affects lake ecosystems.\n",
      "--------------------------------------------------\n",
      "Topic 134: 134_conservation_management_ecosystems_adaptation\n",
      "Representative Documents:\n",
      "  - Recent rapid changes in the Earth's climate have altered ecological systems around the globe. Global warming has been linked to changes in physiology, phenology, species distributions, interspecific interactions, and disturbance regimes. Projected future climate change will undoubtedly result in even more dramatic shifts in the states of many ecosystems. These shifts will provide one of the largest challenges to natural resource managers and conservation planners. Managing natural resources and ecosystems in the face of uncertain climate requires new approaches. Here, the many adaptation strategies that have been proposed for managing natural systems in a changing climate are reviewed. Most of the recommended approaches are general principles and many are tools that managers are already using. What is new is a turning toward a more agile management perspective. To address climate change, managers will need to act over different spatial and temporal scales. The focus of restoration will need to shift from historic species assemblages to potential future ecosystem services. Active adaptive management based on potential future climate impact scenarios will need to be a part of everyday operations. And triage will likely become a critical option. Although many concepts and tools for addressing climate change have been proposed, key pieces of information are still missing. To successfully manage for climate change, a better understanding will be needed of which species and systems will likely be most affected by climate change, how to preserve and enhance the evolutionary capacity of species, how to implement effective adaptive management in new systems, and perhaps most importantly, in which situations and systems will the general adaptation strategies that have been proposed work and how can they be effectively applied.\n",
      "  - Various international and national regulations hold polluters liable for the cleanup of released hazardous substances and the restoration/rehabilitation of natural resources to preincident baseline conditions, a process often referred to as natural resource damage assessment and restoration (NRDAR). Here, we, the authors, describe how global climate change (GCC) will challenge each of the steps of NRDAR processes and offer eight recommendations to improve these processes in light of GCC. First, we call for a better understanding of the net effects of GCC and contaminants on natural resources. Second, we urge facilities and environmental managers to plan for GCC‐related factors that are expected to increase the probability of contaminant releases. Third, we suggest re‐evaluating definitions of baseline and reference conditions given that GCC will alter both their trajectories and variability. Fourth, we encourage long‐term monitoring to improve the quantification of baseline conditions that will change as climate changes. This will enhance the accuracy of injury assessments, the effectiveness of restoration, and the detection of early warning signs that ecosystems are approaching tipping points. Fifth, in response to or anticipation of GCC, restoration projects may need to be conducted in areas distant from the site of injury or focused on functionally equivalent natural resources; thus, community involvement in NRDAR processes will be increasingly important. Sixth, we promote using NRDAR restoration projects as opportunities to mitigate GCC‐related impacts. Seventh, we recommend adaptive management approaches to NRDAR processes and communication of successes and failures widely. Finally, we recommend focusing on managing the stressors that might be exacerbated by GCC, such as pollution and habitat loss, because there is a long history of successfully mitigating these stressors, which can be more easily managed on local scales than climate change. We believe that adoption of these recommendations will lead to a more efficacious NRDAR process, despite the challenges posed by climate change. Environ. Toxicol. Chem. 2013;32:93–101. © 2012 SETAC\n",
      "  - Australia’s future landscapes will be shaped by global climatic, economic, and cultural drivers. Landscapes evolve. They are manifestations of the complex negotiations between nature and cultures, over millennia. In the Anthropocene, humans are the dominant evolutionary force reshaping the biosphere. Landscape management involves all human activities and interventions that change the forms and functions of landscapes. It also involves the ways we learn about, and understand the world, and our place in it. Responses to climate change are driving changes in natural resources policy, research and management. Building capability for large-scale, adaptive management is critical in an era of global change. By rigorously examining and learning from recent experience—bioregional conservation planning, natural resource management (NRM), landcare, and water reform—Australia can build capacity for integrated and adaptive resource management. Climate change compounds existing stressors on ecosystems. It adds complexity and presents new challenges for integrated assessment, planning, and management of natural resources. Given the dynamic nature of the ecosystems, static conservation paradigms and stationary hydrology models are increasingly redundant. In the face of inherent complexity and uncertainty, ‘predict and control’ strategies are likely to be less useful. Adaptive approaches are called for, due to the complex relationships and non-linear feedbacks between social, ecological, and climatic systems. Australia should invest in building professional and community capacity. Australia’s scientific and professional capacity in natural resources provides useful foundations, but substantially increased investment is called for. Research should be focused on guiding and influencing management at large scales and on avoiding undesirable thresholds or tipping points in complex ecological systems. Cultural and governance aspects are emphasised as central to effective adaptation strategies, because landscape management is an intergenerational, societal challenge that requires participatory, adaptive learning approaches.\n",
      "--------------------------------------------------\n",
      "Topic 135: 135_via link top_via link_link top_link top via\n",
      "Representative Documents:\n",
      "  - An amendment to this paper has been published and can be accessed via a link at the top of the paper.\n",
      "  - An amendment to this paper has been published and can be accessed via a link at the top of the paper.\n",
      "  - An amendment to this paper has been published and can be accessed via a link at the top of the paper.\n",
      "--------------------------------------------------\n",
      "Topic 136: 136_aerosol_particles_dust_sulfate\n",
      "Representative Documents:\n",
      "  - The indirect effect of aircraft soot on cirrus clouds is subject to large uncertainties due to uncertainty in the effectiveness of aircraft soot acting as heterogeneous ice nuclei (IN) and the complexity caused by background ice nucleation, which introduces two major competing ice nucleation mechanisms: homogeneous freezing that generally produces more abundant ice particles and heterogeneous nucleation that generally produces fewer ice particles. In this paper, we used the coupled Community Atmosphere Model version 5.2 (CAM5)/IMPACT model to estimate the climate impacts of aircraft soot acting as IN in large‐scale cirrus clouds. We assume that only the aircraft soot particles that are preactivated in persistent contrail cirrus clouds are efficient IN. Further, we assume that these particles lose their ability to act as efficient IN when they become coated with three monolayers of sulfate. We varied the background number concentration of sulfate aerosols allowed to act as homogeneous ice nucleation sites as well as the dust concentrations that act as heterogeneous ice nuclei to examine the sensitivity of the forcing by aircraft soot to the background atmosphere. The global average effect can range from a high negative (cooling) rate, −0.35 W m−2, for the high sulfate/low dust case to a positive (warming) rate, +0.09 W m−2, for the low sulfate/low dust case (default CAM5 setup) when approximately 0.6% of total aviation soot acts as IN. The net negative forcing is caused by the addition of IN to a background atmosphere that is dominated by homogeneous nucleation (mainly in the tropic Indian Ocean, Central America, and North Atlantic Ocean). The forcings can be all positive, about +0.11 to +0.21 W m−2, when the background atmosphere is dominated by pure heterogeneous ice nucleation.\n",
      "  - . Nucleation from the gas phase is an important source of aerosol particles in the Earth's atmosphere, contributing to the number of cloud condensation nuclei, which form cloud droplets. We have implemented in the aerosol-climate model ECHAM5-HAM a new scheme for neutral and charged nucleation of sulfuric acid and water based on laboratory data, and nucleation of an organic compound and sulfuric acid using a parametrization of cluster activation based on field measurements. We give details of the implementation, compare results with observations, and investigate the role of the individual aerosol nucleation mechanisms for clouds and the Earth's radiative forcing. The results of our simulations are most consistent with observations when neutral and charged nucleation of sulfuric acid proceed throughout the troposphere and nucleation due to cluster activation is limited to the forested boundary layer. The globally averaged annual mean contributions of the individual nucleation processes to total absorbed solar short-wave radiation via the direct, semi-direct, indirect cloud-albedo and cloud-lifetime effects in our simulations are −1.15 W/m2 for charged H2SO4/H2O nucleation, −0.235 W/m2 for cluster activation, and −0.05 W/m2 for neutral H2SO4/H2O nucleation. The overall effect of nucleation is −2.55 W/m2, which exceeds the sum of the individual terms due to feedbacks and interactions in the model. Aerosol nucleation contributes over the oceans with −2.18 W/m2 to total absorbed solar short-wave radiation, compared to −0.37 W/m2 over land. We explain the higher effect of aerosol nucleation on Earth's radiative forcing over the oceans with the larger area covered by ocean clouds, due to the larger contrast in albedo between clouds and the ocean surface compared to continents, and the larger susceptibility of pristine clouds owing to the saturation of effects. The large effect of charged nucleation in our simulations is not in contradiction with small effects seen in local measurements: over southern Finland, where cluster activation proceeds efficiently, we find that charged nucleation of sulfuric acid and water contributes on average less than 10% to ultrafine aerosol concentrations, in good agreement with observations.                    \n",
      "  - . In this paper, we investigate the coagulation of interstitial aerosol particles (particles too small to activate to cloud droplets) with cloud drops, a process often ignored in aerosol-climate models. We use the GEOS-Chem-TOMAS (Goddard Earth Observing System-Chemistry TwO-Moment Aerosol Sectional) global chemical transport model with aerosol microphysics to calculate the changes in the aerosol size distribution, cloud-albedo aerosol indirect effect, and direct aerosol effect due to the interstitial coagulation process. We find that inclusion of interstitial coagulation in clouds lowers total particle number concentrations by 15–21% globally, where the range is due to varying assumptions regarding activation diameter, cloud droplet size, and ice cloud physics. The interstitial coagulation process lowers the concentration of particles with dry diameters larger than 80 nm (a proxy for larger CCN) by 10–12%. These 80 nm particles are not directly removed by the interstitial coagulation but are reduced in concentration because fewer smaller particles grow to diameters larger than 80 nm. The global aerosol indirect effect of adding interstitial coagulation varies from +0.4 to +1.3 W m−2 where again the range depends on our cloud assumptions. Thus, the aerosol indirect effect of this process is significant, but the magnitude depends greatly on assumptions regarding activation diameter, cloud droplet size, and ice cloud physics. The aerosol direct effect of the interstitial coagulation process is minor (&lt; 0.01 W m−2) due to the shift in the aerosol size distribution at sizes where scattering is most effective being small. We recommend that this interstitial scavenging process be considered in aerosol models when the size distribution and aerosol indirect effects are important.\n",
      "--------------------------------------------------\n",
      "Topic 137: 137_species_distribution_areas_suitable\n",
      "Representative Documents:\n",
      "  - Climate and land‐use changes are expected to negatively affect many species and ecological processes, leading to biodiversity loss. However, some species can adapt to these changes. Wide‐ranging species are expected to be less impacted by such changes, but they can occur in different domains with contrasting environmental conditions, resulting in different conservation statuses along their range. To understand whether a species will overall benefit or lose with global change, we evaluated the responses of a wide‐ranging but a vulnerable bird (Crax fasciolata) to separate and combined effects of climate and land‐use changes under different environmental policies in Brazil. Using ecological niche modeling and a land‐use model within the Brazilian political context, we quantified climatic, habitat, and environmental suitability for Crax fasciolata under historical (2000) and future (2050) scenarios. Our findings showed that environmental suitability can increase for Crax fasciolata in Brazil in future, but these effects vary according to the domain and the specific future scenario considered. Climatically suitable areas will increase in all scenarios, and those environmental scenarios that include better habitat conditions will provide more environmentally suitable areas for Crax fasciolata. However, this increase comes from newly suitable areas in the Atlantic Forest and the Amazon, while the Pantanal, the Caatinga, and the Cerrado will lose environmental suitability due to native vegetation loss. Despite the availability of these new areas, reduced landscape permeability may hinder Crax fasciolata from reaching them. This reinforces the urgent call for public policies for native vegetation protection, reforestation, and effective deforestation control. in Portuguese is available with online material\n",
      "  -                Climate change and habitat loss have been identified as the main causes of species extinction. Forest regeneration and protected areas are essential to buffer climate change impacts and to ensure quality habitats for threatened species. We assessed the current and future environmental suitability for the maned sloth, Bradypus torquatus, under both future climate and forest restoration scenarios, using ecological niche modeling. We compared environmental suitability for two Evolutionarily Significant Units (ESUnorth and ESUsouth) using two climate change scenarios for 2070, and three potential forest regeneration scenarios. Likewise, we evaluated the protection degree of the suitable areas resulting from the models, according to Brazilian law: PA—Protected Areas; PPA—Permanent Protection Areas (environmentally sensitive areas in private properties); and LR—Legal Reserves (natural vegetation areas in private properties). Finally, we calculated the deficit of PPA and LR in each ESU, considering the current forest cover. Forest regeneration might mitigate the deleterious effects of climate change by maintaining and increasing environmental suitability in future scenarios. The ESUnorth contains more suitable areas (21,570 km²) than the ESUsouth (12,386 km²), with an increase in all future scenarios (up to 45,648 km² of new suitable areas), while ESUsouth might have a significant decrease (up to 7,546 km² less). Suitable areas are mostly unprotected (ESUnorth—65.5% and ESUsouth—58.3%). Therefore, PPA and PA can maintain only a small portion of current and future suitable areas. Both ESUs present a high deficit of PPA and LR, highlighting the necessity to act in the recovery of these areas to accomplish a large-scale restoration, mitigate climate change effects, and achieve, at least, a minimum forested area to safeguard the species. Notwithstanding, a long-term conservation of B. torquatus will benefit from forest regeneration besides those minimum requirements, allied to the protection of forest areas.\n",
      "  - Reptiles are highly susceptible to climate change, responding negatively to thermal and rainfall alterations mainly in relation to their reproductive processes. Based on that, we evaluated the effects of climate change on climatically suitable areas for the occurrence of snakes in the Atlantic Forest hotspot, considering the responses of distinct reproductive groups (oviparous and viviparous). We assessed the species richness and turnover patterns affected by climate change and projected the threat status of each snake species at the end of the century. We also evaluated the effectiveness of the protected areas in safeguarding the species by estimating the mean percentage overlap between snake species distribution and protected areas (PAs) network and by assessing whether such areas will gain or lose species under climate change. Our results showed greater species richness in the eastern-central portion of the Atlantic Forest at present. In general, we evidenced a drastic range contraction of the snake species under climate change. Temporal turnover tends to be high in the western and north-eastern edges of the biome, particularly for oviparous species. Our predictions indicate that 73.6% of oviparous species and 67.6% of viviparous species could lose at least half of their original range by 2080. We also found that existing protected areas of the Atlantic Forest Hotspot have a very limited capacity to safeguard snakes at the current time, maintaining the precarious protection in the future, with the majority of them predicted to lose species at the end of this century. Although oviparous and viviparous snakes have been designated to be dramatically impacted, our study suggests a greater fragility of the former in the face of climate change. We advocated that the creation of new protected areas and/or the redesign of the existing network to harbour regions that maximize the snake species occupancy in the face of future warming scenarios are crucial measures for the conservation of this group.\n",
      "--------------------------------------------------\n",
      "Topic 138: 138_neurons_co2_rtn_cx26\n",
      "Representative Documents:\n",
      "  - CO2 chemoreception may be related to modulation of inward rectifier K+ channels (Kir channels) in brainstem neurons. Kir4.1 is expressed predominantly in the brainstem and inhibited during hypercapnia. Although the homomeric Kir4.1 only responds to severe intracellular acidification, coexpression of Kir4.1 with Kir5.1 greatly enhances channel sensitivities to CO2 and pH. To understand the biophysical and molecular mechanisms underlying the modulation of these currents by CO2 and pH, heteromeric Kir4.1–Kir5.1 were studied in inside-out patches. These Kir4.1–Kir5.1 currents showed a single channel conductance of 59 pS with open-state probability (Popen) ∼ 0.4 at pH 7.4. Channel activity reached the maximum at pH 8.5 and was completely suppressed at pH 6.5 with pKa 7.45. The effect of low pH on these currents was due to selective suppression of Popen without evident effects on single channel conductance, leading to a decrease in the channel mean open time and an increase in the mean closed time. At pH 8.5, single-channel currents showed two sublevels of conductance at ∼1/4 and 3/4 of the maximal openings. None of them was affected by lowering pH. The Kir4.1–Kir5.1 currents were modulated by phosphatidylinositol-4,5-bisphosphate (PIP2) that enhanced baseline Popen and reduced channel sensitivity to intracellular protons. In the presence of 10 μM PIP2, the Kir4.1–Kir5.1 showed a pKa value of 7.22. The effect of PIP2, however, was not seen in homomeric Kir4.1 currents. The CO2/pH sensitivities were related to a lysine residue in the NH2 terminus of Kir4.1. Mutation of this residue (K67M, K67Q) completely eliminated the CO2 sensitivity of both homomeric Kir4.1 and heteromeric Kir4.1–Kir5.1. In excised patches, interestingly, the Kir4.1–Kir5.1 carrying K67M mutation remained sensitive to low pHi. Such pH sensitivity, however, disappeared in the presence of PIP2. The effect of PIP2 on shifting the titration curve of wild-type and mutant channels was totally abolished when Arg178 in Kir5.1 was mutated. Thus, these studies demonstrate a heteromeric Kir channel that can be modulated by both acidic and alkaline pH, show the modulation of pH sensitivity of Kir channels by PIP2, and provide information of the biophysical and molecular mechanisms underlying the Kir modulation by intracellular protons.\n",
      "  - Central chemoreception is the mechanism by which specific brainstem regions, such as the solitary tract (NTS), medullary rapheand retrotrapezoid nucleus (RTN), regulate breathing in response to changes in tissue CO2/pH. In the RTN, the mechanism of chemoreception involves modulation of chemosensitive neurons by CO2‐evoked astrocytic ATP release. However, it is not clear whether purinergic signaling influences CO2‐responsiveness of other putative chemoreceptors. This study aimed to determine whether neuronal activity and CO2‐responsivness of NTS and raphe chemoreceptors are influenced by purinergic signaling in vitro and in vivo. In brain slices, cell‐attached recordings show that CO2‐sensitive neurons in the NTS, but not the raphe, respond to focal ATP application with ~3 fold increase in firing rate. However, bath application of a non‐specific P2‐receptor blocker (PPADS) had no effect on baseline activity or CO2‐responsivness of NTS nor raphe neurons. In anaesthetized adult rats, injection of PPADS into either the caudal NTS or medullary raphe had no effect on baseline phrenic nerve activity or the ventilatory response to CO2. Further, immunohistochemical analysis of an astrocyte marker indicates that the RTN has a higher density of astrocytes compared to the NTS or medullary raphe. Together, these results suggest that purinergic signaling is a unique feature of RTN chemoreception.\n",
      "  - Connexins can assemble into either gap junctions (between two cells) or hemichannels (from one cell to the extracellular space) and mediate cell-to-cell signalling. A subset of connexins (Cx26, Cx30, Cx32) are directly sensitive to CO2 and fluctuations in the level within a physiological range affect their open probability, and thus, change cell conductance. These connexins are primarily found on astrocytes or oligodendrocytes, where increased CO2 leads to ATP release, which acts on P2X and P2Y receptors of neighbouring neurons and changes excitability. CO2-sensitive hemichannels are also found on developing cortical neurons, where they play a role in producing spontaneous neuronal activity. It is plausible that the transient opening of hemichannels allows cation influx, leading to depolarisation. Recently, we have shown that dopaminergic neurons in the substantia nigra and GABAergic neurons in the VTA also express Cx26 hemichannels. An increase in the level of CO2 results in hemichannel opening, increasing whole-cell conductance, and decreasing neuronal excitability. We found that the expression of Cx26 in the dopaminergic neurons in the substantia nigra at P7-10 is transferred to glial cells by P17-21, displaying a shift from being inhibitory (to neuronal activity) in young mice, to potentially excitatory (via ATP release). Thus, Cx26 hemichannels could have three modes of signalling (release of ATP, excitatory flickering open and shut and inhibitory shunting) depending on where they are expressed (neurons or glia) and the stage of development.\n",
      "--------------------------------------------------\n",
      "Topic 139: 139_rainfall_daily_hourly_gcms\n",
      "Representative Documents:\n",
      "  - In accounting for uncertainties in future simulations of hydrological response of a catchment, two approaches have come to the fore: deterministic scenario‐based approaches and stochastic probabilistic approaches. As scenario‐based approaches result in a wide range of outcomes, the role of probabilistic‐based estimates of climate change impacts for policy formulation has been increasingly advocated by researchers and policy makers. This study evaluates the impact of climate change on seasonal river flows by propagating daily climate time series, derived from probabilistic‐based climate scenarios using a weather generator (WGEN), through a set of conceptual hydrological models. Probabilistic scenarios are generated using two different techniques. The first technique used probabilistic climate scenarios developed from statistically downscaled scenarios for Ireland, hereafter calledSDprob. The second technique used output from 17 global climate models (GCMs), all of which participated in CMIP3, to generate change factors (hereafter calledCF). Outputs from both the SDprob and the CF approach were then used in combination with WGEN to generate daily climate scenarios for use in the hydrological models. The range of simulated flow derived with the CF method is in general larger than those estimated with the SDprob method in winter and vice versa because of the strong seasonality in the precipitation signal for the 17 GCMs. Despite this, the simulated probability density function of seasonal mean streamflow estimated with both methods is similar. This indicates the usefulness of the SDprob or probabilistic approach derived from regional scenarios compared with the CF method that relies on sampling a diversity of response from the GCMs. Irrespective of technique used, the probability density functions of seasonal mean flow produced for four selected basins is wide indicating considerable modelling uncertainties. Such a finding has important implications for developing adaptation strategies at the catchment level in Ireland. Copyright © 2011 John Wiley &amp; Sons, Ltd.\n",
      "  -  The use of building simulation programmes for predicting building performance is increasing all the time especially with the advent of cheap, fast computers. Hourly weather data, in particular outdoor dry bulb temperature (DBT) and solar radiation values, are required for simulation programmes for building performance. When hourly values are not available there are algorithms for generating hourly temperature values from daily values. These use the daily maximum temperature TMAX, and daily minimum temperature, TMIN. However, climate prediction models, such as HadCM3 and HadRM3 also provide the daily average dry-bulb temperature TAVE as well as the daily maximum and minimum. The average temperature is important for selecting weather years and also because the average temperature is often different from the average of the maximum and minimum, assumed in the simpler algorithms. Buildings being designed now will need to perform under future weather conditions with climate change, so the downscaling of daily values from climate prediction models to hourly values is required. This paper describes a new, more accurate algorithm for generating hourly temperature values in the UK that uses all three temperature parameters from climate change models, and demonstrates the improvement of the quality of the generated values against traditional algorithms that use just the daily maxima and minima.  Practical application: The proposed algorithm for generating hourly DBT values from daily maximum, minimum and average values is intended primarily for deriving hourly data for running building simulation programmes, as some weather stations and future climate prediction models only provide daily values of weather parameters.  Climate change is affecting all aspects of human life, and as well as being affected by climate change, buildings can also affect the degree of climate change, since well-designed buildings will require less energy to run, thus minimising the amount of carbon dioxide emitted. As the climate is predicted to change significantly in the next 100 years, if buildings are designed to last, it is important for designers to know how buildings will respond and perform then. Building simulation programmes are useful for this, but they require hourly weather data which are not provided by most climate prediction models. By having a quality-assured algorithm for down-scaling the raw daily values to hourly values, data from climate prediction models, such as HadCM3 and HadRM3 can be used for building simulations for any location in the world.  The hourly DBTs derived from using the algorithm suggested in this paper may also be used in conjunction with other hourly weather data, such as wet-bulb temperature, solar irradiance, cloud cover and wind speed, derived from the same dataset. \n",
      "  - A grid‐based flow routing and runoff‐production model, configured to employ regional climate model (RCM) precipitation estimates as input, is used to assess the effects of climate change on river flows in catchments across the UK. This model, the Grid‐to‐Grid model or G2G, has previously been calibrated and assessed with respect to observed river flows under current climate conditions. Here, the G2G distributed model together with a lumped catchment model, the parameter‐generalized PDM, are applied to simulate river flow and derive flood frequency curves. Two sets of RCM precipitation time‐series, on a 25‐km grid and at hourly intervals, are used: (1) Current (1961–1990) and (2) Future (2071–2100). The effect of one extreme rainfall event in the current precipitation series is to raise the estimated peak flows for some catchments for high return periods under present day rainfall conditions. The future flow series does not contain a comparable flow peak. This significantly affects comparison of the flood frequency curves derived from the flow simulations obtained using the current and future precipitation estimates. Such variability in the results and the dependence on one or two extreme rainfall events emphasizes the need to examine more than one set of current/future precipitation scenarios for flood impact studies. In the absence of a formal ensemble of climate predictions, a resampling method is used to investigate the robustness of the modelled changes in flood frequency. Changes in flood frequency at higher return periods are, not surprisingly, found to be generally less robust than at lower return periods. This is particularly the case for catchments in the south and east of England, which were especially affected by the extreme rainfall event in the current precipitation series. Copyright © 2007 Royal Meteorological Society\n",
      "--------------------------------------------------\n",
      "Topic 140: 140_wines_grapes_phenolic_content\n",
      "Representative Documents:\n",
      "  - Wine quality depends on grape quality, which is affected by many factors such as edaphic, climatic and genetic, i.e., cultivar and rootstock. Rootstocks have been selected in worldwide viticulture to confer to vines some adaptation to several types of soil conditions in vineyards, but this adaptation may affect vine physiology and consequently may affect the chemical compounds of grapes, especially their phenolic compounds. Thus, this study compares the chemical composition of grapes and wines, and the sensory profile of wines from vines of the cv. Syrah grafted on two rootstocks, 5C and Gravesac, grown under a biodynamical management system. The results showed higher skin total phenols and skin total tannins in grapes from 5C rootstock. In the resulting wines, the same results were observed. The multivariate analysis demonstrated that the 5C wines presented a higher relationship with all the families of the low-molecular-weight phenolic compounds, while the Gravesac wines showed a strong relationship with acetylated and p-coumaroylated anthocyanins. The sensory analysis showed that the 5C wines presented more color intensity, more astringency and more meaty aromas compared with the Gravesac wines. The results proved that it was possible to obtain grapes and wines of different qualities depending on the rootstocks used under the same climatic and agronomical condition.\n",
      "  - The purpose of the study was to determine the differences between two subspecies: O. vulgare L. subsp. hirtum (Link) Ietswaart (Greek oregano) and O. vulgare L. subsp. vulgare (common oregano) growing in cultivation conditions within temperate climate of Central Europe. The characteristic of the subspecies was undertaken in terms of selected morphological parameters and the quality of the raw material. The herb of both subspecies was evaluated on the content and composition of essential oil by hydrodistillation followed by GC-MS and GC-FID (gas chromatography coupled with mass spectrometry and flame ionization detector), the total content of phenolic acids (according to PP 6th ed.) and the content of rosmarinic acid (by HPLC). The sensory evaluation (QDA) was performed, as well. Greek oregano was distinguished by visibly higher number of glandular trichomes on the leaves (up to 4.85 per 1 mm2) followed by higher content of essential oil in the herb (up to 3.36 g × 100 g−1 DW) in comparison to common oregano. Based on the essential oil composition, Greek oregano was classified as mixed carvacrol/γ-terpinene chemotype, while common oregano as mixed sabinyl/cymyl type rich in sesquiterpenes. Greek oregano was also characterized by higher total content of phenolic acids (up to 6.16 g × 100 g−1 DW) and rosmarinic acid (up to 6787.2 mg × 100 g−1 DW) than common oregano. Essential oil content reached the maximum at the beginning of blooming (common oregano) and at the full blooming stage (Greek oregano). In turn, the amount of phenolic acids followed by rosmarinic acid was the highest at the beginning of seed-setting stage, in the case of both subspecies. The differences between subspecies concerning chemical composition (especially essential oil) were reflected in the sensory attributes, where both odor and taste notes were found at higher level for Greek oregano. Results of our work indicate that Greek oregano is well adapted to grow in the temperate zone conditions. Such adaptation was reflected mainly in the satisfied yield and maintaining characters typical for the Mediterranean plant, e.g., a high essential oil content followed by high carvacrol share, traits the most important from practice viewpoint.\n",
      "  - One of the major challenges that global warming poses to viticulture is the maintenance of adequate acidity at maturity in white grapes for sparkling winemaking. This issue arises from three main occurrences: (i) with higher temperatures, degradation of malic acid is significantly enhanced; (ii) with a general advancement in grapevine phenology, grape maturity may occur under suboptimal climatic conditions; and (iii) harvesting grapes at “traditional” dates results in overripe fruits for sparkling destinations. In this biennial work, we compared the fruit and must composition of a local, widely grown white grape variety in the Colli Piacentini area (cv. Ortrugo, ORT) with those of a minor autochthonous variety, namely, Barbesino (BRB). Furthermore, we compared the composition, aromatic, and sensory profiles of wines obtained from ORT and BRB grapes picked on the same date and, in addition, of a second Barbesino wine from late harvest (BRB-LH). ORT and BRB had a similar sugar accumulation dynamic, whereas BRB exhibited a delayed loss of titratable acidity. In more details, BRB had lower malic acid degradation rates when malate concentration was &lt;9 g/L. As a result, with comparable yield and total soluble solid content (TSS) (∼20°Brix), BRB had a higher berry titratable acidity and malic acid concentration at harvest than ORT. BRB wines showed the highest titratable acidity (TA), while ORT had the lowest TA and a higher pH, and as expected, BRB-LH had the highest pH and a lower TA than BRB although still higher than those of ORT wine. The aroma profiles of wines were mainly characterized by fermentative aromas, including esters, fatty acids, higher alcohols, and C6 compounds, and BRB-LH wines showed the highest concentration of higher alcohols, while the fermentative esters were higher in ORT wines. Panelists considered BRB significantly fresher and with bigger aroma intensity than ORT, confirming that the higher acidity detected in BRB musts is well preserved in final wines. Our work demonstrates that local minor varieties can be reconsidered in light of the new climate change-related issues impairing viticulture sustainability today. In particular, currently neglected cultivars could help preserve must acidity as compared to traditional varieties having early ripening, maintaining the links with terroir and local traditions at the same time.\n",
      "--------------------------------------------------\n",
      "Topic 141: 141_nhc_complexes_ligand_co\n",
      "Representative Documents:\n",
      "  - The process of electrocatalytic CO2 reduction and H2 evolution from water, regarding renewable energy, has become one of the global solutions to problems related to energy consumption and environmental degradation. In order to promote the electrocatalytic reactivity, the study of the role of ligands in catalysis has attracted more and more attention. Herein, we have developed a copper (II) complex with redox-active ligand [Cu(L1)2NO3]NO3 (1, L1 = 2-(6-methoxypyridin-2-yl)-6-nitro-1h-benzo [D] imidazole). X-ray crystallography reveals that the Cu ion in cation of complex 1 is coordinated by two redox ligands L1 and one labile nitrate ligand, which could assist the metal center for catalysis. The longer Cu-O bond between the metal center and the labile nitrate ligand would break to provide an open coordination site for the binding of the substrate during the catalytic process. The electrocatalytic investigation combined with DFT calculations demonstrate that the copper (II) complex could homogeneously catalyze CO2 reduction towards CO and H2 evolution, and this could occur with great performance due to the cooperative effect between the central Cu (II) ion and the redox- active ligand L1. Further, we discovered that the added proton source H2O and TsOH·H2O (p-Toluenesulfonic acid) could greatly enhance its electrocatalytic activity for CO2 reduction and H2 evolution, respectively.\n",
      "  - Nickel(II) dichloride complexes with a pyridine-chelated imidazo[1,5-a]pyridin-3-ylidene py-ImPy ligand were developed as novel catalyst precursors for acrylate synthesis reaction from ethylene and carbon dioxide (CO2), a highly promising sustainable process in terms of carbon capture and utilization (CCU). Two types of ImPy salts were prepared as new C,N-bidentate ligand precursors; py-ImPy salts (3, 4a–4e) having a pyridine group at C(5) on ImPy and a N-picolyl-ImPy salt (10) having a picolyl group at N atom on ImPy. Nickel(II) complexes such as py-ImPyNi(II)Cl2 (7, 8a–8e) and N-picolyl-ImPyNi(II)Cl2 (12) were synthesized via transmetalation protocol from silver(I) complexes, py-ImPyAgCl (5, 6a–6e) and N-picolyl-ImPyAgCl (11). X-ray diffraction analysis of nickel(II) complexes (7, 8b, 12) showed a monomeric distorted tetrahedral geometry and a six-membered chelate ring structure. py-ImPy ligands formed a more planar six-membered chelate with the nickel center than did N-picolyl-ImPy ligand. py-ImPyNi(II)Cl2 complexes (8a–8e) with tert-butyl substituents exhibited noticeable catalytic activity in acrylate synthesis from ethylene and CO2 (up to 108% acrylate). Interestingly, the use of additional additives including monodentate phosphines increased catalytic activity up to 845% acrylate (TON 8).\n",
      "  - Three novel rhenium N−heterocyclic carbene complexes, [Re]−NHC−1−3 ([Re] = fac−Re(CO)3Br), were synthesized and characterized using a range of spectroscopic techniques. Photophysical, electrochemical and spectroelectrochemical studies were carried out to probe the properties of these organometallic compounds. Re−NHC−1 and Re−NHC−2 bear a phenanthrene backbone on an imidazole (NHC) ring, coordinating to Re by both the carbene C and a pyridyl group attached to one of the imidazole nitrogen atoms. Re−NHC−2 differs from Re−NHC−1 by replacing N−H with an N−benzyl group as the second substituent on imidazole. The replacement of the phenanthrene backbone in Re−NHC−2 with the larger pyrene gives Re−NHC−3. The two−electron electrochemical reductions of Re−NHC−2 and Re−NHC−3 result in the formation of the five−coordinate anions that are capable of electrocatalytic CO2 reduction. These catalysts are formed first at the initial cathodic wave R1, and then, ultimately, via the reduction of Re−Re bound dimer intermediates at the second cathodic wave R2. All three Re−NHC−1−3 complexes are active photocatalysts for the transformation of CO2 to CO, with the most photostable complex, Re−NHC−3, being the most effective for this conversion. Re−NHC−1 and Re−NHC−2 afforded modest CO turnover numbers (TONs), following irradiation at 355 nm, but were inactive at the longer irradiation wavelength of 470 nm. In contrast, Re−NHC−3, when photoexcited at 470 nm, yielded the highest TON in this study, but remained inactive at 355 nm. The luminescence spectrum of Re−NHC−3 is red−shifted compared to those of Re−NHC−1 and Re−NHC−2, and previously reported similar [Re]−NHC complexes. This observation, together with TD−DFT calculations, suggests that the nature of the lowest−energy optical excitation for Re−NHC−3 has π→π*(NHC−pyrene) and dπ(Re)→π*(pyridine) (IL/MLCT) character. The stability and superior photocatalytic performance of Re−NHC−3 are attributed to the extended conjugation of the π−electron system, leading to the beneficial modulation of the strongly electron−donating tendency of the NHC group.\n",
      "--------------------------------------------------\n",
      "Topic 142: 142_migration_shocks_countries_happiness\n",
      "Representative Documents:\n",
      "  - We study the effect of climate change on migration from 121 developing and emerging countries to 20 OECD countries between 1980 and 2010. In contrast to earlier studies, we differentiate between low‐ and high‐skilled migrants to account for the fact that not all groups are equally vulnerable and responsive to climate change. This is also the first study that uses a long‐difference approach. That is, in contrast to earlier studies that investigate short‐term weather changes or weather‐related disasters, we also estimate the effect of climate change on migration over longer time periods. We find that both increasing temperatures and precipitation levels matter to the patterns of migration. We show that increasing temperatures only lead to low‐skilled but not high‐skilled migration (suggesting different migration calculi), are only influential in countries located in hotter parts of the world (consistent with the idea of different levels of vulnerability to climate change), and only materialize in the long run (pointing to the adverse impact of intensification effects due to persistent climate change). Furthermore, we provide evidence that low‐skilled out‐migration is also responsive to short‐ and long‐run precipitation changes.\n",
      "  -  Internal migration between Chinese provinces has increased substantially since the mid-1980s. Though it is generally agreed that this has been driven by economic factors, climatic factors might also have had a part to play. The challenge is to evaluate the impact of climatic factors on migration in the simultaneous presence of changing socio-economic influences. We resolve this challenge by carrying out a statistical multivariate regression analysis on bilateral migration rates between Chinese provinces. The analysis simultaneously includes climate change in the form of climate anomalies (temperature, precipitation, sunshine) and various socio-economic factors including energy consumption. To this end we have constructed a unique three-dimensional panel dataset (time, sending province, receiving province) with bilateral migration rates between 30 provinces for the period 1987-2015. Due to the distributional properties of the data and underlying theory we use a Poisson Pseudo Maximum Likelihood (PPML) estimator but include OLS estimates for comparison. The results suggest that increases in temperature and precipitation are significant migration push factors while increased sunshine discourages push migration. Provincial differentials in per capita energy consumption and Gross Regional Product (GRP) are also significant drivers of migration. \n",
      "  - In this paper, we investigate the long-term effects of climate change on the mobility of working-age people. We use a world economy model that covers almost all the countries around the world, and distinguishes between rural and urban regions as well as between flooded and unflooded areas. The model is calibrated to match international and internal mobility data by education level for the last 30 years, and is then simulated under climate change variants. We endogenize the size, dyadic, and skill structure of climate migration. When considering moderate climate scenarios, we predict mobility responses in the range of 70–108 million workers over the course of the twenty-first century. Most of these movements are local or inter-regional. South–South international migration responses are smaller, while the South–North migration response is of the “brain drain” type and induces a permanent increase in the number of foreigners in OECD countries in the range of 6–9% only. Changes in the sea level mainly translate into forced local movements. By contrast, inter-regional and international movements are sensitive to temperature-related changes in productivity. Lastly, we show that relaxing international migration restrictions may exacerbate the poverty effect of climate change at origin if policymakers are unable to select/screen individuals in extreme poverty.\n",
      "--------------------------------------------------\n",
      "Topic 143: 143_lcz_lst_urban_lczs\n",
      "Representative Documents:\n",
      "  - Understanding the urban thermal environment is vital for improving urban planning and strategy development when mitigating urban heat islands. However, urban thermal characteristics of local climate zones (LCZ) are different within cities and most studies lack regional perspective. This study explored surface thermal performances of cities in three urban agglomerations (Jing-Jin-Ji, Yangtze River Delta and Pearl River Delta) in China using MODIS land surface temperature (LST). Besides that, the diurnal and seasonal LST variations of LCZs are also studied. Moreover, the optimal LCZs for better urban cooling are also investigated in this study. Although the thermal distributions of LCZs are different in China, there are still some similar features. Our four key findings were as follows. (1) LCZs in China are well classified, with average overall accuracy of 82% being higher than that in some previous studies. (2) The LST of mid-rise (LCZ 2, 5) is higher than that of high- and low-rise buildings (LCZ 1, 3, 4, 6); and compact buildings are warmer than open buildings (LCZ 1–3 &gt; LST 4–6) in summer of China. That shows both mid-rise and compact buildings are not beneficial to cool urban. In addition, LST variations at daytime and in summer are more significant than nighttime and other seasons. (3) LST differences within LCZs are significant at p &lt; 0.05, and are most significant in Jing-Jin-Ji (JJJ). The LST difference within built types (LCZ 1–10) is more significant than within natural types (LCZ A–G), showing that built types alteration will be more effective for thermal environmental improvement. (4) Under the current population and urban area, increasing greenness and water area in compact high-rise buildings are the most effective strategies for urban cooling in all three urban agglomerations, with the largest reduction in LST of 4.11 K in JJJ. These findings will provide support for thermal environment mitigation, urban planning and sustainable urban development.\n",
      "  - The surface urban heat island (SUHI) effect poses a significant threat to the urban environment and public health. This paper utilized the Local Climate Zone (LCZ) classification and land surface temperature (LST) data to analyze the seasonal dynamics of SUHI in Wuhan based on the Google Earth Engine platform. In addition, the SUHI intensity derived from the traditional urban–rural dichotomy was also calculated for comparison. Seasonal SUHI analysis showed that (1) both LCZ classification and the urban–rural dichotomy confirmed that Wuhan’s SHUI effect was the strongest in summer, followed by spring, autumn and winter; (2) the maximum SUHI intensity derived from LCZ classification reached 6.53 °C, which indicated that the SUHI effect was very significant in Wuhan; (3) LCZ 8 (i.e., large low-rise) had the maximum LST value and LCZ G (i.e., water) had the minimum LST value in all seasons; (4) the LST values of compact high-rise/midrise/low-rise (i.e., LCZ 1–3) were higher than those of open high-rise/midrise/low-rise (i.e., LCZ 4–6) in all seasons, which indicated that building density had a positive correlation with LST; (5) the LST values of dense trees (i.e., LCZ A) were less than those of scattered trees (i.e., LCZ B) in all seasons, which indicated that vegetation density had a negative correlation with LST. This paper provides some useful information for urban planning and contributes to the healthy and sustainable development of Wuhan.\n",
      "  - This study investigated monthly variations of surface urban heat island intensity (SUHII) and the applicability of the local climate zones (LCZ) scheme for land surface temperature (LST) differentiation within three spatial contexts, including urban, rural and their combination, in Shenyang, China, a city with a monsoon-influenced humid continental climate. The monthly SUHII and LST of Shenyang were obtained through 12 LST images, with one in each month (within the period between 2018 and 2020), retrieved from the Thermal InfraRed Sensor (TIRS) 10 in Landsat 8 based on a split window algorithm. Non-parametric analysis of Kruskal-Wallis H test and a multiple pairwise comparison were adopted to investigate the monthly LST differentiations with LCZs. Overall, the SUHII and the applicability of the LCZ scheme exhibited spatiotemporal variations. July and August were the two months when Shenyang underwent strong heat island effects. Shenyang underwent a longer period of cool than heat island effects, occurring from November to May. June and October were the transition months of cool–heat and heat–cool island phenomena, respectively. The SUHII analysis was dependent on the definition of urban and rural boundaries, where a smaller rural buffering zone resulted in a weaker SUHI or surface urban cool island (SUCI) phenomenon and a larger urban area corresponded to a weaker SUHI or SUCI phenomenon as well. The LST of LCZs did not follow a fixed order, where in July and August, the LCZ-10 (Heavy industry) had the highest mean LST, followed by LCZ-2 (Compact midrise) and then LCZ-7 (Lightweight low-rise). In comparison, LCZ-7, LCZ-8 (Large low-rise) and LCZ-9 (Sparsely built) had the highest LST from October to May. The LST of LCZs varied with urban and rural contexts, where LCZ-7, LCZ-8 and LCZ -10 were the three built LCZs that had the highest LST within urban context, while LCZ-2, LCZ-3 (Compact low-rise), LCZ-8, LCZ-9 and LCZ-10 were the five built LCZs that had the highest LST within rural context. The suitability of the LCZ scheme for temperature differentiation varied with the month, where from July to October, the LCZ scheme had the strongest capability and in May, it had the weakest capability. Urban context also made a difference to the suitability, where compared with the whole study area (the combination of urban and rural areas), the suitability of built LCZs in either urban or rural contexts weakened. Moreover, the built LCZs had a higher level of suitability in an urban context compared with a rural context, while the land-cover LCZs within rural had a higher level of suitability.\n",
      "--------------------------------------------------\n",
      "Topic 144: 144_principle_justice_moral_harm\n",
      "Representative Documents:\n",
      "  - The polluter pays principle (PPP) has the form of a reparative principle. It holds that since some countries have historically contributed more to global warming than others, these countries have the follow‐up responsibility now to do more to address climate change. Yet in the climate justice debate, PPP is often rejected for two reasons. First, so the objection goes, it wrongly burdens present‐day individuals because the actions of their predecessors. This is the unfairness objection. The second objection is that early polluters were not aware of the harm that they were doing, and so ought not to be held culpable. This is the objection from excusable ignorance. In this commentary, I defend PPP against these two objections. The aim of this short reflection is not to provide a full justification of PPP, or to respond to all objections that have been made against it. My more limited but, I hope, important goal is to show that PPP is neither immediately unfair (in making innocent parties pay) nor immediately unreasonable (in making excusably ignorant parties pay) as is commonly noted, and is therefore worthy of further consideration as a principle of climate justice.This article is categorized under:Climate, Nature, and Ethics &gt; Climate Change and Global JusticeClimate, Nature, and Ethics &gt; Ethics and Climate Change\n",
      "  -  The prospect of climate change due to human activities has put the question of inter- and intragenerational justice or equity in matters of common concern on the global agenda. This article will focus on the question of intragenerational justice in relation to these issues. This involves three basic questions. Firstly, the question of which distributive criteria may be relevant in the distribution of the goods and bads related to the increasing greenhouse effect. A series of criteria are discussed in relation to different understandings of the problem. The second question is which kind of relationship the global partnership is or should be considered to be in issues of common concern. It is argued that various understandings of the global partnership can be expected to result in the use of different criteria. This diversity leads us to the third question concerning the possibility of identifying an overall social ideal which can be used in cases where several different criteria may be useful. I shall discuss one such ideal in particular, namely the ideal of complex equality. In the concluding remarks it is argued that a distribution of emission quotas to countries in accordance with population size is a reasonable starting point for an equitable solution, although it involves various problems of application. \n",
      "  -  The prospect of climate change due to human activities has put the question of inter- and intragenerational justice or equity in matters of common concern on the global agenda. This article will focus on the question of intragenerational justice in relation to these issues. This involves three basic questions. Firstly, the question of which distributive criteria may be relevant in the distribution of the goods and bads related to the increasing greenhouse effect. A series of criteria are discussed in relation to different understandings of the problem. The second question is which kind of relationship the global partnership is or should be considered to be in issues of common concern. It is argued that various understandings of the global partnership can be expected to result in the use of different criteria. This diversity leads us to the third question concerning the possibility of identifying an overall social ideal which can be used in cases where several different criteria may be useful. I shall discuss one such ideal in particular, namely the ideal of complex equality. In the concluding remarks it is argued that a distribution of emission quotas to countries in accordance with population size is a reasonable starting point for an equitable solution, although it involves various problems of application. \n",
      "--------------------------------------------------\n",
      "Topic 145: 145_zfp521_mice_cells_cell\n",
      "Representative Documents:\n",
      "  -                Mast cells play crucial roles in both innate and adaptive immune responses. Evidence in our laboratory suggests that the ZFP521 (Evi3/ZNF521/EHZF) transcription factor orchestrates key pathways required for proper development and function of mast cells. ZFP521 is a nuclear protein that contains 30 zinc fingers. ZFP521 is important for the renewal and development of hematopoietic cells. Here, we demonstrate that ZFP521 is expressed highly in murine mast cells. To address the intrinsic roles of ZFP521 in mast cells, we developed a model system in which Zfp521 gene expression is ablated conditionally in mast cells of mice with floxed alleles (Zfp521 cKO mice) by mast cell-specific Cre (Mcpt5-Cre transgene). Zfp521 is required for normal numbers of mast cells in the peritoneal cavity (PMC). In part, the reduction of PMC may be due to the reduced expression of CD117 (c-Kit) on Zfp521 cKO-derived mast cells. Both CD117 and its ligand, Stem Cell Factor (SCF), are essential for mast cell development in the bone marrow. Additionally, the expression of several transcription factors, including GATA-1, GATA-2 and GATA-3, which regulate mast cell development and function is reduced in bone marrow-derived Zfp521 cKO mast cells. Together, our data provide insights into 1) a novel role for ZFP521 in hematopoiesis, and 2) the transcriptional regulatory network that governs the development and function of mast cells.\n",
      "  -                Early B cell factor 1 (EBF1) determines B cell lineage specification and commitment. ZFP521, a transcription factor with 30 zinc fingers, negatively regulates EBF1. We determined that EBF1 accelerates B cell development in the absence of ZFP521. Pre-pro-B and pro-B cells are increased substantially, while late pro-B, pre-B and immature B cells are reduced significantly in Zfp521 KO mice. Interestingly, mature IgM+IgD+ B cells, which accumulate in the bone marrow and spleens of 4-5 week old WT mice, are readily detected in 2-3-week old Zfp521 KO mice. Additionally, RUNX1 plays a role in ZFP521-mediated regulation of EBF1 activity. ZFP521 is detected in the nuclei of B cells and interacts with EBF1 in vivo. In contrast with published reports, ZFP521 and EBF1 co-localize on B cell-specific promoters. This indicates that ZFP521 regulates B cell development through functional interactions with EBF1 on target gene chromatin. Using ChIPseq data we are differentiating between two possible models concerning functions of ZFP521: 1) ZFP521 may modulate EBF1 function through direct protein:protein interactions, and/or 2) ZFP521 may direct transcription of cognate target genes independently of EBF1. Together, our studies provide exciting new information concerning functions of EBF1 and ZFP521 in the B cell regulatory network.\n",
      "  -                The ZFP521 (Evi3/ZNF521/EHZF) transcription factor has been identified as an inhibitor of Early B cell factor 1 (EBF1), which is essential for B cell lineage specification and commitment. ZFP521 contains 30-zinc finger (ZF) domains, including C-terminal ZF’s that bind to EBF1. However, whether ZFP521 is required for appropriate B cell development and function has not been addressed. We demonstrated that Zfp521 transcripts correlate inversely with Ebf1 transcripts. Zfp521 transcripts are expressed at the highest levels in pre-pro-B and pro-B cells and decrease progressively with differentiation. In contrast, Ebf1 transcripts are detected only weakly in pre-pro-B cells and are increased at later stages in the bone marrow. In 3-wk old Zfp521 knockout (KO) mice, pre-pro-B and pro-B cells are increased substantially, while late pro-B, pre-B and immature B cells are reduced significantly. Re-circulating mature B cells accumulate prematurely in the bone marrow of Zfp521 KO mice relative to WT mice. We are addressing two possible models in these mice. ZFP521 may modulate EBF1 function through direct protein:protein interactions. Alternatively, because ZFP521 is itself a DNA-binding protein, ZFP521 may direct transcription of cognate target genes independently of EBF1. We obtained evidence that ZFP521 co-occupies functional promoters with EBF1 in pro-B cells. This indicates that ZFP521 regulates B cell development through interactions with EBF1 on target genes.\n",
      "--------------------------------------------------\n",
      "Topic 146: 146_agricultural_farmers_china_agricultural production\n",
      "Representative Documents:\n",
      "  - The threat of climate change to the sustainability of farmers’ livelihoods is becoming more significant. Research on the impact of climate change on the sustainability of farmers’ livelihoods could provide a scientific basis for enhancing farmers’ adaptability to climate change, reducing farmers’ livelihood vulnerability, and promoting the formulation of governmental adaptation strategies. Although studies have assessed the impact of climate change on the sustainability of farmers’ livelihoods, their analysis units have been aggregated. Therefore, this study was grouped based on geographical location (north and south regions), and then an additional grouping was conducted according to the internal economic factors of each region. Using data from China’s labor-force dynamic survey as our sample, this study measured the sustainable livelihood in agricultural households. This research provided a method to quantify the sustainability of farmers’ livelihoods based on measurements of poverty vulnerability. Additionally, using the annual average temperature as the core explanatory variable to describe climate change, this study evaluated the impact and heterogeneity of climate change on the sustainability of farmers’ livelihoods and replaced the annual average temperature with the normalized vegetation index to conduct a robustness test. The empirical study showed that the average annual temperature significantly decreased the sustainability of farmers’ livelihoods. The average annual temperature change had a greater impact on farmers in the southern provinces as compared to those in the north. Southern coastal regions, eastern coastal regions, the middle reaches of the Yangtze River, and the northeast regions were the key areas of concern. Finally, considering the current risk vulnerability of farmers, we concluded that crop breeding should be oriented to the trend of climate change, farmers’ risk prevention awareness should be increased, financial tools should be enhanced to mitigate the impact of meteorological disasters, an appropriate sustainability developmental evaluation index should be implemented, and the construction of agrometeorological disaster prevention and mitigation infrastructure should be advanced.\n",
      "  - Climate change has become a major environmental issue facing all countries, having a significant effect on all aspects of agricultural production, such as the agricultural mechanization process and fertilizer use. Greenhouse gases produced by agricultural machinery and fertilizers during agricultural production are an important cause of climate change. On the basis of the above facts, researching the connection between agricultural mechanization, climate change, and agricultural carbon emissions is crucial for the development of low-carbon agriculture and for addressing climate change. We used a variety of econometric models and methods to analyze data from China’s multiple provinces (cities) covering the years 2000 through 2019, in order to meet the research objectives. Furthermore, we utilized rainfall and sunlight as variables to assess climate change and adopted Granger tests to establish the link between rainfall, sunlight, agricultural mechanization, and carbon emissions in farming. The findings indicate a bidirectional causality relationship between rainfall, sunlight, agricultural mechanization, and carbon emissions in farming. Rainfall and sunlight are Granger causes of agricultural mechanization. Furthermore, agricultural mechanization has favorable effects on carbon emissions of agriculture, and climate change has long-term implications on agricultural mechanization and carbon emissions of agriculture. Finally, this paper investigated the green path suitable for the low-carbon development of Chinese agriculture, arguing that the government should formulate low-carbon agricultural policies by region and actively promote the upgrading of agricultural machinery.\n",
      "  - PurposeThe purpose of this paper is to examine the status of the supply reliability of groundwater irrigation, and discuss how it is affected by climate change and tubewell density in rural China.Design/methodology/approachThis study is based on a nine-province village survey and secondary climate data. A Tobit model (or censored regression model) was used to estimate the determinants of supply reliability of groundwater irrigation.FindingsResults show that the supply reliability of groundwater irrigation was 89 percent on average in the past three years. The non-linear relationship in the econometric results revealed that the 30-year annual temperature significantly influenced the supply reliability of groundwater irrigation. When the temperature rises above the turning point (6.30°C), it shifts from a positive to a negative relationship with the supply reliability of groundwater irrigation. The 30-year annual temperature in eight of the nine provinces (i.e. except for Jilin Province) was higher than the turning point. If the temperature increases by 20°C in the future, other factors being constant, the supply reliability of groundwater irrigation will decline by 20 percent. However, if precipitation increases by 10 percent, the supply reliability of groundwater irrigation could improve by 3 percent, while reducing precipitation by 10 percent will lower the supply reliability of groundwater irrigation by 3 percent. Increasing the density of tubewells considerably improves the supply reliability of groundwater irrigation. However, although increasing the density of tubewells may yield enough groundwater for irrigation, this one-sided approach raises sustainability concerns.Research limitations/implicationsAlthough increasing the density of tubewells may ensure that enough groundwater is available for irrigation, such a conclusion is one sided, and sustainability concerns should be raised in assessing this method of creating supply reliability.Originality/valueThis paper improves the understanding of the impact of climate variables on agriculture irrigation and water supply reliability in the micro scale, and provides a scientific basis for relevant policy making.\n",
      "--------------------------------------------------\n",
      "Topic 147: 147_health_adaptation_management_climate change\n",
      "Representative Documents:\n",
      "  - Countries across the world aspire towards climate resilient sustainable development. The interacting processes of climate change, land change, and unprecedented social and technological change pose significant obstacles to these aspirations. The pace, intensity, and scale of these sizeable risks and vulnerabilities affect the central issues in sustainable development: how and where people live and work, access to essential resources and ecosystem services needed to sustain people in given locations, and the social and economic means to improve human wellbeing in the face of disruptions. This paper addresses the question: What are the characteristics of transformational adaptation and development in the context of profound changes in land and climate? To explore this question, this paper contains four case studies: managing storm water runoff related to the conversion of rural land to urban land in Indonesia; using a basket of interventions to manage social impacts of flooding in Nepal; combining a national glacier protection law with water rights management in Argentina; and community-based relocation in response to permafrost thaw and coastal erosion in Alaska. These case studies contribute to understanding characteristics of adaptation which is commensurate to sizeable risks and vulnerabilities to society in changing climate and land systems. Transformational adaptation is often perceived as a major large-scale intervention. In practice, the case studies in this article reveal that transformational adaptation is more likely to involve a bundle of adaptation interventions that are aimed at flexibly adjusting to change rather than reinforcing the status quo in ways of doing things. As a global mosaic, transformational change at a grand scale will occur through an inestimable number of smaller steps to adjust the central elements of human systems proportionate to the changes in climate and land systems. Understanding the characteristics of transformational adaptation will be essential to design and implement adaptation that keeps society in step with reconfiguring climate and land systems as they depart from current states.\n",
      "  - Introduction:As populations worldwide are experiencing more frequent and intense weather and climate extremes, many professionals of the WADEM community are at the frontline of managing compounding and cascading impacts on physical and mental health. Vulnerable, isolated, and marginalized people are the most affected by climate and weather threats. The elderly and children faced 3.7 billion more life-threatening heatwave days in 2021 than annually in 1986-2005 increasing the need for emergency care on a large scale.Method:The World Health Organization (WHO) and World Meteorological Organization (WMO), together with partners from health agencies, climate services, academia and other sectors are collaborating to accelerate the use of climate, weather and environmental science and services for better health protection. A selection of key resources and tools will be highlighted that can be used by the WADEM community to better understand, anticipate, and manage health risks from extreme weather and climate.Results:Participants will learn about the new WHO-WMO ClimaHealth Portal, a global knowledge and action hub with huge potential for facilitating learning and action to better protect health from climate risks. Tools and resources include the Global Heat Health Information Network (GHHIN) Checklist and Technical Brief for improved heatwave preparedness and response in the context of COVID-19, and a new WHO Guidance Document on Measuring the Climate Resilience of Health Systems providing a framework and indicators for assessing and protecting health systems from climate threats.Conclusion:As extreme weather intensifies, integrated climate-informed services for the health sector including multi-hazard early warning systems and action plans, as well as strengthened partnerships between the health community and hydrometeorological services are indispensable to further restrict adverse health impacts. Accelerating the uptake and upscale of existing tools and resources is urgently needed to meet the increasing health and societal challenges caused by climate change and weather extremes.\n",
      "  - Climate change is increasing risks to human health and to the health systems that seek to protect the safety and well-being of populations. Health authorities require information about current associations between health outcomes and weather or climate, vulnerable populations, projections of future risks and adaptation opportunities in order to reduce exposures, empower individuals to take needed protective actions and build climate-resilient health systems. An increasing number of health authorities from local to national levels seek this information by conducting climate change and health vulnerability and adaptation assessments. While assessments can provide valuable information to plan for climate change impacts, the results of many studies are not helping to build the global evidence-base of knowledge in this area. They are also often not integrated into adaptation decision making, sometimes because the health sector is not involved in climate change policy making processes at the national level. Significant barriers related to data accessibility, a limited number of climate and health models, uncertainty in climate projections, and a lack of funding and expertise, particularly in developing countries, challenge health authority efforts to conduct rigorous assessments and apply the findings. This paper examines the evolution of climate change and health vulnerability and adaptation assessments, including guidance developed for such projects, the number of assessments that have been conducted globally and implementation of the findings to support health adaptation action. Greater capacity building that facilitates assessments from local to national scales will support collaborative efforts to protect health from current climate hazards and future climate change. Health sector officials will benefit from additional resources and partnership opportunities to ensure that evidence about climate change impacts on health is effectively translated into needed actions to build health resilience.\n",
      "--------------------------------------------------\n",
      "Topic 148: 148_embryos_oocytes_vitrified_vitrification\n",
      "Representative Documents:\n",
      "  - Despite the importance of cryoprotectants for avoiding ice crystal formation, the high concentrations required for vitrification may be toxic to bovine oocytes. During warming (thawing), the removal of permeating cryoprotectants from cells can lead to osmotic injury, and the most appropriate time interval for warming and cryoprotectant removal from vitrified oocytes is currently uncertain. The present study aimed to evaluate the effect of cryoprotectant exposure, vitrification, and warming time of bovine cumulus oocyte complexes (COC) on fertilization and ability to develop as embryos in vitro. Follicles &lt;8 mm in diameter were aspirated from slaughterhouse-derived bovine ovaries. Cumulus oocyte complexes with ≥3 layers of cumulus cells and a uniform cytoplasm were selected, washed 3 times in Dulbecco’s PBS + 5% newborn calf serum (CS), and randomly divided into 4 groups: 1) control group: no treatment; 2) VS1 group: COC were exposed to vitrification solution 1 [VS1: 7.5% ethylene glycol (EG) and 7.5% dimethyl sulfoxide (DMSO) in TCM-199 + 20% CS] for 5 min; 3) VS1+VS2 group: COC were exposed to VS1 for 5 min followed by vitrification solution 2 (VS2: 15% EG, 15% DMSO, and 0.5 M sucrose in TCM-199 + 20% CS) for 30 s; and 4) vitrified group: COC were exposed to VS1 and VS2, and then vitrified in liquid nitrogen using cryotops. The COC in VS1, VS1+VS2, and vitrified groups were exposed to a warming solution (0.5 M sucrose in TCM-199) for 1 or 5 min. The COC from all groups were in vitro matured (IVM) for 22 h in TCM-199 containing 5% CS, 5 μg mL–1 LH, 0.5 μg mL–1 FSH, and 0.05 μg mL–1 gentamicin at 38.5°C, 5% CO2, and high humidity, incubated with frozen–thawed sperm in Brackett-Oliphant capacitating medium for 18 h, and the presumptive zygotes were cultured in Charles Rosenkrans 1 amino acids (CR1aa) + 5% CS for 9 days. Data were analysed using Proc Glimmix in SAS® 9.2 (SAS Institute Inc., Cary, NC, USA). Cleavage and blastocyst rates in the vitrified group (25 and 2%, respectively) were significantly lower (P &lt; 0.0001) than in control (75 and 27%), VS1 (68 and 19%), or VS1+VS2 (63 and 22%) groups. Cleavage and blastocyst rates did not differ among non-vitrified groups (P &gt; 0.05). In VS1, VS1+VS2, and vitrified groups, warming time had no effect on cleavage or blastocyst rates (P &gt; 0.05). In conclusion, although cryoprotectant exposure and warming times had no apparent adverse effect, vitrification of bovine COC drastically reduced cleavage and blastocyst rates. Further studies are required to understand how vitrification of bovine COC affects subsequent fertilization and embryo development.This study was supported by the Canadian Animal Genetic Resources Program, Agriculture and Agri-Food Canada.\n",
      "  -                                  Study question                  Does prolactin (PRL) treatment during recovery culture affect human blastocyst outgrowth?                                                Summary answer                  PRL treatment for 120 min promoted trophoblast outgrowth in cryopreserved human blastocysts by upregulating the expressions of epithelial-to-mesenchymal transition (EMT) and focal adhesion-related genes.                                                What is known already                  Human embryos express the PRL receptor at the morula and the blastocyst stages. This expression correlates with the blastocyst diameter and the time required for the embryos to reach the blastocyst stage. Treatment with PRL from cleavage to the blastocyst stage improves blastocyst outgrowth to fibronectin. However, whether PRL treatment after warming cryopreserved blastocysts cultured to the blastocyst stage without PRL influences outgrowth competence remains unknown. Furthermore, the optimal time for post-warming PRL treatment remains to be ascertained.                                                Study design, size, duration                  A total of 374 discarded human vitrified blastocysts donated for research by consenting couples were used. The study was approved by the Institutional Review Board. The blastocysts were randomly allocated to two groups, to be cultured in medium either with PRL (n = 208) or without PRL (control; n = 166). The gene expression level, blastocyst adhesion, outgrowth area, and distance of trophoblast migration were compared between the groups.                                                Participants/materials, setting, methods                  Vitrified human blastocysts were cultured for 120 min after warming. Some blastocysts were treated with PRL for 15–120 min during the recovery period. The blastocysts were plated on fibronectin-coated dishes and cultured to assess blastocyst adhesion and outgrowth. The expressions of PRL-interacting genes were assessed by quantitative RT-PCR 12 h after outgrowth culture. The migration distance at the outer edge of the trophoblast cells was examined using time-lapse systems.                                                Main results and the role of chance                  The mRNA expressions of ezrin, radixin, and moesin, which regulate cell adhesion and invasion by controlling actin reorganisation during EMT, was stimulated by PRL treatment for 120 min. The expressions of EMT-related genes, transforming growth factor β1, snail1, and twist1 were also promoted by treatment with PRL for 120 min. The blastocysts treated with PRL also exhibited augmented expression of cadherin2 and transcriptional repression of cadherin1. Higher mRNA expressions of integrin-based focal adhesion-related genes, ITGA5 and ITGB1, were observed after treatment with PRL for 120 min compared to that in the other groups. PRL treatment for 120 min did not alter the rate of blastocyst adhesion to fibronectin-coated dishes 96 h after the outgrowth culture assay. However, multiple linear regression analysis revealed that the outgrowth area was significantly increased in blastocysts treated with PRL. The migration distance of trophoblast cells was significantly increased after PRL treatment. Furthermore, a more beneficial effect of prolactin treatment on blastocyst outgrowth was observed when the blastocysts were vitrified on day 5 compared to that when the blastocysts were vitrified on day 6. Moreover, the outgrowth area was increased by PRL treatment when the blastocyst diameter was larger than 180 µm.                                                Limitations, reasons for caution                  The results may vary between in vivo and in vitro conditions. Further clinical studies are required to explore the clinical efficacy of PRL treatment.                                                Wider implications of the findings                  This study showed that PRL treatment for 120 min improved trophoblast migration in cryopreserved human blastocysts. Therefore, recovery culture with PRL treatment post-warming followed by blastocyst transfer could improve pregnancy outcomes.                                                Trial registration number                  not applicable               \n",
      "  -                                  Study question                  Does fatty acid (FA) supplementation into vitrification and warming solutions influence the developmental competence of oocyte and embryo after vitrification and warming?                                                Summary answer                  FA supplementation during the warming process improves the developmental competence of vitrified-warmed mouse oocytes and embryonic-morphologies after vitrification at the cleavage-stage in bovines and humans.                                                What is known already                  Vitrified metaphase II stage oocytes exhibit a diminished ability to develop into blastocysts and live births. Previous studies have shown reduction in intracellular lipid content as one of the factors associated with reduced developmental competence of oocytes after vitrification as the intracellular lipid content of oocytes is affected by vitrification. FAs derived from break down of lipids are primarily transferred to the mitochondria, where it plays a crucial role in cellular metabolism. However, the effects of FA supplementation in warming solutions on the cytoplasmic lipid content and subsequent embryo development are unknown.                                                Study design, size, duration                  A chemically defined FA mixture was added to the vitrification and/or warming solutions. Oocytes collected from C57BL6/N (n = 80) were randomly divided into three groups (fresh, n = 634; non-FA (control), n = 961; FA, n = 1,686), and were vitrified-warmed with/without FA. Lipid composition, developmental competence, and gene expression levels were compared among the groups. Bovine embryos (fresh, n = 420; control, n = 524; FA, n = 492) and discarded human day-2 embryos (control, n = 87; FA, n = 92) were used to examine the developmental competence of embryos.                                                Participants/materials, setting, methods                  Lipids in the ooplasm were stained with Nile red and the fluorescence intensity was analysed. The developmental competence of mouse oocytes was examined by performing intracytoplasmic sperm injection. Expressions of FA metabolism-related genes were measured. The bovine embryos were vitrified at the four-cell stage and cultured to the blastocyst stage after warming. Cryopreserved discarded human embryos were warmed and cultured. The obtained blastocysts were then placed on fibronectin-coated dishes to examine the outgrowth formation.                                                Main results and the role of chance                  Lipid content of mouse oocytes was significantly lower in the control group compared to that in the fresh group (P &amp;lt; 0.05). On the contrary, lipid contents of FA and fresh groups were comparable (P = 0.24). Blastocyst formation rate was significantly higher in the FA group than that in the control group (55.7% and 44.8%, respectively; P &amp;lt; 0.05). To examine the optimal timing for FA supplementation, FA was added to the vitrification solution (FAvit), warming solution (FAthaw), and/or both solutions (FAvit-thaw). Blastocyst formation rate was significantly higher in the FAthaw group than that in the control group (59.8% and 50.0%, respectively; P &amp;lt; 0.05). The mRNA expressions of Acaa2 and Hadha in mouse embryos were significantly higher in the FAthaw group compared to that in the control group (P &amp;lt; 0.05). Moreover, FA supplemented warming solutions significantly improved the blastocyst formation rate in bovines (control, 53.5%; FAthaw, 64.5%; P &amp;lt; 0.05). Developmental rate to the expanded blastocyst stage was slightly improved in human embryos (control, 53.7%; FAthaw, 63%; P = 0.38) and the proportion of Grade A in inner cell mass and trophectoderm was significantly higher in the FAthaw group than that in the control group (P &amp;lt; 0.05). There were no differences in the outgrowth abilities between the control and FAthaw groups.                                                Limitations, reasons for caution                  Since the experiments of the current study on human embryos were performed in vitro using discarded embryos, in vivo developmental ability was not evaluated. Therefore, to validate the application of our findings in human assisted reproductive technologies, further clinical trials (ART) are warranted.                                                Wider implications of the findings                  FA supplementation into the warming solutions improved the developmental competence of vitrified–warmed oocytes and cleaved embryos by activating the β-oxidation pathway. These results indicate that FA supplementation into warming solutions is a potential strategy to improve clinical outcomes in human ART.                                                Trial registration number                  not applicable               \n",
      "--------------------------------------------------\n",
      "Topic 149: 149_political_science_policy_politics\n",
      "Representative Documents:\n",
      "  - In response to the threat of climate change, many governments have set policy goals to rapidly and extensively increase the use of renewable energy in order to lessen reliance upon fossil fuels and reduce emissions of greenhouse gases. Such policy goals are ambitious, given past controversies over large‐scale renewable energy projects, particularly onshore wind farms, that have occurred in many countries and involved bitter disputes between private developers and local ‘NIMBYs’ (not in my backyard) protestors. This article critically reviews recent research into how public engagement is conceived and practiced by policy makers and developers, with a specific focus upon the UK. The review reveals a distinction between different scales of technology deployment, with active public engagement only promoted at smaller scales, and a more passive role promoted at larger scales. This passive role stems from the influence of widely held NIMBY conceptions that presume the public to be an ‘ever present danger’ to development, arising from a deficit in factual knowledge and a surfeit of emotion, to be marginalized through streamlined planning processes and one‐way engagement mechanisms. It is concluded that NIMBYism is a destructive, self‐fulfilling way of thinking that risks undermining the fragile, qualified social consent that exists to increase renewable energy use. Breaking the cycle of NIMBYism requires new ways of thinking and practicing public engagement that better connect national policy making with local places directly affected by specific projects. Such a step would match the radical ambitions of rapid increases in renewable energy use with a process of change more likely to facilitate its achievement. WIREs Clim Change 2011 2 19–26 DOI: 10.1002/wcc.89This article is categorized under:Perceptions, Behavior, and Communication of Climate Change &gt; Behavior Change and Responses\n",
      "  - In this paper, I analyze three distinct groups of prominent public intellectuals arguing for action on climate change. I detail how public intellectuals establish their authority, spread their ideas, and shape political discourse, analyzing the contrasting stories that they tell about the causes and solutions to climate change. ‘Ecological Activists’ like U.S. writer/activist BillMcKibbenor Charles Sturt University (AU) philosopher Clive Hamilton argue that climate change is a symptom of a capitalist society that has dangerously exceeded the carrying capacity of the planet. They are skeptical of technological or market‐based solutions to the problem, urging the need for a global movement that dramatically re‐organizes society. ‘Smart Growth Reformers’ likeUKeconomist Nicholas Stern or former U.S. vice president Al Gore agree that climate change poses catastrophic risks but argue that those risks can be avoided if political leaders adopt the right market‐based mechanisms, enabling sustainable economic growth to continue. ‘Ecomodernists’ likeThe New York Times(U.S.) writer Andrew Revkin and Oxford University (UK) anthropologist Steve Rayner argue for recognizing the biases in how we have conventionally defined climate change as a social problem. Progress will be achieved not by relying on social protest or market‐based mechanisms, but by government investment in a diverse menu of policies that catalyze technological innovation, protect against climate impacts, and provide developing countries abundant, cleaner sources of energy. To conclude, I propose methods for building on my analysis and urge the need for forums that feature a diversity of voices, discourses, and ideas.WIREs Clim Change2014, 5:809–823. doi: 10.1002/wcc.317This article is categorized under:Perceptions, Behavior, and Communication of Climate Change &gt; CommunicationSocial Status of Climate Change Knowledge &gt; Knowledge and Practice\n",
      "  -     Risk-based decision-making is widely considered to be the best means of presenting the science of climate change and for developing and presenting climate change evidence for policymaking. This paper examines some of the justifications provided by climate and decision scientists for their preferred approach, and argues that, although risk-based approaches are indeed analytically and instrumentally helpful, they may not always provide the most politically appropriate framework for resolving the politics of evidence-based policymaking. Decision scientists still promote risk-based decision-making under erroneous ideals of linear-instrumental-rationality, even if they have become more circumspect concerning the worst excesses of past technocratic linear-rationality. Moreover, decision scientists have provided very shallow justification to date for ‘risk’ as default decision framework. A reasonable analysis of the general suitability of risk would include comparative analysis with alternative conceptual frames, not simply in terms of their analytical power, but also their political acceptability in constituencies where particular evidence-frames may be challenged on the basis of their premises, rather than their conclusions.&lt;br /&gt;Key messages&lt;br /&gt;Risk-based decision guidance does not fully account for the politics of evidence-based policy.&lt;br /&gt;Decision scientists should avoid conflating the heuristic and prescriptive worth of policy models.&lt;br /&gt;Risk-based approaches should be justified from political analysis with alternate conceptual frames.&lt;br /&gt;Context-appropriate decisions demand context-sensitive conceptual frames for policy-evidence.   \n",
      "--------------------------------------------------\n",
      "Topic 150: 150_adaptation_vulnerability adaptation_vulnerability_climate change gt\n",
      "Representative Documents:\n",
      "  - In this piece we explore the interface between adaptation research and adaptation policy, planning, and investment. We ask, ‘How is research on adaptation informing the nascent domain of adaptation policy and practice?’ To inform this discussion, we extract a few of the more salient lessons from four different domains of adaptation research: risk assessment and impact response, social vulnerability and adaptive capacity, resilience, and the science of decision making and policy implementation. Through a few select case studies of adaptation planning, we explore the extent to which we see these lessons taking hold in adaptation practice. The cases reviewed suggest that there may be significant differences in the type of research that informs planning in more industrial contexts compared to the developing world. Risk assessment and cost/benefit analysis appear to dominate adaptation planning in the industrialized world, while insights concerning governance, the social and economic constraints to adaptation, and building systemic resilience are featured more in planning documents from the developing world. The focus on risk assessment and associated technological interventions in the industrialized world illustrates the difficulty of addressing underlying structural and cognitive barriers to change, as well as the policy implications of conceptualizing adaptation as an outcome rather than a dynamic process. More broadly, the challenge of adaptation now offers an opportunity for innovative and collaborative research in which networks of academics, policy makers, at‐risk populations, and other stakeholders actively participate in understanding the process of adaptation, experimenting in responses to change and learning from that process. WIREs Clim Change 2011 2 141–153 DOI: 10.1002/wcc.100This article is categorized under:Vulnerability and Adaptation to Climate Change &gt; Institutions for AdaptationSocial Status of Climate Change Knowledge &gt; Knowledge and Practice\n",
      "  - Much of human behavior and the very fabric of our economies and culture relate to the nature of our climate, its regularity/variability and severity. Climate change should therefore be a central field of inquiry in the social, behavioral and organizational sciences generally. This is especially so given that much of the observed and current climate change is attributed with a high degree of confidence to human activities and further change is anticipated. Whilst historically biophysical research has tended to dominate attention to the climate-change issue, there is an emerging literature examining laypeople's environment-related knowledge structures and the changes in attitudes, beliefs and behaviors required to effectively implement responses to the issues raised by the physical sciences. However, there are limitations in this literature, particularly regarding how scientists themselves engage with and capture emerging knowledge related to the issue. Although there is a broad consensus that the environmental problems we are experiencing are essentially social, organizational and behavioral problems, insufficient attention has been given to the issue of how to cultivate a cross disciplinary approach to address what is a complex and systemic problem (Cash et al., 2006). This article seeks to bring that issue into focus and offers a whole-of-science agenda for climate-change related research. It is essential that social, behavioral and organizational scientists accept greater responsibility for helping to address and facilitate the social, attitudinal, behavioral and management changes required to ameliorate and respond to the environmental deterioration identified by research in the physical sciences. The need for further and ongoing multi-disciplinary and international research is both necessary and pressing. Moreover, it is an ethical and practical responsibility that individuals of all scientific persuasions cannot afford to shirk.\n",
      "  - Much of human behavior and the very fabric of our economies and culture relate to the nature of our climate, its regularity/variability and severity. Climate change should therefore be a central field of inquiry in the social, behavioral and organizational sciences generally. This is especially so given that much of the observed and current climate change is attributed with a high degree of confidence to human activities and further change is anticipated. Whilst historically biophysical research has tended to dominate attention to the climate-change issue, there is an emerging literature examining laypeople's environment-related knowledge structures and the changes in attitudes, beliefs and behaviors required to effectively implement responses to the issues raised by the physical sciences. However, there are limitations in this literature, particularly regarding how scientists themselves engage with and capture emerging knowledge related to the issue. Although there is a broad consensus that the environmental problems we are experiencing are essentially social, organizational and behavioral problems, insufficient attention has been given to the issue of how to cultivate a cross disciplinary approach to address what is a complex and systemic problem (Cash et al., 2006). This article seeks to bring that issue into focus and offers a whole-of-science agenda for climate-change related research. It is essential that social, behavioral and organizational scientists accept greater responsibility for helping to address and facilitate the social, attitudinal, behavioral and management changes required to ameliorate and respond to the environmental deterioration identified by research in the physical sciences. The need for further and ongoing multi-disciplinary and international research is both necessary and pressing. Moreover, it is an ethical and practical responsibility that individuals of all scientific persuasions cannot afford to shirk.\n",
      "--------------------------------------------------\n",
      "Topic 151: 151_tourism_health_adaptation_vulnerability\n",
      "Representative Documents:\n",
      "  -                                  Background                  The Middle East (ME) is expected to be influenced by climate changes that will significantly affect human health. An increase in temperature and in the intensity, length and frequency of heat waves, alongside a decrease in precipitation, have been observed, and longer summers and shorter winters are expected. Population growth intensifies the stress on water and the ecosystem in an already sensitive region. Moreover, political conflicts intensify the vulnerability of the region's population and prevent cross-border collaboration and knowledge transfer. The aims of this talk are to: 1) present climate scenarios and potential health risks for the ME; and 2) present a regional inter-disciplinary collaboration that focuses on climate and health research.                                                Methods                  To prioritize regional research directions, a group of climatologists and public health researchers from the ME and Europe convened in an expert workshop, which included a process of consensus-building regarding research priorities and potential collaboration.                                                Results                  Associated health risks are mainly increases in morbidity and mortality due to heatwaves, and increases in potentially deadly vector- water- air- and food-borne diseases such as chikungunya, yellow fever and dengue fever, due to expansion of invasive species of mosquitoes. There are wide economic and infrastructure gaps among the region's countries, entailing different levels of preparedness. Countries also face multiple intra- and inter-country political conflicts and instability which further weaken their ability to adapt at the regional level. However, climate change has regional impacts which should be understood and mitigated at that level. Research priorities include spatio-temporal research on heat and health outcomes; regional surveillance of infectious diseases; and preparedness of health systems and pathways for collaboration among health agencies in the midst of a political conflict with an emphasis on vulnerable populations.                                                Key messages                  Inter-sectoral and inter-disciplinary work is a known requirement for tackling climate change challenges. Structural changes are needed at both the local and regional levels to fulfill this vision. Political conflicts in the Middle East weaken the ability to adapt to climate change in a vulnerable region.               \n",
      "  -  The problem of flooding in Warri, Nigeria is as old as the city itself. What has changed in recent years is the rapidly increasing magnitude and frequency of floodwater retention pools on urban streets as urban development expanded into low-lying swamplands within the city. Through the process of community urban risk assessments, urban flood zone occupants acknowledge the growing problem of on-street flood retention pools in a city once dominated by problems with off-street flood retention pools. A factor analysis of the perceived causes of flooding shows that Warri residents believe that human activities that reduced the floodwater storage capacity of its natural drainage sinks (i.e., its swamplands), violated building codes, changed local water levels, altered low-lying mangrove swamp terrain, and eliminated drainage facilities are responsible for the increasing retention of floodwater pools on city streets in the last few decades. Such local stock of flood knowledge has implications for a local participatory approach to community adaptations and mitigation methods to reduce urban flood risks from climate change and uncontrolled urban expansion. Local community adaptation choices guide how flood-affected residents cope with urban floods, especially how they use and alter their living space and respond to emergencies. However, such community views are often ignored by experts seeking solutions to flooding. If the views of flood zone occupants begin to inform flood adaptation choices, proposed solutions to flooding problems would be more likely to receive local support and acceptance, thus making the bottom-up solutions developed in this paper easier to implement and sustain. Once a well-formulated grassroots adaptation strategy for urban flood risk management for resiliency becomes the base for action, a more resilient national policy is sure to succeed, especially in low-income and lower-middle-income countries where informal settlement is the case and the role of government in flood management is still minimal. \n",
      "  -                                                     Climate change seriously threatens health and wellbeing with projected health burdens estimated to cost USD 2-4 billion a year by 2030. Adaptation in the health sector is critical to keep pace with the ongoing consequences of the climate crisis and the impacts projected to occur in the next decade and beyond. Yet estimates by the WHO indicate that climate finance targeting the health sector to date is extremely low: less than 0.5% of multilateral climate adaptation funding has targeted the health sector. In this study, we trace and quantify the amount of adaptation financing targeting the health sector from both multilateral and bilateral sources using publicly available information on the OECD-DAC database and Climate Funds Update. We find that between 2009-2019 only 0.39% of multilateral and bilateral climate adaptation funding targeted health-related efforts specifically. Despite the relatively higher number of health-related projects in Sub-Saharan Africa compared to other regions, a smaller amount of funding is allocated per project compared to other regions. Regional variations in funding are concerning as the countries with the most vulnerability to the climate crisis coincide with regions getting the least amount of funding per project. There is a significant gap in globally financed adaptation efforts in the health sector. Swift and committed remediation is needed to minimise the spiralling risk of high negative health outcomes.                                                Key messages                  • Between 2009-2019 only 0.39% of multilateral and bilateral climate adaptation funding targeted health-related efforts specifically.                  • The countries with the most vulnerability to the climate crisis coincide with regions getting the least amount of funding per health project.               \n",
      "--------------------------------------------------\n",
      "Topic 152: 152_pest_parasitoids_parasitoid_parasitism\n",
      "Representative Documents:\n",
      "  - The highly destructive Asian brown marmorated stink bug (Halyomorpha halys, BMSB) invaded Europe, Caucasus region, and North and South America. Efforts to control it are ongoing in the Palearctic European-Mediterranean Basin and North America by introducing and redistributing two Asian stenophagous scelionid egg parasitoids (Trissolcus japonicus and T. mitsukurii) that are attacked by an adventive oligophagous pteromalid Asian hyperparasitoid (Acroclisoides sinicus). Large BMSB nymphs and adults may be parasitized by new associations of oligophagous tachinid flies and immature stages by egg parasitoids and predators. The terms stenophagous and oligophagous are commonly used to define narrow and wider ranges, respectively, of food eaten, but here they refer to the range of hosts attacked by adult female parasitoids. A holistic weather-driven physiologically based demographic model (PBDM) of the tritrophic interactions was developed to evaluate prospectively the impact of natural enemies on the biological control of BMSB under current and climate change weather. Our study focuses on the European-Mediterranean region, with the results for the USA, Mexico, and Central America reported as supplementary information. The PBDM analysis suggests that biotypes of the egg parasitoids T. japonicus and T. mitsukurii with high search capacity could suppress BMSB regionally, but the requisite levels of parasitism by these parasitoids for economic control are not observed in their native range nor in invaded areas. The model suggests that the action of T. japonicus is greater than that of T. mitsukurii, but that joint interactions of the two egg parasitoids would provide higher mortality of BMSB. Field data and model results suggest that the egg hyperparasitoid A. sinicus has a modest negative impact on the suppression of BMSB. Moreover, tachinid parasitoids of adults could have an important supplemental role in suppressing BMSB densities. Analysis suggests that new biotypes of egg parasitoids and species of tachinid parasitoids of large nymphs and adults be sought.\n",
      "  - The coexistence and efficiency in pest control of introduced and native parasitoids can be challenging. Continuous observations of the cohabitation of parasitoid species could confirm the persistence of the introduced parasitoid in the ecosystem under co-existence scenarios. This study provides an example of such a co-existence for biocontrol of the invasive pest, Phthorimaea absoluta (Meyrick) (Lepidoptera: Gelechiidae). Two parasitoids, the introduced endoparasitoid Dolichogenidea gelechiidivoris (Marsh) (Hymenoptera: Braconidae) and the native ectoparasitoid Bracon nigricans Szépligeti (Hymenoptera: Braconidae) were released in cages containing a tomato plant infested with P. absoluta. Parasitism and killing rate of P. absoluta by both parasitoid species, and the parasitoid and P. absoluta population were monitored weekly. The parasitoid species coexisted for seven weeks in the experimental units. Parasitism by D. gelechiidivoris was significantly affected by the presence of B. nigricans, with 73% and 22% parasitism in the absence and presence of B. nigricans, respectively. Parasitism by B. nigricans was not affected by its co-existence with D. gelechiidivoris. The number of D. gelechiidivoris adults increased eight-fold in five weeks in the absence of B. nigricans, while less than the initial number of adults were present in co-existence with B. nigricans. The P. absoluta infestation declined from the fifth week to 98% lesser than the control in all the treatments, either D. gelechiidivoris or B. nigricans as standalone treatments, as well as in combination. Since B. nigricans negatively affected D. gelechiidivoris population growth, releases of this introduced parasitoid should be considered with caution in areas where B. nigricans occurs.\n",
      "  - Associations between the South American tomato pinworm, Tuta absoluta (Meyrick) (Lepidoptera: Gelechiidae), and its native parasitoids need to be updated to increase the implementation of pest control strategies. In this study, T. absoluta-infested tomato plants were collected from three regions in Kenya. The emerged parasitoids were identified, and their abundance was correlated with agroecological parameters, viz. cropping systems, and the abundance of the predator Nesidiocoris tenuis Reuter (Hemiptera: Miridae). The study further conducted a habitat suitability prediction for the identified parasitoids. Two parasitoid species, Bracon nigricans (Szépligeti) (Hymenoptera: Braconidae) and Stenomesius sp. near japonicus (Ashmead) (Hymenoptera: Eulophidae) emerged from T. absoluta immature stages, with parasitism rates ranging from 0 to 21% and 0 to 17% respectively. Insecticide application and open field cropping negatively influenced the parasitism by S. sp. nr japonicus. Low occurrence of N. tenuis positively affected B. nigricans parasitism. The predicted occurrence of parasitoid species indicated vast suitable areas for B. nigricans in sub-Saharan Africa, Australia, and South America. Low suitability was observed for S. sp. nr japonicus in Africa. Therefore, native parasitoids, especially B. nigricans could be considered for implementation as a biocontrol agent in the Integrated Pest Management program of T. absoluta.\n",
      "--------------------------------------------------\n",
      "Topic 153: 153_herbivory_plant_insect_herbivore\n",
      "Representative Documents:\n",
      "  - Climate warming is predicted to affect species and trophic interactions worldwide, and alpine ecosystems are expected to be especially sensitive to changes. In this study, we used two ongoing climate warming (open‐top chambers) experiments at Finse, southern Norway, to examine whether warming had an effect on herbivory by leaf‐chewing insects in an alpine Dryas heath community. We recorded feeding marks on the most common vascular plant species in warmed and control plots at two experimental sites at different elevations and carried out a brief inventory of insect herbivores. Experimental warming increased herbivory on Dryas octopetala and Bistorta vivipara. Dryas octopetala also experienced increased herbivory at the lower and warmer site, indicating an overall positive effect of warming, whereas B. vivipara experienced an increased herbivory at the colder and higher site indicating a mixed effect of warming. The Lepidoptera Zygaena exulans and Sympistis nigrita were the two most common leaf‐chewing insects in the Dryas heath. Based on the observed patterns of herbivory, the insects life cycles and feeding preferences, we argue that Z. exulans is the most important herbivore on B. vivipara, and S. nigrita the most important herbivore on D. octopetala. We conclude that if the degree of insect herbivory increases in a warmer world, as suggested by this study and others, complex interactions between plants, insects, and site‐specific conditions make it hard to predict overall effects on plant communities.\n",
      "  - Climate warming can modify plant reproductive fitness through direct and indirect pathways. Direct effects include temperature‐driven impacts on growth, reproduction, and secondary metabolites. Indirect effects may manifest through altered species interactions, including herbivory, although studies comparing the interactive effects of warming and herbivory are few. We used experimental warming combined with herbivore exclusion cages to assess the interactive effects of climate warming and herbivory by Popillia japonica, the Japanese beetle, on flowering phenology, growth, defense, and lifetime reproduction of a biennial herb, Oenothera biennis. Regardless of temperature, herbivory delayed flowering phenology and, surprisingly, led to decreased levels of foliar defenses. At ambient temperatures, plants were able to compensate for herbivory by producing smaller seeds and increasing total seed production, leading to similar investment in seed biomass for plants exposed to and protected from herbivores. At elevated temperatures, plants had elevated total seed production, but herbivory had negligible impacts on flower and fruit production, and total lifetime seed biomass was highest in plants exposed to herbivores in warmed conditions. We speculate that warming induced a stress response in O. biennis resulting from low soil moisture, which in turn led to an increase in seed number at the expense of maternal investment in each seed. Plant‐insect interactions might therefore shift appreciably under future climates, and ecologists must consider both temperature and herbivory when attempting to assess the ramifications of climate warming on plant populations.\n",
      "  - Climate change is a mounting global issue, but its consequences will be variable across regions. Tropical species are hypothesized to have reduced climatic adaptability and plasticity. Yet, relative to temperate species, less is understood about how they will respond to climate change. Rising temperature and atmospheric CO2 could impact plant–herbivore systems directly by altering species traits or abundances, or the effects could be indirect by altering the strength and direction of the relationships that govern organismal strategies and interactions. Using open‐top chambers in a Neotropical wet forest, we applied a full‐factorial combination of active warming and CO2 fertilization to investigate the above‐ground, short‐term effects of climate change on plant–herbivore interactions in a common Neotropical shrub, Piper generalense. We aimed to answer two main questions: (1) Could climate change alter plant–herbivore systems through direct effects on plant growth rate, chemical defense, and/or insect herbivore damage rate? and (2) Could climate change affect plant–herbivore systems indirectly by altering (a) the strength of plant resource allocation trade‐offs between growth and defense or (b) the effectiveness of plant chemical defense against herbivory? None of the microclimate treatments had direct effects on plant growth, chemical defense, or herbivore damage. However, we did observe a positive relationship between growth and chemical defense in treatments mimicking climate‐change conditions, which partially supports the growth–differentiation balance hypothesis. We did not detect any effects of treatments on the effectiveness of plant chemical defense against herbivory. It appears that, in this system, increased CO2 concentration and temperature may cause indirect, cascading consequences, even where direct effects are not observable. We recommend more climate‐change experiments addressing multi‐trophic interactions that focus not only on the direct responses of organisms but also on the ways in which climate change can restructure the relationships that govern complex biotic systems.\n",
      "--------------------------------------------------\n",
      "Topic 154: 154_hypothermia_perioperative_perioperative hypothermia_patient\n",
      "Representative Documents:\n",
      "  -  An unplanned fall in body temperature to below 36°C in adult surgical patients, inadvertent perioperative hypothermia is associated with negative recovery outcomes for patients after surgery, despite being largely preventable. The National Institute for Health and Care Excellence ( NICE, 2016 ) guidelines for preventing and managing inadvertent perioperative hypothermia recommend forced-air warming, and the warming of intravenous fluids and blood products before administration, to promote patient warming. Pre-warming could be a significant factor in preventing inadvertent perioperative hypothermia. The Enhanced Recovery After Surgery (ERAS) programme for surgical patients recognises the importance of patient warming for achieving a rapid and uncomplicated recovery from major surgery. \n",
      "  -  Protecting patients from developing inadvertent perioperative hypothermia is an integral element of the enhanced recovery after surgery (ERAS) programme because this protection promotes physical wellbeing throughout a patient's surgical journey. Inadvertent perioperative hypothermia (IPH) is preventable in most cases, yet as many as 70% of surgical patients experience it ( Niranjan et al, 2011 ). It is associated with multiple devastating complications for the patient. As ERAS programmes focus on optimising the patient's physical state prior to, during and after surgery, it fits that maintaining a healthy body temperature forms part of the programme. In this article, the risk factors at all stages of the patient's surgical journey will be discussed, as well as strategies for warming patients and why this is vital for the success of ERAS programmes. \n",
      "  -  Protecting patients from developing inadvertent perioperative hypothermia is an integral element of the enhanced recovery after surgery (ERAS) programme because this protection promotes physical wellbeing throughout a patient's surgical journey. Inadvertent perioperative hypothermia (IPH) is preventable in most cases, yet as many as 70% of surgical patients experience it ( Niranjan et al, 2011 ). It is associated with multiple devastating complications for the patient. As ERAS programmes focus on optimising the patient's physical state prior to, during and after surgery, it fits that maintaining a healthy body temperature forms part of the programme. In this article, the risk factors at all stages of the patient's surgical journey will be discussed, as well as strategies for warming patients and why this is vital for the success of ERAS programmes. \n",
      "--------------------------------------------------\n",
      "Topic 155: 155_rats_breathing_chc_ventilatory\n",
      "Representative Documents:\n",
      "  - Serotonin (5‐HT) and Substance P, typically increase the excitability of neurons within the neural network controlling breathing through G protein‐coupled receptors. These neuromodulators also stimulate pH/CO2 sensitive Phox2b‐expressing (Phox2b+) neurons in the retrotrapezoid nucleus (RTN), but their role in supporting the ventilatory CO2 chemoreflex within the RTN has not been tested in vivo. We hypothesize that unilateral antagonism in the RTN of 5‐HT and/or NK‐1 receptors will attenuate the ventilatory CO2 chemoreflex. To test this hypothesis, 8 week old male Sprague Dawley rats were chronically implanted with guide cannula unilaterally using stereotaxic coordinates previously published (Dias et al., 2008). After 7 or more days of recovery, microdialysis probes were inserted into the guide cannula for dialysis of mCSF alone followed by mCSF mixed with individual or a cocktail of antagonists to 5‐HT7 receptors (SB 269970 (100 μM)), 5‐HT2A receptors (MDL 11,939 (20 μM)) and/or NK‐1 receptors (SR 140333 (40 μM)) while measuring breathing in room air (35 min) and during a 7% CO2 challenge (10 min) before and during drug dialysis. We found that SB 269970 consistently reduced hypercapnic breathing frequency (−9 ± 2%, n=3) compared to mCSF alone, and had mixed effects on eupneic breathing and hypercapnic tidal volume. MDL‐11939 consistently reduced eupneic breathing frequency (−7 ± 0.4%, n=3) and hypercapnic tidal volume (−17 ± 0.8%, n=3) compared to mCSF alone, but had mixed effects on eupneic tidal volume and hypercapnic breathing frequency. In addition, a cocktail of all antagonists consistently increased eupneic breathing frequency (+14%, n=2) and decreased hypercapnic breathing frequency (−7 ± 0.4%, n=2) compared to mCSF alone. These preliminary data suggest 5‐HT and Substance P within the RTN may modulate breathing at rest and during hypercapnic conditions in vivo.Support or Funding InformationThis work was supported by NIH HL122358.This  is from the Experimental Biology 2018 Meeting. There is no full text article associated with this  published in The FASEB Journal.\n",
      "  - Brown adipose tissue (BAT) and shivering thermogenesis and cutaneous vasoconstriction are inhibited in warm climatic conditions to reduce heat production and increase heat dissipation, thereby maintaining core body temperature homeostasis. We tested the hypothesis that the hypothalamic preoptic area (POA) contains warm sensitive neurons (WSNs) that are activated by local warming to produce inhibition of BAT activity. In urethane/α‐chloralose‐anesthetized, artificially‐ventilated rats, warming the POA bilaterally with a thermode (two silver rods connected to a peltier device) increased POA temperature from 35 to 40°C and promptly inhibited skin cooling (35–36°C)‐evoked BAT sympathetic nerve activity (SNA) (from 1061±2.7 to 102±0.1 that corresponds to 100% reduction, p&lt;0.001) and reduced BAT temperature (1.7±0.2, p&lt;0.001), core temperature (0.3±0.1, p&lt;0.05), expired CO2 (0.7±0.1%, p&lt;0.001), heart rate (61±10, p&lt;0.001) and mean arterial pressure (14±6, p&lt;0.05). Bilateral nanoinjections of the GABAA‐agonist, muscimol (500 mM, 100 nl), into the ventral lateral preoptic area (vLPO) prevented (p&lt;0.001) the local POA warming‐induced inhibition of BAT SNA and the reductions in BAT and core temperatures. Blockade of ionotropic glutamate receptors in vLPO with nanoinjections of AP5/CNQX also prevented (p&lt;0.001) the local POA warming‐induced inhibitions of BAT thermogenesis. POA warming failed (p&gt;0.05) to inhibit the elevated BAT SNA following blockade of local GABAA receptors with nanoinjections of bicuculline (BIC) in the rostral raphe pallidus (rRPa), but still effectively inhibited the elevated BAT SNA following BIC nanoinjections in the dorsomedial hypothalamus (DMH). Our results demonstrate that the POA warming‐evoked inhibition of BAT thermogenesis requires activation of GABAA receptors in rRPa, but not those in DMH. In addition, the finding that glutamate receptor blockade in vLPO prevents the POA warming‐induced inhibition of BAT activity, is consistent with WSNs glutamatergically exciting BAT sympathoinhibitory neurons in vLPO to produce the POA warming‐induced inhibition of BAT thermogenesis. These novel findings elucidate the central pathway mediating POA warming‐evoked inhibition of BAT thermogenesis and require the addition of a BAT sympathoinhibitory pathway between vLPO and rRPa to the current model of central autonomic thermoregulation.Support or Funding InformationSupported by NIH R01091066 (SFM).This  is from the Experimental Biology 2018 Meeting. There is no full text article associated with this  published in The FASEB Journal.\n",
      "  - SUMMARYThe goal of this study was to examine the role of respiratory-related afferent input on the chronic hypercapnia (CHC)-induced increase in central respiratory-related pH/CO2 chemosensitivity in cane toads (Bufo marinus). Toads were exposed to CHC (3.5% CO2) for 10 days,following which in vitro brainstem-spinal cord preparations were used to assess central respiratory-related pH/CO2 chemosensitivity. Motor output from the vagus nerve root was used as an index of breathing(fictive breathing). Olfactory denervation (OD), prior to exposure to CHC, was used to remove the influence of CO2-sensitive olfactory chemoreceptors, which inhibit breathing. Exposure to chronic hyperoxic hypercapnia (CHH) was used to reduce the level of arterial chemoreceptor input compared with CHC alone. In vivo experiments examined the effects of CHC, CHH and OD on the acute hypercapnic ventilatory response of intact animals. In vitro, a reduction in artifical cerebral spinal fluid(aCSF) pH increased fictive breathing in preparations taken from control and CHC animals. CHC caused an increase in fictive breathing compared with controls. OD and CHH abolished the CHC-induced augmentation of fictive breathing. In vivo, CHC did not cause an augmentation of the acute hypercapnic ventilatory response. CHH reduced the in vivo acute hypercapnic ventilatory response compared with animals exposed to CHC. In vivo, OD reduced breathing frequency and increased breath amplitude in both control and CHC animals. The results suggest that afferent input from olfactory and arterial chemoreceptors, during CHC, is involved in triggering the CHC-induced increase in central respiratory-related pH/CO2chemosensitivity.\n",
      "--------------------------------------------------\n",
      "Topic 156: 156_dietary_feed_weight_intake\n",
      "Representative Documents:\n",
      "  - The objective of the present study was to investigate the potential effects associated with dietary probiotic inclusion and the stocking density on carcass traits, meat chemical composition, meat sensory quality, microbial populations and ileal histomorphology in broiler chickens raised under hot climate conditions. In total, 1800 1-day-old unsexed broiler chicks (Ross 308) were randomly allocated in a completely randomised design according to a 3 × 2 factorial arrangement, with three concentrations of a dietary probiotic (0, 200 and 400 mg/kg) containing 4 × 109 cfu/g of Bacillus subtilis and two stocking densities (12 or 18 birds/m2), forming six treatments, with three pens (replicates) each. The probiotic concentration had no significant (P &amp;gt; 0.05) effect on bodyweight gain, feed consumption, feed conversion ratio, carcass percentage and meat chemical composition. Dietary probiotic inclusion significantly (P = 0.02) increased the scores of meat colour and odour. The acceptability score was significantly (P &amp;lt; 0.03) affected by the stocking density. Dietary supplementation of the probiotic at both 200 and 400 mg/kg significantly (P = 0.05) reduced the counts of Escherichia coli and Salmonella in the gut and litter. In meat, dietary supplementation of the probiotic at 200 and 400 mg/kg significantly (P = 0.03) reduced the counts of E. coli, compared with those of the control group. Moreover, Salmonella was not detected in meat. Regarding the ileal villi and crypt morphology, dietary probiotic supplementation significantly (P = 0.05) increased the height of the villus. There were no significant probiotic concentration × stocking density interactions for any of the investigated parameters, except for the gizzard percentage. Thus, dietary probiotic supplementation in broilers raised under a high ambient temperature had a significantly positive effect on the ileal villus height and a significantly negative effect on the counts of E. coli and Salmonella in the gut and litter. No negative effects on growth performance, carcass parts and meat quality were detected.\n",
      "  - Supplementation with natural additives such as essential oils (EO) or probiotics has resulted in comparable growth performance to that of supplemental monensin in fattening lambs in hot environments. Supra-supplementation levels of vitamin D3 improved the carcass weight and dressing percentage of steers fattened under tropical conditions. We hypothesized that certain combinations of these natural additives could be complementary. For this reason, a feeding trial was carried out using 48 Pelibuey × Katahdin non-castrated male lambs (107 ± 14 d age; 17.9 ± 2.51 kg LW). Lambs were fed an 88:12 concentrate to forage ratio basal diet supplemented (dry matter basis, DMI) with: (1) no additive (CON); (2) 28 mg monensin/kg diet (MON); (3) 150 mg of essential oils containing a combination of thymol, eugenol, vanillin, guaiac, and limonene plus 0.12 mg vitamin D3 (EO + D3)/kg diet; and (4) 300 mg of essential oils containing a combination of carvacrol and cynamaldehyde plus 2 g probiotic (2.2 × 108 CFU of bacillus subtilis/kg diet, EO + BS). Lambs were grouped by initial weight and assigned within six weight groupings to 24 pens (2 lambs/pen, 6 replicas per treatment) in a randomized complete block design. The experiment lasted 121 days. Daily maximal THI exceeded the 80 “danger or “emergency” range for 119 days of the 121 days of the trial. Lambs supplemented with MON had similar DMI, growth performance, and dietary energetics to those of CON lambs. Lambs supplemented with EO + BS had a greater (9.2%, p ≤ 0.05) average daily gain (ADG) than the CON and MON groups due to enhanced (10.2%, p ≤ 0.05) dry matter intake. Thus, gain efficiency (GF) and estimated dietary energy were similar for CON, MON, and EO + BS. Lambs receiving EO + D3 had similar (0.254 vs. 0.262 kg/d) ADG but a lower DMI (8%, p &lt; 0.05) compared with EO + BS lambs. Consequently, GF and estimated dietary net energy were greater (4.9 and 3.7%, respectively; p ≤ 0.05) for EO + D3 lambs. Even when ambient heat load was elevated, the efficiency of utilization of dietary energy (observed-to-expected dietary net energy) was close to 1.00 (0.992) expected for EO + D3 lambs. In contrast, efficiency of energy utilization was depressed by −4.4% for lambs on the other treatments. Compared with the other treatments, lambs receiving EO + D3 had greater longissimus muscle area (5.6%, p &lt; 0.05) and lower kidney pelvic fat (21.8%, p ≤ 0.05). There were no treatment effects on shoulder tissue composition or whole cuts (expressed as % of cold carcass weight). Compared to CON, lambs that were fed with natural additives showed 3.5% lower (p ≤ 0.05) intestine mass. All supplemental additives decreased visceral fat mass, which was minimal with EO + D3 treatment. Combinations of essential oils with vitamins or probiotics were superior to antibiotic monensin in finishing diets for feedlot lambs. Combining EO with probiotics promoted DM intake and gain but not gain efficiency, while combining EO with vitamin D3 supra-supplementation increased dietary energy efficiency and improved some carcass characteristics in lambs fattening under high ambient heat loads.\n",
      "  - Objective: Microencapsulation technologies have been developed and successfully applied to protect the probiotic bacterial cells damaged by environmental exposure. This study aimed to investigate the effects of microencapsulation of &lt;i&gt;Lactobacillus plantarum&lt;/i&gt; MB001 on the growth performance, ileal nutrient digestibility, jejunal histomorphology and cecal microbiome of broiler chickens in a tropical climate.Methods: A total of 288 one-day-old female broilers (Ross 308) were randomly allocated into 4 groups (6 replicates of 12 birds). Treatments included, i) a basal diet (NC), ii) NC + avilamycin (10 mg/kg) (PC), iii) NC + non-encapsulated &lt;i&gt;L. plantarum&lt;/i&gt; MB001 (1×10&lt;sup&gt;8&lt;/sup&gt; colonyforming unit [CFU]/kg of diet) (N-LP), iv) NC + microencapsulated &lt;i&gt;L. plantarum&lt;/i&gt; MB001 (1×10&lt;sup&gt;8&lt;/sup&gt; CFU/kg of diet) (ME-LP).Results: Dietary supplementation of ME-LP improved average daily gain, and feed conversion ratio of broilers throughout the 42-d trial period (p&lt;0.05), whereas ME-LP did not affect average daily feed intake compared with NC group. Both N-LP and ME-LP improved apparent ileal digestibility of crude protein and ether extract compared with NC group (p&lt;0.05). The broilers fed ME-LP supplemented diet exhibited a beneficial effect on jejunal histomorphology of villus height (VH), crypt depth (CD) and villus height to crypt depth ratio (VH:CD) of broilers compared to NC group (p&lt;0.05). At the phylum level, Firmicutes was enriched (p&lt;0.05) and Proteobacteria was decreased (p&lt;0.05) only in the ME-LP group. At the genus level, the ME-LP diets increased (p&lt;0.05) the number of both &lt;i&gt;Lactobacillus&lt;/i&gt; and &lt;i&gt;Enterococcus&lt;/i&gt; compared to NC, PC, and N-LP groups (p&lt;0.05).Conclusion: Microencapsulation assists the efficient functioning of probiotics. ME-LP could be potentially used as a feed additive for improvement of cecal microbiota, gut integrity and nutrient utilization, leading to better performance of broilers.\n",
      "--------------------------------------------------\n",
      "Topic 157: 157_respondents_knowledge_hpv_health\n",
      "Representative Documents:\n",
      "  -                Introduction: Climate Change is a significant public health problem. Cancer survivors are among the most vulnerable populations during extreme weather events. In this research we aimed to describe attitudes towards climate change among a Hispanics population of cancer patients and caregivers. Methods: A cross-sectional study was done among adults ≥21 years old living in Puerto Rico (PR). Data collection started on April 2023 and is ongoing. After informed consent, participants completed an online or printed survey including sociodemographic, clinical and climate change-related variables. Participants were recruited through activities aimed at cancer patients/survivors and caregivers in PR, cancer treatment and accommodation centers, social media and tv. Descriptive statistics and bivariate analysis were used to describe the outcomes of interest, overall and by type of participant (patient/caregiver). Logistic regression models used to assess demographic factors associated to individual attitudes. Results: From April 22nd-June 8th, 2023, the study has recruited 318 participants from 66 municipalities in PR. For patients, mean age is 56.3 years ±13.5 SD, 79.1% are women, and 85.4% have more than high-school education.  For caregivers, mean age is 45.3 years ±15.4 SD, 91.4% are women, and 92.7% have more than high-school education. Most participants agreed that climate change information is important to them (98.1%), 50.2% disagreed that climate change is inevitable and 90.2% disagreed that it is too early to tell whether climate change is really a problem. Meanwhile, 96.0% agreed that as an individual, they can influence climate change and 80.1% agreed that the government should reward the people who contribute to mitigating climate change. Furthermore, 83.3% agreed that investing in technological innovations is required to tackle climate change. Meanwhile, most participants believe that each individual (98.4%) as well as the government (99.0%) must take action to help reduce the impact of climate change on the population.  Finally, 17.3% agreed that they worked to make a living, even if it is to the environment’s detriment and 27.8% agreed that people have the right to change the environment to suit their own needs. Multivariate logistic regression models showed that individuals with more than high-school education were more likely to agree to be working to make a living, even if it is in the environment detriments (OR=2.94, 95% CI=1.19-7.25) and to agree that people have the right to change the environment to suit their own needs (OR=2.21, 95% CI=1.07-4.60) as compared to their counterparts. No differences were observed between patients and caregivers. Conclusions: This Hispanic population of patients and caregivers is concerned about climate change, is mostly interested in mitigating its effects and thinks that the government should be involved in these efforts. This information is important for cancer control plans and for interventions that target climate change and its impact on cancer populations.               Citation Format: Ana P. Ortiz, Fabiola A. Rivera-Gastón, Jimena Pérez, Pablo A. Méndez-Lázaro. Attitudes towards climate change among cancer patients and caregivers in Puerto Rico []. In: Proceedings of the 16th AACR Conference on the Science of Cancer Health Disparities in Racial/Ethnic Minorities and the Medically Underserved; 2023 Sep 29-Oct 2;Orlando, FL. Philadelphia (PA): AACR; Cancer Epidemiol Biomarkers Prev 2023;32(12 Suppl): nr A113.\n",
      "  - PurposeThe Sustainable Development Goal (SDG) 13 is at the core of many sustainability initiatives on Mexican higher education institutions (HEIs). Yet, progress to SDG 13 and the entire 2030 Agenda might today appear unlikely to meet. To change this situation, it is necessary to form professionals aware of the impacts of climate change and competent to respond efficiently to its adaptation and mitigation. In this context, the purpose of this study is to reveal the beliefs and concerns about global warming of Mexican students enrolled in engineering bachelor's degrees at higher education institutes that promote sustainability.Design/methodology/approachIn an exploratory study, engineering university students at six large public universities in Mexico answered questions regarding their beliefs and concerns regarding climate change. The study was carried out by using the Global Warming's Six Americas survey questionnaire. The questionnaire was developed by a research team from the Yale Program on Climate Change Communication at Yale University to identify different audiences within the American public regarding climate change. Participants were recruited via convenience/snowball techniques which provided access to a diverse sample. Those who agreed to partake in the study were directed to an online platform via Google forms. Data were collected from January to April 2021. Coding and data treatment was conducted according to the developers' codebook and SPSS scripts. After running the statistical program scripts to determine the respondents' segment, a univariate descriptive analysis was performed for each item in the questionnaire to describe general properties in each variable. Subsequently, a series of correspondence analyses was conducted to examine the existence of clusters or patterns that could indicate relationships among selected questions.FindingsThe findings of this study revealed that the majority of the Mexican engineering higher education students participating in the survey fell in the segment of alarmed, 47.3%, or the segment of concerned, 46.%. Furthermore, 78.6% of higher education students in the alarmed segment were extremely sure that global warming is happening. In addition, 98% believed that it is caused mostly by human activities. Furthermore, 89% stated that global warming would harm them personally significantly and 96% thought that future generations would be harmed considerably. About 78% believed that people in Mexico and the USA are currently being harmed by global warming. On the other hand, about 45% of students in the concerned group noted they were extremely sure. In addition, 96% of them thought that global warming is being produced mostly by anthropogenic activities. Furthermore, 39% said global warming will harm them personally to a great deal. However, nearly 80% noted that global warming would also hurt future generations. Although those students in the alarmed and concerned group show similar beliefs and concerns about global warming, the magnitude of concern was more significant for those in the alarmed segment.Research limitations/implicationsThere are several limitations to the study. First, the online questionnaire did not allow for clarification or follow-up on behalf of the respondents. Therefore, it could be possible that respondents misunderstood some items. However, the research team took the following measures to limit confusion: (1) The questionnaire had been previously used in several studies. None of these studies reported problems related to confusion, so the research team took this fact as evidence of the acceptable reliability of the questionnaire. (2) A face-to-face pilot test was carried out with 30 university students where no problems of comprehension were reported. (3) The target population had adequate prior knowledge of climate change, so the possibility of misunderstandings was likely low. A second limitation relates to the nature of the study. Fighting to mitigate the global climate crisis is a positive social norm. Respondents may have provided answers in line with this social norm and presented themselves as more pro-environmental than they actually are. Second, because of our selection criteria, our data may overestimate the general public's “worldviews” on climate change. Finally, this study was carried on during the COVID-19 pandemic, which could have impacted items' responses. These limitations constitute future opportunities for future research. Specifically, future research might ideally use a large-scale comprehensive study evaluating the broader Mexican public's beliefs and views about climate change. Furthermore, because our data showed that our respondents were very concerned about climate change, but did little in terms of behavioral mitigation, future research should continue to examine and explore differences in various measures of climate friendly behaviors among different segments of the population.Practical implicationsThis study's findings have at least twofold implications for university authorities and sustainability practitioners in their pursuit of meeting SDG 13. The first implication is related to academic life. Undoubtedly, having a high percentage of students believing in global warming and mainly that this phenomenon is by anthropogenic activities is a strong indication of their knowledge. But, indirectly, these results validate the sustainability teaching and research efforts in their HEIs, implying the commitment to sustaining and improving the quality of their sustainability-educational initiatives in all institutional areas. The second implication of our findings is related to HEIs' future commitments to address the target of SDG 13 during the present Decade of Actions. Results also lead us to reflect on the role of Mexican HEIs as agents of change, beyond offering good instruction on climate science as an agent of socialization to encourage positive mitigation and adaptation behaviors among the general population.Social implicationsThe social implication behind the environmental values of younger people found in this study is that a deeper understanding of these millennials' beliefs and concerns toward global warming will help Mexican policymakers implement policies in this regard and hopefully will be endorsed by a significant proportion of the Mexican population.Originality/valueThe originality of this study is the application of the Global Warming's Six Americas survey questionnaire in higher education settings. Therefore, the knowledge generated determines the quality of the article. As findings in this study revealed, there is apparently little disagreement among the Mexican engineering higher education students about the belief of the existence of global warming and this phenomenon is being caused mainly by human-related activities. Nevertheless, a minority of students still believe that global warming is caused naturally or not occurring. However, it is not possible to claim victory, as these achievements should not be considered, in any way, a guarantee that students will carry out behaviors in their daily lives that impact a reduction in global warming. Nevertheless, the study provides insights to allow university authorities to ensure that the current beliefs and concerns will not fade in the post-pandemic times. Thus, the COVID-19 pandemic should be taken a pivotal era toward the goal of increasing the global average temperature to well below 2°C above pre-industrial levels and pursuing efforts to limit the temperature increase to 1.5°C above pre-industrial levels.\n",
      "  -                Background: Human Papillomavirus (HPV) is a common sexually transmitted infection that has been associated with the development of cancers, most of them preventable if the HPV vaccine is administered before exposure. HPV school-entry policies could affect the HPV rates at a population level, hence the need for monitoring nationally the support of policies to assess acceptance at different levels. Objective: This study describes the state-level immunization program managers’ (IPMs) perception of the degree of the general public and policymakers’ acceptance or opposition to the HPV vaccine policies to increase HPV vaccination across their state or territory. Methods: As part of the study entitled Implementation of School-Entry Policies for Human Papilloma Virus Vaccination (HPV-PIVac), IPMs were surveyed about their perception regarding the acceptance or opposition of either (1) the public and (2) policymakers towards HPV vaccine policies. Five questions inquired about the degree of public concern towards HPV-related cancers, public hesitancy towards the HPV vaccine, public opposition towards HPV policies, and acceptance or resistance from policymakers regarding HPV vaccine policies using a five-item scale transformed into a three-item scale. Descriptive statistics were used to assess the managers perception about HPV vaccine policies. Fisher’s exact test was conducted to assess regional differences and the relationship between perception items from the public and policymakers. Results: 49 IPMs from 32 different states and territories participated in this study. In relation to the public concern towards HPV-related cancers, 93.8% of IPMs perceived that the public from their participant states and territories had moderate/mild concern. In comparison, only 6.3% perceived strong/overwhelming concern. For public hesitancy towards the HPV vaccine, 81.3% of IPMs perceived that the public had moderate/mild hesitancy, while 18.8% perceived strong/overwhelming reluctance. For public opposition towards HPV vaccine policies, 21.9% of IPMs perceived strong/overwhelming opposition. On the other hand, 40.6% of IPMs reported that the policymakers were resistant to education policies that promote the HPV vaccine. Similarly, 59.4% of IPMs reported that policymakers were resistant to HPV-school entry vaccination policies. No significant differences between regions were observed in the items analyzed (p&amp;gt;0.05). Fisher’s exact test indicated a significant association between the public opposition towards the HPV vaccine policies and the posture of policymakers towards HPV education policies (p&amp;lt;0.05). Conclusion: Results highlight that IPM’s perceive moderate/mild hesitancy and moderate/mild opposition by the public towards HPV vaccines and HPV policies; these attitudes could translate into resistance towards HPV policies by policymakers in the US. Findings support the need for active public engagement strategies to increase policymakers' support for promoting HPV vaccine policies and requirements. Funding: NCI Grant #R01CA232743.               Citation Format: Yiana G. Toro-Garay, Alondra K. Mercado-Andino, Olga L. Diaz-Miranda, Diana T. Medina-Laabes, Ana P. Ortiz, Katelyn Wells, Erick Suárez, Vivian Colón-López. National assessment of the HPV acceptance: Public attitudes and policy climate []. In: Proceedings of the 15th AACR Conference on the Science of Cancer Health Disparities in Racial/Ethnic Minorities and the Medically Underserved; 2022 Sep 16-19; Philadelphia, PA. Philadelphia (PA): AACR; Cancer Epidemiol Biomarkers Prev 2022;31(1 Suppl): nr A129.\n",
      "--------------------------------------------------\n",
      "Topic 158: 158_zu_werden_ist_das\n",
      "Representative Documents:\n",
      "  - Holz hat zahlreiche Vorteile gegenüber anderen Materialien: Es ist nachhaltig, hat eine gute CO2‐ und Energiebilanz, ist aufgrund seiner biologischen Abbaubarkeit umweltfreundlich und seine mechanischen Eigenschaften sind so gut, dass es als Baumaterial z. B. für mehrstöckige Häuser genutzt wird. Außerdem lassen sich offensichtlich nachteilige Eigenschaften von Holz gegenüber anderen Materialien dank moderner Forschung inzwischen durch chemische Modifizierungen hinreichend verbessern: Chemisch modifiziertes Holz hat eine höhere Dauerhaftigkeit und quillt bzw. schwindet bei einer Änderung der Umgebungsbedingungen nicht so stark wie naturbelassenes Holz. Neben Materialien wie biobasierten Kunststoffen oder Kompositen aus Holz und Kunststoffen könnte daher chemisch modifiziertes Holz und damit die Chemie in Zukunft einen Beitrag zu mehr Nachhaltigkeit und Klima‐ sowie Umweltschutz leisten. In diesem Beitrag werden fachliche Grundlagen zum Aufbau, zur molekularen Struktur und chemischen Modifizierung von Holz und anknüpfende curriculumsbezogene Experimente präsentiert, die Einblicke in die aktuelle Forschung geben und mit denen in der Schule oder in einem Schülerlabor Aspekte der Polymerchemie im Kontext von Nachhaltigkeit und Klimaschutz unterrichtet werden können.\n",
      "  - Die Möglichkeit der Klimaentlastung durch die stoffliche Nutzung nachwachsender Rohstoffe im Bauwesen, insbesondere von Holz, findet bisher wenig Beachtung. Obwohl die Qualität von Holz als wirksamer Kohlenstoffspeicher im Grundsatz bekannt ist und seine Berücksichtigung in der Gestaltung der Treibhausgasbudgets im Rahmen des Intergovernmental Panel on Climate Change (IPCC)‐Prozesses entsprechend intensiv diskutiert wird, fehlt es noch an strategischen Ansätzen, dieses Potential zu aktivieren. Insbesondere geben die ordnungsrechtlichen Anforderungen an die Energieeffizienz von Gebäuden bislang keine Anreize für eine stoffliche Verwendung von Holz als aktive CO2‐Senke, obwohl hier mehr als in jedem anderen Nutzungsbereich von Holz eine dauerhafte verrottungsfreie Speichermöglichkeit von Kohlenstoffdioxid gegeben ist. In dem vorliegenden Beitrag wird die CO2‐Senkenwirkung durch stoffliche Holznutzung im Bauwesen gegenüber den energiebedarfsinduzierten CO2‐Emissionen neuer Gebäude abgewogen. Es zeigt sich, dass die stoffliche CO2‐Senkenleistung im Zusammenspiel mit der heute erreichten Emissionsminderung durch Energieeffizienzmaßnahmen und den Einsatz erneuerbarer Energieträger erheblich an Bedeutung gewinnt. Im Interesse des Klimaschutzes ist daher eine Steigerung des stofflichen Einsatzes von Holz anzustreben. Allerdings sind etliche Massivholzbausysteme auf Grund der schon kurzfristig anstehenden Verschärfungen der Anforderungen an die Energieeffizienz von Gebäuden durch die Fortschreibung der Energieeinsparverordnung, vor allem aber durch die Forderungen der EU, ab 2018 bzw. 2020 ausschließlich Niedrigstenergiehäuser zuzulassen (Häuser, die nahezu keinen Primärenergiebedarf aufweisen), akut gefährdet. Es wird daher ein Vorschlag erarbeitet, der Kohlenstoffsenkenleistung des Baustoffes Holz in den öffentlich/rechtlichen Anforderungen an die Energieeffizienz von Gebäuden Rechnung tragen zu können.Using solid wood construction methods in order to reduce emissions affecting the climate; options for reducing the CO2 output created by external building components by using solid wood construction as part of the legal requirements for the energy efficiency of buildings, part 2. Up to now, the use of renewable resources, particularly timber, in order to reduce emissions affecting the climate has not received much attention. In spite of the fact that the properties of timber as an effective carbon store are well known in principle and its use has been extensively discussed for the purpose of determining the greenhouse gas budget within the context of the Intergovernmental Panel on Climate Change (IPCC) process, there is still a lack of strategic approaches to activate this potential. In particular, the statutory requirements for the energy efficiency of buildings have up to now not provided any incentives for the use of timber as a construction material in spite of the fact that timber provides a more durable and lasting carbon dioxide storage opportunity in construction than in any other application of the material. The article below weighs up the CO2 sink effect through use in construction compared with the CO2 emissions of new buildings created by the demand for energy. It is shown that the CO2 sink effect of timber in combination with the emission reductions through energy efficiency measures achievable today, and the use of renewable fuels is of considerable significance. It follows that the increased use of timber as a building material is desirable in the interest of climate protection. Against this background it is worth noting that many solid timber construction systems are currently in danger of being outlawed by the increased requirements for the energy efficiency of buildings which are imminent through the new revision of the Energy Conservation Directive and, above all, the EU demands for extremely low energy houses (houses which have an almost zero demand for primary energy) from 2018/2020. For this reason, the submitted proposal suggests ways of adequately representing the carbon sink effect of timber as a construction material in the statutory requirements for the energy efficiency of buildings.\n",
      "  - Zusammenfassung                Nach der gegenwärtig die Klimaforschung dominierenden Auffassung wird die Menschheit durch den Klimawandel gefährdet. Weil es neben der dominanten auch noch andere und weniger beunruhigende Auffassungen zum Klimawandel und dem menschlichen Einfluss darauf gibt, weil auch bei Unterstellung der Richtigkeit der Befürchtungen der dominanten Auffassung die bisher ins Auge gefassten Gegenmaßnahmen ineffizient oder kostspielig sein könnten oder mit dem Grundwert der Freiheit in Konflikt geraten, wird hier zunächst der Stellenwert von Konsens in menschlichem Denken im Allgemeinen und in der Wissenschaft im Besonderen diskutiert. Dabei wird die Auffassung zurückgewiesen, dass Konsens der Fachleute jemals Gewissheit über den Besitz der Wahrheit vermitteln kann. Wissenschaftliche Erkenntnisse sind grundsätzlich vorläufig und müssen vielleicht revidiert werden. Eine allzu große Nähe von Wissenschaft und Politik ist eher eine Gefahr als eine Verheißung. Um dem entgegenzuwirken müssen bestimmte Normen beachtet und institutionelle Voraussetzungen zum Schutz der Autonomie der Wissenschaft aufgebaut werden. Wettbewerb ist nicht nur auf dem Markt, sondern auch in der Wissenschaft das beste Entdeckungsverfahren. Aufgabe der Wissenschaft kann nie der voreilige Konsens und die Unterdrückung von Zweifeln sein, sondern muss der organisierte Skeptizismus und das Aufdecken von Inkompatibilitäten unter politischen Zielsetzungen bleiben - auch wenn dadurch das Regieren erschwert wird.\n",
      "--------------------------------------------------\n",
      "Topic 159: 159_claim_l13_inflation_climate sensitivity\n",
      "Representative Documents:\n",
      "  - Land use/land cover (LULC) maps are now being used across disciplines for many different types of applications, e.g., to analyze urban heat islands or rainfall-runoff dynamics. Traditional map accuracy metrics are limited in this regard, as they only assess LULC map thematic accuracy. In reality, some types of misclassification lead to larger estimation errors for these specific applications. In a previous study, we developed a new map accuracy metric (referred to here as “JJ19”) to assess the accuracy of local climate zone maps for urban microclimate analysis. In the previous work, we also attempted to reproduce another metric (weighted accuracy (WA)) proposed for this purpose, but misinterpreted it due to a lack of methodological information available (principally, the lack of a confusion matrix to demonstrate how WA was derived). We sincerely thank the authors of Bechtel et al. 2019 for providing more information on WA in response to our previous study and are happy to report that we found that the metric is now both reproducible and valid. On the other hand, we found some other aspects of Bechtel et al. 2019’s study to be inaccurate, particularly their claims regarding the suitability of the JJ19 metric. Finally, we made a minor improvement to the JJ19 metric based on Bechtel et al.’s comments.\n",
      "  - . Henriksson et al. (2010), hereafter HALTL10, criticize Annan and Hargreaves (2006a) (AH06) primarily on the grounds that we assumed that different sources of data were conditionally independent given the climate sensitivity. While we consider this approximation to have been a reasonable one under the circumstances (and provided arguments to justify this approach), we also acknowledged its importance in our original paper and performed several sensitivity analyses. The alternative calculations presented by HALTL10 appear to strengthen rather than contradict our conclusion.  HALTL10 additionally criticize Annan and Hargreaves (2009) (AH09) for proposing a Cauchy type prior (as an alternative to the use of a uniform prior, which was widespread up to that time) \"without sufficient support\", and further claim that anticipated economic damages were used as a means of selecting the prior. We are surprised by these claims, especially considering that the proposed prior was justified at some length both on the basis of both the \"Charney report\" (National Research Council, 1979) and basic physical arguments, and also in light of our elementary demonstration of the pathological failings of the most commonly-used alternative. Thus, these claims are factually incorrect.                    \n",
      "  -  The differences between the results of McIntyre and McKitrick [2003] and Mann et al. [1998] can be reconciled by only two series: The Gaspé cedar ring width series and the first principal component (PC1) from the North American tree ring network. We show that in each case MBH98 methodology differed from what was stated in print and the differences resulted in lower early 15th century index values. In the case of the North American PC1, MBH98 modified the PC algorithm so that the calculation was no longer centered, but claimed that the calculation was “conventional”. The modification caused the PC1 to be dominated by a subset of bristlecone pine ring width series which are widely doubted to be reliable temperature proxies. In the case of the Gaspé cedars, MBH98 did not use archived data, but made an extrapolation, unique within the corpus of over 350 series, and misrepresented the start date of the series. The recent Corrigendum by Mann et al. denied that these differences between the stated methods and actual methods have any effect, a claim we show is false. We also refute the various arguments by Mann et al. purporting to salvage their reconstruction, including their claims of robustness and statistical skill. Finally, we comment on several policy issues arising from this controversy: the lack of consistent requirements for disclosure of data and methods in paleoclimate journals, and the need to recognize the limitations of journal peer review as a quality control standard when scientific studies are used for public policy. \n",
      "--------------------------------------------------\n",
      "Topic 160: 160_aerosol_aerosols_sea salt_optical\n",
      "Representative Documents:\n",
      "  - . This paper introduces and evaluates the second version of the global aerosol-climate model ECHAM-HAM. Major changes have been brought into the model, including new parameterizations for aerosol nucleation and water uptake, an explicit treatment of secondary organic aerosols, modified emission calculations for sea salt and mineral dust, the coupling of aerosol microphysics to a two-moment stratiform cloud microphysics scheme, and alternative wet scavenging parameterizations. These revisions extend the model's capability to represent details of the aerosol lifecycle and its interaction with climate. Nudged simulations of the year 2000 are carried out to compare the aerosol properties and global distribution in HAM1 and HAM2, and to evaluate them against various observations. Sensitivity experiments are performed to help identify the impact of each individual update in model formulation.  Results indicate that from HAM1 to HAM2 there is a marked weakening of aerosol water uptake in the lower troposphere, reducing the total aerosol water burden from 75 Tg to 51 Tg. The main reason is the newly introduced κ-Köhler-theory-based water uptake scheme uses a lower value for the maximum relative humidity cutoff. Particulate organic matter loading in HAM2 is considerably higher in the upper troposphere, because the explicit treatment of secondary organic aerosols allows highly volatile oxidation products of the precursors to be vertically transported to regions of very low temperature and to form aerosols there. Sulfate, black carbon, particulate organic matter and mineral dust in HAM2 have longer lifetimes than in HAM1 because of weaker in-cloud scavenging, which is in turn related to lower autoconversion efficiency in the newly introduced two-moment cloud microphysics scheme. Modification in the sea salt emission scheme causes a significant increase in the ratio (from 1.6 to 7.7) between accumulation mode and coarse mode emission fluxes of aerosol number concentration. This leads to a general increase in the number concentration of smaller particles over the oceans in HAM2, as reflected by the higher Ångström parameters.  Evaluation against observation reveals that in terms of model performance, main improvements in HAM2 include a marked decrease of the systematic negative bias in the absorption aerosol optical depth, as well as smaller biases over the oceans in Ångström parameter and in the accumulation mode number concentration. The simulated geographical distribution of aerosol optical depth (AOD) is better correlated with the MODIS data, while the surface aerosol mass concentrations are very similar to those in the old version. The total aerosol water content in HAM2 is considerably closer to the multi-model average from Phase I of the AeroCom intercomparison project. Model deficiencies that require further efforts in the future include (i) positive biases in AOD over the ocean, (ii) negative biases in AOD and aerosol mass concentration in high-latitude regions, and (iii) negative biases in particle number concentration, especially that of the Aitken mode, in the lower troposphere in heavily polluted regions.                    \n",
      "  - . Anthropogenic aerosol effects on climate produce one of the largest uncertainties in estimates of radiative forcing of past and future climate change. Much of this uncertainty arises from the multi-scale nature of the interactions between aerosols, clouds and large-scale dynamics, which are difficult to represent in conventional general circulation models (GCMs). In this study, we develop a multi-scale aerosol-climate model that treats aerosols and clouds across different scales, and evaluate the model performance, with a focus on aerosol treatment. This new model is an extension of a multi-scale modeling framework (MMF) model that embeds a cloud-resolving model (CRM) within each grid column of a GCM. In this extension, the effects of clouds on aerosols are treated by using an explicit-cloud parameterized-pollutant (ECPP) approach that links aerosol and chemical processes on the large-scale grid with statistics of cloud properties and processes resolved by the CRM. A two-moment cloud microphysics scheme replaces the simple bulk microphysics scheme in the CRM, and a modal aerosol treatment is included in the GCM. With these extensions, this multi-scale aerosol-climate model allows the explicit simulation of aerosol and chemical processes in both stratiform and convective clouds on a global scale. Simulated aerosol budgets in this new model are in the ranges of other model studies. Simulated gas and aerosol concentrations are in reasonable agreement with observations (within a factor of 2 in most cases), although the model underestimates black carbon concentrations at the surface by a factor of 2–4. Simulated aerosol size distributions are in reasonable agreement with observations in the marine boundary layer and in the free troposphere, while the model underestimates the accumulation mode number concentrations near the surface, and overestimates the accumulation mode number concentrations in the middle and upper free troposphere by a factor of about 2. The overestimation of accumulation model number concentrations in the middle and upper free troposphere is consistent with large aerosol mass fraction above 5 km in the MMF model compared with other models. Simulated cloud condensation nuclei (CCN) concentrations are within the observational variations. Simulated aerosol optical depths (AOD) are in reasonable agreement with observations (within a factor of 2), and the spatial distribution of AOD is consistent with observations, while the model underestimates AOD over regions with strong fossil fuel and biomass burning emissions. Overall, this multi-scale aerosol-climate model simulates aerosol fields as well as conventional aerosol models.\n",
      "  - . The uncertainties associated with the wet removal of aerosols entrained above convective cloud bases are investigated in a global aerosol-climate model (ECHAM5-HAM) under a set of limiting assumptions for the wet removal of the entrained aerosols. The limiting assumptions for the wet removal of entrained aerosols are negligible scavenging and vigorous scavenging (either through activation, with size-dependent impaction scavenging, or with the prescribed fractions of the standard model). To facilitate this process-based study, an explicit representation of cloud-droplet-borne and ice-crystal-borne aerosol mass and number, for the purpose of wet removal, is introduced into the ECHAM5-HAM model. This replaces and is compared with the prescribed cloud-droplet-borne and ice-crystal-borne aerosol fraction scavenging scheme of the standard model.  A 20% to 35% uncertainty in simulated global, annual mean aerosol mass burdens and optical depth (AOD) is attributed to different assumptions for the wet removal of aerosols entrained above convective cloud bases. Assumptions about the removal of aerosols entrained above convective cloud bases control modeled upper tropospheric aerosol concentrations by as much as one order of magnitude.  Simulated aerosols entrained above convective cloud bases contribute 20% to 50% of modeled global, annual mean aerosol mass convective wet deposition (about 5% to 10% of the total dry and wet deposition), depending on the aerosol species, when including wet scavenging of those entrained aerosols (either by activation, size-dependent impaction, or with the prescribed fraction scheme). Among the simulations, the prescribed fraction and size-dependent impaction schemes yield the largest global, annual mean aerosol mass convective wet deposition (by about two-fold). However, the prescribed fraction scheme has more vigorous convective mixed-phase wet removal (by two to five-fold relative to the size-dependent impaction scheme) since nearly all entrained accumulation and coarse mode aerosols are assumed to be cloud-droplet borne or ice-crystal borne, and evaporation due to the Bergeron-Findeisen process is neglected.  The simulated convective wet scavenging of entrained accumulation and coarse mode aerosols has feedbacks on new particle formation and the number of Aitken mode aerosols, which control stratiform and convective cloud droplet number concentrations and yield precipitation changes in the ECHAM5-HAM model. However, the geographic distribution of aerosol annual mean convective wet deposition change in the model is driven by changes to the assumptions regarding the scavenging of aerosols entrained above cloud bases rather than by precipitation changes, except for sea salt deposition in the tropics. Uncertainty in the seasonal, regional cycles of AOD due to assumptions about entrained aerosol wet scavenging is similar in magnitude to the estimated error in the AOD retrievals.  The uncertainty in aerosol concentrations, burdens, and AOD attributed to different assumptions for the wet scavenging of aerosols entrained above convective cloud bases in a global model motivates the ongoing need to better understand and model the activation and impaction processes that aerosols undergo after entrainment into convective updrafts.                    \n",
      "--------------------------------------------------\n",
      "Topic 161: 161_montenegro_well pads_thermal erosion_pads\n",
      "Representative Documents:\n",
      "  - The aim of this study is to point out the basic climate modificators and   types in Montenegro. Rarely could you find such a small area with more   climate types and several subtypes and varieties as it is the case here. In   the Part one of the study the most important climate modificators in   Montenegro have been discussed, such as: mathematical - geographical   position, relief dissection, atmospheric circulation and the Adriatic Sea.   Atlantic and Mediterranean aquatories and Eurasian landmass play an important   part in climate modification in the area of Montenegro. These vast areas   represent the source of atmospheric action centres and air masses.\n",
      "  - The main objective of this study is to emphasize the basic climate   modificators and types in Montenegro. Rarely could you find such a small area   with more climate types and several subtypes and varieties as it is the case   here. The most important climate modificators in Montenegro have been   discussed in the Part One of the study, such as: mathematical - geographical   position, relief dissection, atmospheric circulation and the Adriatic Sea.   Atlantic and Mediterranean aquatories and Eurasian landmass play an important   part in climate modification in the area of Montenegro. These vast areas   represent the source of atmospheric action centres and air masses. In the   Part Two of this study, the climate regionalization of Montenegro is given   according to the K?ppen criteria, as it has been proved that it gives a good   basis for solving several practical and scientific problems.\n",
      "  -  The study of exogenous processes and their effects on natural and anthropogenic systems is a very important aspect for the development of Arctic territories. One of these processes is thermal erosion, which is widespread in the Yamalo-Nenets Autonomous District due to the presence of permafrost in the vast majority of its area. The main prerequisites for the manifestation of thermal erosion processes can be divided into several groups of factors. Firstly, the geomorphological characteristics of the territory play a key role: the lengths and slopes. Secondly, the lithological and granulometric composition of rocks, as well as ice content and temperature, determine the resistance of the soil to the thermal and mechanical effects of flowing water. Thirdly, the amount of precipitation is an important factor, especially precipitation in winter and heavy rainfall in summer. They contribute to a high concentration of runoff in short periods of time, which leads to rapid destruction of rocks and the removal of large volumes of loose material. Finally, the fixation of the top layer of soils by the root system can be considered the main reason that counteracts the development of thermal erosion. The purpose of this study is a prognostic assessment of the risks of the development of thermal erosion processes in the context of the observed climate warming. To assess the risks, data from climate modeling of the Yamalo-Nenets Autonomous District for the middle of the XXI century were used for an ensemble of climate models included in the CMIP6 project. The analysis of Google Earth satellite images and information about the geological and geomorphological features of the region are used for zoning the territory in terms of dynamics and dangers of thermal erosion. The result of the study was the compilation of a map of the Yamalo-Nenets Autonomous District by categories of risks associated with thermal erosion processes. It is shown that in the perspective of several decades, more than 50% of the region's area is subject to intensification of thermal erosion destruction of soils, which requires careful planning of economic development and design of protective structures. An attempt has been made to assess the impact of erosive and thermoerosive effects on the natural environment of the Yamalo-Nenets Autonomous Okrug due to climate change using the recommendations of this assessment by Order of the Ministry of Economic Development of the Russian Federation dated 05/13/2021 N 267. Climatic factors can seriously enhance the causes and negative consequences of the development of thermoerosion, while local manifestations should be assessed using field data based on the calculation methods.\t\n",
      "--------------------------------------------------\n",
      "Topic 162: 162_fire_fire weather_wildfire_fire activity\n",
      "Representative Documents:\n",
      "  - ABSTRACTA majority of area burned in the Eastern United States (EUS) results from a limited number of exceptionally large wildfires. Relationships between climatic conditions and the occurrence of very large‐fires (VLF) in the EUS were examined using composite and climate‐niche analyses that consider atmospheric factors across inter‐annual, sub‐seasonal and synoptic temporal scales. While most large‐fires in the EUS coincided with below normal fuel moisture and elevated fire weather, VLF preferentially occurred during a long‐term drought accompanied by more acute sub‐seasonal drought realized through fuel moisture stress and elevated fire‐weather conditions. These results were corroborated across the EUS, with varying influences of drought, fire danger and fire weather discriminating VLF from other large fires across different geographical regions. We also show that the probability of VLF conditioned by fire occurrence increases when long‐term drought, depleted fuel moisture and elevated fire weather align. This framework illustrates the compounding role of different timescales in VLF occurrence and serves as a basis for improving VLF predictions with seasonal climate forecasts and climate change scenarios.\n",
      "  - Changes in global fire activity are influenced by a multitude of factors including land‐cover change, policies, and climatic conditions. This study uses 17 climate models to evaluate when changes in fire weather, as realized through the Fire Weather Index, emerge from the expected range of internal variability due to anthropogenic climate change using the time of emergence framework. Anthropogenic increases in extreme Fire Weather Index days emerge for 22% of burnable land area globally by 2019, including much of the Mediterranean and the Amazon. By the midtwenty‐first century, emergence among the different Fire Weather Index metrics occurs for 33–62% of burnable lands. Emergence of heightened fire weather becomes more widespread as a function of global temperature change. At 2 °C above preindustrial levels, the area of emergence is half that for 3 °C. These results highlight increases in fire weather conditions with human‐caused climate change and incentivize local adaptation efforts to limit detrimental fire impacts.\n",
      "  - Climate strongly influences global wildfire activity, and recent wildfire surges may signal fire weather-induced pyrogeographic shifts. Here we use three daily global climate data sets and three fire danger indices to develop a simple annual metric of fire weather season length, and map spatio-temporal trends from 1979 to 2013. We show that fire weather seasons have lengthened across 29.6 million km2 (25.3%) of the Earth’s vegetated surface, resulting in an 18.7% increase in global mean fire weather season length. We also show a doubling (108.1% increase) of global burnable area affected by long fire weather seasons (&gt;1.0 σ above the historical mean) and an increased global frequency of long fire weather seasons across 62.4 million km2 (53.4%) during the second half of the study period. If these fire weather changes are coupled with ignition sources and available fuel, they could markedly impact global ecosystems, societies, economies and climate.\n",
      "--------------------------------------------------\n",
      "Topic 163: 163_extension_information_farmers_extension professionals\n",
      "Representative Documents:\n",
      "  -                Although agricultural production faces chronic stress associated with extreme precipitation events, high temperatures, drought, and shifts in climate conditions, adoption of climate information into agricultural decision making has been relatively limited. Agricultural advisors have been shown to play important roles as information intermediaries between scientists and farmers, brokering, translating, and adding value to agronomic and economic information of use in agricultural management decision making. Yet little is known about the readiness of different types of agricultural advisors to use weather and climate information to help their clients manage risk under increasing climate uncertainty. More than 1700 agricultural advisors in four midwestern states (Nebraska, Indiana, Iowa, and Michigan) completed a web-based survey during the spring of 2012 about their use of weather and climate information, public or private sector employment, and roles as information intermediaries in three advising specializations: agronomic, conservation, and financial. Key findings reveal that advisors who specialize in providing agronomic information are positively inclined toward acting as weather and climate information intermediaries, based on influence and willingness to use climate information in providing many types of operational and tactical advice. Advisors who provide conservation advice appear to be considering weather and climate information when providing tactical and strategic land-use advice, but advisors who provide financial advice seem less inclined to act as climate information intermediaries. These findings highlight opportunities to increase the capacity of different types of advisors to enable them to be effective weather and climate information intermediaries.\n",
      "  - Climate change impacts on agriculture have been intensifying in the Northeastern and Midwestern United States. Few empirical studies have considered how dairy farmers and/or their advisors are interpreting and responding to climate impacts, risks, and opportunities in these regions. This study investigates dairy farmer and advisor views and decisions related to climate change using data from seven farmer and advisor focus groups conducted in New York and Wisconsin. The study examined how farmers and advisors perceived climate impacts on dairy farms, the practices they are adopting, and how perceived risks and vulnerability affect farmers’ decision making related to adaptation strategies. Although dairy farmers articulated concern regarding climate impacts, other business pressures, such as profitability, market conditions, government regulations, and labor availability were often more critical issues that affected their decision making. Personal experience with extreme weather and seasonal changes affected decision making. The findings from this study provide improved understanding of farmers’ needs and priorities, which can help guide land-grant researchers, Extension, and policymakers in their efforts to develop and coordinate a comprehensive strategy to address climate change impacts on dairy in the Northeast and the Midwest US.\n",
      "  - Climate change impacts on agriculture have been intensifying in the Northeastern United States. In order to encourage the adoption of climate change adaptation and mitigation practices by farmers, it is critical to understand their perspectives on the risks they face and actions they are taking. However, very few empirical studies have considered how farmers are interpreting and responding to climate impacts, risks and opportunities in the Northeast. This study investigates farmer views and decisions related to climate change using data from six farmer focus groups conducted across New York and Pennsylvania. The study examined how farmers perceived climate impacts on their farms, the practices they are willing to adopt, and how perceived risks and vulnerability affect farmers’ decision-making related to adaptation and mitigation strategies. Although farmers articulated concern regarding climate impacts, they also made clear that other business pressures, such as profitability, market conditions, labor availability or government regulations were often more critical issues that affected their decision-making. Decisions about adopting climate change adaptation and mitigation practices vary widely, and personal experience with extreme weather and changing seasons affected decision-making. The findings from this study provide improved understanding of farmers’ needs and priorities, which can help guide land-grant researchers, extension and policymakers in their efforts to develop and coordinate a comprehensive strategy to address climate change impacts on agriculture in the Northeast.\n",
      "--------------------------------------------------\n",
      "Topic 164: 164_urban_lcz_lczs_accuracy\n",
      "Representative Documents:\n",
      "  - Rapid and uncontrolled urbanization in tropical Africa is increasingly leading to unprecedented socio-economical and environmental challenges in cities, particularly urban heat and climate change. The latter calls for a better representation of tropical African cities’ properties relevant for urban climate studies. Here, we demonstrate the possibility of collecting urban canopy parameters during a field campaign in the boreal summer months of 2018 for deriving a Local Climate Zone (LCZ) map and for improving the physical representation of climate-relevant urban morphological, thermal and radiative characteristics. The comparison of the resulting field-derived LCZ map with an existing map obtained from the World Urban Data and Access Portal Tool framework shows large differences. In particular, our map results in more vegetated open low-rise classes. In addition, site-specific fieldwork-derived urban characteristics are compared against the LCZ universal parameters. The latter shows that our fieldwork adds important information to the universal parameters by more specifically considering the presence of corrugated metal in the city of Kampala. This material is a typical roofing material found in densely built environments and informal settlements. It leads to lower thermal emissivity but higher thermal conductivity and capacity of buildings. To illustrate the importance of site-specific urban parameters, the newly derived site-specific urban characteristics are used as input fields to an urban parametrization scheme embedded in the regional climate model COSMO-CLM. This implementations decreases the surface temperature bias from 5.34 to 3.97 K. Based on our results, we recommend future research on tropical African cities to focus on a detailed representation of cities, with particular attention to impervious surface fraction and building materials.\n",
      "  -                Stewart and Oke (2012) recently proposed the concept of Local Climate Zones (LCZ) to describe the siting of urban meteorological stations and to improve the presentation of results amongst researchers. There is now a concerted effort, however, within the field of urban climate studies to map the LCZs across entire cities, providing a means to compare the internal structure of urban areas in a standardised way and to enable the comparison of cities. We designed a new GIS-based LCZ mapping method for Central European cities and compiled LCZ maps for three selected medium-sized Central European cities: Brno, Hradec Králové, and Olomouc (Czech Republic). The method is based on measurable physical properties and a clearly defined decision-making algorithm. Our analysis shows that the decision-making algorithm for defining the percentage coverage for individual LCZs showed good agreement (in 79–89% of cases) with areas defined on the basis of expert knowledge. When the distribution of LCZs on the basis of our method and the method of Bechtel and Daneke (2012) was compared, the results were broadly similar; however, considerable differences occurred for LCZs 3, 5, 10, D, and E. It seems that Central European cities show a typical spatial pattern of LCZ distribution but that rural settlements in the region also regularly form areas of built-type LCZ classes. The delineation and description of the spatial distribution of LCZs is an important step towards the study of urban climates in a regional setting.\n",
      "  - ABSTRACTOne of the major obstacles to using numerical weather prediction models for guidance on mitigating urbanization's impact on local and regional climate is the lack of detailed and model ready morphological data at urban scale. The World Urban Database and Access Portal Tool (WUDAPT) is a recent project developed to extract climate relevant information on urban areas, in the form of local climate zones (LCZs), out of remote sensing imagery. This description of the urban landscape has been tested and used for parameterization of different urban canopy models (UCM) for mesoscale studies. As detailed information is usually bounded within cities' centres, crowdsourced and remote sensing data offer the possibility to move beyond the old barriers of urban climate investigations by studying the full range of variation from the urban core to the periphery and its related impacts on local climate. Thus, for this study we sought to compare the relative impact of using the WUDAPT methodology versus a simplified definition of the urban morphology extracted out of detailed GIS information to initialize a regional weather model and compare the output against official and crowdsourced weather station networks. A case study over Vienna, Austria was conducted using the weather research forecasting (WRF) model, coupled with the building effect parameterization and building energy models (BEP–BEM) in five distinct seasonal periods. Results demonstrated that using detailed GIS data to derive morphological descriptions of LCZs for mesoscale studies provided only a marginal overall improvement over using the default WUDAPT parameters based on the ranges proposed by Stewart and Oke (2012). The findings also highlighted the importance of developing techniques that are better at capturing the morphological heterogeneity across the entire urban landscape and thus improve our understandings of UCM performance over urban areas.\n",
      "--------------------------------------------------\n",
      "Topic 165: 165_journal_botany_online_2022\n",
      "Representative Documents:\n",
      "  - This article comments on:               Eun-Kyeong Han, Ichiro Tamaki, Sang-Hun Oh, Jong-Soo Park, Won-Bum Cho, Dong-Pil Jin, Bo-Yun Kim, Sungyu Yang, Dong Chan Son, Hyeok-Jae Choi, Amarsanaa Gantsetseg, Yuji Isagi, and Jung-Hyun Lee. Genetic and demographic signatures accompanying the evolution of the selfing syndrome in Daphne kiusiana, an evergreen shrub, Annals of Botany, Volume 131, Issue 5, 11 April 2023, Pages 751–767, https://doi.org/10.1093/aob/mcac142\n",
      "  - Ethnic minority farmers’ perceptions and use of local knowledge to adapt to climate change: Some insights from Vietnam by Nguyen The Manh and Mokbul Morshed AhmadThe above article from Singapore Journal of Tropical Geography, published online on September 3, 2021 in Wiley Online Library (https://onlinelibrary.wiley.com/doi/full/10.1111/sjtg.12397), has been retracted by agreement between the co‐editors and John Wiley &amp; Sons Australia, Ltd. The retraction has been agreed due to major overlap with, and lack of citation to, a previously published article from the same group of authors.ReferenceManh N T, Ahmad M M (2021) . Singapore Journal of Tropical Geography 42 (), 397–414. https://doi.org/10.1111/sjtg.12397\n",
      "  - The above article, published online on June 23, 2014 in Wiley Online Library (wileyonlinelibrary.com), has been retracted by agreement between the authors, the journal Editor‐in‐Chief, Nancy Guerra, and Wiley Periodicals, Inc. The retraction has been agreed upon following the discovery that this article contained inaccurate data. It came to the author's attention that the names of some of the items reported in the Measures section of the paper could not be correct because such items did not exist in the surveys. The authors tried to identify exactly which items had been used in the data analyses but they could not establish without some doubt exactly which items had actually been used.ReferenceWang, M.‐T. and Eccles, J. S. (2014), Multilevel Predictors of Math Classroom Climate: A Comparison Study of Student and Teacher Perceptions. Journal of Research on Adolescence. doi: 10.1111/jora.12153\n",
      "--------------------------------------------------\n",
      "Topic 166: 166_stratosphere_stratospheric_qbo_tropospheric\n",
      "Representative Documents:\n",
      "  - . A pronounced ENSO cycle occurred from 1986 to 1989, accompanied by distinct dynamical and chemical anomalies in the global troposphere and stratosphere. Reproducing these effects with current climate models not only provides a model test but also contributes to our still limited understanding of ENSO's effect on stratosphere-troposphere coupling. We performed several sets of ensemble simulations with a chemical climate model (SOCOL) forced with global sea surface temperatures. Results were compared with observations and with large-ensemble simulations performed with an atmospheric general circulation model (MRF9). We focus our analysis on the extratropical stratosphere and its coupling with the troposphere. In this context, the circulation over the North Atlantic sector is particularly important. Relative to the La Niña winter 1989, observations for the El Niño winter 1987 show a negative North Atlantic Oscillation index with corresponding changes in temperature and precipitation patterns, a weak polar vortex, a warm Arctic middle stratosphere, negative and positive total ozone anomalies in the tropics and at middle to high latitudes, respectively, as well as anomalous upward and poleward Eliassen-Palm (EP) flux in the midlatitude lower stratosphere. Most of the tropospheric features are well reproduced in the ensemble means in both models, though the amplitudes are underestimated. In the stratosphere, the SOCOL simulations compare well with observations with respect to zonal wind, temperature, EP flux, meridional mass streamfunction, and ozone, but magnitudes are underestimated in the middle stratosphere. With respect to the mechanisms relating ENSO to stratospheric circulation, the results suggest that both, upward and poleward components of anomalous EP flux are important for obtaining the stratospheric signal and that an increase in strength of the Brewer-Dobson circulation is part of that signal.\n",
      "  - . We report the sensitivity of the Berlin Climate Middle Atmosphere Model (CMAM) to different gravity-wave (GW) parameterisations. We perform five perpetual January experiments: 1) Rayleigh friction (RF) (control), 2) non-orographic GWs, 3) orographic GWs, 4) orographic and non-orographic GWs with no background stress, and 5) as for 4) but with background stress. We also repeat experiment 4) but for July conditions. Our main aim is to improve the model climatology by introducing orographic and non-orographic parameterisations and to investigate the individual effect of these schemes in the Berlin CMAM. We compare with an RF control to determine the improvement upon a previously-published model version employing RF. Results are broadly similar to previously-published works. The runs having both orographic and non-orographic GWs produce a statistically-significant warming of 4-8K in the wintertime polar lower stratosphere. These runs also feature a cooling of the warm summer pole in the mesosphere by 10-15K, more in line with observations. This is associated with the non-orographic GW scheme. This scheme is also associated with a heating feature in the winter polar upper stratosphere directly below the peak GW-breaking region. The runs with both orographic and non-orographic GWs feature a statistically-significant deceleration in the polar night jet (PNJ) of 10-20ms-1 in the lower stratosphere. Both orographic and non-orographic GWs individually produce some latitudinal tilting of the polar jet with height, although the main effect comes from the non-orographic waves. The resulting degree of tilt, although improved, is nevertheless still weaker than that observed. Accordingly, wintertime variability in the zonal mean wind, which peaks at the edge of the vortex, tends to maximise too far polewards in the model compared with observations. Gravity-planetary wave interaction leads to a decrease in the amplitudes of stationary planetary waves 1 and 2 by up to 50% in the upper stratosphere and mesosphere, more in line with observations. Comparing modelled and observed Eliassen-Palm fluxes suggests that planetary wave (PW) breaking occurs too far polewards in the model. The wind and temperature changes are consistent with changes in the Brewer-Dobson (BD) circulation. Results suggest that the effect of enforcing a minimum background wave stress in the McFarlane scheme could be potentially important. In the Southern Hemisphere (SH) in July, the GW schemes had only a small impact on the high-latitude lower stratosphere but there featured strong warming near 0.1hPa.                    \n",
      "  -                The possible role of stratospheric variability on the tropospheric teleconnection between El Niño–Southern Oscillation (ENSO) and the North Atlantic and European (NAE) region is addressed by comparing results from two ensembles of simulations performed with an atmosphere general circulation model fully resolving the stratosphere (with the top at 0.01 hPa) and its low-top version (with the top at 10 hPa). Both ensembles of simulations consist of nine members, covering the 1980–99 period and are forced with prescribed observed sea surface temperatures. It is found that both models capture the sensitivity of the averaged polar winter lower stratosphere to ENSO in the Northern Hemisphere, although with a reduced amplitude for the low-top model. In late winter and spring, the ENSO response at the surface is instead different in the two models. A large-scale coherent pattern in sea level pressure, with high pressures over the Arctic and low pressures over western and central Europe and the North Pacific, is found in the February–March mean of the high-top model. In the low-top model, the Arctic high pressure and the western and central Europe low pressure are very much reduced. The high-top minus low-top model difference in the ENSO temperature and precipitation anomalies is that North Europe is colder and the Northern Atlantic storm track is shifted southward in the high-top model. In addition, it has been found that major sudden stratospheric warming events are virtually lacking in the low-top model, while their frequency of occurrence is broadly realistic in the high-top model. Given that this is a major difference in the dynamical behavior of the stratosphere of the two models and that these events are favored by ENSO, it is concluded that the occurrence of sudden stratospheric warming events affects the reported differences in the tropospheric ENSO–NAE teleconnection. Given that the essence of the high-top minus low-top model difference is a more annular (or zonal) pattern of the anomaly in sea level pressure, relatively larger over the Arctic and the NAE regions, this interpretation is consistent with the observational evidence that sudden stratospheric warmings play a role in giving rise to persistent Arctic Oscillation anomalies at the surface.\n",
      "--------------------------------------------------\n",
      "Topic 167: 167_documentary_series_droughts_ghd\n",
      "Representative Documents:\n",
      "  - . This paper addresses droughts in the Czech Lands in the 1090–2012 AD period, basing its findings on documentary evidence and instrumental records. Various documentary sources were employed for the selection of drought events, which were then interpreted at a monthly level. While the data on droughts before 1500 AD are scarce, the analysis concentrated mainly on droughts after this time. A dry year in 1501–1804 period (i.e. pre-instrumental times) was defined as a calendar year in the course of which dry patterns occurred on at least two consecutive months. Using this definition, 129 dry years were identified (an average of one drought per 2.4 yr). From the 16th to the 18th centuries these figures become 41, 36 and 49 yr respectively, with the prevailing occurrence of dry months from April to September (73.7%). Drought indices – SPEI-1, Z-index and PDSI – calculated for the Czech Lands for April–September describe drought patterns between 1805 and 2012 (the instrumental period). N-year recurrence intervals were calculated for each of the three indices. Using N ≥ 5 yr, SPEI-1 indicates 40 drought years, Z-index 39 yr and PDSI 47 yr. SPEI-1 and Z-index recorded 100 yr drought in 1834, 1842, 1868, 1947 and 2003 (50 yr drought in 1992). PDSI as an indicator of long-term drought disclosed two important drought periods: 1863–1874 and 2004–2012. The first period was related to a lack of precipitation, the other may be attributed to recent temperature increases without significant changes in precipitation. Droughts from the pre-instrumental and instrumental period were used to compile a long-term chronology for the Czech Lands. The number of years with drought has fluctuated between 26 in 1951–2000 and 16 in 1651–1700. Only nine drought years were recorded between 1641 and 1680, while between 1981 and 2012 the figure was 22 yr. A number of past severe droughts are described in detail: in 1540, 1590, 1616, 1718 and 1719. A discussion of the results centres around the uncertainty problem, the spatial variability of droughts, comparison with tree-ring reconstructions from southern Moravia, and the broader central European context.\n",
      "  - . We present an open-access dataset of grape harvest dates (GHD) series that has been compiled from international, French and Spanish literature and from unpublished documentary sources from public organizations and from wine-growers. As of June 2011, this GHD dataset comprises 380 series mainly from France (93% of the data) as well as series from Switzerland, Italy, Spain and Luxemburg. The series have variable length (from 1 to 479 data, mean length of 45 data) and contain gaps of variable sizes (mean ratio of observations/series length of 0.74). The longest and most complete ones are from Burgundy, Switzerland, Southern Rhône valley, Jura and Ile-de-France. The most ancient harvest date of the dataset is in 1354 in Burgundy.  The GHD series were grouped into 27 regions according to their location, to geomorphological and geological criteria, and to past and present grape varieties. The GHD regional composite series (GHD-RCS) were calculated and compared pairwise to assess their reliability assuming that series close to one another are highly correlated. Most of the pairwise correlations are significant (p-value &lt; 0.001) and strong (mean pairwise correlation coefficient of 0.58). As expected, the correlations tend to be higher when the vineyards are closer. The highest correlation (R = 0.91) is obtained between the High Loire Valley and the Ile-de-France GHD-RCS.  The strong dependence of the vine cycle on temperature and, therefore, the strong link between the harvest dates and the temperature of the growing season was also used to test the quality of the GHD series. The strongest correlations are obtained between the GHD-RCS and the temperature series of the nearest weather stations. Moreover, the GHD-RCS/temperature correlation maps show spatial patterns similar to temperature correlation maps. The stability of the correlations over time is explored. The most striking feature is their generalised deterioration at the late 19th–early 20th century. The possible effects on GHD of the phylloxera crisis, which took place at this time, are discussed.  The median of all the standardized GHD-RCS was calculated. The distribution of the extreme years of this general series is not homogenous. Extremely late years all occur during a two-century long time window from the early 17th to the early 19th century, while extremely early years are frequent during the 16th and since the mid-19th century.                    \n",
      "  - . The history of drought occurrence in Poland in the last millennium is poorly known. To improve this knowledge we have conducted a comprehensive analysis using both proxy data (documentary and dendrochronological) and instrumental measurements of precipitation. The paper presents the main features of droughts in Poland in recent centuries, including their frequency of occurrence, coverage, duration, and intensity. The reconstructions of droughts based on all the mentioned sources of data covered the period 996–2015. Examples of megadroughts were also chosen using documentary evidence, and some of them were described. Various documentary sources have been used to identify droughts in the area of Poland in the period 1451–1800 and to estimate their intensity, spatial coverage, and duration. Twenty-two local chronologies of trees (pine, oak, and fir) from Poland were taken into account for detecting negative pointer years (exceptionally narrow rings). The delimitation of droughts based on instrumental data (eight long-term precipitation series) was conducted using two independent approaches (Standard Precipitation Index, SPI, calculated for 1-, 3-, and 24-month timescales, and a new method proposed by authors). For delimitation of droughts (dry months), the criteria used were those proposed by McKee et al. (1993) and modified for the climate conditions of Poland by Łabędzki (2007). More than 100 droughts were found in documentary sources in the period 1451–1800, including 17 megadroughts. A greater than average number of droughts were observed in the second halves of the 17th century and the 18th century in particular. Dendrochronological data confirmed this general tendency in the mentioned period. Analysis of SPI (including its lowest values, i.e. droughts) showed that the long-term frequency of droughts in Poland has been stable in the last two or three centuries. Extreme and severe droughts were most frequent in the coastal part of Poland and in Silesia. Most droughts had a duration of 2 months (about 60 %–70 %) or 3–4 months (10 %–20 %). Frequencies of droughts with a duration of 5-or-more months were lower than 10 %. The frequency of droughts of all categories in Poland in the instrumental period 1722–2015 was greatest in winter, while in the documentary evidence (1451–1800) droughts in this season are rarely mentioned. The occurrence of negative pointer years (a good proxy for droughts) was compared with droughts delimited based on documentary and instrumental data. A good correspondence was found between the timing of occurrence of droughts identified using all three kinds of data (sources).\n",
      "--------------------------------------------------\n",
      "Topic 168: 168_pavement_pavement performance_asphalt_pavement design\n",
      "Representative Documents:\n",
      "  -  A method to assess the impacts of forecasted climate change on pavement deterioration is presented. Traditional methods of pavement design use historic climate data and assume that climate is stationary with time. Climate change challenges this assumption of stationarity (i.e., natural driving forces of engineering have a variability described by a time-invariant probability density function). Therefore, the use of historic climate data is insufficient for the prediction of climate conditions. The focus is on the preparation and the use of climate model data sets as inputs to the Mechanistic–Empirical Pavement Design Guide (MEPDG) model to simulate flexible pavement performance and deterioration over time. The method is illustrated with a case study that uses future climate model temperature data from three North American Regional Climate Change Assessment Program scenarios at four sites across New England. Pavement distress predicted with future temperature scenarios is compared with that from MEPDG temperature data. Application of the method demonstrates the importance of matching the overlapping periods before using climate forecast output in the MEPDG. Although the simulated impact of future temperature changes on pavement performance was negligible for alligator cracking at the four study sites, asphalt concrete rutting differences were great enough to warrant additional consideration and to suggest that climate change and variability in future climate scenarios could affect pavement design and evaluation. The proposed method can be used to evaluate the impact of other climate variables alone or in combination. The method also can readily use new climate model output and be adapted for new downscaling methods. \n",
      "  -  Information extracted from global climate models suggests that average temperatures and annual precipitation will increase over the next several decades, with potential implications for pavement performance and design. With Canadian data from the Long-Term Pavement Performance program, the Mechanistic-Empirical Pavement Design Guide was used to quantify the impacts of projected climatic changes on pavement performance of low-volume roads at six sites. A series of analyses was conducted to assess the impact of pavement structure, material characteristics, traffic loads, and changes in climate on incremental and terminal pavement deterioration and performance. Results suggest that rutting (asphalt, base, and subbase layers) and both longitudinal and alligator cracking will be exacerbated by climate change, with transverse cracking becoming less of a problem. In general, maintenance, rehabilitation, and reconstruction will be required earlier in the design life; however, the effects of climate change were found to be modest relative to effects of regional baseline climate differences and increased future traffic. For road authorities, key adaptations will relate to when and how to modify current design and maintenance practices. Pavement engineers should be encouraged to develop a protocol for considering potential climate change in the development and evaluation of future designs and maintenance programs. Incorporating other climate-related road infrastructure issues– for instance those associated with concrete pavements; surface-treated roads; and airfields bridges, and culverts–would be beneficial. At a minimum, long time series of historic climatic and road weather observations (e.g., &gt;30 years) should be incorporated into analyses of pavement deterioration and assignment of performance graded materials. \n",
      "  -                Pavement design procedures heavily rely on historical climate. This practice can be a threat to the pavement infrastructure predominantly because of anthropogenic climate change. Therefore, there is a necessity to consider the climate change parameters in pavement design. This study quantifies the influence of climate change on pavement performance in New Jersey. In addition, this study also explores various modified asphalt mixtures to mitigate the climate change impact on asphalt and composite pavements. The scope of this work is carried out in four phases, which include data collection, laboratory material testing for both conventional and modified asphalt materials, pavement performance prediction using pavement mechanistic-empirical design, and selection of optimal modified asphalt materials to mitigate the climate change impacts. To achieve this, two pavement sections are considered in New Jersey. The pavement material, design, and traffic data were collected from the New Jersey Department of Transportation. In addition, statistically downscaled climate change models were gathered from Coupled Model Intercomparison Project (CMIP) GFDL-EMS2g.1, which was processed by the US Department of Transportation CMIP Data Processing Tool. This study concludes that increased temperature caused by climate change results in high pavement deformation in the asphalt concrete layer. Using modified asphalt mixtures can be an alternative to mitigate the climate change impact in New Jersey.\n",
      "--------------------------------------------------\n",
      "Topic 169: 169_farmers_adoption_farm_households\n",
      "Representative Documents:\n",
      "  - Farmers have a long history of adjusting their production practices in response to changing production conditions. Using a multinomial endogenous treatment effects model that accounts for observable and unobservable heterogeneity, this study investigates the adoption and welfare impacts of climate‐resilient practices on Vietnamese rice‐cultivating households. We found evidence of clear and positive welfare impacts from the adoption of canal irrigation (CI) and the joint adoption of agricultural conservation practices (CP) and CI as the main adaptation strategies to increase water stress. More importantly, although farmers with access to CI systems obtained the highest returns, the joint adoption of multiple practices still had substantially high adoption rates and significantly positive effects on rice yield, rice revenue and household income. Our findings indicate that farms' and farmers' characteristics, market information and climatic conditions are generally the main factors driving rice farmers' decisions to adopt climate‐resilient technologies, both individually and jointly. Follow‐up policy interventions should focus on improving CI systems and promoting the joint adoption of climate‐resilient technologies to improve rice farmers' well‐being and enhance their resilience capacity to cope with incoming climatic uncertainty.\n",
      "  - Climate-smart agriculture (CSA) has been receiving increasing attention in recent policy dialogues for its potential to improve agricultural transformation, risk management, and welfare. This study seeks to provide evidence on the welfare impacts of CSA adoption and its complementarity with non-farm employment using household-level data from Ethiopia combined with novel historical weather data. The study uses a multinomial endogenous switching regression model to deal with selection bias and farmer heterogeneity. The results show that households adopting CSA enjoy higher welfare benefits than non-adopter households. Households experience a higher welfare impact (lower monetary and multidimensional poverty rate) when CSA and non-farm employment are adopted simultaneously. However, there is less evidence regarding the complementarity between CSA and non-farm employment when considering per capita consumption expenditure. The study findings will have important policy implications for climate change adaptation, resilience, and poverty reduction in low-income countries.\n",
      "  - Increased climate variability during the last four decades has made the agricultural environment in many developing countries more uncertain, resulting in increasing exposure to risk when producing crops. In this study, we use recent farm‐level data from Ghana to examine the drivers of individual and joint adoption of crop choice and soil and water conservation practices, and how adoption of these practices impacts on farm performance (crop revenue) and exposure to risks (skewness of crop yield). We employ a multinomial endogenous switching regression model to account for selectivity bias due to both observable and unobservable factors. The empirical results reveal that farmers’ adoption of crop choice and soil and water conservation leads to higher crop revenues and reduced riskiness in crop production, with the largest impact on crop revenues coming from joint adoption. The findings also show that education of the household head, access to extension and weather information influence the likelihood of adopting these practices. Thus, enhancing extension services and access to climate information and irrigation can reduce gaps in adoption of soil and water conservation and crop choice, considered as climate‐smart practices that will eventually improve crop revenues and reduce farmers’ exposure to climate‐related production risks.\n",
      "--------------------------------------------------\n",
      "Topic 170: 170_health_children_public health_climate change\n",
      "Representative Documents:\n",
      "  -                Alzheimer’s disease and related dementias (ADRD) represent a public health crisis poised to worsen in a changing climate. Substantial dementia burden is modifiable, attributable to risk rooted in social and environmental conditions. Climate change threatens older populations in numerous ways, but implications for cognitive aging are poorly understood. We illuminate key mechanisms by which climate change will shape incidence and lived experiences of ADRD, and propose a framework for strengthening research, clinical, and policy actions around cognitive health in the context of climate change. Direct impacts and indirect risk pathways operating through built, social, interpersonal, and biomedical systems are highlighted. Air pollution compromises brain health directly and via systemic cardiovascular and respiratory ailments. Flooding and extreme temperatures constrain health behaviors like physical activity and sleep. Medical care resulting from climate-related health shocks imposes economic and emotional tolls on people living with dementia and caregivers. Throughout, inequitable distributions of climate-exacerbated risks and adaptive resources compound existing disparities in ADRD incidence, comorbidities, and care burden. Translational research, including work prioritizing underserved communities, is crucial. A mechanistic framework can guide research questions and methods and identify clinical- and policy-level intervention loci for prevention and mitigation of climate-related impacts on ADRD risk and burden.\n",
      "  - ObjectivesIncreasing obesity rates and accelerating climate change represent two global health challenges shaped by lifestyle change and human environmental modifications. Yet, few studies have considered how these issues may interact to exacerbate disease risk.MethodsIn this theory article, we explore evidence that obesity‐related disease and climatic changes share socio‐ecological drivers and may interact to increase human morbidity and mortality risks. Additionally, we consider how obesity‐climate change interactions may disproportionately affect vulnerable populations and how anthropological research can be applied to address this concern.ResultsInteractions between heat stress and cardiometabolic disease represent an important pathway through which climate change and obesity‐related morbidities may jointly impair health. For example, individuals with higher body fatness and obesity‐related metabolic conditions (eg, type 2 diabetes) exhibit a reduced ability to dissipate heat. The risk of poor health resulting from these interactions is expected to be heterogeneous, with low‐ and middle‐income countries, individuals of lower socioeconomic status, and minority populations facing a greater disease burden due to relative lack of resource access (eg, air conditioning). Moreover, older adults are at higher risk due to aging‐associated changes in body composition and loss of thermoregulation capabilities.ConclusionsFew policy makers appear to be considering how interventions can be designed to simultaneously address the medical burden posed by increasing obesity rates and climate change. Anthropological research is well situated to address this need in a nuanced and culturally‐sensitive way; producing research that can be used to support community resilience, promote holistic well‐being, and improve health outcomes.\n",
      "  - The climate crisis is the existential threat of our times and for generations to come. This is no longer a threat but a reality affecting us, our children, and the generations that follow. Pregnant mothers, their fetuses, and their children are among those at greatest risk in every population and every jurisdiction. A timely consideration is the health of racialized groups who are particularly vulnerable owing to the confluence of several risk factors that are compounded by climate change. Included among these are Indigenous communities that are the most directly threatened by climate change. This review discusses the main health challenges faced by mothers, fathers, and their children during the climate crisis, focusing on mental health as a causal factor. Exploration of this topic includes the role of prenatal maternal and paternal stresses, allostatic load, and the effect of degradation of the environment and ecosystems on individuals. These will be examined in relation to adverse pregnancy outcomes and altered developmental trajectories of children. The climate crisis is a health threat multiplier that amplifies the health inequities of the most at-risk populations and individuals. It accelerates the increase in allostatic load of those at risk. The path of tragedy begins with an accumulating allostatic load that overwhelms both individual and socio-ecological resilience. This can lead to worse mental health including depression and anxiety and, in the case of pregnant women and their children, more adverse pregnancy outcomes and impaired developmental trajectories for their newborn children. We argue that there is an urgent need to develop new (or re-discover or re-purpose existing) tools that will predict communities and individuals who are experiencing the highest levels of climate-related hazards and intervene to reduce stress and increase resilience in pre-conceptual women and men, pregnant and post-partum women, and their young children.\n",
      "--------------------------------------------------\n",
      "Topic 171: 171_natural gas_natural_industry_gas\n",
      "Representative Documents:\n",
      "  - In world energy markets, the current chaos around uncertainty of supplies and price spikes highlights the critical need for a balanced energy policy, both in the United States and abroad. Of course, the most recent disruption is due primarily to the world and energy market's reaction to the Russian invasion of Ukraine and its consequences. One can only hope and pray that by the time this column is published, that crisis will have been peacefully resolved. However, embargoes on Russian oil and natural gas, with the associated stress they have placed on Europe and other countries who rely on these commodities, only exacerbated a situation that was already spiraling out of control. Many governments around the world, the United States included, announced major policy initiatives to move away from oil and natural gas, in favor of renewable energy resources, such as wind and solar. A great deal of that movement has already happened in Europe, leading to very tough energy choices in 2021 when wind as a resource option was diminished—it just wasn't windy enough. Some policies were a bit ambivalent about natural gas, recognizing its environmental advantages over other fossil fuels, but—at least in the United States—consistent, “cancel culture” hostility toward any development of drilled hydrocarbons pervaded environmental nongovernment organizations (NGOs) and many government agencies.\n",
      "  - The beginning of 2023 has witnessed the biggest decline in natural gas prices in a long time. Production has been at record highs, an exceptionally warm start to January suppressed supply demand, and liquefied natural gas (LNG) exports have been down since June 2022 when Freeport LNG's export facility went offline due to a fire at its facility. The CME/NYMEX February natural gas futures contract slid to an 18‐month low of $2.94/MMBtu and expired at $3.109/MMBtu, down 54 percent from where the contract closed just two months earlier in December 2022. In other words, market prices plunged, and in the middle of the winter—usually the strongest period for natural gas sales and prices. The March contract extended the slide to a 20‐month low of $2.677/MMBtu. Freeport's eventual return will restore existing LNG export capacity, thus picking up demand levels, and by the time of publication of this column may be back in service. However, there is no new LNG export capacity due online this year—for the first time since 2016. After one of the tightest natural gas markets of the last decade in 2022, which pushed prices much higher than they had been for a long time, other than during the short but fierce Winter Storm Uri experience in 2021, things they are a'changing. The stage is set for one of the most oversupplied markets the industry has seen in years. However, in keeping with the natural gas industry's history of keeping traders on their toes, it looks as if we are reaching the end of the steady oversupply we have experienced since 2009, when the Shale Revolution swarmed in to move the entire industry from shortage to abundance, and enabled U.S. energy independence to take root. How did we get here, and how does the future look for natural gas supply and prices?\n",
      "  - Europe's energy supply is in crisis this winter. Owing to the evident Russian manipulation of its natural gas exports to the European Union (EU) in advance of its invasion of Ukraine, prices have spiked wildly—24 times the prevailing EU natural gas price in the summer of 2020 and up to 10 times contemporaneous US natural gas prices in early 2022. Because natural gas prices often‐enough drive the EU's electricity market model prices, the resulting electricity prices at the time of writing throughout the EU were three to six times higher than their 2019 level. The result is a disaster for EU energy consumers in 2022. Russia's potential to hold hostage critical winter natural gas supplies to Europe's millions of natural gas consumers was not unforeseen. Lacking the means to protect against such energy hostage‐taking should call the EU's natural gas regulations into question. It is uncertain whether the EU can avoid such situations next winter and beyond without a fundamental political reexamination of how its regulatory methods led to the current crisis.\n",
      "--------------------------------------------------\n",
      "Topic 172: 172_permafrost_glacier_glaciers_plateau\n",
      "Representative Documents:\n",
      "  - The increase in low flows (winter discharge and minimum monthly discharge), caused primarily by permafrost degradation, is common in high‐latitude permafrost regions, whereas the dynamics of low flows in high‐altitude permafrost regions remain largely unknown. Long‐term discharge data from 28 unregulated catchments in western China were analysed, and the findings showed that winter discharge/minimum monthly discharge significantly increased (p ≤ 0.1) in 82/82%, 55/64%, and 0/0% of the catchments in the higher‐latitude mountain permafrost regions (Tienshan Mountains), mid‐latitude mountain permafrost regions (Qilian Mountains), and mid‐ to low‐latitude plateau permafrost regions (the source regions of the Yangtze and Yellow rivers), respectively. The differences in permafrost type and the distribution of permafrost and alpine cold desert (which is similar to tundra) were found to be the main causes for the different responses in the low flows. The rate of change of low flows (winter discharge and minimum monthly discharge) was negatively and linearly correlated with permafrost coverage when coverage was less than 40% of the catchment area, whereas the low flows changed only slightly when the permafrost coverage exceeded 40%. A significant thickening of the active layer increased the low flows in the lower permafrost‐covered catchments, which are dominated by warm permafrost. However, in the higher permafrost‐covered catchments with cold permafrost and a cold climate, only an increase in permafrost temperature (without a notable thickening of the active layer) occurred, resulting in non‐significant changes in low flows.\n",
      "  - Relict permafrost regions are characterized by thin permafrost and relatively high temperatures. Understanding the ecosystem respiration rate (ERR) and its relationship with soil hydrothermal conditions in these areas can provide knowledge regarding the permafrost carbon cycle in a warming world. In this study, we examined a permafrost area, a boundary area, and a seasonally frozen ground area within a relict permafrost region on the east edge of the Qinghai‐Tibetan Plateau, China. Measurements from July 2015 to September 2016 showed that the mean annual ecosystem CO2 emissions for the boundary area were greater than the permafrost area. The Q10 value of the ERRs in the seasonally frozen ground area was greater than the permafrost area, indicating that the carbon emissions in the nonpermafrost areas were more sensitive to warming. The 1 year open‐top chamber (OTC) warming increased soil temperatures in both the permafrost and seasonally frozen ground areas throughout the year, and the warming increased the ERRs by 1.18 (0.99–1.38, with interquartile range) and 1.13 (0.75–1.54, with interquartile range) μmol CO2 m−2 s−1 in permafrost and seasonally frozen ground areas, respectively. The OTC warming increased annual ERRs by approximately 50% for both permafrost and seasonally frozen ground areas with half the increase occurring during the nongrowing seasons. These results suggest that the ERRs in relict permafrost are high in comparison with arctic regions, and the carbon balance in relict permafrost areas could be greatly changed by climate warming.\n",
      "  - Cold season air warming was more rapid than warm season air warming on the Qinghai‐Tibetan Plateau (QTP). However, the effect of this asymmetrical seasonal air warming on permafrost hydrological changes has not been fully understood. This study applied a distributed cryospheric hydrological model to evaluate the effects of different seasonal air warming on the changes in frozen soil and hydrological processes in a typical catchment, the source region of the Lancang River on the eastern QTP. The results show that the area of permafrost reduced by 14.0%. The maximum frozen depth of seasonally frozen ground (MFDSFG) decreased at 5.0 cm decade−1, and the active layer thickness (ALT) of permafrost increased by 3.3 cm decade−1. Controlled experiments illustrate that cold season air warming dominated the reduction in MFDSFG which caused the liquid soil moisture increase in seasonally frozen ground, and warm season air warming primarily determined the increase in ALT which enhanced the liquid soil moisture in permafrost. Cold season air warming had a greater effect on runoff than warm season air warming because it dominated the permafrost degradation into seasonally frozen ground. In the region where permafrost degraded into seasonally frozen ground, both the cold and warm season air warming contributed to the soil liquid water increase, and the cold season warming had a greater effect due to its more important role in thermal degradation of permafrost. The findings of this study reveal different complex impacts of cold and warm season air warming on permafrost hydrological changes on the QTP.\n",
      "--------------------------------------------------\n",
      "Topic 173: 173_diets_diet_dietary_bioenergy\n",
      "Representative Documents:\n",
      "  - BackgroundImmediate action is needed to stabilise the climate. Dietitians require knowledge of how the therapeutic diets they prescribe may contribute to climate change. No previous research has quantified the climate footprint of therapeutic diets. This study sought to quantify and compare the climate footprint of two types of therapeutic diets for people with chronic kidney disease (CKD) with two reference diets.MethodsA usual diet for an individual with CKD and a novel plant‐based diet for CKD were compared with the current Australian diet and the Australian‐adapted EAT Lancet Planetary Health Diet (PHD). The climate footprint of these diets was measured using the Global Warming Potential (GWP*) metric for a reference 71‐year‐old male.ResultsNo diets analysed were climate neutral, and therefore, all contribute to climate change. The novel plant‐based diet for CKD (1.20 kg carbon dioxide equivalents [CO2e] per day) produced 35% less CO2e than the usual renal diet for an individual with CKD (1.83 kg CO2e per day) and 50% less than the current Australian diet (2.38 kg CO2e per day). The Australian‐adapted EAT Lancet PHD (1.04 kg CO2e per day) produced the least amount of CO2e and 56% less than the current Australian diet. The largest contributors to the climate footprint of all four diets were foods from the meats and alternatives, dairy and alternatives and discretionary food groups.ConclusionsDietetic advice to reduce the climate footprint of therapeutic diets for CKD should focus on discretionary foods and some animal‐based products. Future research is needed on other therapeutic diets.\n",
      "  - Low-carbon diets can counteract climate change and promote health if they are nutritionally adequate, affordable and culturally acceptable. This study aimed at developing sustainable diets and to compare these with the EAT-Lancet diet. The Swedish national dietary survey Riksmaten Adolescents 2016–2017 was used as the baseline. Diets were optimized using linear programming for four dietary patterns: omnivores, pescatarians, vegetarians and vegans. The deviation from the baseline Riksmaten diet was minimized for all optimized diets while fulfilling nutrient and climate footprint constraints. Constraining the diet-related carbon dioxide equivalents of omnivores to 1.57 kg/day resulted in a diet associated with a reduction of meat, dairy products, and processed foods and an increase in potatoes, pulses, eggs and seafood. Climate-friendly, nutritionally adequate diets for pescatarians, vegetarians and vegans contained fewer foods and included considerable amounts of fortified dairy and meat substitutes. The optimized diets did not align very well with the food-group pattern of the EAT-Lancet diet. These findings suggest how to design future diets that are climate-friendly, nutritionally adequate, affordable, and culturally acceptable for Swedish adolescents with different dietary patterns. The discrepancies with the EAT diet indicate that the cultural dietary context is likely to play an important role in characterizing sustainable diets for specific populations.\n",
      "  -                                  Background                  The food sector contributes to a third of global Greenhouse gas emissions. Food-based dietary guidelines (FBDG) are policy tools that provide food advice compatible with health. There is a growing effort to include environmental sustainability in dietary guidelines, but less is known about the extent to which different countries include dietary recommendations with climate change mitigation potential.                                                Methods                  Based on a systematic review and quantitative content analysis of food-based dietary guidelines (FBDG), a Dietary Climate Mitigation (DCM) score was developed to assess and rank the climate change mitigation potential of dietary guidelines at three levels: food life cycle, dietary patterns, and food groups. To avoid an overestimation of recommendations with relatively lower climate mitigation potential, the overall DMC score assigns higher weights to the dietary patterns and food groups sub-scores, compared to the food life cycle sub-score.                                                Results                  Of the selected 92 countries, 38 mention environmental sustainability in their dietary guidelines. The Dietary Climate Mitigation (DCM) score ranged 4-84 (median 31.14 IQR 19.71-39.14, score range 0-100). Scores were significantly higher in high-income countries, dietary guidelines published after 2010, and those that explicitly address environmental sustainability. The highest scores are those from Belgium-Flemish, Australia, Zambia, Israel, Spain, Netherlands, Seychelles, Denmark, Sweden, and United Kingdom. Food advice with high climate mitigation potential are less frequent than advice with relatively lower mitigation potential.                                                Conclusions                  Future dietary guidelines can be more aligned to health and climate goals if they factor in the differential environmental footprints of food choices. Explicit inclusion of environmental considerations in dietary advice has grown, yet most guidelines can still evolve from pro-environmental (intent-based), to environmentally significant (impact-based) food advice.                                                Key messages                  • While there is a growth in dietary guidelines that mention environmental sustainability, most countries have still a low coverage of food recommendations with high climate mitigation potential.                  • To be compatible with planetary health, dietary guidelines can benefit from an impact-weighted approach to dietary advice.               \n",
      "--------------------------------------------------\n",
      "Topic 174: 174_dial_ppm_laser_detection\n",
      "Representative Documents:\n",
      "  - We designed a tunable diode laser absorption spectroscopy (TDLAS) sensor for the online monitoring of CO2 and H2O concentrations. It comprised a small self-design multi-pass cell, home-made laser drive circuits, and a data acquisition circuit. The optical and electrical parts and the gas circuit were integrated into a portable carrying case (height = 134 mm, length = 388 mm, and width = 290 mm). A TDLAS drive module (size: 90 mm × 45 mm) was designed to realize the function of laser current and temperature control with a temperature control accuracy of ±1.4 mK and a current control accuracy of ±0.5 μA, and signal acquisition and demodulation. The weight and power consumption of the TDLAS system were only 5 kg and 10 W, respectively. Distributed feedback lasers (2004 nm and 1392 nm) were employed to target CO2 and H2O absorption lines, respectively. According to Allan analysis, the detection limits of CO2 and H2O were 0.13 ppm and 3.7 ppm at an average time of 18 s and 35 s, respectively. The system response time was approximately 10 s. Sensor performance was verified by measuring atmospheric CO2 and H2O concentrations for 240 h. Experimental results were compared with those obtained using a commercial instrument LI-7500, which uses non-dispersive infrared technology. Measurements of the developed gas analyzer were in good agreement with those of the commercial instrument, and its accuracy was comparable. Therefore, the TDLAS sensor has strong application prospects in atmospheric CO2 and H2O concentration detection and ecological soil flux monitoring.\n",
      "  - The traditional detection method of CO2 concentration in seed respiration has defects such as low detection accuracy, low detection efficiency, and inability to monitor in real time. In order to solve these problems, we report a seed respiration CO2 detection system based on wavelength modulation spectroscopy (WMS) techniques in tunable diode laser absorption spectroscopy (TDLAS). This system uses a 2004 nm distributed feedback (DFB) laser as the light source, and a double-layer seed respiration device (about 1.5 L) is designed based on Herriott cell with an effective optical path of about 21 meters. Then, the second harmonic (2f) signal is extracted by the wavelength modulation method for CO2 concentration inversion. When the ambient temperature and pressure changes greatly, the corrected 2f signal is used for CO2 concentration inversion to improve the accuracy. A series of verification and comparison experiments have proved that the seed respiration CO2 detection system has the advantages of strong stability, high sampling frequency, and high detection accuracy. Finally, we used the developed system to measure the respiration intensity and respiration rate of 1 g corn seeds. The respiration intensity curves and respiration rate change details show that the seed respiration CO2 detection system is more suitable for a small amount of seeds than nondispersive infrared (NDIR) CO2 sensor and gas chromatography in real-time monitoring of the breathing process.\n",
      "  - The laser heterodyne radiometer (LHR) has the advantages of miniaturization, low cost, and high spectral-resolution as a ground-verification instrument for satellite observation of atmospheric trace-gas concentration. To verify the accuracy of LHR measurements, a new performance evaluation method is presented here, based on an ASE source and a CO2 absorption cell in the laboratory. Preliminary simulation analysis based on the system parameters of LHR is carried out for the performance analysis and data processing of this new combined test system. According to the simulation results, at wavelength deviation of fewer than 30 MHz, the retrieval error, which increases with bandwidth, can obtain an accuracy of 1 ppm within the bandwidth range of the photodetector (1.2 GHz) when this instrument line shape (ILS) is calibrated. Meanwhile, when the filter bandwidth is less than 200 MHz, the maximum error without ILS correction does not exceed 0.07 ppm. Moreover, with an ideal 60 MHz bandpass filter without ILS correction, LHR’s signal-to-noise ratio (SNR) should be greater than 20 to achieve retrieval results of less than 1 ppm. When the SNR is 100, the retrieval error is 0.206 and 0.265 ppm, corresponding to whether the system uncertainties (temperature and pressure) are considered. Considering all the error terms, the retrieval error (geometrically added) is 0.528 ppm at a spectral resolution of 0.004 cm−1, which meets the measurement accuracy requirement of 1 ppm. In the experiment, the retrieval and analysis of the heterodyne signals are performed for different XCO2 with [400 ppm, 420 ppm] in the absorption cell. Experimental results match well with the simulation, and confirm the accuracy of LHR with an error of less than 1 ppm with an SNR of 100. The LHR will be used to measure atmospheric-CO2 column concentrations in the future, and could be effective validation instruments on the ground for spaceborne CO2-sounding sensors.\n",
      "--------------------------------------------------\n",
      "Topic 175: 175_vitrification_pregnancy_embryos_blastocysts\n",
      "Representative Documents:\n",
      "  -                                  STUDY QUESTION                  Does double vitrification and warming of human blastocysts having undergone biopsy once or twice have an impact on the clinical outcome?                                                SUMMARY ANSWER                  The clinical pregnancy rate obtained with double vitrification single biopsy blastocysts was comparable to that obtained with single vitrification single biopsy blastocysts in our center in the same time period (46%; 2016–2018), whereas that obtained with double-vitrified double-biopsied blastocysts seemed lower and will need further study.                                                WHAT IS KNOWN ALREADY                  Genetic testing on cryopreserved unbiopsied embryos involves two cryopreservation procedures. Retesting of failed/inconclusive-diagnosed blastocysts inevitably involves a second round of biopsy and a second round of vitrification as well. To what extent this practice impacts on the developmental potential of blastocysts has been studied to a limited extent so far and holds controversy. Additionally, the obstetrical/perinatal outcome after the transfer of double-vitrified/single or double-biopsied blastocysts is poorly documented.                                                STUDY DESIGN, SIZE, DURATION                  This retrospective observational study included 97 cycles of trophectoderm biopsy and preimplantation genetic testing (PGT) on vitrified-warmed embryos followed by a second round of vitrification between March 2015 and December 2019.                                                PARTICIPANTS/MATERIALS, SETTING, METHODS                  In 36 warming cycles, no biopsy was performed on the embryos before the first vitrification (single biopsy group). In 61 warming cycles, the embryos had been biopsied on Day 3 (n = 4) or on Day 5/6 (n = 57) before the first vitrification (double biopsy group). A second biopsy was mostly indicated in cycles of failed or inconclusive diagnosis at the first biopsy. Two cycles involved a more specific mutation test for X-linked diseases on male embryos and one cycle involved testing for a second monogenic indication supplementary to a previously tested reciprocal translocation. Post-warming suitability for biopsy, availability of genetically transferable embryos and clinical outcome of subsequent frozen-thawed embryo transfer (FET) cycles were reported. Neonatal follow-up of the children was included.                                                MAIN RESULTS AND THE ROLE OF CHANCE                  In total, 91 cleavage-stage embryos and 154 blastocysts were warmed, of which 34 (37.4%) and 126 (81.8%), respectively, were of sufficient quality to undergo trophectoderm biopsy and were subsequently vitrified for a second time. Out of these, 92 underwent biopsy for the first time (single biopsy), whereas 68 underwent a second biopsy (double biopsy). After diagnosis, 77 blastocysts (48.1%) were revealed to be genetically transferable (44 in the single biopsy group and 33 in the double biopsy group). In 46 warming cycles, 51 blastocysts were warmed and 49 survived this second warming procedure (96.0%). Subsequently, there were 45 FET cycles resulting in 27 biochemical pregnancies and 18 clinical pregnancies with fetal heartbeat (40.0% per FET cycle: 44.0% in the single biopsy group and 35.0% in the double biopsy group, P = 0.54). Thirteen singletons were born (eight in the single biopsy group and five in the double biopsy group), while three pregnancies were ongoing. A total of 26 embryos (13 in each group) remain vitrified and have the potential to increase the final clinical pregnancy rate. The neonatal follow-up of the children born so far is reassuring.                                                LIMITATIONS, REASONS FOR CAUTION                  This is a small retrospective cohort, thus, the implantation potential of double vitrification double biopsy blastocysts, as compared to double vitrification single biopsy blastocysts and standard PGT (single vitrification, single biopsy), certainly needs further investigation. Although one could speculate on birthweight being affected by the number of biopsies performed, the numbers in this study are too small to compare birthweight standard deviation scores in singletons born after single or double biopsy.                                                WIDER IMPLICATIONS OF THE FINDINGS                  PGT on vitrified-warmed embryos, including a second vitrification-warming step, results in healthy live birth deliveries, for both single- and double-biopsied embryos. The neonatal follow-up of the 13 children born so far did not indicate any adverse effect. The present study is important in order to provide proper counseling to couples on their chance of a live birth per initial warming cycle planned and concerning the safety issue of rebiopsy and double vitrification.                                                STUDY FUNDING/COMPETING INTEREST(S)                  None.                                                TRIAL REGISTRATION NUMBER                  N/A.               \n",
      "  -                                  Study question                  Does exposure of embryos to double vitrification and double warming affect the chances of ongoing pregnancy for patients undergoing PGT-A and transfer euploid embryos?                                                Summary answer                  Our analysis shows that there is no statistically significant difference in implantation or ongoing pregnancy rate between single or double vitrification/warming cycles.                                                What is known already                  The use of PGT-A is increasing in the last years and progressively more patients opting in for this, in order to reduce time to pregnancy. Implantation failures prior to genetic testing or the incidence of no-result embryos post PGT-A are some of the scenarios that expose the embryos to multiple rounds of vitrification/warming cycles. The exact effect that such exposure has on embryos is still to be investigated and confirmed as to whether it affects the outcome (i.e. implantation/ongoing pregnancy rate) or the future health of the child.                                                Study design, size, duration                  Our analysis is a retrospective observation study of data collected from 151 consecutive frozen euploid embryo transfers (FET). These were performed at a single centre between January-December 2020. Two groups were created for this study. The first group includes euploid embryos that were transferred post being exposed to single vitrification/warming (n = 126). In the second group euploid embryos were exposed twice to vitrification/warming (n = 25). Statistical analysis using chi-square test and statistical significance was calculated when p ≤ 0.05.                                                Participants/materials, setting, methods                  Blastocysts from 151 patients were split into two groups based on the number of vitrification/warming cycles that they underwent prior to FET. The first group includes embryos that were subjected to trophectoderm biopsy and were then vitrified (n = 126). The second group includes embryos that were initially vitrified without undergoing PGT-A analysis. Following implantation failures, their remaining embryos were warmed, biopsied and re-vitrified. Post PGT-A analysis euploid embryos were then re-warmed and transferred (n = 25).                                                Main results and the role of chance                  For the first group (A), 450 blastocysts (day 5–7) were subjected to trophectoderm biopsy, where 5-cells taken, and embryos were then vitrified. Post PGT-A analysis 260 euploid embryos identified. From them 126 embryos transferred in frozen replacement cycles, where the mean embryo age for the group was 36.1±4.2. The grade of embryos transferred were of 4BC or better based on Gardner’s grading system. The implantation and ongoing pregnancy rate for this group was 62%.                  For the second group (B), 101 blastocysts (day 5–7) warmed, in order to undergo trophectoderm biopsy and were then re-vitrified. Post PGT-A analysis 49 euploid embryos identified. From them, 25 embryos transferred in frozen replacement cycles, where the mean maternal age for the group was 35.05±5.2. The grade of embryos transferred were of similar quality to group A. The implantation and ongoing pregnancy rate for this group was 64%.                  Statistical analysis confirmed that there is no statistical difference between the groups (p = 0.74).                  In addition, 60% of patients (n = 5) who had double vitrification, double biopsy and double warming have ongoing pregnancy.                  In conclusion, for transferrable quality euploid blastocysts, double vitrification has comparable reproductive outcomes as in single vitrification, thereby supporting the efficacy of double vitrification/warming when necessary.                                                Limitations, reasons for caution                  This study uses a small sample size of patients. The data are observational and were retrospectively analysed so unknown confounders could not be assessed. The addition of more cycles and further multivariate analysis, including the child’s health is essential for confirmation of the findings. However, initial results are very reassuring.                  Wider implications of the findings: Our study has implications for clinical practice and patient counselling. Especially in patients that they choose to undergo PGT-A with pre-vitrified embryos post implantation failures with non PGT-A tested embryos.                                                Trial registration number                  N/A               \n",
      "  -                                  Study question                  Does double vitrification and thawing impact clinical pregnancy rate after a single blastocyst transfer?                                                Summary answer                  The clinical pregnancy rate obtained after double vitrification was comparable to that obtained after single vitrification.                                                What is known already                  Double vitrification-warming (DVW) is commonly practiced to accommodate surplus viable embryos suitable for transfer, allow retesting of inconclusive-diagnosed blastocysts for PGT and circumvent limitations associated with national policies on embryo culture in certain countries. Despite its popularity, the evidence concerning the impact of DVW on IVF/ICSI outcomes is limited and lacking credibility. Biopsied blastocysts have comparable chance of clinical pregnancy following double and single round of vitrification. However, our study is the first to report clinical pregnancy outcomes following DVW in the absence of biopsy and in the case where the first round of vitrification occurred at the zygote stage.                                                Study design, size, duration                  This is a retrospective observational analysis of n = 452 single blastocyst transfers that were either vitrified-warmed once (SVW, n = 349) or twice (DVW, n = 103) between January 2017 and December 2021.                                                Participants/materials, setting, methods                  In the SVW group, blastocysts were vitrified on day 5/6 and warmed on the day of embryo transfer (ET). In the DVW group, zygotes (2PN) were first vitrified-warmed and then vitrified again on day 5/6 and warmed on the day of ET. Exclusion criteria were ETs from PGT and vitrified-warmed oocyte cycles. All ETs were performed at the University Hospital of Zurich in Switzerland following a spontaneous or artificial endometrial preparation.                                                Main results and the role of chance                  Mean maternal age at oocyte pick-up (OPU) and at ET did not differ between the two groups: at OPU: 35.1±4.4 and 35.9±4.1 years for DVW and SVW groups respectively (p = 0.106), at ET: 36.6±4.4 and 36.5±4.4 years for DVW and SVW respectively (p = 0.73). The causes of infertility did not differ between the groups (p = 0.87): male factor infertility was most common: 46.6% and 50.1% of cases for DVW and SVW respectively while other causes included idiopathic infertility, anovulation, endometriosis and polycystic ovarian syndrome. The rate of fertilisation method utilised was similar between the groups (p = 0.98): DVW had 71.8% ICSI and 29% IVF while SVW had 71.9% ICSI and 28% IVF. The quality of blastocysts at ET was equal in the two groups (p = 0.09): DVW had 33.9% top, 30.9% medium and 35.9% low quality blastocyst while SVW had 34.3% top, 31.2% medium and 34.3% low quality blastocysts. The blastocyst expansion grade at ET was similar between the groups (p = 0.087): DVW had 64.9% 3-4 expanded, 32% hatching and 2.9% hatched blastocysts while SVW had 75.8% 3-4 expanded, 21.7% hatching and 2.2% hatched blastocysts. The clinical pregnancy rate was comparable between the groups (p = 0.54): for DVW it was 46.6% and for SVW it was 43.2%.                                                Limitations, reasons for caution                  The study is limited by its retrospective nature and rather small cohort. Caution should be taken concerning interpretation of these findings in the case that double vitrification-warming occurs at different stages of embryo development.                                                Wider implications of the findings                  The result of the present study on double vitrification-warming procedure provides a framework for counselling couples on their chance of clinical pregnancy per warming cycle. It additionally provides confidence and reassurance to laboratory professionals in certain countries where national policies limit embryo culture strategies making DVW inevitable.                                                Trial registration number                  N/A               \n",
      "--------------------------------------------------\n",
      "Topic 176: 176_energy_renewable_hydrogen_eu\n",
      "Representative Documents:\n",
      "  - PurposeThe purpose of this paper is to highlight the opportunity for the energy policy in Brazil to tackle the very high cost-effectiveness potencial of solar energy to the power system. Three mechanisms to achieve ambitious reductions in the greenhouse gas emissions from the power sector by 2030 and 2040 are assessed wherein treated as solar targets under ambitious reductions in the greenhouse gas emissions from the power sector. Then, three mechanisms to achieve these selected solar targets are suggested.Design/methodology/approachThis paper reviews current and future incentive mechanisms to promote solar energy. An integrated energy system optimization model shows the most cost-efficient deployment level. Incentive mechanisms can promote renewable sources, aiming to tackle climate change and ensuring energy security, while taking advantage of endogenous energy resources potential. Based on a literature review, as well as on the specific characteristics of the Brazilian power system, under restrictions for the expansion of hydroelectricity and ambitious limitation in the emissions of greenhouse gases from the power sector.FindingsThe potential unexploited of solar energy is huge but it needs the appropriate incentive mechanism to be deployed. These mechanisms would be more effective if they have a specific technological and temporal focus. The solar energy deployment in large scale is important to the mitigation of climate change.Originality/valueThe value of the research is twofold: estimations of the cost-effective potential of solar technologies, generated from an integrated optimization energy model, fully calibrated for the Brazilian power system, while tacking the increasing electricity demand, the expected reduction of greenhouse gas emissions and the need to increase the access to clean and affordable energy, up to 2040; proposals of three mechanisms to deploy centralized PV, distributed PV and solar thermal power, taking the best experiences in several countries and the recent Brazilian cases.\n",
      "  -                 Background                With sustainable bioenergy in the European energy mix, intermediate bioenergy carriers (IBC) become of growing importance, as they can ensure a more efficient utilisation of biomass feedstocks from agricultural and forest residues. A high potential for market uptake is foreseen for fast pyrolysis bio-oil (FPBO), one of several IBCs. While facing the chicken and egg problem in market entry, the aim of this study was the development of adequate strategies to support market implementation. The case study findings and methodological approach can provide policymakers, industry, and a broader audience with a vision for addressing similar challenges in market adoption of innovations in the bioeconomy and beyond. Therefore, we tested a new PESTEL + I approach and its practical applicability to an IBC value chain.                              Results                With an adopted PESTEL method, we analysed a promising value chain in which FPBO is produced from sawdust in Sweden and Finland, transported to the Netherlands and upgraded and marketed as a marine biofuel. Our results show that the market uptake of IBCs such as FPBO and subsequently produced biofuels is above all driven by the European Renewable Energy Directive II (RED II). In Annex IX Part A, sawdust is listed as a feedstock for advanced biofuels, which can be double counted towards the 14% renewable energy share goal in the transport sector in 2030. To support the use of advanced biofuels in the maritime and aviation sector, the proposal for revision of RED II 2021 contains a new multiplier (1.2x) for fuels delivered to these sectors, while all other multipliers are deleted. These legal European obligations and implementation into national law of member states create strong incentives for many downstream market actors to use advanced biofuel. However, technological challenges for FPBO use still hamper fast market introduction.                              Conclusions                Overcoming technology challenges and the creation of long-term validity of guidelines and regulatory framework will create stable market conditions, investment security and finally stimulate long-term offtake agreements between feedstock providers, technology developers and downstream customers. The approach and findings can provide a vision to overcome similar challenges in other bioeconomy innovations’ market uptake and beyond.              \n",
      "  - The energy production market based on hydrogen technologies is an innovative solution that will allow the industry to achieve climate neutrality in the future in Poland and in the world. The paper presents the idea of using hydrogen as a modern energy carrier, and devices that, in cooperation with renewable energy sources, produce the so-called green hydrogen and the applicable legal acts that allow for the implementation of the new technology were analyzed. Energy transformation is inevitable, and according to reports on good practices in European Union countries, hydrogen and the hydrogen value chain (production, transport and transmission, storage, use in transport, and energy) have wide potential. Thanks to joint projects and subsidies from the EU, initiatives supporting hydrogen technologies are created, such as hydrogen clusters and hydrogen valleys, and EU and national strategic programs set the main goals. Poland is one of the leaders in hydrogen production both in the world and in Europe. Domestic tycoons from the energy, refining, and chemical industries are involved in the projects. Eight hydrogen valleys that have recently been created in Poland successfully implement the assumptions of the “Polish Hydrogen Strategy until 2030 with a perspective until 2040” and “Energy Policy of Poland until 2040”, which are in line with the assumptions of the most important legal acts of the EU, including the European Union’s energy and climate policy, the Green Deal, and the Fit for 55 Package. The review of the analysis of the development of hydrogen technologies in Poland shows that Poland does not differ from other European countries. As part of the assumptions of the European Hydrogen Strategy and the trend related to the management of energy surpluses, electrolyzers with a capacity of at least 6 GW will be installed in Poland in 2020–2024. It is also assumed that in the next phase, planned for 2025–2030, hydrogen will be a carrier in the energy system in Poland. Poland, as a member of the EU, is the creator of documents that take into account the assumptions of the European Union Commission and systematically implement the assumed goals. The strategy of activities supporting the development of hydrogen technologies in Poland and the value chain includes very extensive activities related to, among others, obtaining hydrogen, using hydrogen in transport, energy, and industry, developing human resources for the new economy, supporting the activities of hydrogen valley stakeholders, building hydrogen refueling stations, and cooperation among Poland, Slovakia, and the Czech Republic as part of the HydrogenEagle project.\n",
      "--------------------------------------------------\n",
      "Topic 177: 177_make following_wish make following_wish make_wish\n",
      "Representative Documents:\n",
      "  - The authors wish to make the following corrections to this paper [...]\n",
      "  - The authors wish to make the following corrections to this paper [...]\n",
      "  - The authors wish to make the following corrections to this paper [1]: [...]\n",
      "--------------------------------------------------\n",
      "Topic 178: 178_vulnerability_species_assessments_threatened\n",
      "Representative Documents:\n",
      "  - The Arafura and Timor Seas region is shared by Indonesia, Timor Leste, Australia, and Papua New Guinea (PNG), and is at the intersection of the Pacific and Indian oceans. High coastal population densities, degraded habitats, overexploited fisheries, low profile coasts, shallow continental shelves and macro-tidal conditions mean that coastal and marine environments in the region are currently facing multiple pressures. Climate change is expected to exacerbate these pressures and have profound effects on the status and distribution of coastal and marine habitats, the fish and invertebrates they support and, therefore, dependent communities and industries. Downscaled climate change projections for 2041–2070 for air and sea temperature, ocean chemistry and rainfall were modelled to provide spatially relevant regional data for a structured semi-quantitative vulnerability assessment. Results of the assessment were spatially variable and identified shallow coral reefs as highly vulnerable, particularly in the Timor-Leste and Indonesia-Arafura sub-regions. Seagrass meadows were most vulnerable in the Gulf of Carpentaria, Indonesia-Arafura, and Timor-Leste sub-regions. Mangrove habitats were most vulnerable in Timor-Leste and Western PNG sub-regions. Drivers of vulnerability include poor habitat condition, non-climate pressures, low connectivity, and limited formal management. Marine species vulnerability was also spatially variable, with highly vulnerable and priority species identified for each sub-region, including finfish and marine invertebrates. A key driver of species vulnerability was their stock status, with many species in Timor-Leste, Western PNG and Indonesia, and several in northern Australia, overfished or potentially overfished. Limited management in some sub-regions, as well as non-climate pressures such as habitat decline, poor water quality and illegal, unregulated and unreported fishing were also key drivers. Species of conservation interest (dugong and marine turtles) were also highly vulnerable to climate change, driven by their threatened status and the fact that they are low productivity species that take years to recover from impacts. Priority species and habitats for local action were identified and current pressures that undermine condition and/or resilience, with strategic recommendations aimed at minimising climate change vulnerability.\n",
      "  - International Union for Conservation of Nature (IUCN) Red List assessments rely on published data and expert inputs, and biases can be introduced where underlying definitions and concepts are ambiguous. Consideration of climate change threat is no exception, and recently numerous approaches to assessing the threat of climate change to species have been developed. We explored IUCN Red List assessments of amphibians and birds to determine whether species listed as threatened by climate change display distinct patterns in terms of habitat occupied and additional nonclimatic threats faced. We compared IUCN Red List data with a published data set of species’ biological and ecological traits believed to infer high vulnerability to climate change and determined whether distributions of climate change‐threatened species on the IUCN Red List concur with those of climate change‐threatened species identified with the trait‐based approach and whether species possessing these traits are more likely to have climate change listed as a threat on the IUCN Red List. Species in some ecosystems (e.g., grassland, shrubland) and subject to particular threats (e.g., invasive species) were more likely to have climate change as a listed threat. Geographical patterns of climate change‐threatened amphibians and birds on the IUCN Red List were incongruent with patterns of global species richness and patterns identified using trait‐based approaches. Certain traits were linked to increases or decreases in the likelihood of a species being threatened by climate change. Broad temperature tolerance of a species was consistently related to an increased likelihood of climate change threat, indicating counterintuitive relationships in IUCN assessments. To improve the robustness of species assessments of the vulnerability or extinction risk associated with climate change, we suggest IUCN adopt a more cohesive approach whereby specific traits highlighted by our results are considered in Red List assessments. To achieve this and to strengthen the climate change‐vulnerability assessments approach, it is necessary to identify and implement logical avenues for further research into traits that make species vulnerable to climate change (including population‐level threats).\n",
      "  - Estimating and planning for the impacts of climate change on the biodiversity of protected areas is a major challenge for conservation managers. When these areas are topographically heterogenous and contain species' entire ranges, this challenge is exacerbated because the coarse spatial scales of Global Circulation Model projections provide limited information for within‐park management. South Africa's Table Mountain National Park, home to three endemic amphibian species in just ~24,500 hectares, provides a case study for identifying conservation needs under climate change. Selecting the park's herpetofauna as pilot taxa, we identified life history and demographic characteristics believed to make species more sensitive and less able to adapt to climate change. We organized these into assessment frameworks and, through a combination of literature review and expert elicitation, reviewed and used them to assess climate change vulnerability of 18 amphibian and 41 reptile species. The assessment highlighted that 73% and 67% of the park's reptile and amphibian species, respectively, had at least one high‐sensitivity and low‐adaptive capacity trait. Using ordinal and additive scoring methods, we identified the species most vulnerable to climate change and highlight the park areas containing their highest concentrations. These areas will be used to inform landscape‐scale management priorities and park use zones. The current IUCN Red List assessments for these species do not incorporate climate change vulnerability. Considering some species appear to be threatened by climate change, their conservation needs might be underestimated. Identifying the most vulnerable species and the mechanisms underpinning their vulnerability can guide the identification and prioritization of conservation needs, while the highlighted knowledge gaps inform priorities for monitoring and research. While comprehensive climate change adaptation planning for Table Mountain National Park requires additional assessment of other taxonomic groups, this trait‐based assessment example highlights a viable tool for assessing climate change vulnerability in protected areas.\n",
      "--------------------------------------------------\n",
      "Topic 179: 179_waste_kg co2_tonne_ghg\n",
      "Representative Documents:\n",
      "  -  The greenhouse gas (GHG) emissions related to the recycling of wood waste have been assessed with the purpose to provide useful data that can be used in accounting of greenhouse gas emissions. Here we present data related to the activities in a material recovery facility (MRF) where wood waste is shredded and foreign objects are removed in order to produce wood chips for use in the production of particleboard. The data are presented in accordance with the UOD (upstream, operational, downstream) framework presented in Gentil et al. ( Waste Management &amp; Research, 27, 2009). The GHG accounting shows that the emissions related to upstream activities (5 to 41 kg CO2-equivalents tonne —1 wood waste) and to activities at the MRF (approximately 5 kg CO2-equivalents tonne—1 wood waste) are negligible compared to the downstream processing (—560 to —120 kg CO2equivalents tonne—1 wood waste). The magnitude of the savings in GHG emissions downstream are mainly related to savings in energy consumption for drying of fresh wood for particleboard production. However, the GHG account highly depends on the choices made in the modelling of the downstream system. The inclusion of saved electricity from avoided chipping of virgin wood does not change the results radically (—665 to —125 kg CO2-equivalents tonne— 1 wood waste). However, if in addition it is assumed that the GHG emissions from combustion of wood has no global warming potential (GWP) and that the energy produced from excess wood due to recycling substitutes energy from fossil fuels, here assumed to be coal, potentially large downstream GHG emissions savings can be achieved by recycling of waste wood (—1.9 to —1.3 tonnes CO2-equivalents tonne— 1 wood waste). As the data ranges are broad, it is necessary to carefully evaluate the feasibility of the data in the specific system which the GHG accounting is to be applied to. \n",
      "  -  Greenhouse gas (GHG) emissions related to recycling of glass waste were assessed from a waste management perspective. Focus was on the material recovery facility (MRF) where the initial sorting of glass waste takes place. The MRF delivers products like cullet and whole bottles to other industries. Two possible uses of reprocessed glass waste were considered: (i) remelting of cullet added to glass production; and (ii) re-use of whole bottles. The GHG emission accounting included indirect upstream emissions (provision of energy, fuels and auxiliaries), direct activities at the MRF and bottle-wash facility (combustion of fuels) as well as indirect downstream activities in terms of using the recovered glass waste in other industries and, thereby, avoiding emissions from conventional production. The GHG accounting was presented as aggregated global warming factors (GWFs) for the direct and indirect upstream and downstream processes, respectively. The range of GWFs was estimated to 0—70 kg CO2eq. tonne —1 of glass waste for the upstream activities and the direct emissions from the waste management system. The GWF for the downstream effect showed some significant variation between the two cases. It was estimated to approximately —500 kg CO2-eq. tonne— 1 of glass waste for the remelting technology and —1500 to —600 kg CO2-eq. tonne—1 of glass waste for bottle re-use. Including the downstream process, large savings of GHG emissions can be attributed to the waste management system. The results showed that, in GHG emission accounting, attention should be drawn to thorough analysis of energy sources, especially electricity, and the downstream savings caused by material substitution. \n",
      "  -  Accounting of greenhouse gas (GHG) emissions from waste landfilling is summarized with the focus on processes and technical data for a number of different landfilling technologies: open dump (which was included as the worst-case-scenario), conventional landfills with flares and with energy recovery, and landfills receiving low-organic-carbon waste. The results showed that direct emissions of GHG from the landfill systems (primarily dispersive release of methane) are the major contributions to the GHG accounting, up to about 1000 kg CO2-eq. tonne —1 for the open dump, 300 kg CO2-eq. tonne —1 for conventional landfilling of mixed waste and 70 kg CO2-eq. tonne—1 for low-organic-carbon waste landfills. The load caused by indirect, upstream emissions from provision of energy and materials to the landfill was low, here estimated to be up to 16 kg CO2-eq. tonne—1. On the other hand, utilization of landfill gas for electricity generation contributed to major savings, in most cases, corresponding to about half of the load caused by direct GHG emission from the landfill. However, this saving can vary significantly depending on what the generated electricity substitutes for. Significant amounts of biogenic carbon may still be stored within the landfill body after 100 years, which here is counted as a saved GHG emission. With respect to landfilling of mixed waste with energy recovery, the net, average GHG accounting ranged from about —70 to 30 kg CO2-eq. tonne— 1, obtained by summing the direct and indirect (upstream and downstream) emissions and accounting for stored biogenic carbon as a saving. However, if binding of biogenic carbon was not accounted for, the overall GHG load would be in the range of 60 to 300 kg CO2-eq. tonne —1. This paper clearly shows that electricity generation as well as accounting of stored biogenic carbon are crucial to the accounting of GHG of waste landfilling. \n",
      "--------------------------------------------------\n",
      "Topic 180: 180_century_twenty first_twenty first century_first century\n",
      "Representative Documents:\n",
      "  - The ability of phase 5 of the Coupled Model Intercomparison Project (CMIP5) climate models to simulate the twentieth-century “warming hole” over North America is explored, along with the warming hole’s relationship with natural climate variability. Twenty-first-century warming hole projections are also examined for two future emission scenarios, the 8.5 and 4.5 W m−2 representative concentration pathways (RCP8.5 and RCP4.5). Simulations from 22 CMIP5 climate models were analyzed, including all their ensemble members, for a total of 192 climate realizations. A nonparametric trend detection method was employed, and an alternative perspective emphasizing trend variability. Observations show multidecadal variability in the sign and magnitude of the trend, where the twentieth-century temperature trend over the eastern United States appears to be associated with low-frequency (multidecadal) variability in the North Atlantic temperatures. Most CMIP5 climate models simulate significantly lower “relative power” in the North Atlantic multidecadal oscillations than observed. Models that have relatively higher skill in simulating the North Atlantic multidecadal oscillation also are more likely to reproduce the warming hole. It was also found that the trend variability envelope simulated by multiple CMIP5 climate models brackets the observed warming hole. Based on the multimodel analysis, it is found that in the twenty-first-century climate simulations the presence or absence of the warming hole depends on future emission scenarios; the RCP8.5 scenario indicates a disappearance of the warming hole, whereas the RCP4.5 scenario shows some chance (10%–20%) of the warming hole’s reappearance in the latter half of the twenty-first century, consistent with CO2 stabilization.\n",
      "  - Due to the significant negative consequences of winter cold extremes, there is need to better understand and simulate the mechanisms driving their occurrence. The impact of atmospheric blocking on winter cold spells over North America is investigated using ERA-Interim and NCEP-DOE-R2 reanalyses for 1981–2010. Initial-condition large-ensembles of two generations of Canadian Earth System Models (CanESM5 and its predecessor, CanESM2) are evaluated in terms of their ability to represent the blocking-cold spell linkage and the associated internal-variability. The reanalysis datasets show that 72 and 58% of cold spells in southern and northern North America coincide with blocking occurring in the high-latitude Pacific-North America. Compared to the two reanalyses, CanESM2 and CanESM5 ensembles underestimate by 19.9 and 14.3% cold spell events coincident with blocking, due to significant under-representation of blocking frequency over the North Pacific (− 47.1 and − 29.0%), whereas biases in cold spell frequency are relatively small (6.6 and − 4.7%). In the reanalyses, regions with statistically significant above-normal cold spell frequency relative to climatology lie on the east and/or south flanks of blocking events, whereas those with below-normal frequency lie along the core or surrounding the blocking. The two ensembles reproduce the observed blocking-cold spell linkage over North America, despite underestimating the magnitude of blocking frequency. The two ensembles also reproduce the physical drivers that underpin the blocking-cold spell linkage. Spatial agreement with the reanalyses is found in the simulated patterns of temperature advection and surface heat flux forcing anomalies during blocking events. While CanESM5 shows an improved representation of the blocking climatology relative to CanESM2, both yield similar results in terms of the blocking-cold spell linkage and associated internal-variability.\n",
      "  -                The climatology and trend of atmospheric angular momentum from the phase 3 and the phase 5 Climate Model Intercomparison Project (CMIP3 and CMIP5, respectively) simulations are diagnosed and validated with the Twentieth Century Reanalysis (20CR). It is found that CMIP5 models produced a significantly smaller bias in the twentieth-century climatology of the relative MR and omega MΩ angular momentum compared to CMIP3. The CMIP5 models also produced a narrower ensemble spread of the climatology and trend of MR and MΩ. Both CMIP3 and CMIP5 simulations consistently produced a positive trend in MR and MΩ for the twentieth and twenty-first centuries. The trend for the twenty-first century is much greater, reflecting the role of greenhouse gas (GHG) forcing in inducing the trend. The simulated increase in MR for the twentieth century is consistent with reanalysis. Both CMIP3 and CMIP5 models produced a wide range of magnitudes of decadal and interdecadal variability of MR compared to 20CR. The ratio of the simulated standard deviation of decadal or interdecadal variability to its observed counterpart ranges from 0.5 to over 2.0 for individual models. Nevertheless, the bias is largely random and ensemble averaging brings the ratio to within 18% of the reanalysis for decadal and interdecadal variability for both CMIP3 and CMIP5. The twenty-first-century simulations from both CMIP3 and CMIP5 produced only a small trend in the amplitude of decadal or interdecadal variability, which is not statistically significant. Thus, while GHG forcing induces a significant increase in the climatological mean of angular momentum, it does not significantly affect its decadal-to-interdecadal variability in the twenty-first century.\n",
      "--------------------------------------------------\n",
      "Topic 181: 181_energy consumption_energy_building_consumption\n",
      "Representative Documents:\n",
      "  - Under the influence of global epidemics and the need for urban expansion, many outpatient buildings have been rapidly constructed, but the problem of high energy consumption has been neglected. There is a lack of research on the impact of outpatient building forms on energy consumption in different climate zones. Many studies have demonstrated that the energy consumption of a given building can be greatly reduced by adopting a reasonable spatial form design at the early stages of design. Therefore, if architects choose a reasonable spatial form, this could effectively reduce energy consumption. In this study, outpatient building cases in China were summarized, and three typical spatial forms were proposed: the centralized, corridor, and courtyard forms. The DesignBuilder tool was used to simulate and analyse the typical building energy consumption in different climate zones. The results showed that the corridor form (southwards) should be chosen in the severe cold zone, the centralized form (southwards) should be chosen in the cold zone and the hot summer and cold winter zone, the centralized form (northwards) should be chosen in the hot summer and warm winter zone, and the centralized or corridor form can be chosen in the warm zone. The results of this study could provide a reference for energy-efficient design of outpatient buildings in China and other regions with similar conditions and could help architects quickly select reasonable spatial forms at the early stages of design.\n",
      "  - In previous studies, the concept of degree days has been widely used to indicate heating or cooling energy requirements, but it does not consider the dehumidification effect. In the present study, the concept of dehumidification degree days based on moisture content is used, and the degree days over the past 57 years for temperature decreasing and dehumidification in 4 cities belonging to major climate zones of China are analyzed. The results showed that the number of cooling degree days showed a significant increase (1.2–4.6 days/10 a) in all the selected cities, corresponding to the warming climate. In contrast, the degree days of dehumidification accounted for 19%–45% of the total days in summer and showed significant decreases (2.0–3.7 days/10 a) in the cold, hot summer and cold winter, and hot summer and warm winter climate zones. Comfortable days, i.e., days requiring no cooling and no dehumidification, accounting for 8–45% of the total days in summer, decreased significantly in the extreme cold and cold zones (0.9–1.8 days/10 a) but showed no apparent changes in the hot summer and cold winter and hot summer and warm winter climate zones. This study suggests that energy consumption for cooling increases linearly with climate warming, and only the energy consumed for dehumidification had an apparent decrease. The degree days of dehumidification, as well as those requiring no cooling and no dehumidification, should be fully considered in the capacity design of air-conditioning units, especially air-conditioning systems with temperature- and humidity-independent control (THIC). This study indicates that the assessment of energy consumption for requests for air-conditioning in relation to climate change should be carried out after separating energy consumption for cooling from energy consumption for dehumidification to improve building energy efficiency and indoor comfort.\n",
      "  - Under the impact of COVID-19 and the needs for urban expansion, a large number of outpatient buildings have been rapidly constructed, but the problem of high energy consumption has always been ignored. There is a lack of research on the adaptability of building shape in different climate zones. Many studies have shown that a reasonable shape in the early stage of design can significantly reduce the energy consumption of buildings. Therefore, it helps if architects quickly select a reasonable shape that can effectively reduce energy consumption. This study summarized a number of outpatient building cases in China and proposed three typical building shapes: centralized-type (Shape-1), corridor-type (Shape-2), and courtyard-type (Shape-3). The Design Builder tool was used to simulate and analyze the typical building energy consumption in different climate zones. The simulation results show that Shape-2 (angle: 0°) should be chosen in severe cold zone; Shape-1 (angle: 90°) should be chosen in cold zone; Shape-1 (angle: 0°) should be chosen in hot summer and cold winter zone; Shape-1 (angle: 60°) should be chosen in hot summer and warm winter zone; and Shape-1 or Shape-2 can be chosen in warm zone. The results of this study can provide suggestions for the energy saving design of outpatient buildings in China and other areas with similar conditions. The result can help architects make rapid shape selection in the early stage of design.\n",
      "--------------------------------------------------\n",
      "Topic 182: 182_catchment_flood_rainfall_river\n",
      "Representative Documents:\n",
      "  - The UK road network is deteriorating due to ageing infrastructure, climate change and increasing traffic. Due to community and economic reliance on a functioning road system, there is an urgent requirement to build resilience. The roads of south Lincolnshire have high susceptibility to ground movement due to the underlying geology. Deposits such as peat, tidal flat deposits and alluvium have a high susceptibility to compress, particularly when loaded or through loss of water content driven by climate change or lowering of water in drainage channels. The shallow foundations of Lincolnshire's rural evolved roads, originating from old mud tracks, are poorly constructed, increasing their vulnerability to movement. Types of damage include longitudinal cracking, edge failure and uneven long-section profiles. Through knowledge exchange, data sharing and collaboration between the British Geological Survey and Lincolnshire County Council, a direct relationship between road condition and geohazard susceptibility has been demonstrated; showing compressible ground has a greater correlation with road damage than originally considered. This suggests improved understanding of the relationships between the geological, climatic and anthropogenic driving forces on ground movement and road damage enables more informed repair prioritization, decision support and improved bespoke road repair practices, increasing future resilience of road networks.                      Thematic collection:            This article is part of the Climate change and resilience in Engineering Geology and Hydrogeology collection available at:            https://www.lyellcollection.org/topic/collections/climate-change-and-resilience-in-engineering-geology-and-hydrogeology          \n",
      "  - . The effects of climate change are causing more frequent extreme rainfall events and an increased risk of flooding in developed areas. Quantifying this increased risk is of critical importance for the protection of life and property as well as for infrastructure planning and design. The updated National Oceanic and Atmospheric Administration (NOAA) Atlas 14 intensity–duration–frequency (IDF) relationships and temporal patterns are widely used in hydrologic and hydraulic modeling for design and planning in the United States. Current literature shows that rising temperatures as a result of climate change will result in an intensification of rainfall. These impacts are not explicitly included in the NOAA temporal patterns, which can have consequences on the design and planning of adaptation and flood mitigation measures. In addition there is a lack of detailed hydraulic modeling when assessing climate change impacts on flooding. The study presented in this paper uses a comprehensive hydrologic and hydraulic model of a fully developed urban/suburban catchment to explore two primary questions related to climate change impacts on flood risk. (1) How do climate change effects on storm temporal patterns and rainfall volumes impact flooding in a developed complex watershed? (2) Is the storm temporal pattern as critical as the total volume of rainfall when evaluating urban flood risk? We use the NOAA Atlas 14 temporal patterns, along with the expected increase in temperature for the RCP8.5 scenario for 2081–2100, to project temporal patterns and rainfall volumes to reflect future climatic change. The model results show that different rainfall patterns cause variability in flood depths during a storm event. The changes in the projected temporal patterns alone increase the risk of flood magnitude up to 35 %, with the cumulative impacts of temperature rise on temporal patterns and the storm volume increasing flood risk from 10 to 170 %. The results also show that regional storage facilities are sensitive to rainfall patterns that are loaded in the latter part of the storm duration, while extremely intense short-duration storms will cause flooding at all locations. This study shows that changes in temporal patterns will have a significant impact on urban/suburban flooding and need to be carefully considered and adjusted to account for climate change when used for the design and planning of future storm water systems.\n",
      "  - . Due to its location within the typhoon belt, the Philippines is vulnerable to tropical cyclones that can cause destructive floods. Climate change is likely to exacerbate these risks through increases in tropical cyclone frequency and intensity. To protect populations and infrastructure, disaster risk management in the Philippines focuses on real-time flood forecasting and structural measures such as dikes and retaining walls. Real-time flood forecasting in the Philippines mostly utilises two models from the Hydrologic Engineering Center (HEC): the Hydrologic Modeling System (HMS) for watershed modelling, and the River Analysis System (RAS) for inundation modelling. This research focuses on using non-structural measures for flood mitigation, such as changing land use management or watershed rehabilitation. This is being done by parameterising and applying the Land Utilisation and Capability Indicator (LUCI) model to the Cagayan de Oro watershed (1400 km2) in southern Philippines. The LUCI model is capable of identifying areas providing ecosystem services such as flood mitigation and agricultural productivity, and analysing trade-offs between services. It can also assess whether management interventions could enhance or degrade ecosystem services at fine spatial scales. The LUCI model was used to identify areas within the watershed that are providing flood mitigating services and areas that would benefit from management interventions. For the preliminary comparison, LUCI and HEC-HMS were run under the same scenario: baseline land use and the extreme rainfall event of Typhoon Bopha. The hydrographs from both models were then input to HEC-RAS to produce inundation maps. The novelty of this research is two-fold: (1) this type of ecosystem service modelling has not been carried out in the Cagayan de Oro watershed; and (2) this is the first application of the LUCI model in the Philippines. Since this research is still ongoing, the results presented in this paper are preliminary. As the land use and soil parameterisation for this watershed are refined and more scenarios are run through the model, more robust comparisons can be made between the hydrographs produced by LUCI and HEC-HMS and how those differences affect the inundation map produced by HEC-RAS.                    \n",
      "--------------------------------------------------\n",
      "Topic 183: 183_species_abundance_pika_declines\n",
      "Representative Documents:\n",
      "  - Biotic responses to climate change will vary among taxa and across latitudes, elevational gradients, and degrees of insularity. However, due to factors such as phenotypic plasticity, ecotypic variation, and evolved tolerance to thermal stress, it remains poorly understood whether losses should be greatest in populations experiencing the greatest climatic change or living in places where the prevailing climate is closest to the edge of the species' bioclimatic envelope (e.g., at the hottest, driest sites). Research on American pikas (Ochotona princeps) in montane areas of the Great Basin during 1994–1999 suggested that 20th‐century population extirpations were predicted by a combination of biogeographic, anthropogenic, and especially climatic factors. Surveys during 2005–2007 documented additional extirpations and within‐site shifts of pika distributions at remaining sites. To evaluate the evidence in support of alternative hypotheses involving effects of thermal stress on pikas, we placed temperature sensors at 156 locations within pika habitats in the vicinity of 25 sites with historical records of pikas in the Basin. We related these time series of sensor data to data on ambient temperature from weather stations within the Historical Climate Network. We then used these highly correlated relationships, combined with long‐term data from the same weather stations, to hindcast temperatures within pika habitats from 1945 through 2006. To explain patterns of loss, we posited three alternative classes of direct thermal stress: (1) acute cold stress (number of days below a threshold temperature); (2) acute heat stress (number of days above a threshold temperature); and (3) chronic heat stress (average summer temperature). Climate change was defined as change in our thermal metrics between two 31‐yr periods: 1945–1975 and 1976–2006. We found that patterns of persistence were well predicted by metrics of climate. Our best models suggest some effects of climate change; however, recent and long‐term metrics of chronic heat stress and acute cold stress, neither previously recognized as sources of stress for pikas, were some of the best predictors of pika persistence. Results illustrate that extremely rapid distributional shifts can be explained by climatic influences and have implications for conservation topics such as reintroductions and early‐warning indicators.\n",
      "  - Advances in understanding the factors that limit a species’ range, particularly in the context of climate change, have come disproportionately through investigations at range edges or margins. The margins of a species’ range might often correspond with anomalous microclimates that confer habitat suitability where the species would otherwise fail to persist. We addressed this hypothesis using data from an interior, climatic range margin of the American pika (Ochotona princeps), an indicator of relatively cool, mesic climates in rocky habitats of western North America. Pikas in Lava Beds National Monument, northeastern California, USA, occur at elevations much lower than predicted by latitude and longitude. We hypothesized that pika occurrence within Lava Beds would be associated primarily with features such as “ice caves” in which sub‐surface ice persists outside the winter months. We used data loggers to monitor sub‐surface temperatures at cave entrances and at non‐cave sites, confirming that temperatures were cooler and more stable at cave entrances. We surveyed habitat characteristics and evidence of pika occupancy across a random sample of cave and non‐cave sites over a 2‐yr period. Pika detection probability was high (~0.97), and the combined occupancy of cave and non‐cave sites varied across the 2 yr from 27% to 69%. Contrary to our hypothesis, occupancy was not higher at cave sites. Vegetation metrics were the best predictors of site use by pikas, followed by an edge effect and elevation. The importance of vegetation as a predictor of pika distribution at this interior range margin is congruent with recent studies from other portions of the species’ range. However, we caution that vegetation composition depends on microclimate, which might be the proximal driver of pika distribution. The microclimates available in non‐cave crevices accessible to small animals have not been characterized adequately for lava landscapes. We advocate innovation in the acquisition and use of microclimatic data for understanding the distributions of many taxa. Appropriately scaled microclimatic data are increasingly available but rarely used in studies of range dynamics.\n",
      "  - Grassland biomes in North America are threatened by agricultural intensification with implications for grassland‐associated bird populations via habitat loss, alteration, pesticide use, and declining landscape heterogeneity. Despite decades of conservation concern, steep declines of grassland birds continue. Key to optimizing conservation effort is understanding how land‐use practices, such as agriculture, across the annual cycle affect population status. Determining the relative influence of impacts on grassland bird declines is difficult given that the most robust estimate of trends, the North American Breeding Bird Survey (BBS), is conducted throughout agriculturally dominated regions. Our goal was to explore whether agriculture during the breeding season is a major driver of grassland bird declines, by evaluating population trends in regions with different amounts of agricultural development. We derived trends for 16 bird species spanning 23 years (1994–2016) at a large (459 km2), native prairie site, Suffield National Wildlife Area (SNWA) in Alberta, Canada. We compared those trends with the BBS across three spatial scales, a regional monitoring scheme with higher than average native grass cover (Grassland Bird Monitoring [GBM]), Bird Conservation Region 11 Canada (Canada), and all of Bird Conservation Region 11 (BCR 11). Trends measured as annual percent change and credible interval varied greatly among species and survey strata. Across all species, declines were greatest for Canada (−1.3%, CI: −2.8, 0.0) and BCR 11 (−1.9%, CI: −3.2, −0.6). This contrasts with positive trends for GBM routes (1.0%, CI: −0.4, 2.3) and the SNWA data (1.7%, CI: 0.3, 3.3). Six of 16 species at SNWA were increasing with one decreasing. Five species increased at GBM and four declined. Canada had 10 species declines and 3 increases and BCR 11 had 10 declines and no increases. None of the six grassland obligate species declined at SNWA, two declined at GBM, and all six declined over the two larger BBS strata. Our results showing fewer negative population trends at a large native grassland site compared with BBS at three spatial scales across the North American prairies support the prediction that agricultural intensification on breeding grounds may be driving population declines and protection of native grasslands is a key component of grassland bird conservation efforts.\n",
      "--------------------------------------------------\n",
      "Topic 184: 184_zooplankton_phytoplankton_lakes_plankton\n",
      "Representative Documents:\n",
      "  - Summary1. Winter temperatures differ markedly on the Canadian prairies compared with Denmark. Between 1 January 1998 and 31 December 2002, average weekly and monthly temperatures did not drop below 0 °C in the vicinity of Silkeborg, Denmark. Over this same time, weekly average temperatures near Calgary, Alberta, Canada, often dropped below −10 °C for 3–5 weeks and the average monthly temperature was below 0 °C for 2–4 months. Accordingly, winter ice conditions in shallow lakes in Canada and Denmark differed considerably.2. To assess the implications of winter climate for lake biotic structure and function we compared a number of variables that describe the chemistry and biology of shallow Canadian and Danish lakes that had been chosen to have similar morphometries.3. The Danish lakes had a fourfold higher ratio of chlorophyll‐a: total phosphorus (TP). Zooplankton : phytoplankton carbon was related to TP and fish abundance in Danish lakes but not in Canadian lakes. There was no significant difference in the ratio log total zooplankton biomass : log TP and the Canadian lakes had a significantly higher proportion of cladocerans that were Daphnia. These differences correspond well with the fact that the Danish lakes have more abundant and diverse fish communities than the Canadian lakes.4. Our results suggest that severe Canadian winters lead to anoxia under ice and more depauperate fish communities, and stronger zooplankton control on phytoplankton in shallow prairie lakes compared with shallow Danish lakes. If climate change leads to warmer winters and a shorter duration of ice cover, we predict that shallow Canadian prairie lakes will experience increased survivorship of planktivores and stronger control of zooplankton. This, in turn, might decrease zooplankton control on phytoplankton, leading to ‘greener’ lakes on the Canadian prairies.\n",
      "  - Long‐term dynamics of phytoplankton have been addressed in marine and lake systems, but rarely in rivers. Large rivers, however, are highly human‐impacted, whereas global warming may further affect the functioning of phytoplankton at long‐term scale.In the middle section of the large European Danube River, long‐term decrease in phytoplankton biomass (Chl‐a) and increase in species diversity have formerly been revealed. The functional community composition that relates to ecosystem functioning directly has not been addressed previously. We analyse a 34‐year‐long phytoplankton data set from the middle river section at Göd (N‐Budapest), Hungary. We focus on gradual changes in the functional composition and functional diversity components based on the functional trait and functional group approaches.We hypothesised that long‐term gradual changes in major environmental constraints should be followed by gradual shifts in dominance relationships among functional traits and functional groups of phytoplankton. We further hypothesised that functional shifts were highlighted by gradual changes in functional diversity components: evenness, divergence and dispersion.Water discharge of the middle Danube shifted towards the more frequent occurrence of lower values. On the other hand, high floods (&gt;3,000 m3/s) increased significantly with shortening tendency in duration and altered seasonality. The concentration of N and P forms, as well as total suspended solids decreased significantly. Water temperature increased significantly, especially in summer. In the phytoplankton, single‐celled eutrophic centric diatoms decreased in relative abundance, but flagellated, elongated and filamentous forms increased. A clear functional shift was the dominance decrease in planktonic taxa and the relative abundance increase in benthic diatoms.All functional diversity components increased significantly in the entire data set, except functional evenness (FEVE) based on the functional group approach. At seasonal scale, all significant trends showed increases, except the FEVE components of the functional group approach, which decreased in winter and spring significantly.Long‐term increase in functional diversity components alone could indicate enhanced ecosystem functioning of phytoplankton in the middle section of the Danube. However, we argue that the observed increase in functional diversity may be related to a gradual shift from high‐biomass communities with the dominance of eutrophic centric diatoms towards the relative increase in several, but low‐biomass elements. These include a few planktonic algae well adapted to the altered conditions, diatoms with benthic origin and dispersed limnophilic taxa.Our results provide the first evidence for a long‐term phytoplankton functional regime shift in a European large river. Global warming, human impacts and oligotrophication might potentially increase the functional diversity of large river phytoplankton, but the origin and functional role of taxa should carefully be considered. The observed functional shift in phytoplankton might also be indicative for alterations in the food‐web structure of the middle section of the Danube River at long‐term scale.\n",
      "  - . Climate change has multiple effects on Baltic Sea species, communities andecosystem functioning through changes in physical and biogeochemicalenvironmental characteristics of the sea. Associated indirect and secondaryeffects on species interactions, trophic dynamics and ecosystem function are expected to be significant. We review studies investigating species-,population- and ecosystem-level effects of abiotic factors that may changedue to global climate change, such as temperature, salinity, oxygen, pH,nutrient levels, and the more indirect biogeochemical and food webprocesses, primarily based on peer-reviewed literature published since 2010. For phytoplankton, clear symptoms of climate change, such as prolongation of the growing season, are evident and can be explained by the warming, butotherwise climate effects vary from species to species and area to area.Several modelling studies project a decrease of phytoplankton bloom inspring and an increase in cyanobacteria blooms in summer. The associatedincrease in N:P ratio may contribute to maintaining the “vicious circle of eutrophication”. However, uncertainties remain because some field studies claim that cyanobacteria have not increased and some experimental studies show that responses of cyanobacteria to temperature, salinity and pH vary from species to species. An increase of riverine dissolved organic matter (DOM) may also decrease primary production, but the relative importance of this process in different sea areas is not well known. Bacteria growth is favoured by increasing temperature and DOM, but complex effects in the microbial food web are probable. Warming of seawater in spring also speeds up zooplankton growth and shortens the time lag between phytoplankton and zooplankton peaks, which may lead to decreasing of phytoplankton in spring. In summer, a shift towards smaller-sized zooplankton and a decline of marine copepod species has been projected. In deep benthic communities, continued eutrophication promotes highsedimentation and maintains good food conditions for zoobenthos. If nutrientabatement proceeds, improving oxygen conditions will first increasezoobenthos biomass, but the subsequent decrease of sedimenting matter willdisrupt the pelagic–benthic coupling and lead to a decreased zoobenthosbiomass. In the shallower photic systems, heatwaves may produceeutrophication-like effects, e.g. overgrowth of bladderwrack by epiphytes,due to a trophic cascade. If salinity also declines, marine species such asbladderwrack, eelgrass and blue mussel may decline. Freshwater vascularplants will be favoured but they cannot replace macroalgae on rockysubstrates. Consequently invertebrates and fish benefiting frommacroalgal belts may also suffer. Climate-induced changes in the environment also favour establishment of non-indigenous species, potentially affecting food web dynamics in the Baltic Sea. As for fish, salinity decline and continuing of hypoxia is projected to keep cod stocks low, whereas the increasing temperature has been projected to favour sprat and certain coastal fish. Regime shifts and cascading effects have been observed in both pelagic and benthic systems as a result of several climatic and environmental effects acting synergistically. Knowledge gaps include uncertainties in projecting the future salinity level, as well as stratification and potential rate of internal loading, under different climate forcings. This weakens our ability to project how pelagic productivity, fish populations and macroalgal communities may change in the future. The 3D ecosystem models, food web models and 2D species distribution models would benefit from integration, but progress is slowed down by scale problems and inability of models to consider the complex interactions between species. Experimental work should be better integrated into empirical and modelling studies of food web dynamics to get a morecomprehensive view of the responses of the pelagic and benthic systems toclimate change, from bacteria to fish. In addition, to better understand theeffects of climate change on the biodiversity of the Baltic Sea, more emphasisshould be placed on studies of shallow photic environments. The fate of the Baltic Sea ecosystem will depend on various intertwinedenvironmental factors and on development of the society. Climate changewill probably delay the effects of nutrient abatement and tend to keep theecosystem in its “novel” state. However, several modelling studies conclude that nutrient reductions will be a stronger driver for ecosystem functioning of the Baltic Sea than climate change. Such studies highlight the importance of studying the Baltic Sea as an interlinked socio-ecological system.                    \n",
      "--------------------------------------------------\n",
      "Topic 185: 185_abyssal_waters_weddell_bottom\n",
      "Representative Documents:\n",
      "  - Abyssal ocean warming contributed substantially to anthropogenic ocean heat uptake and global sea level rise between 1990 and 2010. In the 2010s, several hydrographic sections crossing the South Pacific Ocean were occupied for a third or fourth time since the 1990s, allowing for an assessment of the decadal variability in the local abyssal ocean properties among the 1990s, 2000s, and 2010s. These observations from three decades reveal steady to accelerated bottom water warming since the 1990s. Strong abyssal (z &gt; 4,000 m) warming of 3.5 (±1.4) m°C/year (m°C = 10−3 °C) is observed in the Ross Sea, directly downstream from bottom water formation sites, with warming rates of 2.5 (±0.4) m°C/year to the east in the Amundsen‐Bellingshausen Basin and 1.3 (±0.2) m°C/year to the north in the Southwest Pacific Basin, all associated with a bottom‐intensified descent of the deepest isotherms. Warming is consistently found across all sections and their occupations within each basin, demonstrating that the abyssal warming is monotonic, basin‐wide, and multidecadal. In addition, bottom water freshening was strongest in the Ross Sea, with smaller amplitude in the Amundsen‐Bellingshausen Basin in the 2000s, but is discernible in portions of the Southwest Pacific Basin by the 2010s. These results indicate that bottom water freshening, stemming from strong freshening of Ross Shelf Waters, is being advected along deep isopycnals and mixed into deep basins, albeit on longer timescales than the dynamically driven, wave‐propagated warming signal. We quantify the contribution of the warming to local sea level and heat budgets.\n",
      "  -                Warming and freshening of abyssal waters in the eastern Indian Ocean between 1994/95 and 2007 are quantified using data from two closely sampled high-quality occupations of a hydrographic section extending from Antarctica northward to the equator. These changes are limited to abyssal waters in the Princess Elizabeth Trough and the Australian–Antarctic Basin, with little abyssal change evident north of the Southeast Indian Ridge. As in previous studies, significant cooling and freshening is observed in the bottom potential temperature–salinity relations in these two southern basins. In addition, analysis on pressure surfaces shows abyssal warming of about 0.05°C and freshening of about 0.01 Practical Salinity Scale 1978 (PSS-78) in the Princess Elizabeth Trough, and warming of 0.1°C with freshening of about 0.005 in the abyssal Australian–Antarctic Basin. These 12-yr differences are statistically significant from zero at 95% confidence intervals over the bottom few to several hundred decibars of the water column in both deep basins. Both warming and freshening reduce the density of seawater, contributing to the vertical expansion of the water column. The changes below 3000 dbar in these basins suggest local contributions approaching 1 and 4 cm of sea level rise, respectively. Transient tracer data from the 2007 occupation qualitatively suggest that the abyssal waters in the two southern basins exhibiting changes have significant components that have been exposed to the ocean surface within the last few decades, whereas north of the Southeast Indian Ridge, where changes are not found, the component of abyssal waters that have undergone such ventilation is much reduced.\n",
      "  - Warming of abyssal waters in recent decades contributes to global heat uptake and sea level rise. Repeat oceanographic section data in the western South Atlantic taken mostly in 1989 (1995 across the Scotia Sea), 2005, and 2014 are used to quantify warming in abyssal waters that spread northward through the region from their Antarctic origins in the Weddell Sea. While much of the Scotia Sea warmed between 1995 and 2005, only the southernmost portion, on the north side of the Weddell Gyre, continued to warm between 2005 and 2014. The abyssal Argentine Basin also warmed between 1989 and 2005, but again only the southernmost portion continued to warm between 2005 and 2014, suggesting a slowdown in the inflow of the coldest, densest Antarctic Bottom Waters into the western South Atlantic between 1989 and 2014. In contrast, the abyssal waters of the Brazil Basin warmed both between 1989 and 2005 and between 2005 and 2014, at a rate of about 2 m°C yr−1. This warming is also assessed in terms of the rates of change of heights above the bottom for deep isotherms in each deep basin studied. These results, together with findings from previous studies, suggest the deep warming signal observed in the Weddell Sea after the mid‐1970s Weddell Polynya was followed by abyssal warming in the Argentine Basin from the late 1970s through about 2005, then warming in the deep Vema Channel from about 1992 through at least 2010, and warming in the Brazil Basin from 1989 to 2014.\n",
      "--------------------------------------------------\n",
      "Topic 186: 186_rainfall_siocz_precipitation_projections\n",
      "Representative Documents:\n",
      "  -  Future projections of precipitation at regional scales are vital to inform climate change adaptation activities. Therefore, is it important to quantify projected changes and associated uncertainty, and understand model processes responsible. This paper addresses these challenges for southern Africa and the adjacent Indian Ocean focusing on the local wet season. Precipitation projections for the end of the twenty-first century indicate a pronounced dipole pattern in the CMIP5 multimodel mean. The dipole indicates future wetting (drying) to the north (south) of the climatological axis of maximum rainfall, implying a northward shift of the ITCZ and south Indian Ocean convergence zone that is not consistent with a simple “wet get wetter” pattern. This pattern is most pronounced in early austral summer, suggesting a later and shorter wet season over much of southern Africa. Using a decomposition method we determine physical mechanisms underlying this dipole pattern of projected change, and the associated intermodel uncertainty. The projected dipole pattern is largely associated with the dynamical component of change indicative of shifts in the location of convection. Over the Indian Ocean, this apparent northward shift in the ITCZ may reflect the response to changes in the north–south SST gradient over the Indian Ocean, consistent with a “warmest get wetter” mechanism. Over land subtropical drying is relatively robust, particularly in the early wet season. This has contributions from dynamical shifts in the location of convection, which may be related to regional SST structures in the southern Indian Ocean, and the thermodynamic decline in relative humidity. Implications for understanding and potentially constraining uncertainty in projections are discussed. \n",
      "  - Southern Africa relies heavily on precipitation for agricultural purposes; therefore, spatial and temporal changes in precipitation are crucial to identify and understand. The South Indian Ocean Convergence Zone (SIOCZ), a large-scale, austral summer rainfall feature extending across southern Africa into the southwest Indian Ocean, is evaluated in future projections. Using a best-fit algorithm, future projections of the SIOCZ are determined, which indicate a northward shift of approximately 120 km in CMIP5 models under RCP8.5. A dipole pattern of precipitation wetting/drying is evident, where wetting occurs to the north of the climatological axis of maximum rainfall, implying a northward shift of the Inter Tropical Convergence Zone, consistent with the SIOCZ shift. Common drivers responsible for model changes include enhanced warming in the northern Indian Ocean in line with the ‘warmest-get-wetter’ sea surface temperature hypothesis, which impacts circulation by transporting moisture away from the SIOCZ towards the equator. Most CMIP5 models exhibit drying trends over the SIOCZ region, with mechanisms driving uncertainty related to diverse warming trends across models. Empirical orthogonal function patterns of future precipitation changes across CMIP5 models exhibit a pattern much like the SIOCZ, which is related to inter-model changes in future temperature changes. Reductions in model spread are established in SIOCZ projections, whereby model processes of change exhibit agreement, despite differing initial SIOCZ conditions. Therefore, model process convergence and coherence are established with respect to projected changes in the SIOCZ, irrespective of initial climatology biases. Understanding future changes in this feature will help inform decision-making for water and agriculture adaptation planning in southern Africa.\n",
      "  -                This paper examines nine analyses of global ocean 0-/700-m temperature and heat content during the 43-yr period of warming, 1960–2002. Among the analyses are two that are independent of any numerical model, six that rely on sequential data assimilation, including an ocean general circulation model, and one that uses four-dimensional variational data assimilation (4DVAR), including an ocean general circulation model and its adjoint. Most analyses show gradual warming of the global ocean with an ensemble trend of 0.77 × 108 J m−2 (10 yr)−1 (=0.24 W m−2) as the result of rapid warming in the early 1970s and again beginning around 1990. One proposed explanation for these variations is the effect of volcanic eruptions in 1963 and 1982. Examination of this hypothesis suggests that while there is an oceanic signal, it is insufficient to explain the observed heat content variations.               A second potential cause of decadal variations in global heat content is the uncorrelated contribution of heat content variations in individual ocean basins. The subtropical North Atlantic is warming at twice the global average, with accelerated warming in the 1960s and again beginning in the late 1980s and extending through the end of the record. The Barents Sea region of the Arctic Ocean and the Gulf of Mexico have also warmed, while the western subpolar North Atlantic has cooled. Heat content variability in the North Pacific differs significantly from the North Atlantic. There the spatial and temporal patterns are consistent with the decadal variability previously identified through observational and modeling studies examining SST and surface winds. In the Southern Hemisphere large heat content anomalies are evident, and while there is substantial disagreement among analyses on average the band of latitudes at 30°–60°S contribute significantly to the global warming trend. Thus, the uncorrelated contributions of heat content variations in the individual basins are a major contributor to global heat content variations.               A third potential contributor to global heat content variations is the effect of time-dependent bias in the set of historical observations. This last possibility is examined by comparing the analyses to the unbiased salinity–temperature–depth dataset and finding a very substantial warm bias in all analyses in the 1970s relative to the latter decades. This warm bias may well explain the rapid increase in analysis heat content in the early 1970s, but not the more recent increase, which began in the early 1990s.               Finally, this study provides information about the similarities and differences between analyses that are independent of a model and those that use sequential assimilation and 4DVAR. The comparisons provide considerable encouragement for the use of the sequential analyses for climate research despite the presence of erroneous variability (also present in the no-model analyses) resulting from instrument bias. The strengths and weaknesses of each analysis need to be considered for a given application.\n",
      "--------------------------------------------------\n",
      "Topic 187: 187_gpp_carbon_ecosystem_soil\n",
      "Representative Documents:\n",
      "  - SummaryWe are developing a process‐based modelling approach to investigate how carbon (C) storage of tundra across the entire Arctic will respond to projected climate change. To implement the approach, the processes that are least understood, and thus have the most uncertainty, need to be identified and studied. In this paper, we identified a key uncertainty by comparing the responses of C storage in tussock tundra at one site between the simulations of two models – one a global‐scale ecosystem model (Terrestrial Ecosystem Model, TEM) and one a plot‐scale ecosystem model (General Ecosystem Model, GEM). The simulations spanned the historical period (1921–94) and the projected period (1995–2100). In the historical period, the model simulations of net primary production (NPP) differed in their sensitivity to variability in climate. However, the long‐term changes in C storage were similar in both simulations, because the dynamics of heterotrophic respiration (RH) were similar in both models. In contrast, the responses of C storage in the two model simulations diverged during the projected period. In the GEM simulation for this period, increases in RH tracked increases in NPP, whereas in the TEM simulation increases in RH lagged increases in NPP. We were able to make the long‐term C dynamics of the two simulations agree by parameterizing TEM to the fast soil C pools of GEM. We concluded that the differences between the long‐term C dynamics of the two simulations lay in modelling the role of the recalcitrant soil C. These differences, which reflect an incomplete understanding of soil processes, lead to quite different projections of the response of pan‐Arctic C storage to global change. For example, the reference parameterization of TEM resulted in an estimate of cumulative C storage of 2032 g C m−2 for moist tundra north of 50°N, which was substantially higher than the 463 g C m−2 estimated for a parameterization of fast soil C dynamics. This uncertainty in the depiction of the role of recalcitrant soil C in long‐term ecosystem C dynamics resulted from our incomplete understanding of controls over C and N transformations in Arctic soils. Mechanistic studies of these issues are needed to improve our ability to model the response of Arctic ecosystems to global change.\n",
      "  - Atmospheric measurements and land‐based inventories imply that terrestrial ecosystems in the northern hemisphere are taking up significant amounts of anthropogenic cabon dioxide (CO2) emissions; however, there is considerable disagreement about the causes of this uptake, and its expected future trajectory. In this paper, we use the ecosystem demography (ED) model to quantify the contributions of disturbance history, CO2 fertilization and climate variability to the past, current, and future terrestrial carbon fluxes in the Eastern United States. The simulations indicate that forest regrowth following agricultural abandonment accounts for uptake of 0.11 Pg C yr−1 in the 1980s and 0.15 Pg C yr−1 in the 1990s, and regrowth following forest harvesting accounts for an additional 0.1 Pg C yr−1 of uptake during both these decades. The addition of CO2 fertilization into the model simulations increases carbon uptake rates to 0.38 Pg C yr−1 in the 1980s and 0.47 Pg C yr−1 in the 1990s. Comparisons of predicted aboveground carbon uptake to regional‐scale forest inventory measurements indicate that the model's predictions in the absence of CO2 fertilization are 14% lower than observed, while in the presence of CO2 fertilization, predicted uptake rates are 28% larger than observed. Comparable results are obtained from comparisons of predicted total Net Ecosystem Productivity to the carbon fluxes observed at the Harvard Forest flux tower site and in model simulations free‐air CO2 enrichment (FACE) experiments. These results imply that disturbance history is the principal mechanism responsible for current carbon uptake in the Eastern United States, and that conventional biogeochemical formulations of plant growth overestimate the response of plants to rising CO2 levels. Model projections out to 2100 imply that the carbon uptake arising from forest regrowth will increasingly be dominated by forest regrowth following harvesting. Consequently, actual carbon storage declines to near zero by the end of the 21st century as the forest regrowth that has occurred since agricultural abandonment comes into equilibrium with the landscape's new disturbance regime. Incorporating interannual climate variability into the model simulations gives rise to large interannual variation in regional carbon fluxes, indicating that long‐term measurements are necessary to detect the signature of processes that give rise to long‐term uptake and storage.\n",
      "  - . Drought is predicted to increase in the future due to climate change, bringing with it myriad impacts on ecosystems. Plants respond to drier soils by reducing stomatal conductance in order to conserve water and avoid hydraulic damage. Despite the importance of plant drought responses for the global carbon cycle and local and regional climate feedbacks, land surface models are unable to capture observed plant responses to soil moisture stress. We assessed the impact of soil moisture stress on simulated gross primary productivity (GPP) and latent energy flux (LE) in the Joint UK Land Environment Simulator (JULES) vn4.9 on seasonal and annual timescales and evaluated 10 different representations of soil moisture stress in the model. For the default configuration, GPP was more realistic in temperate biome sites than in the tropics or high-latitude (cold-region) sites, while LE was best simulated in temperate and high-latitude (cold) sites. Errors that were not due to soil moisture stress, possibly linked to phenology, contributed to model biases for GPP in tropical savanna and deciduous forest sites. We found that three alternative approaches to calculating soil moisture stress produced more realistic results than the default parameterization for most biomes and climates. All of these involved increasing the number of soil layers from 4 to 14 and the soil depth from 3.0 to 10.8 m. In addition, we found improvements when soil matric potential replaced volumetric water content in the stress equation (the “soil14_psi” experiments), when the critical threshold value for inducing soil moisture stress was reduced (“soil14_p0”), and when plants were able to access soil moisture in deeper soil layers (“soil14_dr*2”). For LE, the biases were highest in the default configuration in temperate mixed forests, with overestimation occurring during most of the year. At these sites, reducing soil moisture stress (with the new parameterizations mentioned above) increased LE and increased model biases but improved the simulated seasonal cycle and brought the monthly variance closer to the measured variance of LE. Further evaluation of the reason for the high bias in LE at many of the sites would enable improvements in both carbon and energy fluxes with new parameterizations for soil moisture stress. Increasing the soil depth and plant access to deep soil moisture improved many aspects of the simulations, and we recommend these settings in future work using JULES or as a general way to improve land surface carbon and water fluxes in other models. In addition, using soil matric potential presents the opportunity to include plant functional type-specific parameters to further improve modeled fluxes.\n",
      "--------------------------------------------------\n",
      "Topic 188: 188_arctic_niño_el niño_el\n",
      "Representative Documents:\n",
      "  - El Niño events exhibit rich diversity in their spatial patterns, which can lead to distinct global impacts. Therefore, how El Niño pattern diversity will change in a warmer climate is one of the most critical issues for future climate projections. Based on the sixth Coupled Model Intercomparison Project simulations, we report an inter-model consensus on future El Niño diversity changes. Central Pacific (CP) El Niño events are projected to occur more frequently compared to eastern Pacific (EP) El Niño events. Concurrently, EP El Niño events are projected to increase in amplitude, leading to higher chances of extreme EP El Niño occurrences. We suggest that enhanced upper-ocean stability due to greenhouse warming can lead to a stronger surface-layer response for increasing positive feedbacks, more favorable excitation of CP El Niño. Whereas, enhanced nonlinear atmospheric responses to EP sea surface temperatures can lead to a higher probability of extreme EP El Niño.\n",
      "  -  Great effort is made to address heat waves (HWs) in developed countries because of their devastating impacts on society, economy, and environment. However, HWs are still understudied over developing countries. This is particularly true in West Africa, and especially in the Sahel, where temperatures recurrently reach critical values, such as during the 2010 HW event in the western Sahel. This work aims at characterizing the Sahelian HWs during boreal spring seasons (April–May–June) and understanding the mechanisms associated with such extreme events. Over the last three decades, Sahelian HWs have been becoming more frequent, lasting longer, covering larger areas, and reaching higher intensities. The physical mechanisms associated with HWs are examined to assess the respective roles of atmospheric dynamics and radiative and turbulent fluxes by analyzing the surface energy budget. Results suggest that the greenhouse effect of water vapor is the main driver of HWs in the western Sahel, increasing minimum temperatures by enhanced downward longwave radiation. Atmospheric circulation plays an important role in sustaining these warm anomalies by advecting moisture from the Atlantic Ocean and the Guinean coasts into the Sahel. Maximum temperature anomalies are mostly explained by increased downward shortwave radiation due to a reduction in cloud cover. Interannual variability of HWs is affected by the delayed impact of El Niño–Southern Oscillation (ENSO), with anomalous temperature warming following warm ENSO events, resulting from an amplified water vapor feedback. \n",
      "  - By means of a 21-year simulation of a coupled regional pan-Arctic atmosphere-ocean-ice model for the 1980's and 1990's and comparison of the model results with SSM/I satellite-derived sea-ice concentrations, the patterns of maximum amplitude of interannual variability of the Arctic summer sea-ice cover are revealed. They are shown to concentrate beyond an area enclosed by an isopleth of barotropic planetary potential vorticity that marks the edge of the cyclonic rim current around the deep inner Arctic basin. It is argued that the propagation of the interannual variability signal farther into the inner Arctic basin is hindered by the dynamic isolation of upper Arctic Ocean and the high summer cloudiness usually appearing in the central Arctic. The thinning of the Arctic sea-ice cover in recent years is likely to be jointly responsible for its exceptionally strong decrease in summer 2007 when sea-ice decline was favored by anomalously high atmospheric pressure over the western Arctic Ocean, which can be regarded as a typical feature for years with low sea-ice extent. In addition, unusually low cloud cover appeared in summer 2007, which led to substantial warming of the upper ocean. It is hypothesized that the coincidence of several favorable factors for low sea-ice extent is responsible for this extreme event. Owing to the important role of internal climate variability in the recent decline of sea ice, a temporal return to previous conditions or stabilization at the current level can not be excluded just as further decline.\n",
      "--------------------------------------------------\n",
      "Topic 189: 189_strain_strains_isolates_isolated\n",
      "Representative Documents:\n",
      "  - A Gram-stain-negative, rod-shaped, bright-orange coloured bacterium without flagellum, designated as strain GRR-S6-50T, was isolated from a tidal flat of Garorim bay, Taean-gun, Chungcheongbuk-do, Republic of Korea. Cells grew aerobically at 20–37 °C (optimum, 30 °C), pH 7.0–10.0 (optimum, pH 7.0) and with 1–5 % (w/v) NaCl (optimum, 3 %). The 16S rRNA gene sequence analysis demonstrated that strain GRR-S6-50T was closely related to                                              Sphingomicrobium aestuariivivum                                        AH-M8T with a sequence similarity of 97.80 % followed by                                              Sphingomicrobium astaxanthinifaciens                                        CC-AMO-30BT (97.44 %),                                              Sphingomicrobium marinum                                        CC- AMZ-30MT (97.16 %),                                              Sphingomicrobium arenosum                                        CAU 1457T (96.37 %),                                              Sphingomicrobium flavum                                        CC-AMZ-30NT (95.31 %) and                                              Sphingomicrobium lutaoense                                        CC-TBT-3T (95.23 %). The average nucleotide identity and digital DNA–DNA hybridization values with related strains ranged from 74.5 to 77.3% and 21.1 to 35.0 %, respectively. The G+C content of strain GRR-S6-50T was 63.30 mol%. The strain has ubiquinone-10 as the predominant respiratory quinone and the major fatty acids were C18 : 3                   ω6c (54.57 %) and C17 : 1                   ω6c (10.58 %). The polar lipids consisted of phosphatidylethanolamine, phosphatidylglycerol, three unidentified lipids and one glycolipid. On the basis of the results of phylogenetic, phenotypic and chemotaxonomic studies, strain GRR-S6-50T is regarded to represent a novel species within the genus                                              Sphingomicrobium                                       , for which the name Sphingomicrobium sediminis sp. nov. (KACC 22562T=KCTC 92123T=JCM 35084T) is proposed.\n",
      "  - Some species of the genus                                              Clostridium                                        are efficient acetate producers and have been deemed useful for upgrading industrial biogas. An acetogenic, strictly anaerobic, Gram-stain-positive, subterminal endospore-forming bacterium designated strain PL3T was isolated from peatland soil enrichments with H2 and CO2. Cells of strain PL3T were 0.8–1.0×4.0–10.0 µm in size and rod-shaped. Growth of strain PL3T occurred at pH 6.0–7.5 (optimum, pH 7.0), at 20–40 °C (optimum, 30 °C) and with 0–1.5 % (w/v) NaCl (optimum, 0.5%). Biochemical analyses revealed that strain PL3T metabolized lactose, maltose, raffinose, rhamnose, lactic acid, sorbitol, arabinose and glycerol. Acetic acid was the predominant metabolite under anaerobic respiration with H2/CO2. The major cellular fatty acids were C16 : 0, C16 : 1                   cis 9 and C17 : 0 cyc. The main polar lipids were diphosphatidylglycerol, phosphatidylethanolamine, aminolipid and aminophospholipid. Phylogenetic analysis based on 16S rRNA gene sequences showed that strain PL3T belongs to the genus                                              Clostridium                                        with the highest sequence similarity to                                              Clostridium aciditolerans                                        DSM 17425T (98.6 %) followed by                                              Clostridium nitrophenolicum                                        (97.8 %). The genomic DNA G+C content of strain PL3T was 31.1 mol%.The genomic in silico DNA–DNA hybridization value between strain PL3T and                                              C. aciditolerans                                        DSM 17425T was 25.1 %, with an average nucleotide identity of 80.2 %. Based on phenotypic, chemotaxonomic and phylogenetic differences, strain PL3T was suggested to represent a novel species of the genus                                              Clostridium                                       , for which the name Clostridium thailandense sp. nov. is proposed. The type strain is PL3T (=DSM 111812T=TISTR 2984T).\n",
      "  - A novel Gram-stain-negative, rod-shaped, cream-coloured, motile, halotolerant bacterium, designated as YJPS3-2T, was isolated from saltern sediment of the Yellow sea in Yongyu-do, Republic of Korea. Strain YJPS3-2T grew at pH 5.0–10.0 (optimum, pH 7.0), 4–40 °C (optimum, 30 °C) and with 1–15% (w/v) NaCl (optimum 3 %). The 16S rRNA gene sequence analysis indicated that strain YJPS3-2T was closely related to those of                                              Halomonas halophila                                        F5-7T (98.75 %),                                              Halomonas salina                                        F8-11T (98.74 %),                                              Halomonas smyrnensis                                        AAD6T (98.66 %),                                              Halomonas organivorans                                        G-16.1T (98.34 %),                                              Halomonas koreensis                                        SS20T (97.98 %) and                                              Halomonas beimenensis                                        NTU-107T (96.93 %). The average nucleotide identity and digital DNA–DNA hybridization values between YJPS3-2T and related type strains were 86.9–91.6 % and 32.0–44.8 %. Strain YJPS3-2T was characterized as having Q-9 as the predominant respiratory quinone and the principal fatty acids (&gt;10 %) were C16 : 0 (31.4 %), C19 : 0                   ω8c cyclo (16.3 %), C17 : 0 cyclo (11.9 %) and C12 : 0 3-OH (10.4 %). The polar lipids consisted of phosphatidylcholine, diphosphatidylglycerol, phosphatidylethanolamine and phosphatidylglycerol. The DNA G+C content of strain YJPS3-2T is 68.1mol %. Based on the polyphasic taxonomic evidence presented in this study, YJPS3-2T should be classified as representing a novel species within the genus Halmonas, for which name Halomonas getboli is proposed, with the type strain YJPS3-2T (= KCTC 92124T=KACC 22561T=JCM 35085T).\n",
      "--------------------------------------------------\n",
      "Topic 190: 190_species_distribution_species distribution_land use\n",
      "Representative Documents:\n",
      "  - Questions:  How can SDMs be adopted as a tool for forest management planning? Based on presence‐absence data, which modelling techniques are appropriate to determine species potential distribution for forest management planning under climate change? Do species distribution models (SDMs) agree with expert knowledge about species distribution and species traits? How can forest researcher deal with distribution data of a species whose distribution is heavily affected by human impacts?Location:  Bavaria (Southern Germany).Methods:  We used SDMs based on the Second National Forest Inventory from 2002 (4 × 4 km grid) containing presence‐absence data of tree species to identify species environment relationships (‘Grinnellian niche’). As an example, the distribution of silver fir (Abies alba Mill.) was modelled. Site condition data of the plots were derived from solar radiation, climate and soil maps. Models applied were boosted regression trees (BRT) and generalised additive models (GAM). Model predictions were compared with an expert based evaluation of the potential natural vegetation and were run with a climate change scenario (WETTREG B1) to project future distribution of silver fir.Results:  Both models discriminated well between presence and absence of silver fir but underestimated the potential distribution. The BRT model was more sensitive to local site conditions in the present data, but the GAM showed more generality. The truncated response curves and high uncertainties of predictions at the edge of the site spectrum indicated a low data density and that the data did not cover the whole niche space of silver fir. As indicated by validation with expert knowledge, the model output approached potential distribution by optimizing true positive predictions. The classification of SDMs output into risk classes allowed model evaluation and interpretation. Predictions of GAM and BRT under the climate change scenario showed high accordance and therefore, low uncertainty. Finally, large areas of Bavaria are described to have a high risk of silver fir cultivation in future.Conclusions:  SDMs are especially interesting as a decision basis for forest management because some of the general limitations of static modelling approaches are not relevant in this context. Limitations of forest inventory data can be partially overcome by using information on the potential distribution of species. The transferability of the models to future scenarios strongly depends on the spectrum and range of the training data sets and the depicted functional relationships. In order to improve the models and reduce the uncertainties, we need to improve the soil data and cover the whole niche space of silver fir.\n",
      "  - AimMany rare species are dispersal‐limited; their colonization capacity can be impacted by land use and climate changes. Most ecological niche models predict the distribution of species under future climate and land use change scenarios without incorporating species‐specific dispersal abilities. Here we investigate the effect of climate and land use change on low vagile species accounting for their dispersal capacity and define accessible areas in the future.LocationEurope.TaxonSaproxylic beetles.MethodsWe used the current (2007–2012) occurrences of six endangered saproxylics to develop ecological niche models using current climate and land use conditions. We projected species distributions under four future climate and land use change scenarios to estimate their potential occurrences. Finally, accounting for species‐specific dispersal, we limited their distributions to accessible areas in 2040–2050.ResultsWithout accounting for dispersal abilities we found a strong and positive impact of climate change on the distribution of Cerambix cerdo, Cucujus cinnaberinus, Morimus funereus and Rosalia alpina and a positive effect of land use change on the distribution of Lucanus cervus and Osmoderma eremita. When species‐specific dispersal was included, we found a strong and positive impact of land use change on the distribution of all the species. In this case climate change had a lower but positive effect on the distribution of C. cerdo, C. cinnaberinus, L. cervus and R. alpina, and a negative effect on the distribution of O. eremita.Main conclusionWe found that climate change would promote the expansion of saproxylic beetles only in the unrealistic case of unlimited dispersal. Accounting for dispersal abilities, the expansion of our species would be mainly conditioned by the effect of land use change. Thus, we encourage researchers to combine climate and land use change with dispersal when projecting species distribution under future scenarios to accurately identify areas with fundamental species‐specific resources.\n",
      "  - ABSTRACTAim  Species ranges have adapted during the Holocene to altering climate conditions, but it remains unclear if species will be able to keep pace with recent and future climate change. The goal of our study is to assess the influence of changing macroclimate, competition and habitat connectivity on the migration rates of 14 tree species. We also compare the projections of range shifts from species distribution models (SDMs) that incorporate realistic migration rates with classical models that assume no or unlimited migration.Location  Europe.Methods  We calibrated SDMs with species abundance data from 5768 forest plots from ICP Forest Level 1 in relation to climate, topography, soil and land‐use data to predict current and future tree distributions. To predict future species ranges from these models, we applied three migration scenarios: no migration, unlimited migration and realistic migration. The migration rates for the SDMs incorporating realistic migration were estimated according to macroclimate, inter‐specific competition and habitat connectivity from simulation experiments with a spatially explicit process model (TreeMig). From these relationships, we then developed a migration cost surface to constrain the predicted distributions of the SDMs.Results  The distributions of early‐successional species during the 21st century predicted by SDMs that incorporate realistic migration matched quite well with the unlimited migration assumption (mean migration rate over Europe for A1fi/GRAS climate and land‐use change scenario 156.7 ± 79.1 m year−1 and for B1/SEDG 164.3 ± 84.2 m year−1). The predicted distributions of mid‐ to late‐successional species matched better with the no migration assumption (A1fi/GRAS, 15.2 ± 24.5 m year−1 and B1/SEDG, 16.0 ± 25.6 m year−1). Inter‐specific competition, which is higher under favourable growing conditions, reduced range shift velocity more than did adverse macroclimatic conditions (i.e. very cold or dry climate). Habitat fragmentation also led to considerable time lags in range shifts.Main conclusions  Migration rates depend on species traits, competition, spatial habitat configuration and climatic conditions. As a result, re‐adjustments of species ranges to climate and land‐use change are complex and very individualistic, yet still quite predictable. Early‐successional species track climate change almost instantaneously while mid‐ to late‐ successional species were predicted to migrate very slowly.\n",
      "--------------------------------------------------\n",
      "Topic 191: 191_gt lt_lt_gt_sub gt\n",
      "Representative Documents:\n",
      "  - Owing to its excellent photoactivity, good stability and low cost, TiO&lt;sub&gt;2&lt;/sub&gt; is one of the moststudied semiconductor materials to convert CO&lt;sub&gt;2&lt;/sub&gt; into useful chemicals, contributing to mitigate globalwarming. In this review, starting from the basic kinetic and thermodynamic principles of CO&lt;sub&gt;2&lt;/sub&gt; photoreduction,the focus is on the surface processes involved in its capture and subsequent reactivity onTiO&lt;sub&gt;2&lt;/sub&gt;. In particular, the role of different TiO&lt;sub&gt;2&lt;/sub&gt; morphologies, facets and surface heterostructures is discussed.The effect of relevant co-adsorbed molecules (e.g., H&lt;sub&gt;2&lt;/sub&gt;O) on the CO&lt;sub&gt;2&lt;/sub&gt; reaction pathways is alsoconsidered. Moreover, the coupling of TiO&lt;sub&gt;2&lt;/sub&gt; with graphene and metal nanoparticles to enhance the reactionrates is presented. A deeper understanding at the atomic level of these surface mechanismscould help the design of TiO&lt;sub&gt;2&lt;/sub&gt;-based photocatalysts with improved efficiency and selectivity.\n",
      "  - The gas huff-n-puff process has been widely employed in low permeability reservoir development practices. At present, the understanding of synergistic effects of different injection fluids and rock permeability is still limited and is worthy of in-depth investigation. Therefore, laboratory studies on oil recovery performance of supercritical CO&lt;sub&gt;2&lt;/sub&gt; (scCO&lt;sub&gt;2&lt;/sub&gt;) and N&lt;sub&gt;2&lt;/sub&gt; huff-n-puff processes in ultra-low (&amp;#60; 0.5 mD), extra-low (0.5-1 mD), and average-low permeability (1-10 mD) core samples were systematically investigated. More effective cycles could be achieved in the CO&lt;sub&gt;2&lt;/sub&gt; huff-n-puff process than in the N&lt;sub&gt;2&lt;/sub&gt; process. The CO&lt;sub&gt;2&lt;/sub&gt; huff-n-puff operation could produce 29.9&amp;#37; oil in the ultralow permeability core, which is obviously higher than 20.2&amp;#37; for N&lt;sub&gt;2&lt;/sub&gt;. With increasing core permeability, the oil recovery ratio for both the scCO&lt;sub&gt;2&lt;/sub&gt; and N&lt;sub&gt;2&lt;/sub&gt; huff-n-puff processes increases as well. Laboratory results show oil recovery ratios of 33.1&amp;#37; and 47.3&amp;#37; for the scCO&lt;sub&gt;2&lt;/sub&gt; process in 0.5 mD and 10 mD cores and 36.3&amp;#37; and 49.1&amp;#37; for the N&lt;sub&gt;2&lt;/sub&gt; process in 0.5 mD and 9.5 mD cores, respectively. Although the oil recovery rates for the N&lt;sub&gt;2&lt;/sub&gt; and CO&lt;sub&gt;2&lt;/sub&gt; huff-n-puff processes are close in the 0.5 mD and 10 mD cores, the effective oil extraction pressure for the scCO&lt;sub&gt;2&lt;/sub&gt; puff process is found to be 5&amp;#126;10 MPa, which is much higher than 0&amp;#126;2 MPa for the N&lt;sub&gt;2&lt;/sub&gt; puff process. The study's findings can help provide a better understanding of the oil extraction behaviors in the huff-n-puff process with different injection fluids as well as in different low permeability cores.\n",
      "  - In this work, different slit structures of coals (brown coal, bituminous coal, and anthracite coal) with various ranks are established at a molecular level. Based on the grand canonical Monte Carlo (GCMC) and molecular dynamics (MD) methods, the effects of coal rank on CO&lt;sub&gt;2&lt;/sub&gt;, CH&lt;sub&gt;4&lt;/sub&gt;, N&lt;sub&gt;2&lt;/sub&gt; and H&lt;sub&gt;2&lt;/sub&gt;O multi-component gases adsorption and diffusion in slit structures are investigated. The influence of coal rank on the swelling ratio caused by adsorption and diffusion in different slit structures is discussed for the first time. It is shown that the adsorption capacity of CO&lt;sub&gt;2&lt;/sub&gt;, CH&lt;sub&gt;4&lt;/sub&gt;, N&lt;sub&gt;2&lt;/sub&gt; and H&lt;sub&gt;2&lt;/sub&gt;O in different slit structures follows the order of H&lt;sub&gt;2&lt;/sub&gt;O &amp;#62; CO&lt;sub&gt;2&lt;/sub&gt; &amp;#62; CH&lt;sub&gt;4&lt;/sub&gt; &amp;#62; N&lt;sub&gt;2&lt;/sub&gt;, whereas the diffusion coefficient follows H&lt;sub&gt;2&lt;/sub&gt;O &amp;#60; CO&lt;sub&gt;2&lt;/sub&gt; &amp;#60; CH&lt;sub&gt;4&lt;/sub&gt; &amp;#60; N&lt;sub&gt;2&lt;/sub&gt;. With the growth of coal rank, the adsorption capacity and diffusion coefficients of CO&lt;sub&gt;2&lt;/sub&gt;, CH&lt;sub&gt;4&lt;/sub&gt;, N&lt;sub&gt;2&lt;/sub&gt; and H&lt;sub&gt;2&lt;/sub&gt;O increase, meanwhile, the adsorption selectivity coefficients of CH&lt;sub&gt;4&lt;/sub&gt;/CO&lt;sub&gt;2&lt;/sub&gt;, N&lt;sub&gt;2&lt;/sub&gt;/CH&lt;sub&gt;4&lt;/sub&gt;, and CO&lt;sub&gt;2&lt;/sub&gt;/H&lt;sub&gt;2&lt;/sub&gt;O rise, following the order of anthracite coal &amp;#62; bituminous coal &amp;#62; brown coal. In addition, both the adsorption and diffusion swelling ratio reduce with the decrease of coal rank. The present molecular investigation of competitive adsorption and diffusion characteristics of multi-component gases can provide theoretical basis for efficient exploitation of coalbed methane.\n",
      "--------------------------------------------------\n",
      "Topic 192: 192_trends_precipitation_series_annual\n",
      "Representative Documents:\n",
      "  - . We present time series of equilibrium-line altitude (ELA) measured from the end-of-summer snow line altitude computed using satellite images, for 43 glaciers in the western Alps over the 1984–2010 period. More than 120 satellite images acquired by Landsat, SPOT and ASTER were used. In parallel, changes in climate variables, summer cumulative positive degree days (CPDD) and winter precipitation, were analyzed over the same time period using 22 weather stations located inside and around the study area. Assuming a continuous linear trend over the study period: (1) the average ELA of the 43 glaciers increased by about 170 m; (2) summer CPDD increased by about 150 PDD at 3000 m a.s.l.; and (3) winter precipitation remained rather stationary. Summer CPDD showed homogeneous spatial and temporal variability; winter precipitation showed homogeneous temporal variability, but some stations showed a slightly different spatial pattern. Regarding ELAs, temporal variability between the 43 glaciers was also homogeneous, but spatially, glaciers in the southern part of the study area differed from glaciers in the northern part, mainly due to a different precipitation pattern. A sensitivity analysis of the ELAs to climate and morpho-topographic variables (elevation, aspect, latitude) highlighted the following: (1) the average ELA over the study period of each glacier is strongly controlled by morpho-topographic variables; and (2) the interannual variability of the ELA is strongly controlled by climate variables, with the observed increasing trend mainly driven by increasing temperatures, even if significant nonlinear, low-frequency fluctuations appear to be driven by winter precipitation anomalies. Finally, we used an expansion of Lliboutry's approach to reconstruct fluctuations in the ELA of any glacier of the study area with respect to morpho-topographic and climate variables, by quantifying their respective weight and the related uncertainties in a consistent manner within a hierarchical Bayesian framework. This method was tested and validated using the ELA measured on the satellite images.                    \n",
      "  - The Saudi Arabia (SA) climate varies greatly, depending on the geography and the season. According to K                                                  ppen and Geiger, the climates of SA is “desert climate”.  The analysis of the seasonal rainfall detects that spring and winter seasons have the highestrainfall incidence, respectively. Through the summer,small quantities of precipitation are observed, while autumn received more precipitation more than summer season considering the total annual rainfall. In all seasons, the SW area receives rainfall, with a maximum in spring, whereas in the summer season, the NE and NW areas receive very little quantities of precipitation. The Rub Al-Khali (the SE region) is almost totally dry. The maximum amount of annual rainfall does not always happen at the highest elevation. Therefore, the elevation is not the only factor in rainfall distribution.A great inter-annual change in the rainfall over the SA for the period (1978–2009) is observed. In addition, in the same period, a linear decreasing trend is found in the observed rainfall, whilst in the recent past (1994–2009) a statistically significant negative trend is observed. In the Southern part of the Arabian Peninsula (AP) and along the coast of the Red Sea, it is interesting to note that rainfall increased, whilst it decreased over most areas of SA during the 2000–2009 decade, compared to 1980–1989.Statistical and numerical models are used to predict rainfall over Saudi Arabia (SA). The statistical models based on stochastic models of ARIMA and numerical models based on Providing Regional Climates for Impact Studies of Hadley Centre (PRECIS). Climate and its qualitative character and quantified range of possible future changes are investigated. The annual total rainfall decreases in most regions of the SA and only increases in the south. The summertime precipitation will be the highest between other seasons over the southern, the southwestern provinces and Asir mountains, while the wintertime rainfall will remain the lowest.The climate in the SA is instructed by the El Niño Southern Oscillation (ENSO) and other circulations such as centers of high and low pressure, the North Atlantic Oscillation (NAO) and SOI. Strength and oscillation of subtropical jet stream play a big role in pulling hot, dry air masses of SA.\n",
      "  - The rainfall is essential to Brazil's hydrological cycle, agricultural development, and power generation, mainly Cerrado biome. Thus, the study assessed the influence of the El Niño–Southern Oscillation (ENSO) and synoptic systems on rainfall variability over the Brazilian Cerrado. To evaluate this variability, it used monthly rainfall data from the second version of the Climate Hazard Group InfraRed Precipitation with Station (CHIRPS) database (1981–2020), based on the annual densidrograms and thematic maps. In Annual terms, the average climatological was 1,417 mm·year−1. The highest precipitation values (&gt;1,500 mm·year−1) occurred at the boundaries between Cerrado and Amazon, mainly in the states of the Maranhão, Mato Grosso, and Tocantins due to physiography (&lt;500 m). The seasonal rainfall was more frequent in summer (on average, 48% of the annual total) distributed over the biome due to the South American monsoon system and South Atlantic convergence zone. The climatological dry period occurred between November and March (on average, 8% of the annual total) due to the Atmospheric Blocking called as Bolivia High that inhibit the passage of synoptic system transients in Central Brazil. In monthly terms, January (July) is the wetter month with 18% (drier month with 1%) of the annual total. The annual densidrograms appointed the following wetter (drier) years: 1985, 1989, and 2009 (1990, 1993, and 2012), influenced by ENSO events. The year 1985 appointed an increase of 19% in the mean annual rainfall, but in 1990 showed a reduction of 18% in climatology (1981–2020). In terms of seasonal anomalies, the summer of 1985 (1990) appointed an increase of 26% above (2.5% below) mean seasonal climatological, verified in the states of Maranhão, Piauí, and Tocantins (states of Mato Grosso). The La Niña (El Niño) events influenced positively (negatively) the annual rainfall anomalous pattern in Cerrado.HighlightsThe rainiest period occurs during September and April months (&gt;200 mm·month−1).The driest period occurs during May and August months (&lt;200 mm·month−1).1985 (1990) year presents the most significant (smallest) annual rainfall average.The border zone between Amazon and Cerrado presents the highest annual rainfall.\n",
      "--------------------------------------------------\n",
      "Topic 193: 193_root_leaf_warming_seedlings\n",
      "Representative Documents:\n",
      "  - The short‐term effects of two levels of air temperature (ambient and warmed) and light (full light and ca. 10% of full light regimes) on the early growth and physiology of Picea asperata and Abies faxoniana seedlings was determined using open‐top chambers (OTC). The OTC manipulation increased mean air temperature and soil surface temperature by 0.51°C and 0.34°C under the 60‐year plantation, and 0.69°C and 0.41°C under the forest opening, respectively. Warming, with either full‐light or low‐light conditions, generally caused a significant increase in plant growth, biomass accumulation, and stimulated photosynthetic performance of P. asperata seedlings. However, the warming of A. faxoniana seedlings only significantly increased their growth under low‐light conditions, possibly as a result of photoinhibition caused by full light, which may shield and/or impair the effects of warming manipulation, per se, on the growth and physiological performance of A. faxoniana seedlings. In response to warming, P. asperata seedlings allocated relatively more biomass to roots and A. faxoniana more to foliage under similar environments. This might provide A. faxoniana with an adaptive advantage when soil moisture was not limiting and an advantage to P. asperata if substantial moisture stress occurred. Warming markedly increased the efficiency of PSII in terms of the increase in Fv/Fm and photosynthetic pigment concentrations for the two conifer seedlings, but the effects of warming were generally more pronounced under low‐light conditions than under full‐light conditions. On balance, this study suggested that warming had a beneficial impact on the early growth and development of conifer seedlings, at least in the short term. Consequently, warming may lead to changes in forest regeneration dynamics and species composition for subalpine coniferous ecosystems under future climate change.\n",
      "  -                Extreme drought is one of the key climatic drivers of tree mortality on a global scale. However, it remains unclear whether the drought-induced tree mortality will increase under nocturnal climate warming. Here we exposed seedlings of two wide-ranging subtropical tree species, Castanopsis sclerophylla and Schima superba, with contrasting stomatal regulation strategies to prolonged drought under ambient and elevated night-time temperature by 2 °C. We quantified the seedling survival time since drought treatment by measuring multiple leaf traits such as leaf gas exchange, predawn leaf water potential and water-use efficiency. The results showed that all seedlings in the ambient temperature died within 180 days and 167 days of drought for C. sclerophylla and S. superba, respectively. Night warming significantly shortened the survival time of C. sclerophylla, by 31 days, and S. superba by 28 days, under the drought treatment. A survival analysis further showed that seedlings under night warming suffered a 1.6 times greater mortality risk than those under ambient temperature. Further analyses revealed that night warming suppressed net leaf carbon gain in both species by increasing the nocturnal respiratory rate of S. superba across the first 120 days of drought and decreasing the photosynthetic rate of both species generally after 46 days of drought. These effects on net carbon gain were more pronounced in S. superba than C. sclerophylla. After 60 days of drought, night warming decreased the predawn leaf water potential and leaf water-use efficiency of C. sclerophylla but not S. superba. These contrasting responses are partially due to variations in stomatal control between the two species. These findings suggest that stomatal traits can regulate the response of leaf gas exchange and plant water-use to nocturnal warming during drought. This study indicates that nocturnal warming can accelerate tree mortality during drought. Night warming accelerates the mortality of two subtropical seedlings under drought.Night warming differently affects the drought response of leaf gas exchange and plant water-use between the two species due to species-specific stomatal morphological traits.Carbon metabolism changes and hydraulic damage play differential roles in driving night-warming impacts on the drought-induced mortality between the two species.\n",
      "  -                The variation in fine root respiration with root age provides insight into root adaptation to climate warming, but the mechanism is poorly understood. In this study, we investigated the respiratory response of fine roots (&amp;lt;1 mm and 1–2 mm) of different ages (2-, 4- and 6-month old) of Chinese fir (Cunninghamia lanceolata (Lamb.)) seedlings to soil warming (4 °C above the control using cable heating). Fine roots were excised to measure the specific respiration rate at a reference temperature of 20 °C (SRR20), and root morphological and chemical traits were measured. Soil warming significantly increased SRR20 by 40% compared with the control, potentially indicating limited acclimation on a short time scale (6 months). However, soil warming increased SRR20 significantly in 2-month-old roots (by 72%) compared with 4- and 6-month-old roots, leading to a steeper decline in SRR20 with root age. This result suggests possible increased nutrient uptake efficiency in young fine roots under warmer temperatures. Soil warming significantly increased specific root length (SRL) but not root tissue nitrogen concentration (RTN). The variation in SRR20 between warming treatments, but not across root ages, was predicted by SRL and RTN individually or together. Our findings conclusively indicate that soil warming increased the respiration cost of young fine roots, which was predicted by adjusting for SRL and RTN, indicating that Chinese fir may adopt a faster fine root turnover strategy to enhance nutrient uptake and soil exploitation under warmer temperatures. Future studies should simultaneously investigate age-related root respiration and nutrient uptake in warming experiments to better understand the effects of warming on root metabolic activity.\n",
      "--------------------------------------------------\n",
      "Topic 194: 194_growth_trees_beech_tree\n",
      "Representative Documents:\n",
      "  - Key messageBeech and pine respond differently to climate change. June precipitation is of particular influence for beech, and February/March temperature for pine.Climate warming exposes forests to increasing abiotic stress, demanding for difficult silvicultural decisions about the right choice of future timber species. Scots pine (Pinus sylvestris) and European beech (Fagus sylvatica) are major timber species in the North German Lowlands, which have suffered from recent hot droughts, thus raising concern about their suitability for future production forests in the region. We investigated the climate sensitivity of tree growth and long-term growth trends of ten paired beech and pine forests along a precipitation gradient in the North German Lowlands with the aim to compare the species’ climate sensitivity and to search for species-specific climatic thresholds. In the majority of beech stands, basal area increment (BAI) has lost its positive trend since the 1980s or growth declined since then, while the BAI of pine has continually increased. Long-term change in June precipitation is in the study region a more important determinant of beech growth trends than the amount of MAP, while pine growth is largely dependent on the warmth of February/March. Yet, pine growth is also sensitive to dry mid summers, with sensitivity increasing toward low MAP. Climate sensitivity of growth has significantly declined since the 1980s in beech, while the dominant drought signal of June persisted in pine. We conclude that recent climate change is affecting radial growth of beech and pine differently with both species revealing signs of vulnerability to hot droughts, suggesting for the drier part of the study region the preference of more drought-tolerant hardwood timber species over beech and pine.\n",
      "  - AimClimatic changes affect the growth dynamics of temperate trees, but these effects might differ between co‐occurring ring‐ and diffuse‐porous species as well as between mesic and xeric rear‐edge populations. We explore whether recent climate warming has increased the climate sensitivity and within‐stand synchrony of growth in these groups differently.LocationThe natural beech–oak ecotone in Western Romania at the dry margin of beech occurrence.TaxaThree ring‐porous oak species (Quercus petraea, Q. frainetto and Q. cerris), and diffuse‐porous European beech (Fagus sylvatica) and silver linden (Tilia tomentosa).MethodsWe correlated tree‐ring records with monthly and seasonal climate data (period 1940–2017). Regional growth synchrony was assessed through the analysis of inter‐series correlation of growth within populations and among populations using mixed models.ResultsIn all five species including two south‐east European oak taxa and silver linden, water availability in summer was the most important climatic determinant of radial growth. This factor has gained in importance since the onset of rapid warming after 1980, while the impact of other climate factors in spring and summer has decreased. Within‐population growth synchrony as a measure of overall climatic stress has increased, or remained stable, since 1980 in beech and silver linden, but has decreased in the oak species, matching declining growth trends in beech and linden and increasing (or stable) trends in the oaks.Main ConclusionsThe patterns of growth synchrony provide valuable information on tree species' drought susceptibility in efforts to select suitable tree species for climate change‐adapted forestry. The climate vulnerability of beech is higher than that of the more drought‐resistant oak species due to its marked summer‐drought sensitivity of growth.\n",
      "  - Systematic forest networks of health monitoring have been established to follow changes in tree vigor and mortality. These networks often lack long-term growth data, but they could be complemented with tree ring data, since both defoliation and radial growth are proxies of changes in tree vigor. For instance, a severe water shortage should reduce growth and increase tree defoliation in drought-prone areas. However, the effects of climatic stress and drought on growth and defoliation could also depend on tree age. To address these issues, we compared growth and defoliation data with recent climate variability and drought severity in Abies pinsapo old and young trees sampled in Southern Spain, where a systematic health network (Andalucía Permanent Plot Network) was established. Our aims were: (i) to assess the growth sensitivity of old and young A. pinsapo trees and (ii) to test if relative changes in radial growth were related with recent defoliation, for instance, after severe droughts. We also computed the resilience indices to quantify how old and young trees recovered growth after recent droughts. Wet-cool conditions during the prior autumn and the current early summer improved the growth of old trees, whereas late-spring wet conditions enhanced the growth of young trees. Old trees were more sensitive to wet and sunny conditions in the early summer than young trees. Old and young trees were more responsive to the Standardized Precipitation-Evapotranspiration Index drought index of June–July and July–August calculated at short (one–three months) and mid (three–six months) time scales, respectively. Old trees presented a higher resistance to a severe drought in 1995 than young trees. A positive association was found between stand defoliation and relative growth. Combining monitoring and tree ring networks is useful for the detection of early warning signals of dieback in similar drought-prone forests.\n",
      "--------------------------------------------------\n",
      "Topic 195: 195_hydrogen_production_energy_co2 emissions\n",
      "Representative Documents:\n",
      "  - The greatest lever for advancing climate adaptation and mitigation is the defossilization of energy systems. A key opportunity to replace fossil fuels across sectors is the use of renewable hydrogen. In this context, the main political and social push is currently on climate neutral hydrogen (H2) production through electrolysis using renewable electricity. Another climate neutral possibility that has recently gained importance is biohydrogen production from biogenic residual and waste materials. This paper introduces for the first time a novel concept for the production of hydrogen with net negative emissions. The derived concept combines biohydrogen production using biotechnological or thermochemical processes with carbon dioxide (CO2) capture and storage. Various process combinations referred to this basic approach are defined as HyBECCS (Hydrogen Bioenergy with Carbon Capture and Storage) and described in this paper. The technical principles and resulting advantages of the novel concept are systematically derived and compared with other Negative Emission Technologies (NET). These include the high concentration and purity of the CO2 to be captured compared to Direct Air Carbon Capture (DAC) and Post-combustion Carbon Capture (PCC) as well as the emission-free use of hydrogen resulting in a higher possible CO2 capture rate compared to hydrocarbon-based biofuels generated with Bioenergy with Carbon Capture and Storage (BECCS) technologies. Further, the role of carbon-negative hydrogen in future energy systems is analyzed, taking into account key societal and technological drivers against the background of climate adaptation and mitigation. For this purpose, taking the example of the Federal Republic of Germany, the ecological impacts are estimated, and an economic assessment is made. For the production and use of carbon-negative hydrogen, a saving potential of 8.49–17.06 MtCO2,eq/a is estimated for the year 2030 in Germany. The production costs for carbon-negative hydrogen would have to be below 4.30 € per kg in a worst-case scenario and below 10.44 € in a best-case scenario in order to be competitive in Germany, taking into account hydrogen market forecasts.\n",
      "  - This paper shows the results of an in-depth techno-economic analysis of the public transport sector in a small to midsize city and its surrounding area. Public battery-electric and hydrogen fuel cell buses are comparatively evaluated by means of a total cost of ownership (TCO) model building on historical data and a projection of market prices. Additionally, a structural analysis of the public transport system of a specific city is performed, assessing best fitting bus lines for the use of electric or hydrogen busses, which is supported by a brief acceptance evaluation of the local citizens. The TCO results for electric buses show a strong cost decrease until the year 2030, reaching 23.5% lower TCOs compared to the conventional diesel bus. The optimal electric bus charging system will be the opportunity (pantograph) charging infrastructure. However, the opportunity charging method is applicable under the assumption that several buses share the same station and there is a “hotspot” where as many as possible bus lines converge. In the case of electric buses for the year 2020, the parameter which influenced the most on the TCO was the battery cost, opposite to the year 2030 in where the bus body cost and fuel cost parameters are the ones that dominate the TCO, due to the learning rate of the batteries. For H2 buses, finding a hotspot is not crucial because they have a similar range to the diesel ones as well as a similar refueling time. H2 buses until 2030 still have 15.4% higher TCO than the diesel bus system. Considering the benefits of a hypothetical scaling-up effect of hydrogen infrastructures in the region, the hydrogen cost could drop to 5 €/kg. In this case, the overall TCO of the hydrogen solution would drop to a slightly lower TCO than the diesel solution in 2030. Therefore, hydrogen buses can be competitive in small to midsize cities, even with limited routes. For hydrogen buses, the bus body and fuel cost make up a large part of the TCO. Reducing the fuel cost will be an important aspect to reduce the total TCO of the hydrogen bus.\n",
      "  - This work includes calculations of the cumulative CO2 emissions of two comparable cars—the VW Golf VII—one with a combustion engine and the other with an electric motor. Calculation of CO2 emissions was performed, taking into account the stages of production, utilization and use of the above-mentioned vehicles. For the use phase, it was assumed that the total mileage of the car will be 150,000 km over 10 years. For the electric vehicle, calculations were made assuming five different sources of electricity (from coal only, from natural gas only, from PV and wind turbines, an average mix of European power sources and an average mix of Polish power sources; W1–W5 designations, respectively). For individual sources of electricity, cumulative CO2 emissions were taken into account, that is, resulting both from the production of electricity and the use of the resources (for example, technical service per 1 kWh of electricity produced). The obtained results of the analysis show that for the adopted assumptions regarding operation, for variants W2–W5, the use of an electric car results in lower cumulative CO2 emission than a the use of a combustion car. For a combustion car, the value was 37,000 kg-CO2, and for an electric car, depending on the variant, the value was 43, 31, 16, 23 and 34 thousand kg-CO2 for variants W1 to W5, respectively. Based on the emissions results obtained for individual stages of the use of selected vehicles, a comparative analysis of cumulative CO2 emissions was performed. The purpose of this analysis was to determine whether the replacement of an existing combustion car (that has already been manufactured; therefore, this part of the analysis does not include CO2 emissions in the production stage) with a new electric car, which has to be manufactured, therefore associated with additional CO2 emissions, would reduce cumulative CO2 emissions. Considering three adopted average annual car mileages (3000, 7500 and 15,000 km) and the previously described power options (W1–W5), we sought an answer as to whether the use of a new electric car would be burdened with lower cumulative CO2 emissions. In this case we assumed an analysis time of 15 years. For the worst variant from the point of view of CO2 emissions (W1, electricity from coal power sources only), further use of a combustion car is associated with lower cumulative CO2 emissions than the purchase of a new electric car over the entire analyzed period of 15 years. In turn, for the most advantageous variant (W3, electricity from PV or wind power sources) with an annual mileage of 3000 km, the purchase of a new electric car results in higher cumulative CO2 emissions throughout the analyzed period, whereas for an annual milage of 7500 or 15,000 km, replacing the car with an electric car “pays back” in terms of cumulative CO2 emissions after 8.5 or 4 years, respectively.\n",
      "--------------------------------------------------\n",
      "Topic 196: 196_water_groundwater_water resources_supplies\n",
      "Representative Documents:\n",
      "  - This article addresses the future of freshwater resources in the Palestinian West Bank through a discussion of contemporary issues that each plays a vital role in determining the long‐term sustainability of freshwater reserves, such as water resource availability, trans‐boundary water issues, water reuse and conservation, changes in land use, and the potential impact of climate change on long‐term water management. Climate change and changing land use patterns are already altering this region's water resources. Future predictions regarding the long‐term effects of these changes are complex and therefore inherently uncertain. However, the consensus among most studies on this subject indicates that currently water‐poor regions such as the Middle East will experience even greater water stress in the future. Nearly all of the freshwater consumed in the West Bank is obtained from local groundwater supplies that are suffering overdraft as well as decreasing water quality. Climate change will exacerbate water stress by increasing overall temperatures, decreasing and fluctuating precipitation, and reducing overall aquifer replenishment. Expanding urbanization will continue to strain freshwater supplies by negatively impacting the quality and quantity of available freshwater. Water management in the West Bank is further complicated by total Israeli control over water resources, which often causes water delivery to Palestinians in this region to be marginalized. This article finds that Palestinian and Israeli water managers must plan for future water crises, which will likely be a result of the combined effects of increasing urbanization and climate change coupled with exponential population growth.\n",
      "  - The current Southwest drought is exceptional for its high temperatures and arguably the most severe in history. Coincidentally, there has been an increase in forest and woodland mortality due to fires and pathogenic outbreaks. Although the high temperatures and aridity are consistent with projected impacts of greenhouse warming, it is unclear whether the drought can be attributed to increased greenhouse gasses or is a product of natural climatic variability. Climate models indicate that the 21st century will be increasingly arid and droughts more severe and prolonged. Forest and woodland mortality due to fires and pathogens will increase. Demography and food security dictate that water demand in the Southwest will remain appreciable. If projected population growth is twinned with suburb-centered development, domestic demands will intensify. Meeting domestic demands through transference from agriculture presents concerns for rural sustainability and food security. Environmental concerns will limit additional transference from rivers. It is unlikely that traditional supply-side solutions such as more dams will securely meet demands at current per-capita levels. Significant savings in domestic usage can be realized through decreased applications of potable water to landscaping, but this is a small fraction of total regional water use, which is dominated by agriculture. Technical innovations, policy measures, and market-based solutions that increase supply and decrease water demand are all needed. Meeting 21st-century sustainability challenges in the Southwest will also require planning, cooperation, and integration that surpass 20th-century efforts in terms of geographic scope, jurisdictional breadth, multisectoral engagement, and the length of planning timelines.\n",
      "  -                Florida has been described as ‘ground zero’ for climate change in the United States with coastal communities vulnerable to sea-level rise and water supplies under threat from saline-water intrusion, changes in precipitation amounts and patterns, and temperature-driven increases in demands. Water utilities and regional suppliers are responsible for their own water supply plans and adaptation strategies, which are developed largely by a relatively small group of technical specialists (internal and contracted). Water supply planning is prescribed by the state water governance system and local community planning processes. The degree of engagement of large coastal communities and water utilities and regional water suppliers in Florida with climate change research is generally high. Climate change-induced impacts to water supplies and demands over the common 20-year planning horizon are likely to be small relative to increases in demand caused by projected on-going population growth and normal climatic variation. Water utilities in Florida have been incidentally moving toward more climate-resilient supplies (e.g., brackish groundwater desalination) due to the unavailability of additional permittable, inexpensive fresh groundwater rather than climate change concerns. Climate change will narrow the alternatives for future water-supply development.\n",
      "--------------------------------------------------\n",
      "Topic 197: 197_co2 emissions_construction_emissions_concrete\n",
      "Representative Documents:\n",
      "  - To comply with recent international trends and initiatives, and in order to help achieve sustainable development, Korea has established a greenhouse gas (GHG) emission reduction target of 37% (851 million tons) of the business as usual (BAU) rate by 2030. Regarding environmentally-oriented standards such as the IGCC (International Green Construction Code), there are also rising demands for the assessment on CO2 emissions during the life cycle in accordance with ISO (International Standardization Organization’s Standard) 14040. At present, precast concrete (PC) engineering-related studies primarily cover structural and construction aspects, including improvement of structural performance in the joint, introduction of pre-stressed concrete and development of half PC. In the manufacture of PC, steam curing is mostly used for the early-strength development of concrete. In steam curing, a large amount of CO2 is produced, causing an environmental problem. Therefore, this study proposes a method to assess CO2 emissions (including absorption) throughout the PC life cycle by using a life cycle assessment (LCA) method. Using the proposed assessment method, CO2 emissions during the life cycle of a precast concrete girder (PCG) were assessed. In addition, CO2 absorption was assessed against a PCG using conventional carbonation and CO2 absorption-related models. As a result, the CO2 emissions throughout the life cycle of the PCG were 1365.6 (kg-CO2/1 PCG). The CO2 emissions during the production of raw materials among the CO2 emissions throughout the life cycle of the PCG were 1390 (kg-CO2/1 PCG), accounting for a high portion to total CO2 emissions (nearly 90%). In contrast, the transportation and manufacture stages were 1% and 10%, respectively, having little effect on total CO2 emissions. Among the use of the PCG, CO2 absorption was mostly decided by the CO2 diffusion coefficient and the amount of CO2 absorption by cement paste. The CO2 absorption by carbonation throughout the service life of the PC was about 11% of the total CO2 emissions, which is about 16% of CO2 emissions from ordinary Portland cement (OPC) concrete.\n",
      "  - Recent research in the construction industry has focused on the reduction of CO2 emission using quantitative assessment of building life. However, most of this research has focused on the operational stage of a building’s life cycle. Few comprehensive studies of CO2 emissions during building construction have been performed. The purpose of this study is to analyze the CO2 emissions of an apartment housing during the construction process. The quantity of CO2 emissions associated with the utilization of selected building materials and construction equipment were used to estimate the CO2 emissions related to the apartment housing life cycle. In order to set the system boundary for the construction materials, equipment, and transportation used, 13 types of construction work were identified; then the CO2 emissions produced by the identified materials were calculated for each type of construction work. The comprehensive results showed that construction work involving reinforced concrete accounted for more than 73% of the total CO2 emissions. The CO2 emissions related to reinforced concrete work was mainly due to transportation from the supplier to the construction site. Therefore, at the time that reinforced concrete is being supplied, shipping distance and fuel economy management of concrete transportation vehicles should be considered thoroughly for significant reduction of CO2 emissions.\n",
      "  - In recent years, research to reduce CO2 emission through quantitative assessment of building life cycle CO2 emissions has been performed as it relates to the construction industry. However, most research efforts related to building CO2 emission assessment has been focused on evaluation during the operational stage of a building’s life cycle. Few comprehensive studies of the CO2 emissions during a building’s construction have been performed. The purpose of this study is an assessment method that quantitatively evaluates the CO2 emissions of buildings during the construction. This study analyzed the amount of CO2 emissions produced by 13 process of construction works. building materials, construction and transport equipment used for the selected process of construction works were identified, and CO2 emissions produced by the identified materials and equipment were calculated for these 13 process of construction works. The energy consumption of construction and transport equipment was calculated by analyzing fuel efficiency and equipment productivity rates. The combination of the expected levels of CO2 emissions associated with the utilization of building materials and construction equipment provides means for estimating the quantity of CO2 emissions related to the construction stage of a building’s life cycle. It comprehensively analysis result, main process of construction works, “Reinforced concrete work” accounting for more than 73% of the total CO2 emissions were deducted.\n",
      "--------------------------------------------------\n",
      "Topic 198: 198_scientists_eos_think_zimmerman\n",
      "Representative Documents:\n",
      "  - In a summary of their survey on the opinion about global warming among Earth scientists (see Eos, 90(3), 20 January 2009), Peter Doran and Maggie Kendall Zimmerman conclude that the debate on the role of human activity is largely nonexistent, and that the challenge is “how to effectively communicate this fact to policy makers” and to the public.However, I argue that neither of these conclusions can be drawn from the survey. For example, one issue that is much discussed in the public debate is the role of greenhouse gas emissions in global warming. Perhaps there is not much debate about this issue among scientists, but this cannot be concluded from the survey, in which nothing is said about such emissions. In the second question of their survey, Doran and Kendall Zimmerman refer only to “human activity.”\n",
      "  - The feature article “Examining the scientific consensus on climate change,” by Peter Doran and Maggie Kendall Zimmerman (see Eos, 90(3), 20 January 2009), while interesting, has a primary flaw that calls their interpretation into question. In their opening sentence, the authors state that on the basis of polling data, “47% [of Americans] think climate scientists agree… that human activities are a major cause of that [global] warming….” They then described the two‐question survey they had posed to a large group of Earth scientists and scientifically literate (I presume) people in related fields. While the polled group is important, in any poll the questions are critical. My point revolves around their question 2, to wit, “Do you think human activity is a significant contributing factor in changing mean global temperatures?” Note that the opening sentence of their article uses the phrase “major cause” in reporting the results of the polling, while the poll itself used the phrase “significant contributing factor.” There is a large difference between these two phrases.\n",
      "  - In his Forum, Kenneth Verosub (Eos, 91(33), 291, doi:10.1029/2010EO330003, 2010) tries to explain the climate denial phenomenon as due to postmodernist misinterpretation of scientific results. Unfortunately, I fear that this is only a minor cause and that the true explanation is much more insidious, with serious ramifications for all scientists, not just climatologists. As documented in several recent publications [e.g., Mayer, 2010], climate scientists are currently bearing the brunt of a deliberate, antiscience, misinformation campaign that is financed by certain fossil fuel companies and propagated by certain conservative radio programs, television organizations, and think tanks. Verosub wonders why no one has offered an explanation for why scientists worldwide are engaged in this supposed hoax. But explanations are frequently offered on conservative talk shows. For example, I found myself listening to The War Room With Quinn and Rose last fall while driving in the Pittsburgh, Pa., area and was appalled by the scenario painted in the show by cohost Jim Quinn. Apparently, all academics are socialists. Further, the Earth is not warming—it has been getting cooler since 1999. Quinn continued with this gem: Climate warming is an international conspiracy, funded by billionaire George Soros, perpetrated by scientists everywhere, and intended to delude governments into spending vast sums of money to counter a non‐existent threat until the governments become bankrupt. Then in the ensuing chaos, socialists can take over and form a world socialist government.\n",
      "--------------------------------------------------\n",
      "Topic 199: 199_wave_breakwater_offshore_waves\n",
      "Representative Documents:\n",
      "  -  With the advancement of oil &amp; gas into ultra deepwater, the need for drilling and production platforms has becomes more acute. The dry tree semisubmersible can be used for direct vertical access into reservoirs from deepwater since it offers small in-place motions, large open deck areas, dockside commissioning and minimum offshore hookup. The direct access allows the operator to drill, complete and work over the well directly from the same platform. The drytree semisubmersible consists of a keel tank which can be telescoped up and down based on the requirement of the platform. The keel tank is fully telescoped down while in operating condition and telescoped up while in transportation condition. The transportation analysis of a drytree semisubmersible using the linear radiation, diffraction panel program WAMIT is presented in this paper. Parametric studies were carried out in WAMIT by varying the size of the keel tank by considering the keel tank size as 80X80m, 91.5X91.5m and 100X100m. The Case 2 in which the keel tank dimensions were 91.5×91.5 m was found to be most appropriate of all, as the response for it was lower compared to other cases and also the structure was good from stability point of view. It was found that the heave and response were high only beyond 15 seconds wave period thus making transportation operations safe, as transportation is carried out in sea states 5 and 6 which have wave periods less than 14 seconds. Also the pitch RAO was found to be very low thus posing no threat in transportation mode. \n",
      "  -  Slender cylindrical members form the major components of many of the coastal and offshore structures. These members are frequently subjected to breaking wave impact which often resulted in damages and failure of structures. In order to overcome this intricacy, it is essential to understand the physics of the breaking wave impact on offshore structural members and the resulting induced critical stresses. An experimental investigation has been carried out to measure the effect of breaking wave impact on a slender vertical cylinder. Simultaneous qualitative visual observations and quantitative pressure measurements were made to appreciate the impact induced effect. The induced impact pressure on the cylinder varies with the intensity of wave breaking and the relative location of the cylinder. The impact pressure is maximum when the wave profile reaches its maximum steepness just before the crest destabilization. Impact pressure observed due to a severe plunging wave is about nine times higher than due to spilling. The pressure rise time is found to be an important parameter in dictating the nature of impact. \n",
      "  -  Many of the coastal and offshore structures consist of slender cylindrical member as the fundamental component. Since the structural damages and failures are catastrophic under wave impact, it is essential to understand the influence of breaking wave impact on the structural members. Past literature dictates that the magnitude of impact pressures is of the order of ten times more than the non breaking wave induced pressure. The standard codal provisions for the structural design of those members under breaking wave impact are scarce. In the present study, an experimental investigation has been carried out to measure the response of the slender vertical cylinder under breaking waves. Acceleration measurements were made under the incidence of breaking waves of different intensities varying from Plunging to Spilling. Deflections are found out from the measured acceleration. The maximum acceleration observed under severe plunging event is 0.5 times that of moderate plunging event, the deflection induced by the moderate plunging is two order higher than that of severe plunging. Acceleration is maximum not only above still water level (SWL) but also lies in the impact zone. Hence moderate plunging events with higher impulse and larger pressure rise time is crucial in the design of offshore and coastal structural member under breaking wave impact load. \n",
      "--------------------------------------------------\n",
      "Topic 200: 200_vegetation_greening_qtp_evi\n",
      "Representative Documents:\n",
      "  - Rapid global vegetation greening has been observed for the past two decades, but its implications to the hydrological cycle are not well understood in many regions, including the Yangtze River Basin (YRB). This study used a remote sensing‐driven ecosystem model, the Coupled Carbon and Water model, to fully examine the individual and combined hydrological effects of vegetation and climate changes through a series of modeling experiments. During the study period (2001–2018), the vegetation showed a significant greening trend with the mean annual normalized difference vegetation index increasing at a rate of 0.4% per year (p &lt; 0.001). In contrast, climate exhibited a marginal wetting trend with annual precipitation increasing at a rate of 6.7 mm/yr (p = 0.08). Annual evapotranspiration (ET) in the YRB significantly increased (3.1 mm/yr,p = 0.01) primarily due to enhanced ecosystem productivity associated with vegetation greening, rather than climatic factors. However, the enhancement in ET did not lead to a significant decline in total water yield at the YRB scale. The large inter‐annual variability of precipitation masked the effects of vegetation greening on water yield. Overall, our study indicated that the recent land “greening up” has accelerated the regional hydrological cycle through increasing ET and resulted in enhanced risks of water resource shortage. Our findings highlighted the close connection between land cover dynamics and hydrological cycle under climate variability in one of the world’s largest river systems. Effective basin water resource management must consider hydrological response to vegetation greening and climate change.\n",
      "  - Spatiotemporal dynamics of remote‐sensed vegetation indices and derived variables such as land surface phenology have often been studied as a function of climate with implied assumption of negligible land‐cover change. However, this assumption is not valid for areas with intensive human activities such as fast‐developing countries. To address the impact of land cover on vegetation greenness, we analyzed the trend of EVI59, enhanced vegetation index in May–September, within the 25‐km2 patches centered at 674 meteorological stations located mostly in peri‐urban areas of China, and the impacts of land cover and intraannual climate variability on the EVI, during 2001–2015 by means of linear mixed‐effect model. Impacts of land cover were assessed with the enhancement of sum of the squared difference with respect to the climate model. The climate models explained on average 60% sum of the squared difference of the full models (climate plus land cover), and this proportion reached 83% and 94% for the temperate grassland and the high‐cold Tibet, respectively. Including land cover enhanced on average 40% of the sum of the squared difference, and the enhancement is over 60% for the dense‐populated warm‐temperate‐deciduous forest and subtropical‐evergreen forest zones. The impact of land cover not only depends on the intensity but also on the type of land‐cover change. Forest regrowth in east China and vegetation growth from bare land in temperate desert significantly enhanced greenness but the shift from agriculture to shrubs in temperate grassland may not significantly alter the greenness. We showed that climate variability is important for EVI in all zones except Tibet, and the climate variability contributed on average 64% of climate impacts.\n",
      "  - Climate change and human activities have already caused degradation in a large fraction of vegetation on the Qinghai‐Tibetan Plateau (QTP). Many studies report that climate variability instead of overgrazing has been the primary cause for large‐scale vegetation cover changes on the QTP, for example, Lehnert et al., 2016, https://doi.org/10.1038/srep24367. However, it remains unclear how human activities (mainly livestock grazing) regulate vegetation dynamics under climate change. This paper takes the AVHRR/GIMMS Normalized Difference Vegetation Index (NDVI) as an indicator to analyze the growth status of vegetation zones in the QTP, which has highly sensitive to climate change. The spatiotemporal dynamics of vegetation growth between 1981 and 2015 were analyzed. The dual effects of climate change and human activities were examined by correlation analyses of data from 87 meteorological stations and economic statistical data of the QTP. Results show that: (a) The vegetation in central and southwestern QTP with high altitudes was improving due to the warm‐humid climate trend. An increase in temperature and a reduction in the harsh frigid climate at high altitudes due to global warming has resulted in expansions of the vegetated areas, with the NDVI showing a concordant increase. (b) The degraded areas were mainly confined to the northern and eastern QTP, which have high human and livestock population densities. In comparison to gently changing climate regimes, anthropogenic activities such as chronic concentration of population and livestock in the valleys with a less harsh climate exerts a much stronger pressure on vegetation. The study indicates that the anthropogenic pressures are much more intensive than the impact of climate change and are critical for the conservation and sustainable management of the QTP vegetation.\n",
      "--------------------------------------------------\n",
      "Topic 201: 201_uk_infrastructure_risk_ukcp09\n",
      "Representative Documents:\n",
      "  - This paper explores the lessons learnt from the Optimising Adaptation Investment projects for the Department of Climate Change and Energy Efficiency–it includes coastal settlements, water supply and rail infrastructure case studies. These projects are the first of their kind in Australia and are considered internationally as a leading example of economic cost benefit analysis. They have been used effectively to inform decision making on specific adaptation responses to climate change risks to existing and new infrastructure. The lessons learnt will be explored for offshore platforms, ports, rail, road, drainage, tailings dams, mine facilities, water, and power supply, which includes the following elements:What decision makers require to make informed decisions under the uncertainty of climate change impacts.Reducing the uncertainty through economic modelling and cost benefit analysis.Optimising the right timing and scale of various adaptation options.Benefiting from oil and gas infrastructure adaptation opportunities.To further support the elements above, the applied process for integrating climate adaptation into infrastructure planning, design and operation will be illustrated by AECOM project experiences. AECOM has completed more than 60 significant climate change risk and adaptation projects for mines, ports, water supply and treatment, energy generation, transmission and distribution, rail, road, and coastal settlements in Australia, including the report: Climate Change Impacts to Infrastructure in Australia for the Garnaut Climate Change Review.\n",
      "  - Efficient and accountable management of water resources in Northern Victoria has become a critical issue for the future of irrigation, communities and the environment, both north and south of the Great Dividing Range. To increase efficiencies and enhance accountability for water resource use, the Victorian Government is investing $1 billion through the Northern Victoria Irrigation Renewal Project (NVIRP) to upgrade ageing irrigation infrastructure across the Goulburn-Murray Irrigation District. The upgrade is expected to generate an additional 225 GL of water that will be distributed equally between irrigators, the environment and Melbourne. Whilst there are significant potential benefits for the environment as a whole from the water savings initiatives, there may also be adverse impacts from altering the hydrology of the diverse array of wetlands and rivers which are directly linked to the irrigation delivery network. The NVIRP Environmental Referrals process has investigated these potential impacts and identified ten wetlands and four rivers of high environmental value that require the development of environmental watering plans. These plans are the primary means by which the NVIRP commitment to ‘no net environmental loss’ will be achieved and assets of high environmental value will be protected. Three Environmental Watering Plans (EWPs) were completed prior to the operation of NVIRP works in the 2009-2010 irrigation season. These are for Johnson Swamp, Lake Elizabeth and Lake Murphy. The paper will describe the development of the Lake Elizabeth EWPs by the North Central Catchment Management Authority (NCCMA), within the context of uncertain climatic conditions, the recent long drought and the need to demonstrate accountability and efficiency in the use of a scarce and finite resource.\n",
      "  -  The assessment of the potential impact of climate change on transport is an area of research very much in its infancy, and one that requires input from a multitude of disciplines including geography, engineering and technology, meteorology, climatology and futures studies. This paper investigates the current state of the art for assessments on urban surface transport, where rising populations and increasing dependence on efficient and reliable mobility have increased the importance placed on resilience to weather. The standard structure of climate change impact assessment (CIA) requires understanding in three important areas: how weather currently affects infrastructure and operations; how climate change may alter the frequency and magnitude of these impacts; and how concurrent technological and socio-economic development may shape the transport network of the future, either ameliorating or exacerbating the effects of climate change. The extent to which the requisite knowledge exists for a successful CIA is observed to decrease from the former to the latter. This paper traces a number of developments in the extrapolation of physical and behavioural relationships on to future climates, including a broad move away from previous deterministic methods and towards probabilistic projections which make use of a much broader range of climate change model output, giving a better representation of the uncertainty involved. Studies increasingly demand spatially and temporally downscaled climate projections that can represent realistic sub-daily fluctuations in weather that transport systems are sensitive to. It is recommended that future climate change impact assessments should focus on several key areas, including better representation of sub-daily extremes in climate tools, and recreation of realistic spatially coherent weather. Greater use of the increasing amounts of data created and captured by ‘intelligent infrastructure’ and ‘smart cities’ is also needed to develop behavioural and physical models of the response of transport to weather and to develop a better understanding of how stakeholders respond to probabilistic climate change impact projections. \n",
      "--------------------------------------------------\n",
      "Topic 202: 202_planets_habitable_earth like_planet\n",
      "Representative Documents:\n",
      "  - ABSTRACT               We study ultra-diffuse galaxies (UDGs) in zoom in cosmological simulations, seeking the origin of UDGs in the field versus galaxy groups. We find that while field UDGs arise from dwarfs in a characteristic mass range by multiple episodes of supernova feedback (Di Cintio et al.), group UDGs may also form by tidal puffing up and they become quiescent by ram-pressure stripping. The field and group UDGs share similar properties, independent of distance from the group centre. Their dark-matter haloes have ordinary spin parameters and centrally dominant dark-matter cores. Their stellar components tend to have a prolate shape with a Sérsic index n ∼ 1 but no significant rotation. Ram pressure removes the gas from the group UDGs when they are at pericentre, quenching star formation in them and making them redder. This generates a colour/star-formation-rate gradient with distance from the centre of the dense environment, as observed in clusters. We find that ∼20 per cent of the field UDGs that fall into a massive halo survive as satellite UDGs. In addition, normal field dwarfs on highly eccentric orbits can become UDGs near pericentre due to tidal puffing up, contributing about half of the group-UDG population. We interpret our findings using simple toy models, showing that gas stripping is mostly due to ram pressure rather than tides. We estimate that the energy deposited by tides in the bound component of a satellite over one orbit can cause significant puffing up provided that the orbit is sufficiently eccentric. We caution that while the simulations produce UDGs that match the observations, they under-produce the more compact dwarfs in the same mass range, possibly because of the high threshold for star formation or the strong feedback.\n",
      "  - In an effort to derive temperature-based criteria of habitability for multicellular life, we investigated the thermal limits of terrestrial poikilotherms, i.e. organisms whose body temperature and the functioning of all vital processes is directly affected by the ambient temperature. Multicellular poikilotherms are the most common and evolutionarily ancient form of complex life on earth. The thermal limits for the active metabolism and reproduction of multicellular poikilotherms on earth are approximately bracketed by the temperature interval 0°C ≤ T ≤ 50°C. The same interval applies to the photosynthetic production of oxygen, an essential ingredient of complex life, and for the generation of atmospheric biosignatures observable in exoplanets. Analysis of the main mechanisms responsible for the thermal thresholds of terrestrial life suggests that the same mechanisms would apply to other forms of chemical life. We therefore propose a habitability index for complex life,h050, representing the mean orbital fraction of planetary surface that satisfies the temperature limits 0°C ≤ T ≤ 50°C. With the aid of a climate model tailored for the calculation of the surface temperature of Earth-like planets, we calculatedh050as a function of planet insolation,S, and atmospheric columnar mass,Natm, for a few earth-like atmospheric compositions with trace levels of CO2. By displayingh050as a function ofSandNatm, we built up an atmospheric mass habitable zone (AMHZ) for complex life. At variance with the classic habitable zone, the inner edge of the complex life habitable zone is not affected by the uncertainties inherent to the calculation of the runaway greenhouse limit. The complex life habitable zone is significantly narrower than the habitable zone of dry planets. Our calculations illustrate how changes in ambient conditions dependent onSandNatm, such as temperature excursions and surface dose of secondary particles of cosmic rays, may influence the type of life potentially present at different epochs of planetary evolution inside the AMHZ.\n",
      "  - The search for life in the Universe is a fundamental problem of astrobiology and modern science. The current progress in the detection of terrestrial-type exoplanets has opened a new avenue in the characterization of exoplanetary atmospheres and in the search for biosignatures of life with the upcoming ground-based and space missions. To specify the conditions favourable for the origin, development and sustainment of life as we know it in other worlds, we need to understand the nature of global (astrospheric), and local (atmospheric and surface) environments of exoplanets in the habitable zones (HZs) around G-K-M dwarf stars including our young Sun. Global environment is formed by propagated disturbances from the planet-hosting stars in the form of stellar flares, coronal mass ejections, energetic particles and winds collectively known as astrospheric space weather. Its characterization will help in understanding how an exoplanetary ecosystem interacts with its host star, as well as in the specification of the physical, chemical and biochemical conditions that can create favourable and/or detrimental conditions for planetary climate and habitability along with evolution of planetary internal dynamics over geological timescales. A key linkage of (astro)physical, chemical and geological processes can only be understood in the framework of interdisciplinary studies with the incorporation of progress in heliophysics, astrophysics, planetary and Earth sciences. The assessment of the impacts of host stars on the climate and habitability of terrestrial (exo)planets will significantly expand the current definition of the HZ to the biogenic zone and provide new observational strategies for searching for signatures of life. The major goal of this paper is to describe and discuss the current status and recent progress in this interdisciplinary field in light of presentations and discussions during the NASA Nexus for Exoplanetary System Science funded workshop ‘Exoplanetary Space Weather, Climate and Habitability’ and to provide a new roadmap for the future development of the emerging field of exoplanetary science and astrobiology.\n",
      "--------------------------------------------------\n",
      "Topic 203: 203_lulc_land_cover_lulc changes\n",
      "Representative Documents:\n",
      "  - This study analyzed the spatiotemporal pattern of settlement expansion in Abuja, Nigeria, one of West Africa’s fastest developing cities, using geoinformation and ancillary datasets. Three epochs of Land-use Land-cover (LULC) maps for 1986, 2001 and 2014 were derived from Landsat images using support vector machines (SVM). Accuracy assessment (AA) of the LULC maps based on the pixel count resulted in overall accuracy of 82%, 92% and 92%, while the AA derived from the error adjusted area (EAA) method stood at 69%, 91% and 91% for 1986, 2001 and 2014, respectively. Two major techniques for detecting changes in the LULC epochs involved the use of binary maps as well as a post-classification comparison approach. Quantitative spatiotemporal analysis was conducted to detect LULC changes with specific focus on the settlement development pattern of Abuja, the federal capital city (FCC) of Nigeria. Logical transitions to the urban category were modelled for predicting future scenarios for the year 2050 using the embedded land change modeler (LCM) in the IDRISI package. Based on the EAA, the result showed that urban areas increased by more than 11% between 1986 and 2001. In contrast, this value rose to 17% between 2001 and 2014. The LCM model projected LULC changes that showed a growing trend in settlement expansion, which might take over allotted spaces for green areas and agricultural land if stringent development policies and enforcement measures are not implemented. In conclusion, integrating geospatial technologies with ancillary datasets offered improved understanding of how urbanization processes such as increased imperviousness of such a magnitude could influence the urban microclimate through the alteration of natural land surface temperature. Urban expansion could also lead to increased surface runoff as well as changes in drainage geography leading to urban floods.\n",
      "  - Forests are valuable natural resources, beneficial for the storage of carbon, production of oxygen, protection of soil and controlling the water cycle. Despite forests providing different services to the environment, they are being destroyed at an alarming pace. Forest cover change in Murree, Pakistan over the past few years has created different climatic issues. There was a research gap on the detection of forest cover change along with climate variation in the past few years in Murree, so there is a dire need to highlight the above problem in the respective site. Further, it was equally important to keep an eye on the drivers of deforestation to give or suggest solutions accordingly to curb deforestation. The main objectives of this study are to assess forest cover change in subtropical Chir pine forests in Murree, Pakistan over the last 20 years (2001–2021) and to correlate forest cover change with the climatic variables (minimum and maximum temperature and precipitation) of the study area during this time span (2001–2021). This research also intends to identify the main drivers of deforestation in the study area. Five land-use land-cover (LULC) categories are demarcated and classified by applying a supervised classification technique (MLC) through GIS. The accuracy of classified images is assessed and analyzed using KAPPA analysis for the agreement of the image classification. Climatic data are interpolated by empirical Bayesian kriging (EBK) interpolation and it was correlated with forest cover change graphically. Drivers of deforestation are identified through a questionnaire and analyzed in SPSS. The results showed that forest area has decreased 8.26% in Murree from 2001 to 2021. Fuelwood (54%), agriculture expansion (22%), timber production (16%), and urbanization (8%) are recorded as drivers of deforestation in the study area. Climatic variables (maximum and minimum temperature and precipitation) had also shown variation in Murree, as the average maximum temperature has risen 0.26 °C, the average minimum temperature has risen 1.71 °C and annual rainfall has decreased 139.8 mm in the past 20 years (2001–2021), showing that forest decline has caused an increase in temperature and a decrease in rainfall in Murree.\n",
      "  - The concerns over land use and land cover (LULC) change have emerged on the global stage due to realization that changes occurring on the land surface also influence climate, ecosystem and its services. This study aimed to map the temporal dynamic of LULC patterns and LST in the Jarmet wetland in Ethiopia. The dynamics and pattern of changes for a period of 21 years (2000-2021) were analyzed using geospatial techniques. Multi-temporal satellite images from Landsat ETM+ and Landsat-8 OLI sensor data were used to extract land-cover maps. The Land Surface Temperature (LST) trend of the study areas was computed using MODIS satellite imagery (2000-2021). Supervised classification using a Maximum Likelihood Classifier (MLC) was applied to prepare LULC maps of the watershed. The accuracy of the classified map was assessed using high-resolution data, and ground realities have been verified and ascertained through field observations. The results revealed a decreased trend in wetland, forest, shrubland and grassland in the period of 21 years (2000-2021) by -1148.71ha, -1073.26 ha, -1480.1 ha, and -87.73 ha, respectively. On the other hand, farmland and plantation areas followed an increasing trend. LST revealed decreasing trend in terms of mean and minimum with a fraction change of -0.018 and -0.073, whereas the maximum LST value shows an increasing trend with 0.021. The overall accuracy was 84.41%, with Kappa index of 76.13%. The analysis and findings of the study highlight important policy implications for sustainable LULC management in the study area. The study suggests the design and implementation of a guided natural resource policy, stopping the illegal expansion of farmland and educating society about the value of the sustainable management of habitat reserves.\n",
      "--------------------------------------------------\n",
      "Topic 204: 204_biogas_removal_cod_sludge\n",
      "Representative Documents:\n",
      "  - A laboratory-scale system consisting of an upflow anaerobic sludge blanket (UASB) reactor followed by a modified Ludzack-Ettinger (MLE) activated sludge process was adopted to investigate COD and nitrogen removals in municipal sewage treatment in warm climate. The COD, SCOD, acetic acid (HAc), NH4+-N and PO43−-P conversions in the UASB reactor were investigated. A 35% reduction in volatile suspended solid (VSS) was achieved in the UASB process. The net methane (CH4) production was 0.06 l (g CODremoved)−1. Acids accumulation was not observed. In the MLE activated sludge process, nitrification was almost complete while denitrification was modest. Little excess sludge was produced as the bulk of the COD was removed in the UASB reactor, which reduced the COD mass load to the activated sludge process. The average COD and SCOD of the final effluent of the activated sludge process were 51 and 25 mg l−1, respectively and the average NH4+-N concentration of the final effluent was 3.1 mg N l−1. The results illustrated that the coupled process is feasible for COD and nitrogen removals in municipal sewage treatment in warm climate. However, the low pH of the final effluent (&amp;lt;6 on average) remains an issue to be solved.\n",
      "  - Carbon dioxide (CO2) emissions from fossil fuels have led industries to seek cheaper carbon abatement technologies to mitigate environmental pollution. Herein, the effect of a magnetic photocatalyst (Fe-TiO2) on biogas production in anaerobic digestion (AD) of wastewater was investigated with three bioreactors coupled with UV-light (18 W). Three experimental setups defined as the control (AD system with no Fe-TiO2), biophotoreactor (BP), and biophotomagnetic (BPM) systems were operated at a mesophilic temperature (35 ± 5 °C) for a hydraulic retention time (HRT) of 30 days. The control system (ADs) had no Fe-TiO2 additives. The BPMs with 2 g Fe-TiO2 were exposed to a magnetic field, whereas the BPs were not. The removal rate of the chemical oxygen demand (COD), volatile solids (VS), and total solids (TS), together with biogas production and composition were monitored for each reactor. The degree of degradation of 75% COD was observed for the BPMs at a pH of 6.5 followed by the BPs (65% COD) and the ADs (45% COD). The results showed that the rate of degradation of COD had a direct correlation with the cumulative biogas production of the BPMs (1330 mL/d) &gt; BPs (1125 mL/d) &gt; AD (625 mL/d). This finding supports the use of biophotomagnetic systems (BPMs) in wastewater treatment for resource recovery and CO2 reduction (0.64 kg CO2/L) as an eco-friendly technology.\n",
      "  - This study presents a biophotocatalytic system as a sustainable technology for the recovery of clean water and renewable energy from wastewater, thereby providing a unique opportunity to drive industrialization and global sustainable development throughputs. Herein, inhouse magnetized photocatalyst (Fe-TiO2) with surface area 62.73 m2/g synthesized via co-precipitation, was hypothesized to hasten an up-flow anaerobic sludge blanket (UASB) reactor for the treatment of local South Africa municipality wastewater with the benefit of high-quality biogas production. A lab scale UASB process with a working volume of 5 L coupled with two UV-lights (T8 blacklight-blue tube, 365 nm, 18 W) was operated batchwise under mesophilic conditions for the period of 30 days with a constant organic load charge of 2.76 kg COD/m3. d. This biophotocatalytic system performance was investigated and compared with and without the Fe-TiO2 charge (2–6 g) with respect to effluent quality, biogas production and CO2 methanation. Using chemical oxygen demand (COD) measured as the degree of degradation of the pollutants, the best efficiency of 93% COD removal was achieved by a 4 g Fe-TiO2 charge at 14 days and pH of 7.13, as compared to zero charge where only 49.6% degradation was achieved. Under the same charge, cumulative biogas and methane content of 1500 mL/g COD.d and 85% were respectively attained as compared with the control with 400 mL/g COD.d and 65% methane content. Also, the energy produced can be used to offset the energy utilized by the UV-light for the wastewater abatement and other limitations of photocatalysis. The BP system was found to be an eco-friendly and cost-effective technology to be explored in water treatment settings.\n",
      "--------------------------------------------------\n",
      "Topic 205: 205_enso_variability_mean state_annual cycle\n",
      "Representative Documents:\n",
      "  -                The basic effect of extratropical atmosphere–ocean thermal coupling is to enhance the variance of both anomalous sea surface temperatures (SSTs) and air temperatures (AIRT) due to a decreased energy flux between the atmosphere and ocean, called reduced thermal damping. In this paper it is shown that rapidly varying surface winds, through their influence upon the turbulent surface heat fluxes that drive this coupling, act to effectively weaken the coupling and thus partially counteract the reduced thermal damping. In effect, rapid fluctuations in wind speed somewhat insulate the atmosphere and ocean from each other.               The nonlinear relationship between the rapidly varying wind speed anomalies and SST and AIRT anomalies results in a rapidly varying component of the surface heat fluxes. The clear separation between the dynamical time scales of the ocean and atmosphere allows this rapidly varying flux to be simply approximated by a stochastic process in which rapidly varying wind speed is represented as Gaussian white noise whose amplitude is modulated by the more slowly evolving thermal anomalies. Such state-dependent (multiplicative) noise can alter the dynamics of atmosphere–ocean coupling because it induces an additional heat flux term, the noise-induced drift, that effectively acts to weaken both coupling and dissipation. Another key implication of the outlined theory is that air–sea coupling includes both deterministic and stochastic components.               The theory is tested by examining daily observations during extended winter (November–April) at several ocean weather stations (OWSs). Two important results are found. First, multiplicative noise at OWS P effectively decreases the coupling by about one-third, with about a 10% (20%) decrease in the damping of SST (AIRT). This suggests that multiplicative noise may be responsible for roughly half of the AIRT variability at OWS P on subseasonal time scales. Second, OWS observations reveal that joint probability distribution functions of daily averaged SST and AIRT anomalies are significantly non-Gaussian. It is shown that treating the rapidly varying boundary layer heat fluxes as state-dependent noise can reproduce this observed non-Gaussianity. It is concluded that the effect of state-dependent noise is crucial to understand and model atmosphere–ocean coupling.\n",
      "  -                Decadal variations in the amplitude of El Niño and the Southern Oscillation have been the subject of great interest in the literature for the past decade. One theory suggests that ENSO is best described as a stable system driven by linear dynamics and that stochastic atmospheric forcing is responsible for the development and modulation of ENSO on interannual as well as decadal time scales. Another theory suggests that ENSO is driven by strong nonlinear coupled feedbacks between the ocean and atmosphere and low frequency changes in ENSO amplitude are driven by decadal changes in the tropical Pacific mean state. Unfortunately, the observed record is too short to collect reliable statistics for such low frequency behavior. A hybrid coupled model composed of a simple statistical atmosphere coupled to the Poseidon isopycnal ocean model has been developed for the study of ENSO decadal variability. The model simulates realistic ENSO variability on interannual and decadal time scales with negligible climate drift over 1000 years. Through analysis and experimentation the authors show that low frequency changes in the atmospheric “weather noise” drive changes in the tropical Pacific mean state leading to changes in the amplitude of ENSO on decadal time scales. Additional model simulations suggest that, while predictability is limited by the presence of atmospheric noise, there are extended periods when the coupled instability, strengthened by changes in the mean state, is insensitive to noise on interannual time scales.               The relationship between decadal modulation of ENSO and mean state changes resides somewhere between the linear damped stochastically forced theory and the strongly unstable theory. Unlike the strongly unstable system, changes in ENSO amplitude on longer time scales are determined by the stochastic forcing. The stochastic forcing is not necessary in this model to sustain ENSO; however, its presence is crucial for low frequency changes in the mean state of the tropical Pacific. The strong relationship between the mean state and ENSO amplitude modulation in the model is in opposition to the linear damped stochastically forced theory. The fact that changes in the tropical Pacific mean state lead directly to changes in ENSO amplitude and predictability has positive implications for predictability.\n",
      "  - . Diabatic processes significantly affect the development and structure of extratropical cyclones. Previous studies quantified the dynamical relevance of selected diabatic processes by studying their influence on potential vorticity (PV) in individual cyclones. However, a more general assessment of the relevance of all PV-modifying processes in a larger ensemble of cyclones is currently missing. Based on a series of twelve 35 d model simulations using the Integrated Forecasting System of the European Centre for Medium-Range Weather Forecasts, this study systematically quantifies the diabatic modification of positive and negative low-level PV anomalies along the cold front, warm front, and in the center of 288 rapidly intensifying extratropical cyclones. Diabatic PV modification is assessed by accumulating PV tendencies associated with each parametrized process along 15 h backward trajectories. The primary processes that modify PV typically remain temporally consistent during cyclone intensification. However, a pronounced case-to-case variability is found when comparing the most important processes across individual cyclones. Along the cold front, PV is primarily generated by condensation in half of the investigated cyclones in the cold season (October to March). For most of the remaining cyclones, convection or long-wave radiative cooling is the most important process. Similar results are found in the warm season (April to September); however, the fraction of cyclones with PV generation by convection as the most important process is reduced. Negative PV west of the cold front is primarily produced by turbulent mixing of momentum, long-wave radiative heating, or turbulent mixing of temperature. The positive PV anomaly at the warm front is most often primarily generated by condensation in the cold season and by turbulent mixing of momentum in the warm season. Convection is the most important process only in a few cyclones. Negative PV along the warm front is primarily produced by long-wave radiative heating, turbulent mixing of temperature, or melting of snow in the cold season. Turbulent mixing of temperature becomes the primary process in the warm season, followed by melting of snow and turbulent mixing of momentum. The positive PV anomaly in the cyclone center is primarily produced by condensation in most cyclones, with only few cases primarily associated with turbulent mixing or convection. A composite analysis further reveals that cyclones primarily associated with PV generation by convection exhibit a negative air–surface temperature difference in the warm sector, which promotes a heat flux directed into the atmosphere. These cyclones generally occur over warm ocean currents in the cold season. On the other hand, cyclones that occur in a significantly colder environment are often associated with a positive air–surface temperature difference in the warm sector, leading to PV generation by long-wave radiative cooling. Finally, long-wave radiative heating due to a negative air–surface temperature difference in the cold sector produces negative PV along the cold and warm front, in particular in the cold season.                    \n",
      "--------------------------------------------------\n",
      "Topic 206: 206_heat_mixed layer_ocean_mixed\n",
      "Representative Documents:\n",
      "  -                Sea surface temperature (SST) in the southwestern tropical Indian Ocean exerts a significant influence on global climate through its influence on the Indian summer monsoon and Northern Hemisphere atmospheric circulation. In this study, measurements from a long-term moored buoy are used in conjunction with satellite, in situ, and atmospheric reanalysis datasets to analyze the seasonal mixed layer heat balance in the thermocline ridge region of the southwestern tropical Indian Ocean. This region is characterized by a shallow mean thermocline (90 m, as measured by the 20°C isotherm) and pronounced seasonal cycles of Ekman pumping and SST (seasonal ranges of −0.1 to 0.6 m day−1 and 26°–29.5°C, respectively). It is found that surface heat fluxes and horizontal heat advection contribute significantly to the seasonal cycle of mixed layer heat storage. The net surface heat flux tends to warm the mixed layer throughout the year and is strongest during boreal fall and winter, when surface shortwave radiation is highest and latent heat loss is weakest. Horizontal heat advection provides warming during boreal summer and fall, when southwestward surface currents and horizontal SST gradients are strongest, and is close to zero during the remainder of the year. Vertical turbulent mixing, estimated as a residual in the heat balance, also undergoes a significant seasonal cycle. Cooling from this term is strongest in boreal summer, when surface wind and buoyancy forcing are strongest, the thermocline ridge is shallow (&amp;lt;90 m), and the mixed layer is deepening. These empirical results provide a framework for addressing intraseasonal and interannual climate variations, which are dynamically linked to the seasonal cycle, in the southwestern tropical Indian Ocean. They also provide a quantitative basis for assessing the accuracy of numerical ocean model simulations in the region.\n",
      "  -                The surface heat flux response to underlying sea surface temperature (SST) anomalies (the surface heat flux feedback) is estimated using 42 yr (1956–97) of ship-derived monthly turbulent heat fluxes and 17 yr (1984–2000) of satellite-derived monthly radiative fluxes over the global oceans for individual seasons. Net surface heat flux feedback is generally negative (i.e., a damping of the underlying SST anomalies) over the global oceans, although there is considerable geographical and seasonal variation. Over the North Pacific Ocean, net surface heat flux feedback is dominated by the turbulent flux component, with maximum values (28 W m−2 K−1) in December–February and minimum values (5 W m−2 K−1) in May–July. These seasonal variations are due to changes in the strength of the climatological mean surface wind speed and the degree to which the near-surface air temperature and humidity adjust to the underlying SST anomalies. Similar features are observed over the extratropical North Atlantic Ocean with maximum (minimum) feedback values of approximately 33 W m−2 K−1 (9 W m−2 K−1) in December–February (June–August). Although the net surface heat flux feedback may be negative, individual components of the feedback can be positive depending on season and location. For example, over the midlatitude North Pacific Ocean during late spring to midsummer, the radiative flux feedback associated with marine boundary layer clouds and fog is positive, and results in a significant enhancement of the month-to-month persistence of SST anomalies, nearly doubling the SST anomaly decay time from 2.8 to 5.3 months in May–July.               Several regions are identified with net positive heat flux feedback: the tropical western North Atlantic Ocean during boreal winter, the Namibian stratocumulus deck off West Africa during boreal fall, and the Indian Ocean during boreal summer and fall. These positive feedbacks are mainly associated with the following atmospheric responses to positive SST anomalies: 1) reduced surface wind speed (positive turbulent heat flux feedback) over the tropical western North Atlantic and Indian Oceans, 2) reduced marine boundary layer stratocumulus cloud fraction (positive shortwave radiative flux feedback) over the Namibian stratocumulus deck, and 3) enhanced atmospheric water vapor (positive longwave radiative flux feedback) in the vicinity of the tropical deep convection region over the Indian Ocean that exceeds the negative shortwave radiative flux feedback associated with enhanced cloudiness.\n",
      "  -                The seasonal cycle of the mixed layer heat budget in the northeastern tropical Atlantic (0°–25°N, 18°–28°W) is quantified using in situ and satellite measurements together with atmospheric reanalysis products. This region is characterized by pronounced latitudinal movements of the intertropical convergence zone (ITCZ) and strong meridional variations of the terms in the heat budget. Three distinct regimes within the northeastern tropical Atlantic are identified. The trade wind region (15°–25°N) experiences a strong annual cycle of mixed layer heat content that is driven by approximately out-of-phase annual cycles of surface shortwave radiation (SWR), which peaks in boreal summer, and evaporative cooling, which reaches a minimum in boreal summer. The surface heat-flux-induced changes in the mixed layer heat content are damped by a strong annual cycle of cooling from vertical turbulent mixing, estimated from the residual in the heat balance. In the ITCZ core region (3°–8°N) a weak seasonal cycle of mixed layer heat content is driven by a semiannual cycle of SWR and damped by evaporative cooling and vertical turbulent mixing. On the equator the seasonal cycle of mixed layer heat content is balanced by an annual cycle of SWR that reaches a maximum in October and a semiannual cycle of turbulent mixing that cools the mixed layer most strongly during May–July and November. These results emphasize the importance of the surface heat flux and vertical turbulent mixing for the seasonal cycle of mixed layer heat content in the northeastern tropical Atlantic.\n",
      "--------------------------------------------------\n",
      "Topic 207: 207_policies_pricing_mitigation_emissions\n",
      "Representative Documents:\n",
      "  - In order to achieve the temperature goals of the Paris Agreement, the world must reach net‐zero carbon emissions around mid‐century, which calls for an entirely new energy system. Carbon pricing, in the shape of taxes or emissions trading schemes, is often seen as the main, or only, necessary climate policy instrument, based on theoretical expectations that this would promote innovation and diffusion of the new technologies necessary for full decarbonization. Here, we review the empirical knowledge available in academic ex‐post analyses of the effectiveness of existing, comparatively high‐price carbon pricing schemes in the European Union, New Zealand, British Columbia, and the Nordic countries. Some articles find short‐term operational effects, especially fuel switching in existing assets, but no article finds mentionable effects on technological change. Critically, all articles examining the effects on zero‐carbon investment found that existing carbon pricing scheme have had no effect at all. We conclude that the effectiveness of carbon pricing in stimulating innovation and zero‐carbon investment remains a theoretical argument. So far, there is no empirical evidence of its effectiveness in promoting the technological change necessary for full decarbonization.This article is categorized under:Climate Economics &gt; Economics of Mitigation\n",
      "  - Brazil occupies a unique position among the major greenhouse gas (GHG) emitting countries due to its low per‐capita energy‐related GHG emissions (2.4 tons CO2 in 2014), attributable to abundant clean energy sources. Recently, deforestation in Brazil has slowed considerably, to the point where forestry has ceased to be the major source of emissions. Brazil has reduced its overall GHG emissions by 41% from 2005 to 2012, and its total GHG emissions per capita decreased from a high in 2004 of 14.4 tCO2e to an estimated 6.5 tCO2e in 2012. Brazil faces the challenge of building upon its historically low energy‐related GHG emission levels through new decarbonization strategies, while pursuing higher living standards for its population. There is a huge potential to further reduce national GHG emissions through the implementation of a wide spectrum of mitigation measures. While several observers from the scientific community have a different view, Brazilian government considers that the country has been playing both a pioneer and a leader role in ambitious climate action, including the submission of a quite ambitious intended nationally determined contribution, and a constructive role played in COP21, joining the High Ambition club at the end of the negotiations. Several motivations exist for Brazil joining other ‘climate clubs’ focusing on innovative financial mechanisms and sustainable energy and forestry technologies. WIREs Clim Change 2017, 8:e439. doi: 10.1002/wcc.439This article is categorized under:The Carbon Economy and Climate Mitigation &gt; Policies, Instruments, Lifestyles, BehaviorPolicy and Governance &gt; International Policy Framework\n",
      "  - As many countries, regions, cities, and states implement emissions trading policies to limit CO2 emissions, they turn to the European Union's experience with its emissions trading scheme since 2005. As a prominent example of a regional carbon pricing policy, it has attracted significant attention from scholars interested in evaluating the effectiveness and impacts of emissions trading. Among the key difficulties faced by researchers is isolating the effect of the EU ETS on industry operation, investment, and pricing decisions from other dominant factors such as the financial crisis, and establishing credible counterfactual scenarios against this backdrop. This article reviews the evidence, focusing on two intended effects (emissions abatement and investment in low‐carbon technologies) as well as two side‐effects (profits and price impacts). We find that the EU ETS cut CO2 emissions by 40–80 million t/year on average, or 2–4% of the total capped, while the evidence on innovation and investment impacts is inconclusive. There is strong empirical support for cost‐pass through in electricity (20–100%), in diesel and gasoline (&gt;50%), and some preliminary evidence of pricing power in other industrial sectors. Windfall profits have amounted to billions of Euros, and concentrated in a few large companies.This article is categorized under:Climate Economics &gt; Economics of MitigationThe Carbon Economy and Climate Mitigation &gt; Policies, Instruments, Lifestyles, BehaviorPolicy and Governance &gt; Multilevel and Transnational Climate Change Governance\n",
      "--------------------------------------------------\n",
      "Topic 208: 208_cardiac_heart_fh_oxygen\n",
      "Representative Documents:\n",
      "  - Thermal tolerance in fish may be related to an oxygen limitation of cardiac function. While the hearts of some fish species receive oxygenated blood via a coronary circulation, the influence of this oxygen supply on thermal tolerance and cardiac performance during warming remain unexplored. Here, we analyzed the effect in vivo of acute warming on coronary blood flow in adult sexually mature rainbow trout ( Onchorhynchus mykiss) and the consequences of chronic coronary ligation on cardiac function and thermal tolerance in juvenile trout. Coronary blood flow at 10°C was higher in females than males (0.56 ± 0.08 vs. 0.30 ± 0.08 ml·min−1·g ventricle−1), and averaged 0.47 ± 0.07 ml·min−1·g ventricle−1across sexes. Warming increased coronary flow in both sexes until 14°C, at which it peaked and plateaued at 0.78 ± 0.1 and 0.61 ± 0.1 ml·min−1·g ventricle−1in females and males, respectively. Thus, the scope for increasing coronary flow was 101% in males, but only 39% in females. Coronary-ligated juvenile trout exhibited elevated heart rate across temperatures, reduced Arrhenius breakpoint temperature for heart rate (23.0 vs. 24.6°C), and reduced upper critical thermal maximum (25.3 vs. 26.3°C). To further analyze the effects of coronary flow restriction on cardiac rhythmicity, electrocardiogram characteristics were determined before and after coronary occlusion in anesthetized trout. Occlusion resulted in reduced R-wave amplitude and an elevated S-T segment, indicating myocardial ischemia, while heart rate was unaffected. This suggests that the tachycardia in ligated trout across temperatures in vivo was mainly to compensate for reduced cardiac contractility to maintain cardiac output. Moreover, our findings show that coronary flow increases with warming in a sex-specific manner. This may improve whole animal thermal tolerance, presumably by sustaining cardiac oxygenation and contractility at high temperatures.\n",
      "  - Oxygen supply to the heart has been hypothesized to limit cardiac performance and whole animal acute thermal tolerance (CTmax) in fish. We tested these hypotheses by continuously measuring venous oxygen tension (Pvo2) and cardiovascular variables in vivo during acute warming in European perch ( Perca fluviatilis) from a reference area during summer (18°C) and a chronically heated area (Biotest enclosure) that receives warm effluent water from a nuclear power plant and is normally 5–10°C above ambient (24°C at the time of experiments). While CTmaxwas 2.2°C higher in Biotest compared with reference perch, the peaks in cardiac output and heart rate prior to CTmaxoccurred at statistically similar Pvo2values (2.3–4.0 kPa), suggesting that cardiac failure occurred at a common critical Pvo2threshold. Environmental hyperoxia (200% air saturation) increased Pvo2across temperatures in reference fish, but heart rate still declined at a similar temperature. CTmaxof reference fish increased slightly (by 0.9°C) in hyperoxia, but remained significantly lower than in Biotest fish despite an improved cardiac output due to an elevated stroke volume. Thus, while cardiac oxygen supply appears critical to elevate stroke volume at high temperatures, oxygen limitation may not explain the bradycardia and arrhythmia that occur prior to CTmax. Acute thermal tolerance and its thermal plasticity can, therefore, only be partially attributed to cardiac failure from myocardial oxygen limitations, and likely involves limiting factors on multiple organizational levels.\n",
      "  - Tolerance to acute environmental warming in fish is partly governed by the functional capacity of the heart to increase systemic oxygen delivery at high temperatures. However, cardiac function typically deteriorates at high temperatures, due to declining heart rate and an impaired capacity to maintain or increase cardiac stroke volume, which in turn has been attributed to a deterioration of the electrical conductivity of cardiac tissues and/or an impaired cardiac oxygen supply. While autonomic regulation of the heart may benefit cardiac function during warming by improving myocardial oxygenation, contractility and conductivity, the role of these processes for determining whole animal thermal tolerance is not clear. This is in part because interpretations of previous pharmacological in vivo experiments in salmonids are ambiguous and were confounded by potential compensatory increases in coronary oxygen delivery to the myocardium. Here, we tested the previously advanced hypothesis that cardiac autonomic control benefits heart function and acute warming tolerance in perch (Perca fluviatilis) and roach (Rutilus rutilus); two species that lack coronary arteries and rely entirely on luminal venous oxygen supplies for cardiac oxygenation. Pharmacological blockade of β-adrenergic tone lowered the upper temperature where heart rate started to decline in both species, marking the onset of cardiac failure, and reduced the critical thermal maximum (CTmax) in perch. Cholinergic (muscarinic) blockade had no effect on these thermal tolerance indices. Our findings are consistent with the hypothesis that adrenergic stimulation improves cardiac performance during acute warming, which, at least in perch, increases acute thermal tolerance.\n",
      "--------------------------------------------------\n",
      "Topic 209: 209_prediction_lstm_lcz_accuracy\n",
      "Representative Documents:\n",
      "  - In order to implement the national need for the optimal allocation of power resources, power load forecasting, as an important research topic, has important theoretical and practical significance. The purpose of this study is to construct a prediction model considering climate factors based on a large amount of historical data, and to prove that the prediction accuracy is related to both climate factors and load regularity. The results of load forecasting are affected by many climate factors, so firstly the climate variables affecting load forecasting are screened. Secondly, a load prediction model based on the IPSO-Elman network learning algorithm is constructed by taking the difference between the predicted value of the neural network and the actual value as the fitness function of particle swarm optimization. In view of the great influence of weights and thresholds on the prediction accuracy of the Elman neural network, the particle swarm optimization algorithm (PSO) is used to optimize parameters in order to improve the prediction accuracy of ELMAN neural network. Thirdly, prediction with and without climate factors is compared and analyzed, and the prediction accuracy of the model compared by using cosine distance and various error indicators. Finally, the stability discriminant index of historical load regularity is introduced to prove that the accuracy of the prediction model is related to the regularity of historical load in the forecast area. The prediction method proposed in this paper can provide reference for power system scheduling.\n",
      "  -                Accurate runoff prediction is of great significance for flood prevention and mitigation, agricultural irrigation, and reservoir scheduling in watersheds. To address the strong non-linear and non-stationary characteristics of runoff series, a hybrid model of monthly runoff prediction, variational mode decomposition (VMD)–long short-term memory (LSTM)–Transformer, is proposed. Firstly, VMD is used to decompose the runoff series into multiple modal components, and the sample entropy of each modal component is calculated and divided into high-frequency and low-frequency components. The LSTM model is then used to predict the high-frequency components and the transformer to predict the low-frequency components. Finally, the prediction results are summed to obtain the final prediction results. The Mann–Kendall trend test method is used to analyze the runoff characteristics of the Miyun Reservoir, and the constructed VMD–LSTM–Transformer model is used to forecast the runoff of the Miyun Reservoir. The prediction results are compared and evaluated with those of VMD–LSTM, VMD–Transformer, empirical mode decomposition (EMD)–LSTM–Transformer, and empirical mode decomposition (EMD)–LSTM models. The results show that the Nash–Sutcliffe efficiency coefficient (NSE) value of this model is 0.976, mean absolute error (MAE) is 0.206 × 107 m3, mean absolute percentage error (MAPE) is 0.381%, and root mean squared error (RMSE) is 0.411 × 107 m3, all of which are better than other models, indicating that the VMD–LSTM–Transformer model has higher prediction accuracy and can be applied to runoff prediction in the actual study area.\n",
      "  - Long-time-series climate prediction is of great significance for mitigating disasters; promoting ecological civilization; identifying climate change patterns and preventing floods, drought and typhoons. However, the general public often struggles with the complexity and extensive temporal range of meteorological data when attempting to accurately forecast climate extremes. Sequence disorder, weak robustness, low characteristics and weak interpretability are four prevalent shortcomings in predicting long-time-series data. In order to resolve these deficiencies, our study gives a novel hybrid spatiotemporal model which offers comprehensive data preprocessing techniques, focusing on data decomposition, feature extraction and dimensionality upgrading. This model provides a feasible solution to the puzzling problem of long-term climate prediction. Firstly, we put forward a Period Division Region Segmentation Property Extraction (PD-RS-PE) approach, which divides the data into a stationary series (SS) for an Extreme Learning Machine (ELM) prediction and an oscillatory series (OS) for a Long Short-term Memory (LSTM) prediction to accommodate the changing trend of data sequences. Secondly, a new type of input-output mapping mode in a three-dimensional matrix was constructed to enhance the robustness of the prediction. Thirdly, we implemented a multi-layer technique to extract features of high-speed input data based on a Deep Belief Network (DBN) and Particle Swarm Optimization (PSO) for parameter searching of a neural network, thereby enhancing the overall system’s learning ability. Consequently, by integrating all the above innovative technologies, a novel hybrid SS-OS-PSO-DBN-ELM-LSTME (SOPDEL) model with comprehensive data preprocessing was established to improve the quality of long-time-series forecasting. Five models featuring partial enhancements are discussed in this paper and three state-of-the-art classical models were utilized for comparative experiments. The results demonstrated that the majority of evaluation indices exhibit a significant optimization in the proposed model. Additionally, a relevant evaluation system showed that the quality of “Excellent Prediction” and “Good Prediction” exceeds 90%, and no data with “Bad Prediction” appear, so the accuracy of the prediction process is obviously insured.\n",
      "--------------------------------------------------\n",
      "Topic 210: 210_ccsm4_resolution_ssws_monsoon\n",
      "Representative Documents:\n",
      "  -                A regional climate model is tested for several domain configurations over the southwestern Indian Ocean to examine the ability of the model to reproduce observed cyclones and their landfalling tracks. The interaction between large-scale and local terrain forcing of tropical storms approaching and transiting the island landmass of Madagascar makes the southwestern Indian Ocean a unique and interesting study area. In addition, tropical cyclones across the southern Indian Ocean are likely to be significantly affected by the large-scale zonal flow. Therefore, the effects of model domain size and the positioning of its lateral boundaries on the simulation of tropical cyclone–like vortices and their tracks on a seasonal time scale are investigated. Four tropical cyclones, which occurred over the southwestern Indian Ocean in January of the years 1995–97, are studied, and four domains are tested. The regional climate model is driven by atmospheric lateral boundary conditions that are derived from large-scale meteorological analyses. The use of analyzed boundary forcing enables comparison with observed cyclones in these tests. Simulations are performed using a 60-km horizontal resolution and for an extended time integration of about 6 weeks. Results show that the positioning of the eastern boundary of the regional model domain is of major importance in the life cycle of simulated tropical cyclone–like vortices: a vortex entering through the eastern boundary of the regional model is generally well simulated. The size of the domain also has a bearing on the ability of the regional model to simulate vortices in the Mozambique Channel, and the island landmass of Madagascar additionally influences storm tracks. These results show that the regional model can produce cyclonelike vortices and their tracks (with some deficiencies) given analyzed lateral boundary forcing. Statistical analyses of GCM-driven nested model ensemble integrations are now required to further address predictive skill of cyclones in the southwestern Indian Ocean and to test if the model can realistically simulate tropical storm genesis as opposed to advecting existing tropical disturbances entering through the model boundaries.\n",
      "  -                This is the second part of a two part series studying simulation characteristics of the Community Climate System Model, version 4 (CCSM4) for various monsoon regimes around the global tropics. Here, the West African, East African, North American, and South American monsoons are documented in CCSM4. Comparisons are made to an Atmospheric Model Intercomparison Project (AMIP) simulation of the atmospheric component in CCSM4 (CAM4), to deduce differences in the monsoon simulations run with observed SSTs and with ocean–atmosphere coupling. These simulations are also compared to a previous version of the coupled model (CCSM3) to evaluate progress. In most, but not all instances, monsoon rainfall is too heavy in the uncoupled AMIP run with the Community Atmosphere Model, version 4 (CAM4), and monsoon rainfall amounts are generally better simulated with ocean coupling in CCSM4. Some aspects of the monsoon simulations are improved in CCSM4 compared to CCSM3. Early-season rainfall in the West African monsoon is better simulated in CAM4 than in CCSM4 presumably because of the specification of SSTs in the Gulf of Guinea, but the Sahel rainfall season is captured better in CCSM4 as are the African easterly jet and the tropical easterly jet. Improvements in the simulation of the Sahel rainy season (July, August, and September) in CCSM4 compared with CCSM3 are significant, but problems remain in the simulation of the early season (May and June) in association with the misrepresentation of eastern Atlantic (Gulf of Guinea) SSTs. Precipitation distributions and the southwesterly low-level inflow in the North American monsoon are improved in CCSM4 compared to CCSM3. Both CAM4 and CCSM4 reproduce the seasonal evolution of rainfall over the South American monsoon region, but the location of maximum rainfall is misplaced to the northeast in both models.\n",
      "  -                The simulation characteristics of the Asian–Australian monsoon are documented for the Community Climate System Model, version 4 (CCSM4). This is the first part of a two part series examining monsoon regimes in the global tropics in the CCSM4. Comparisons are made to an Atmospheric Model Intercomparison Project (AMIP) simulation of the atmospheric component in CCSM4 [Community Atmosphere Model, version 4, (CAM4)] to deduce differences in the monsoon simulations run with observed sea surface temperatures (SSTs) and with ocean–atmosphere coupling. These simulations are also compared to a previous version of the model (CCSM3) to evaluate progress. In general, monsoon rainfall is too heavy in the uncoupled AMIP run with CAM4, and monsoon rainfall amounts are generally better simulated with ocean coupling in CCSM4. Most aspects of the Asian–Australian monsoon simulations are improved in CCSM4 compared to CCSM3. There is a reduction of the systematic error of rainfall over the tropical Indian Ocean for the South Asian monsoon, and well-simulated connections between SSTs in the Bay of Bengal and regional South Asian monsoon precipitation. The pattern of rainfall in the Australian monsoon is closer to observations in part because of contributions from the improvements of the Indonesian Throughflow and diapycnal diffusion in CCSM4. Intraseasonal variability of the Asian–Australian monsoon is much improved in CCSM4 compared to CCSM3 both in terms of eastward and northward propagation characteristics, though it is still somewhat weaker than observed. An improved simulation of El Niño in CCSM4 contributes to more realistic connections between the Asian–Australian monsoon and El Niño–Southern Oscillation (ENSO), though there is considerable decadal and century time scale variability of the strength of the monsoon–ENSO connection.\n",
      "--------------------------------------------------\n",
      "Topic 211: 211_forest_management_forest management_thinning\n",
      "Representative Documents:\n",
      "  -                 Background                Forestry plays a major role in climate change mitigation. However, which intensity of logging is best suited for that task remains controversial. We contribute to the debate by quantitatively analyzing three different forest management scenarios in Germany—a baseline scenario which represents a continuation of current forest management practice as well as an intensive and an extensive logging scenario. We assess whether increased carbon storage in wood products and substitution of other emission-intensive materials can offset reduced carbon stocks in the forest due to increased harvesting. For that, we calculate annual required displacement factors (RDF)—a dimensionless quantity that indicates the minimal displacement factor (DF) so that intensive forestry outperforms extensive forestry from a climate perspective.                              Results                If the intensive forest management scenario is included in the comparison, the RDF starts off with relatively high values (1 to 1.5) but declines over time and eventually even reaches negative values. Comparing the extensive scenario to a baseline yields RDF values between 0.1 and 0.9 with a slightly increasing trend. Compared to RDFs, expected future DFs are too low to favour the intensive forestry scenario and too high to favour the extensive forestry scenario, during the first 25 years of the modeling period. However, towards the end of the modeling period, the relationship between DFs and RDF is turned around in both comparisons. In the comparison between intensive and extensive forest management RDF values are very similar to future DF trajectories.                              Conclusion                RDFs are a useful tool for comparing annual climate impacts of forest growth scenarios and can be used to benchmark material and energy substitution effects of wood. Our results indicate that the baseline scenario reflects an effective compromise between carbon stocks in the forest and carbon displacement by wood use. For a longer modeling period, however, this might not be the case. Which of the alternative scenarios would be best suited for climate change mitigation is heavily dependent on future DF trajectory. Hence, our findings highlight the necessity of robust projections of forest dynamics and industry decarbonization pathways.              \n",
      "  - In this work, we studied the potentials offered by managed boreal forests and forestry to mitigate the climate change using forest‐based materials and energy in substituting fossil‐based materials (concrete and plastic) and energy (coal and oil). For this purpose, we calculated the net climate impacts (radiative forcing) of forest biomass production and utilization in the managed Finnish boreal forests (60°–70°N) over a 90‐year period based on integrated use forest ecosystem model simulations (on carbon sequestration and biomass production of forests) and life‐cycle assessment (LCA) tool. When studying the effects of management on the radiative forcing in a system integrating the carbon sink/sources dynamics in both biosystem and technosystem, the current forest management (baseline management) was used a reference management. Our results showed that the use of forest‐based materials and energy in substituting fossil‐based materials and energy would provide an effective option for mitigating climate change. The negative climate impacts could be further decreased by maintaining forest stocking higher over the rotation compared to the baseline management and by harvesting stumps and coarse roots in addition to logging residues in the final felling. However, the climate impacts varied substantially over time depending on the prevailing forest structure and biomass assortment (timber, energy biomass) used in substitution.\n",
      "  - We studied the effects of climate change and forest management scenarios on net climate impacts (radiative forcing) of production and utilization of energy biomass, in a Norway spruce forest area over an 80‐year simulation period in Finnish boreal conditions. A stable age‐class distribution was used in model‐based analyses to identify purely the management effects under the current and changing climate (SRES B1 and A2 scenarios). The radiative forcing was calculated based on an integrated use of forest ecosystem model simulations and a life cycle assessment (LCA) tool. In this work, forest‐based energy was used to substitute coal, and current forest management (baseline management) was used as a reference management. In alternative management scenarios, the stocking was maintained 20% higher in thinning compared to the baseline management, and nitrogen fertilization was applied. Intensity of energy biomass harvest (e.g. logging residues, coarse roots and stumps) was varied in the final felling of the stands at the age of 80 years. Also, the economic profitability (NPV, 3% interest rate) of integrated production of timber and energy biomass was calculated for each management scenario. Our results showed that compared to the baseline management, climate benefits could be increased by maintaining higher stocking in thinning over rotation, using nitrogen fertilization and harvesting logging residues, stumps and coarse roots in the final felling. Under the gradually changing climate (in both SRES B1 and A2), the climate benefits were lower compared to the current climate. Trade‐offs between NPV and net climate impacts also existed.\n",
      "--------------------------------------------------\n",
      "Topic 212: 212_adaptation_women_vulnerability_adaptive capacity\n",
      "Representative Documents:\n",
      "  - PurposeThis paper aims to draw on community risk assessment (CRA) for assessing vulnerability to climate change in north-western Ghana, focusing on sunshine, temperature and wind, elements of climate which are seldom explored in vulnerability assessments to climate change.Design/methodology/approachThe paper draws on data collected from a qualitative research design that used participatory rural appraisal methods, particularly, in-depth interviews, focus group discussions and seasonal calendar analysis in three selected rural communities of the Sissala East District. Furthermore, an inter-generational framework was adopted for comparative assessment of vulnerability and changes in vulnerability to climate change.FindingsThe results show that the current generation of smallholder farmers is more vulnerable to climate change than the past generation, the era of grandparents. Thus, farmers are exposed to higher-intensity sunshine, temperature and wind in contemporary times than was the case in the past. Consequently, their livelihoods are affected the most by the damaging effects of these climatic hazards. The CRA process revealed the relevance of indigenous knowledge systems for vulnerability assessments and at the same time, underpins the need for adaptation of such knowledge if it is to sustain smallholder farmer efforts at climate change adaptation at community levels.Practical implicationsThe paper recommends an endogenous development approach to climate change adaptation planning (CCAP), one that will build on indigenous knowledge systems for effective community education, mobilization and participatory response to climate change. Policy interventions should aim at enhancing climate change adaptation through innovations in soil and water conservation, access to water for irrigation and domestic use, climate smart-housing architecture and agro-forestry within the framework of decentralization and district development planning.Originality/valueThis paper will contribute to climate change research in two ways: first, by drawing attention to the usefulness of CRA in vulnerability assessment; and second, by focusing on climate elements which are critical for CCAP but rarely given sufficient attention in vulnerability assessments.\n",
      "  - Following a case study, community adaptation plans are a bottom-up approach that focus on increasing climate-vulnerable communities’ engagement in local adaptation planning and policy design, prioritization, and implementation in Nepal. This paper explains how Community-Based Adaptation Action Plan (CAPA) groups are being studied to assess the climate vulnerability of the local socio-ecosystem and to develop community-level adaptation measures. However, there is insufficient research to differentiate local vulnerabilities caused by climate change. This paper, therefore, examines climate change vulnerability with respect to community vulnerability and potential adaptation measures to increase community resilience and adaptive capacity through CAPAs. The study compares differences by gender, caste/ethnicity, and wealth in relation to specific climate-related hazards (exposure, sensitivity, and adaptive capacity) of communities. The study draws on secondary sources of information along with field observations, 73 household interviews, 13 key-informant interviews, consultations, and 9 interactive meetings in 3 districts of Nepal. Differential impact analysis refers to the exposure, sensitivity, and adaptive capacity of local socio-ecological systems. In addition, multivariate analysis was conducted using the Canoco program to analyze the role of actors with respect to climate vulnerability. The results conclude that the degree of vulnerability varies widely at the household level and is strongly influenced by socio-economic characteristics such as gender, caste/ethnicity, and wealth. Immediate and focused attention is needed to improve access to government resources for vulnerable households, requiring positive support from decision makers. Equally important is improving the chain of communication, which includes information, skills, knowledge, capacity, and institutional arrangements. Analysis of the differential vulnerability and the adaptive capacity of a vulnerable community is more appropriate for the design of local adaptation plans. Therefore, the study suggests that engagement of local partners, including local authorities, in addressing vulnerability and adaptation is required to confront the social process, new institutional arrangements, local adaptation, and capacity-building with technical solutions.\n",
      "  - PurposeAcross societies, gendered climate response decisions remain top-down and have limited progress because the influenced risk dynamics and their interrelations are not adequately understood. This study aims to address this gap by proposing an interdisciplinary innovative method, called women climate vulnerability (WCV) index, for measuring and comparing a diverse range of risks that threaten to undermine the adaptive capacity and resilience of rural women.Design/methodology/approachThis paper builds on the literature to identify 12 risk categories across physical, economic and political sectors that affect rural women. These categories and attendant 51 risk indicators form the WCV index. A case study in Ben Tre Province (Vietnam) was used to demonstrate the application of the WCV methodology to rural contexts. The authors combined empirical, survey and secondary data from different sources to form data on the indicators. Structured expert judgment was used to address data gaps. Empirical and expert data were combined using a few weighting steps and a comprehensive coding system was developed to ensure objective evaluation.FindingsThe WCV assessment results reveal a reasonably worrisome picture of women’s vulnerability in Ben Tre as top highest-likelihood and deepest-impact risks predominate in physical and economic risk sectors. Stability, human security and governance categories have lowest scores, demonstrating a fairly politically favourable condition in the province. The medium risk scores captured in land and infrastructure categories reveal promising determinants of the adaptation of women in this rural province. The results demonstrate the usefulness of the WCV index in collecting bottom-up data, evaluating a wide variety of risks that rural women face and pinpointing priority areas that need to be addressed.Originality/valueThe WCV is systematic, customisable and localised. It combines field research and empirical data through structured expert judgment, thus enables researchers to fill data gaps and to do evidence-based assessment about diverse risk vulnerabilities. By doing so, the WCV index gives critical insights into the challenges that rural women face. This enables local governments to better understand cross-sectoral risks, pinpoint priority areas of action and timely channel funding and policy resources to support women where they need it most.\n",
      "--------------------------------------------------\n",
      "Topic 213: 213_urban_albedo_roofs_land\n",
      "Representative Documents:\n",
      "  - A parameterization for urban surfaces has been incorporated into the Community Land Model as part of the Community Climate System Model. The parameterization allows global simulation of the urban environment, in particular the temperature of cities and thus the urban heat island. Here, the results from climate simulations for the AR4 A2 emissions scenario are presented. Present‐day annual mean urban air temperatures are up to 4 °C warmer than surrounding rural areas. Averaged over all urban areas resolved in the model, the heat island is 1.1 °C, which is 46% of the simulated mid‐century warming over global land due to greenhouse gases. Heat islands are generally largest at night as evidenced by a larger urban warming in minimum than maximum temperature, resulting in a smaller diurnal temperature range compared to rural areas. Spatial and seasonal variability in the heat island is caused by urban to rural contrasts in energy balance and the different responses of these surfaces to the seasonal cycle of climate. Under simulation constraints of no urban growth and identical urban/rural atmospheric forcing, the urban to rural contrast decreases slightly by the end of the century. This is primarily a different response of rural and urban areas to increased long‐wave radiation from a warmer atmosphere. The larger storage capacity of urban areas buffers the increase in long‐wave radiation such that urban night‐time temperatures warm less than rural. Space heating and air conditioning processes add about 0.01 W m−2 of heat distributed globally, which results in a small increase in the heat island. The significant differences between urban and rural surfaces demonstrated here imply that climate models need to account for urban surfaces to more realistically evaluate the impact of climate change on people in the environment where they live. Copyright © 2010 Royal Meteorological Society\n",
      "  - The surface energy budget has been used to illustrate the influence of urban landscape on both global and regional climate. This was done using empirical as well as remotely sensed data of components of the surface energy equation.At the global scale, the urban land cover has the least impact on the sensible and latent heat fluxes compared to the other land cover types. Replacing the urban land cover with vegetation did not result in a significant change to the proportionate values of the turbulent fluxes originally due to vegetation. The least impact of current urbanization on the global climate in terms of radiation and surface fluxes is because the urban land cover has the smallest fraction of all the land cover types.The relative importance of the urban landscape at the regional scale was illustrated using the example of Chester County and surroundings near Philadelphia, Pennsylvania, in the USA. The urban effect becomes more important as the fraction of urban land cover to the total increases. This is illustrated by computing turbulent fluxes for 1987, 1988, 1991, 1993 and 1996 over the Chester County area. Urbanization in Chester County and surrounding areas increased from 11% in 1987 to 19% in 1996. In 1996, urban land cover produced the largest proportionate sensible (21.4 Wm−2) and latent (14.2 Wm−2) heat fluxes during winter. During the 1996 summer, urban and vegetation land cover produced the largest proportionate sensible heat (59.2 Wm−2) while urban land cover produced the second largest proportionate latent heat flux (39.5 Wm−2). The implications of this simple analytical study point to the need to account for the urban landscape particularly in regional studies. Copyright © 2009 Royal Meteorological Society\n",
      "  - Urban greening is often proposed for urban heat island (UHI) mitigation because vegetation provides shade and increases evapotranspiration. However, vegetation has lower albedo and higher emissivity than the bare soil it often replaces, which increases incoming energy fluxes. Here, we use the Weather Research and Forecasting model to quantify and compare the albedo and non‐albedo effects (i.e., changes in emissivity, surface roughness, and evaporative fluxes) of urban greening in the Los Angeles Basin under policy relevant urban greening scenarios. When albedo‐induced effects were included in the model, daytime surface temperatures in urban areas warmed by 0.70 ± 0.89°C with increases in the sensible heat flux outweighing increases in the latent heat flux from increased evapotranspiration. In contrast, daytime surface temperatures cooled by 0.27 ± 0.72°C when the albedo‐induced effects were ignored. At night, including albedo‐induced effects of urban greening resulted in only half the cooling modeled in the non‐albedo simulations. Near surface air temperatures also had contrasting model results, with nighttime cooling of 0.21 ± 0.47°C outweighing slight daytime warming of 0.04 ± 0.32°C in the non‐albedo simulations and daytime warming of 0.33 ± 0.41°C outweighing slight nighttime cooling of 0.05 ± 0.46°C in the albedo simulations. Our results reveal the critical role that albedo plays in determining the net surface climate effects of urban greening. Reductions in albedo from urban greening should be carefully considered by policy makers and urban planners, especially as high albedo roofs and pavements are simultaneously being deployed for UHI mitigation in many cities.\n",
      "--------------------------------------------------\n",
      "Topic 214: 214_co2_gasification_syngas_h2\n",
      "Representative Documents:\n",
      "  - In this study, plasma reforming of toluene as a tar model compound from biomass gasification has been carried out using an AC gliding arc discharge reactor. The influence of steam and CO2 addition on the reforming of toluene has been evaluated. The results show that the highest toluene conversion (59.9%) was achieved when adding 3 vol% CO2 at a toluene concentration of 16.1 g/Nm3 and a specific energy input of 0.25 kWh/m3. Further increasing CO2 concentration to 12 vol% decreased the conversion of toluene. The presence of steam in the plasma CO2 reforming of toluene creates oxidative OH radicals which contribute to the enhanced conversion of toluene and energy efficiency of the plasma reforming process through stepwise oxidation of toluene and reaction intermediates. Hydrogen and C2H2 were identified as the major gas products in the plasma reforming of toluene without CO2 or steam, with a yield of 9.7% and 14.5%, respectively, while syngas was the primary products with a maximum yield of 58.3% (27.5% for H2 and 30.8% for CO) in the plasma reforming with the addition of 12 vol% CO2. The plausible reaction pathways and mechanism in the plasma reforming of toluene have been proposed through the combination of the analysis of gas and condensed products and spectroscopic diagnostics.\n",
      "  -                Discarded cigarette butts contain polymers, biomass, and a variety of toxins that cause an adverse effect to the human health and environment for years. The cigarette residuals are not recyclable and often get mixed with other kinds of wastes so that much of this waste ends up in landfills. This study investigates the safe disposal of cigarette butts by the thermochemical pathways using pyrolysis and gasification. Mass loss during its thermal decomposition was examined first using a thermogravimetric analyzer. The effect of temperature on the pyrolysis and CO2-assisted gasification was then conducted using a semi-batch reactor with a focus on the flowrate of total syngas and its gas components. Syngas yield, energy recovery, as well as energy efficiency were calculated and compared. The effect of temperature on the CO2 consumption during the gasification process was also examined. The thermal decomposition of cellulose acetate, tar, and wrapping paper were the main contributors during the pyrolysis of cigarette butt. However, the gasification process mainly consisted of the pyrolysis, cracking, and reforming reactions in the gas phase and gasification of char derived from wrapping paper. An increase in temperature enhanced the syngas flowrate, syngas yield, and gas efficiency while decreasing the char yield and reaction time for both the processes. Energy recovery from gasification was higher than pyrolysis due to added CO generation. The maximum syngas energy of 13.0 kJ/g under the gasification condition at 1223 K was 67.2% higher as compared with the pyrolysis. High temperature strongly affected the gasification reaction, while it was negligible at a temperature lower than 1023 K. Complete conversion occurred during gasification at 1223 K that provided only ash residue. The CO2 gasification of cigarette butts provided an effective pathway to utilize 0.5 g CO2/g feedstock at 1223 K to form valuable CO by the Boudouard reaction. Compared with the gasification of other solid wastes, syngas energy yield from cigarette butts was found to be higher than syngas from polystyrene and polyethylene terephthalate. These results support the effectiveness of thermochemical pathways in the rapid conversion of cigarette butts to valuable syngas along with CO2 utilization.\n",
      "  -                Syngas production from catalytic gasification of polystyrene and pinewood in CO2 atmosphere was investigated over Ni-Mg/Al2O3 catalyst in a fixed-bed reactor at 900 °C. A quasi in situ method was adopted for catalytic gasification wherein the catalyst placed downstream of the feedstock in the same reactor was used for enhanced syngas production. The effect of catalyst on evolutionary behavior, cumulative syngas yield, syngas composition, and cold gas efficiency was systematically analyzed. The results showed that addition of catalyst for polystyrene gasification resulted in enhanced yields of 63% H2, 20% CO, 119% CH4, and 85% C2-C3 yields. Enhanced H2 and light hydrocarbon yields were mainly from enhanced cracking of pyrolytic vapors from polystyrene degradation, while the CO yield was attributed to CO2-assisted reforming of benzene derivatives from primary cracking and polycyclic aromatic hydrocarbons (PAHs) from secondary gas phase condensations. The yields of H2, CO, CH4, and C2-C3 from pinewood gasification in the presence of catalyst was also enhanced by 150%, 14%, 39%, and 16%, respectively, indicating that Ni-Mg/Al2O3 catalyst can efficiently enhance syngas production in CO2-assisted gasification. A comparison of syngas composition between non-catalytic and catalytic conditions revealed improved syngas quality in catalytic gasification with increased H2 mole fraction but decreased CO mole fraction. Furthermore, cold gas efficiency enhanced from 44% to 57% in catalytic polystyrene gasification, and from 75% to 94% in catalytic pinewood gasification. The results suggest that catalytic CO2 gasification offers a promising pathway for efficient energy production from wastes plastics and biomass while simultaneously using CO2.\n",
      "--------------------------------------------------\n",
      "Topic 215: 215_initialization_skill_prediction_sea ice\n",
      "Representative Documents:\n",
      "  -                This paper investigates the impact of different ocean initialization strategies on the forecast skill of decadal prediction experiments performed with the ECHAM5/Max Planck Institute Ocean Model (MPI-OM) coupled model. The ocean initializations assimilate three-dimensional temperature and salinity anomalies from two different ocean state estimates, the ocean reanalysis of the German contribution to Estimating the Circulation and Climate of the Ocean (GECCO) and an ensemble of MPI-OM ocean experiments forced with the NCEP–NCAR atmospheric reanalysis. The results show that North Atlantic and Mediterranean sea surface temperature (SST) variations can be skillfully predicted up to a decade ahead and with greater skill than by both uninitialized simulations and persistence forecasts. The regional distribution of SST predictive skill is similar in both initialization approaches; however, higher skill is found for the NCEP hindcasts than for the GECCO hindcasts when a combination of predictive skill measures is used. Skillful predictions of surface air temperature are obtained over northwestern Europe, northern Africa, and central-eastern Asia. The North Atlantic subpolar gyre region stands out as the region with the highest predictive skill beyond the warming trend, in both SST and upper-ocean heat-content predictions. Here the NCEP hindcasts deliver the best results due to a more accurate initialization of the observed variability. The dominant mechanism for North Atlantic climate predictability is of dynamical origin and can be attributed to the initialization of the Atlantic meridional overturning circulation, thus explaining the reoccurrence of high predictive skill within the second pentad of the hindcasts experiments. The results herein demonstrate that ocean experiments forced with the observed history of the atmospheric state constitute a simple but successful alternative strategy for the initialization of skillful climate predictions over the next decade.\n",
      "  - . Decadal climate predictions, obtained by constraining the initial condition of a dynamical model through a truthful estimate of the observed climate state, provide an accurate assessment of near-term climate change and are a useful tool to inform decision-makers on future climate-related risks. Here we present results from the CMIP6 (Coupled Model Intercomparison Project Phase 6) Decadal Climate Prediction Project (DCPP) decadal hindcasts produced with the operational CMCC (Euro-Mediterranean Center on Climate Change) decadal prediction system (DPS), based on the fully coupled CMCC-CM2-SR5 dynamical model. A 20-member suite of 10-year retrospective forecasts, initialized every year from 1960 to 2020, is performed using a full-field initialization strategy. The predictive skill for key variables is assessed and compared with the skill of an ensemble of non-initialized historical simulations so as to quantify the added value of the initialization. In particular, the CMCC DPS is able to skillfully reproduce past climate surface and subsurface temperature fluctuations over large parts of the globe. The North Atlantic Ocean is the region that benefits the most from initialization, with the largest skill enhancement occurring over the subpolar region compared to historical simulations. On the other hand, the predictive skill over the Pacific Ocean rapidly decays with forecast time, especially over the North Pacific. In terms of precipitation, the skill of the CMCC DPS is significantly higher than that of the historical simulations over a few specific regions, including the Sahel, northern Eurasia, and over western and central Europe. The Atlantic multidecadal variability is also skillfully predicted, and this likely contributes to the skill found over remote areas through downstream influence, circulation changes, and teleconnections. Considering the relatively small ensemble size, a remarkable prediction skill is also found for the North Atlantic Oscillation, with maximum correlations obtained in the 1–9 lead year range. Systematic errors also affect the forecast quality of the CMCC DPS, featuring a prominent cold bias over the Northern Hemisphere, which is not found in the historical runs, suggesting that, in some areas, the adopted full-field initialization strategy likely perturbs the equilibrium state of the model climate quite significantly. The encouraging results obtained in this study indicate that climate variability over land can be predictable over a multiyear range, and they demonstrate that the CMCC DPS is a valuable addition to the current generation of DPSs. This stresses the need to further explore the potential of the near-term predictions, further improving future decadal systems and initialization methods, with the aim to provide a reliable tool to inform decision-makers on how regional climate will evolve in the next decade.\n",
      "  - . A substantial part of Arctic climate predictability at interannual timescales stems from the knowledge of the initial sea ice conditions. Among all sea ice properties, its volume, which is a product of sea ice concentration (SIC) and thickness (SIT), is the most responsive parameter to climate change. However, the majority of climate prediction systems are only assimilating the observed SIC due to lack of long-term reliable global observation of SIT. In this study, the EC-Earth3 Climate Prediction System with anomaly initialization to ocean, SIC and SIT states is developed. In order to evaluate the regional benefits of specific initialized variables, three sets of retrospective ensemble prediction experiments are performed with different initialization strategies: ocean only; ocean plus SIC; and ocean plus SIC and SIT initialization. In the Atlantic Arctic, the Greenland–Iceland–Norway (GIN) and Barents seas are the two most skilful regions in SIC prediction for up to 5–6 lead years with ocean initialization; there are re-emerging skills for SIC in the Barents and Kara seas in lead years 7–9 coinciding with improved skills of sea surface temperature (SST), reflecting the impact of SIC initialization on ocean–atmosphere interactions for interannual-to-decadal timescales. For the year 2–9 average, the region with significant skill for SIT is confined to the central Arctic Ocean, covered by multi-year sea ice (CAO-MYI). Winter preconditioning with SIT initialization increases the skill for September SIC in the eastern Arctic (e.g. Kara, Laptev and East Siberian seas) and in turn improve the skill of air surface temperature locally and further expanded over land. SIT initialization outperforms the other initialization methods in improving SIT prediction in the Pacific Arctic (e.g. East Siberian and Beaufort seas) in the first few lead years. Our results suggest that as the climate warming continues and the central Arctic Ocean might become seasonal ice free in the future, the controlling mechanism for decadal predictability may thus shift from sea ice volume to ocean-driven processes.                    \n",
      "--------------------------------------------------\n",
      "Topic 216: 216_gpa_h2o_inclusions_fluid\n",
      "Representative Documents:\n",
      "  -                —Experimental modeling of decarbonation reactions with the formation of Mg,Fe-garnets and CO2 fluid during mantle–crust interactions was carried out in a wide range of the upper-mantle pressures and temperatures. Experimental studies were performed in the MgCO3–Al2O3–SiO2 and (Mg,Fe)CO3–Al2O3–SiO2 systems in the pressure range 3.0–7.5 GPa and temperature range 950–1450 °C (t = 10– 60 h), using a multianvil high-pressure apparatus of the “split-sphere” type (BARS). Experiments were carried out with a specially designed high-pressure buffered cell with a hematite container that prevents the diffusion of hydrogen into a Pt-capsule with a sample. It has been experimentally established that in the MgCO3–Al2O3–SiO2 system decarbonation occurs by the schematic reaction MgCO3 + SiO2 + Al2O3 → Mg3Al2Si3O12 + CO2 at 1100 ± 20 °C (3.0 GPa), 1150 ± 20 °C (6.3 GPa), and 1400 ± 20 °C (7.5 GPa) and in the (Mg,Fe)CO3–Al2O3– SiO2 system, by the reaction (Mg,Fe)CO3 + SiO2 + Al2O3 → (Mg,Fe)3Al2Si3O12 + CO2 at 1000 ± 20 °C (3.0 GPa), 1150 ± 20 °C (6.3 GPa), and 1400 ± 20 °C (7.5 GPa). Based on Raman spectroscopic characterization of the synthesized garnets, the position of the main modes R, υ2, and υ1 in the pyrope has been determined to be 364, 562, and 924–925 cm-1, respectively, and that in pyrope-almandine, 350–351, 556–558, and 918–919 cm-1. The effectiveness of the hematite container was demonstrated by means of mass spectrometry analysis. It has been found that the fluid composition corresponded to pure CO2 in all experiments. The P,T-positions of decarbonation curves leading to the formation of a CO2 fluid in assemblage with pyrope and pyrope-almandine have been experimentally reconstructed and compared with the previous calculation and experimental data. It has been established that the experimentally reproduced reaction lines with the formation of pyrope + CO2 or pyrope-almandine + CO2 assemblages are shifted to lower temperatures by 50–150 °C relative to the calculated ones. When considering the obtained results with regard to the stability of natural carbonates of various compositions in subduction settings, it has been found that at depths of ~90–190 km Mg,Fe-carbonates react with oxides in the temperature range 1000–1250 °C, and at depths of ~225 km, at 1400 °C.\n",
      "  -                Melting phase relations involving model carbonated basalt with excess silica were studied in experiments over the pressure range of 4–7 GPa in the system CaO-MgO-Al2O3-SiO2-CO2 to determine if there is a sharp decrease in the melting temperatures along the transition from carbon dioxide vapor (vapor) to dolomite. The phase assemblages of clinopyroxene + garnet + coesite + vapor + carbon dioxide-bearing silicate liquid (silicate liquid) and clinopyroxene + garnet + coesite + dolomite + carbonate liquid, exist over 4–5 and 5.8–7 GPa, respectively. These two distinct phase assemblages form the two, vapor + silicate liquid and dolomite + carbonate liquid-bearing divariant surfaces. The dissolved carbon dioxide and the molar calcium number [Ca# 100*(Ca/Ca + Mg)] of the silicate and carbonate liquids are approximately 4–8 wt% and between 50–55 and 35–40 wt% and 69–71, respectively. The compositions of phases vary little, implying minimal topography along the two surfaces, and the temperatures rise linearly along the silicate liquid-bearing divariant surface over 4–5 GPa. Between 5.2 and 5.6 GPa, however, the temperatures decrease precipitously by ~200–250°C and, along with this steep decline, the liquid changes from silicate to carbonate, with the rest of the phase assemblage of clinopyroxene + garnet + coesite + vapor, persisting. Hence, and this is important to emphasize, this liquid, coexisting with vapor, is carbonate in composition in the absence of dolomite. Isobaric invariance, at 5.4 GPa/1250°C, 5.6 GPa/1150°C, and 5.8 GPa/1100°C, consists of the six-phase assemblage of clinopyroxene + garnet + coesite + vapor + dolomite + carbonate liquid. Melting phase relations are thus univariant, and correspond to that of a solidus ‘ledge’, i.e. with a negative Clapeyron slope, in this part of the composition space. The melting reaction along the ledge is clinopyroxene + vapor = garnet + coesite + dolomite + carbonate liquid, and the ledge separates the two divariant surfaces. The Ca# of the coexisting carbonate liquid and dolomite here are opposite to those of the carbonate liquid and dolomite on the calcite-magnesite join at similar pressures as in this study. This is most likely a consequence of the combined effects of (a) observations from experiments and theory that the fusion curve of calcite starts to diverge from that of magnesite toward lower temperatures at pressures in excess of ~5 GPa, and (b) the pressure, where ultrabasic silicate–carbonate (~2.5–3 GPa) and excess-silica carbonate-basalt (&amp;gt;4 GPa, as inhere) systems undergo carbonation. These, in turn, cause the liquid and dolomite in experiments here to become more calcic and more magnesian than observed in experiments on the calcite-magnesite join. The solidus ledge, here, has a profound effect because the most plausible modern-day model ocean crust subduction zone geotherms in Earth will, in all likelihood, intersect it and cause fusion of dolomite, thereby, in effect, liberating all carbon from what once was a carbonate-basalt mixture. Thereafter, little exists to suggest that there is anything ‘deep’ to the carbon cycle, through recycling, with most of it likely confined to less than ~200 km in Earth.\n",
      "  -                Many lines of evidence from high P–T experiments, thermodynamic models, and natural observations suggest that slab-derived aqueous fluids, which flux mantle wedges contain variable amounts of dissolved carbon. However, constraints on the effects of H2O–CO2 fluids on mantle melting, particularly at mantle wedge P–T conditions, are limited. Here, we present new piston cylinder experiments on fertile and depleted peridotite compositions with 3.5 wt.% H2O and XCO2 [= molar CO2 / (CO2 + H2O)] of 0.04–0.17. Experiments were performed at 2–3 GPa and 1350°C to assess how temperature, peridotite fertility, and XCO2 of slab-derived fluid affects partial melting in mantle wedges. All experiments produce olivine + orthopyroxene +7 to 41 wt.% partial melt. Our new data, along with previous lower temperature data, show that as mantle wedge temperature increases, primary melts become richer in SiO2, FeO*, and MgO and poorer CaO, Al2O3, and alkalis when influenced by H2O–CO2 fluids. At constant P–T and bulk H2O content, the extent of melting in the mantle wedge is largely controlled by peridotite fertility and XCO2 of slab-fluid. High XCO2 depleted compositions generate ~7 wt.% melt, whereas, at identical P–T, low XCO2 fertile compositions generate ~30 to 40 wt.% melt. Additionally, peridotite fertility and XCO2 have significant effects on peridotite partial melt compositions. At a constant P–T–XCO2, fertile peridotites generate melts richer in CaO and Al2O3 and poorer in SiO2, MgO + FeO, and alkalis. Similar to previous experimental studies, at a constant P–T fertility condition, as XCO2 increases, SiO2 and CaO of melts systematically decrease and increase, respectively. Such distinctive effects of oxidized form of dissolved carbon on peridotite partial melt compositions are not observed if the carbon-bearing fluid is reduced, such as CH4-bearing. Considering the large effect of XCO2 on melt SiO2 and CaO concentrations and the relatively oxidized nature of arc magmas, we compare the SiO2/CaO of our experimental melts and melts from previous peridotite + H2O ± CO2 studies to the SiO2/CaO systematics of primitive arc basalts and ultra-calcic, silica-undersaturated arc melt inclusions. From this comparison, we demonstrate that across most P–T–fertility conditions predicted for mantle wedges, partial melts from bulk compositions with XCO2 ≥ 0.11 have lower SiO2/CaO than all primitive arc melts found globally, even when correcting for olivine fractionation, whereas partial melts from bulk compositions with XCO2 = 0.04 overlap the lower end of the SiO2/CaO field defined by natural data. These results suggest that the upper XCO2 limit of slab-fluids influencing primary arc magma formation is 0.04 &amp;lt; XCO2 &amp;lt; 0.11, and this upper limit is likely to apply globally. Lastly, we show that the anomalous SiO2/CaO and CaO/Al2O3 signatures observed in ultra-calcic arc melt inclusions can be reproduced by partial melting of either CO2-bearing hydrous fertile and depleted peridotites with 0 &amp;lt; XCO2 &amp;lt; 0.11 at 2–3 GPa, or from nominally CO2-free hydrous fertile peridotites at P &amp;gt; 3 GPa.\n",
      "--------------------------------------------------\n",
      "Topic 217: 217_aerosols_organic aerosols_cooking_arctic wildlife\n",
      "Representative Documents:\n",
      "  - Atmospheric aging through diverse reaction pathways modifies redox potential and composition of organic aerosols, leading to varied dynamic behaviors of aerosols in the respiratory system and endpoint toxic results.\n",
      "  - Sulfur aerosols and soot from supersonic aircraft may cause greater climate impacts than the emitted CO2. Both fuel composition and cruise altitude must be considered when evaluating the effects of supersonic aircraft on climate and the ozone layer.\n",
      "  - Mixed fleet particle number emission factors as derived from 3 years of size-resolved particle flux observations show about 2/3 of emission in the nucleation mode &lt;30 nm. Long-term monitoring helps to understand variation in emission factors.\n",
      "--------------------------------------------------\n",
      "Topic 218: 218_adaptation_municipalities_design_social innovation\n",
      "Representative Documents:\n",
      "  - Climate change, with various economic, environmental and social consequences, is one of the greatest challenges faced by society. Climate change governance in forestry and nature conservation includes developing joint activities and collaboration among stakeholders that combine different interests, influences and competences at national, regional and local levels. This research aims to classify climate change stakeholders within the forestry and nature conservation sectors in Serbia. They are classified according to their interests and perceived influences. We analyze factors impacting the development of different areas for the collaboration by combining stakeholder analysis and social network analysis. A total of 103 representatives of civil society and public sector organizations in forestry and nature conservation at different governance levels with expertise in climate change participated in the survey. The results show that most civil sector organizations are distributed in the ‘subject’ quadrant with lower perceived influence and are not well interconnected. Seven different areas for the collaboration were identified, with disconnected stakeholders and limited representation and mostly peripheral position of civil society organizations (except in the case of the area for the collaboration through workshop and seminars knowledge exchange). The analyzed factors have different positive and negative effects on the development of the different areas for the collaboration, with the frequency of contacts standing out as a significant factor of collaboration at the level of the whole collaboration network. There is a strong indication of a centralized, top-down approach to climate change governance in forestry and nature conservation in Serbia. Multilevel and horizontal stakeholder governance is needed to achieve effective implementation of strategic climate-change policy commitments. The most important step to achieve such a structure is the empowerment of local-level organizations in climate change collaboration.\n",
      "  -                                  Background                  The headline goal for SDG13 focus specially on strengthening resilience, adaptive capacity to climate-related hazards and natural disasters as well as integrating climate change measures into national policies, strategies and planning. In Colombia, the increase in rainfall and temperature jeopardize the well-being of the population. The Transdisciplinary Seminar on Environmental Health and Climate Change drives the strengthening of multisectoral research on impacts and vulnerability in the territory, promotes the construction of collective adaptation strategies that mitigate the health effects of recent emergency climate declaration.                                                Objective                  ZIGZAG Knowledge Management (ZIGZAG-KM) generate common points from a collective construction on the Climate Change Adaptation Plan from the Environmental Health Component guided by participants. The steps of this methodology lead the stakeholders to develop practical constructions with freedom of adaptation and change, capacity for a new learning culture and an opportunity for collaboration in a team that identifies and balances their interests from a community approach, local resilience and citizen science. After 18 months we concrete a consensus Report on the determination of the contextual vulnerability analysis as a technical outcomes, nowadays, the scientific results are running on and will be included in a Report of collaborative learning about citizen scientists oriented for implement strategies of the adaptation plan with a community approach for Antioquia and the strengthening citizen participation actions to impulse collectively resilience to climate change. This Seminar was structured about multidisciplinary theoretical rules and transdisciplinary practical considerations, which will contribute in the social understanding of adaptation strategies.                                                Conclusions                  In spite of the efforts, the culture of knowledge transformation continues to be limited due to interests that may arise among the participants.                                                Key messages                  ZIGZAG-KM learning guided by experts, decision makers and defenders of health and the environment. Transdisciplinary orientation in thematic dialogues and actions is useful health adaptation on Climate Change and Emergency Climate Declaration.               \n",
      "  -                                  Background                  In 2022 the Norwegian Institute for Public Health was asked to ascertain how local authorities help their citizens maintain a healthy, sustainable and climate-friendly diet. The research should identify the barriers and promoting factors involved, and pinpoint national policies and tools that would support the local authorities, using quantitative and qualitative methods.                                                Methods                  356 municipalities and 10 counties were asked to fill in an online questionnaire. 6 municipalities and 6 counties took part in qualitative interviews. Interview transcripts and text from the 180 received questionnaires were subjected to content analysis and combined with questionnaire data in a mixed methods analysis.                                                Results                  The municipalities did not consider sustainability and climate in their nutrition work, apart from projects on food waste. The counties were involved on their own behalf and also tried to support the municipalities. Main barriers for the municipalities were lack of personnel (67%), economic resources (65%), and competence (48%). Several municipalities indicated that lack of policy foundations and support from local authorities along with lack of knowledge about local challenges hindered this work. The opportunities indicated by the municipalities were making nutrition a part of local policies and budgets (55%) and making the prioritization of nutrition visible within the municipality (66%). Local cooperation and having access to personnel with nutritional competence and responsibility for nutrition were also considered important. The counties saw their roles as facilitators and distributors of project funds to the municipalities, but many of them required more resources to fulfil their duties.                                                Conclusions                  The municipalities’ work to promote a healthy and sustainable diet is inadequately anchored in Norwegian municipalities’ policies and governance. The municipalities need interventions and tools to increase the public health sector's competence in the field.                                                Key messages                  • Municipalities should include nutrition and sustainability in local planning, policy, and governance.                  • Counties should be provided with tools that help them to support local level work.               \n",
      "--------------------------------------------------\n",
      "Topic 219: 219_gasification_carbonation_ashes_combustion\n",
      "Representative Documents:\n",
      "  - Since 1980, one of the most promising solutions for the exploitation of natural gas hydrate reservoirs was found to be the replacement of methane with carbon dioxide in order to improve the efficiency of methane recovery and, at the same time, permanently store carbon dioxide. However, the process efficiency is still too low and far from reaching technical maturity and becoming economically competitive. In this sense, studying the intrinsic properties of CO2 hydrates formation and dissociation processes may help in better defining the reasons for this low efficiency and finding feasible solutions. This work deals with carbon dioxide hydrates formation in a natural silica-based porous medium and in fresh water. A lab-scale apparatus was used for experiments, which were carried out consecutively and with the same gas–water mixture in order to detect the possible occurrence of the “memory effect”. Six tests were carried out: the quantity of gas available for the formation of hydrates led to an initial pressure equal to 39.4 bar within the reactor (the initial pressure was 46 bar; however, the dissolution of CO2 in water during the first test caused a reduction in the quantity of gas available for the process). Each experiment started and ended at temperatures equal or higher than 20 °C. Considering the local pressures, these temperatures ensured the complete dissociation of hydrates. Besides thermodynamic parameters, the gas consumption and the rate constant were evaluated throughout the whole of the experiments. Conversely to what is asserted in the literature, the results demonstrated the weak persistence of the memory effect at a temperature slightly above 25 °C. As expected, ice formation competed with hydrates; however, during tests, it caused the partial release of carbon dioxide previously trapped into hydrates or dissolved in water. Finally, the rate constant completely agreed with the labile Cluster Theory and proved that primordial clusters and hydrate crystals formed and dissociated during the whole test. The first phenomenon was predominant during the formation phase, while the opposite occurred during the following step. The rate constant was found to be an effective parameter to quantify differences between measured and real equilibrium conditions for the system.\n",
      "  - An autothermal fluidized bed reactor was used to research the influence of pressure (0–2 barg) on the gasification process of different types of biomasses. The tested feedstocks were bark and lignin while softwood pellet was used as a reference fuel. A mixture of O2/CO2/H2O was used as a gasification agent. The impact of the application of CO2 on the yield of H2 in product gas was determined. Resulting product gas was characterized by a high content of CO which makes its use for applications based on chemical synthesis very difficult without extensive upgrading or supply of H2 from external sources. CO2 proved to improve carbon conversion efficiency (CCE) of the gasification process and to be an option for its chemical sequestration (negative carbon footprint). A slight modification of conventional indices used to evaluate efficiencies of gasification systems (CCE and water/carbon ratio) was proposed, to take into account the impact of the additional source of carbon fed into the reactor. The increase of system pressure led to changes in the composition of the product gas in line with predictions of Le Chatelier’s principle. The influence was predominantly visible in higher yields of CH4 and lower overall production of product gas. For higher hydrocarbons (CxHy), the trend was unclear. A set of stable gasification parameters were achieved for each pressure level and a standard gasification temperature of 850 °C, except for gasification of lignin performed at 2 barg. A proposed explanation for the problem is the combined effect of the increasing concentration of ash in the fluidized bed and its low characteristic melting temperatures. Due to the obtained experimental findings, a new ash agglomeration index was formulated.\n",
      "  - The production of electricity and heat in Poland is the reason why the commercial power industry is the largest emitter of CO2. At the same time, significant amounts of solid by-products of combustion, which can be used to bind CO2 by mineral carbonation, are generated during the production processes. The article presents the results of research on mineral sequestration of CO2 (suspension-CO2) using fluidized bed combustion (FBC) fly ashes from hard coal combustion. The analyzed fluidized bed combustion (FBC) fly ashes were characterized by a significant free CaO content (1.7–6.8%) and a high CO2 binding potential ranging from 9.7 to 15.7%. In the case of fluidized bed combustion (FBC) fly ashes suspensions, the basic product of the carbonation process is calcium carbonate, which is clearly indicated by the results of the phase composition determination of solidified suspensions of fluidized bed combustion (FBC) fly ashes. The degree of carbonation, i.e. the degree of CO2 binding, calculated on the basis of the calcium carbonate content, in the analyzed suspensions was up to 1.1%. Mineral carbonation also reduces the leachability of pollutants such as: Zn, Cu, Pb, Ni, As, Hg, Cd, Cr, Cl, and SO42-. The pH is also reduced from about 12 to about 9. Aqueous suspensions of fluidized bed combustion (FBC) fly ashes with introduced CO2 can potentially be used in underground mining. These activities are in line with the concepts of Carbon Capture and Utilization and the idea of circular economy.\n",
      "--------------------------------------------------\n",
      "Topic 220: 220_health_public_cancer_public health\n",
      "Representative Documents:\n",
      "  - We used data from nationally representative surveys conducted in the United States, Canada and Malta between 2008 and 2009 to answer three questions: Does the public believe that climate change poses human health risks, and if so, are they seen as current or future risks? Whose health does the public think will be harmed? In what specific ways does the public believe climate change will harm human health? When asked directly about the potential impacts of climate change on health and well-being, a majority of people in all three nations said that it poses significant risks; moreover, about one third of Americans, one half of Canadians, and two-thirds of Maltese said that people are already being harmed. About a third or more of people in the United States and Canada saw themselves (United States, 32%; Canada, 67%), their family (United States, 35%; Canada, 46%), and people in their community (United States, 39%; Canada, 76%) as being vulnerable to at least moderate harm from climate change. About one third of Maltese (31%) said they were most concerned about the risk to themselves and their families. Many Canadians said that the elderly (45%) and children (33%) are at heightened risk of harm, while Americans were more likely to see people in developing countries as being at risk than people in their own nation. When prompted, large numbers of Canadians and Maltese said that climate change can cause respiratory problems (78–91%), heat-related problems (75–84%), cancer (61–90%), and infectious diseases (49–62%). Canadians also named sunburn (79%) and injuries from extreme weather events (73%), and Maltese cited allergies (84%). However, climate change appears to lack salience as a health issue in all three countries: relatively few people answered open-ended questions in a manner that indicated clear top-of-mind associations between climate change and human health risks. We recommend mounting public health communication initiatives that increase the salience of the human health consequences associated with climate change.\n",
      "  -                 Background                Rural health professionals stand at the forefront of community response to climate change, but few studies have assessed their perceptions of the threat. Further, no previous study has compared the opinions of environmental to public health professionals or extensively analyzed the factors related to these experts’ climate beliefs, risk perceptions, and issue prioritization.                              Methods                In conjunction with the Montana Climate Assessment’s 2021 Special Report on Climate Change and Human Health, the 479 members of the Montana Public Health Association and Montana Environmental Health Association were surveyed during September–October 2019, with 39% completing the survey. We summarized descriptive data about their perceptions of local climate-related changes and their beliefs that global warming is happening, is mostly human-caused, is a risk to human health, and that their offices and others should take action. We also evaluated which sociodemographic and risk perception factors related to these climate beliefs, risk perceptions, and workplace issue prioritization.                              Results                Health professionals in Montana, a politically conservative state, demonstrated high levels of awareness that global warming is happening, human-caused, and a threat to human health, well above reported rates of public concern. Eighty-eight percent said that global warming is occurring and 69% that it is mostly anthropogenic. Sixty-nine percent said that their own health was already affected by climate, and 86% said they were already seeing at least one climate change-related event in their communities. Seventy-two percent said that their departments should be preparing to deal with climate change’s health effects, but just 30% said that it is currently happening. We found no statistically significant differences between Montana environmental health and public health professionals in regression models predicting climate beliefs, risk perception, and prioritization. As in studies of the public, political ideology and the observation of local climate-related changes were the strongest factors.                              Conclusions                Montana environmental and public health officials said that departmental action was needed on climate change, indicating the readiness of rural health professionals to take action. Further studies of health professionals in rural regions are warranted.              \n",
      "  -  e13623  Background: Climate change is one of the largest threats to human health and greenhouse gas (GHG) emissions are a substantial component of climate change. In the U.S., the healthcare industry accounts for an estimated 8.5% of GHG emissions, equating to the loss of 470,000 disability-adjusted life-years annually. Cancer care encapsulates a significant portion of hospital resources and climate change has disproportionate effects on cancer patients. Therefore, it is imperative and urgent that cancer centers actively engage in reducing healthcare related GHG emissions. In this systematic analysis and comprehensive review, we reviewed publicly accessible sustainability plans of National Cancer Institute (NCI)-designated Cancer Centers and their affiliated organizations to understand the involvement Cancer Centers have in their organization's sustainability efforts. Methods: We reviewed 64 NCI designated Cancer Centers, using the first 20 results of a Google search with terms: “Hospital X AND (climate action plan OR climate change OR sustainability plan OR carbon neutral)” and hospital homepages to identify publicly accessible sustainability plans for each organization. We reviewed the plans, performed a Google search/Cancer Center homepage search and messaged sustainability plan developers to identify involvement of the hospital and Cancer Center. We identified which hospitals assigned sustainability personnel. We performed a student’s t-test to assess for a correlation between incidence of lung cancer in a state and presence of a sustainability plan for that state’s Cancer Center. Data was collected by one reviewer, independently validated by a separate reviewer and differences were resolved by a joint data review. Results: Amongst the 65 Cancer Centers and organizations reviewed, 55 (36 university, 12 hospital, 7 joint) had publicly available sustainability plans. Of which, 31% (11/36) of university plans explicitly mentioned an affiliated hospital as part of the sustainability plan. Two Cancer Centers (3%) had independent sustainability plans and 7 (11%) centers mentioned sustainability on their homepage. 77% (23/30) of hospitals with sustainability plans identified sustainability personnel. We did not find an association between the existence of Cancer Center sustainability plan and that state’s lung cancer incidence rates (p = 0.932). Conclusions: In this review and analysis of NCI-designated Cancer Center sustainability plans, we found that while most centers’ affiliated organizations have publicly accessible sustainability plans, the majority (86%) of centers do not independently report on their sustainability efforts. These findings highlight a pressing need to increase engagement between Cancer Centers and their organizations regarding sustainability plans, and a need for greater transparency in publicizing sustainability plans. \n",
      "--------------------------------------------------\n",
      "Topic 221: 221_causes increase_causality_co2 concentration_co2\n",
      "Representative Documents:\n",
      "  - It is common knowledge that increasing CO2 concentration plays a major role in enhancement of the greenhouse effect and contributes to global warming. The purpose of this study is to complement the conventional and established theory that increased CO2 concentration due to human emissions causes an increase of temperature, by considering the reverse causality. Since increased temperature causes an increase in CO2 concentration, the relationship of atmospheric CO2 and temperature may qualify as belonging to the category of “hen-or-egg” problems, where it is not always clear which of two interrelated events is the cause and which the effect. We examine the relationship of global temperature and atmospheric carbon dioxide concentration at the monthly time step, covering the time interval 1980–2019, in which reliable instrumental measurements are available. While both causality directions exist, the results of our study support the hypothesis that the dominant direction is T → CO2. Changes in CO2 follow changes in T by about six months on a monthly scale, or about one year on an annual scale. We attempt to interpret this mechanism by involving biochemical reactions, as at higher temperatures soil respiration, and hence CO2 emission, are increasing.\n",
      "  - It is common knowledge that increasing CO2 concentration plays a major role in enhancement of the greenhouse effect and contributes to global warming. The purpose of this study is to complement the conventional and established theory that increased CO2 concentration due to human emissions causes an increase of temperature, by considering the reverse causality. Since increased temperature causes an increase in CO2 concentration, the relationship of atmospheric CO2 and temperature may qualify as belonging to the category of “hen-or-egg” problems, where it is not always clear which of two interrelated events is the cause and which the effect. We examine the relationship of global temperature and atmospheric carbon dioxide concentration at the monthly time step, covering the time interval 1980–2019, in which reliable instrumental measurements are available. While both causality directions exist, the results of our study support the hypothesis that the dominant direction is T → CO2. Changes in CO2 follow changes in T by about six months on a monthly scale, or about one year on an annual scale. We attempt to interpret this mechanism by involving biochemical reactions, as at higher temperatures soil respiration, and hence CO2 emission, are increasing.\n",
      "  - It is common knowledge that increasing CO2 concentration plays a major role in enhancement of the greenhouse effect and contributes to global warming. The purpose of this study is to complement the conventional and established theory that increased CO2 concentration due to human emissions causes an increase of temperature, by considering the reverse causality. Since increased temperature causes an increase in CO2 concentration, the relationship of atmospheric CO2 and temperature may qualify as belonging to the category of “hen-or-egg” problems, where it is not always clear which of two interrelated events is the cause and which the effect. We examine the relationship of global temperature and atmospheric carbon dioxide concentration at the monthly time step, covering the time interval 1980–2019, in which reliable instrumental measurements are available. While both causality directions exist, the results of our study support the hypothesis that the dominant direction is T → CO2. Changes in CO2 follow changes in T by about six months on a monthly scale, or about one year on an annual scale. We attempt to interpret this mechanism by involving biochemical reactions, as at higher temperatures soil respiration, and hence CO2 emission, are increasing.\n",
      "--------------------------------------------------\n",
      "Topic 222: 222_flame_flames_dilution_combustion\n",
      "Representative Documents:\n",
      "  -                The application of the oxy-fuel combustion technique could tackle the combustion process's environmental issues. Experiments were conducted on partially premixed air- and oxy-methane combustion flames stabilized over a novel perforated burner in the present work. The burner has a premixing ratio of 7.0. In oxy-fuel combustion, the experiments were performed at oxygen fractions (OF%: volumetric percentage of O2 in the oxidizer mixture) of 29%, 32%, and 36% and over a range of operating conditions necessary for a stable flame. The results of oxy-combustion flames were compared with the corresponding air-combustion flames at the same operating conditions. Two sets of statistical analyses were performed for further confirmation of the experimental results. The first set investigated the operating parameters’ effect, including OF and oxidizer Reynolds number (Re), on the upper flammability limits (UFL). Simultaneously, the second set studied the impact of OF and equivalence ratio on flame length. The experimental results revealed that the flammability limits get wider as the OF increases due to the resulting flame speed rise with O2-enrichment. The statistical analysis is conducted by analysis of variance (ANOVA) technique, which carries innovation and confirms that OF and Re significantly impacted the UFL. The visual flame length of oxy-flames was longer than its correspondents of air-flames due to the reduction of flame speed associated with the negative influence of CO2 dilution in oxy-flames. The statistical analysis showed a significant effect of OF and equivalence ratio on the visible flame appearance.\n",
      "  -                A counterflow diffusion flame for supercritical CO2 combustion is investigated at various CO2 dilution levels and pressures by accounting for real gas effects into both thermal and transport properties. The UCF 1.1 24-species mechanism is used to account the chemistry. The nature of important nonpremixed combustion characteristics such as Prandtl number, thermal diffusivity, Lewis number, stoichiometric scalar dissipation rate, flame thickness, and Damköhler number are investigated with respect to CO2 dilution and pressure. The results show that the aforementioned parameters are influenced by both dilution and pressure; the dilution effect is more dominant. Further, the result shows that Prandtl number increases with CO2 dilution and at 90% CO2 dilution, the difference between the Prandtl number of the inlet jets and the flame is minimal. Also, the common assumption of unity Lewis number in the theory and modeling of nonpremixed combustion does not hold reasonable for sCO2 applications due to large difference of Lewis number across the flame and the Lewis number on the flame drop significantly with an increase in the CO2 dilution. An interesting relation between Lewis number and CO2 dilution is observed. The Lewis number of species drops by 15% when increasing the CO2 dilution by 30%. Increasing the CO2 dilution increases both the flow and chemical timescales; however, chemical timescale increases faster than the flow timescales. The magnitudes of the Damköhler number signify the need to consider finite rate chemistry for sCO2 applications. Further, the Damköhler numbers at 90% sCO2 dilution are very small; hence, laminar flamelet assumptions in turbulent combustion simulations are not physically correct for this application. Also, it is observed that the Damköhler number drops nonlinearly with increasing CO2 dilution in the oxidizer stream. This is a very important observation for the operation of sCO2 combustors. Further, the flame thickness is found to increase with CO2 dilution and reduce with pressure.\n",
      "  -                With increased interest in reducing emissions, the staged combustion concept for gas turbine combustors is gaining in popularity. For this work, the effect of CO2 dilution on laminar burning velocities of premixed methane/air flames was investigated at elevated temperature through both experiments and numerical simulations. Validation of the experimental setup and methodology was completed through experimental testing of methane/air mixtures at 1 bar and 298 K. Following validation, high temperature experiments were conducted in an optically accessible constant volume combustion chamber at 1 bar and 473 K. Laminar burning velocities of premixed methane/air flames with 0%, 5%, 10%, and 15% CO2 dilution were determined using the constant pressure method enabled via schlieren visualization of the spherically propagating flame front. Results show that laminar burning velocities of methane/air mixtures at 1 bar increase by 106–145% with initial temperature increases from 298 K to 473 K. Additions of 5%, 10%, and 15% CO2 dilution at 1 bar and 473 K cause a 30–35%, 51–54%, and 66–68% decrease in the laminar burning velocity, respectively. Numerical results were obtained with CHEMKIN (Kee et al., 1985, “PREMIX: A Fortran Program for Modeling Steady Laminar One-Dimensional Premixed Flames,”) using the GRI-Mech 3.0 (Smith et al., 2019) and the San Diego (“Chemical-Kinetic Mechanisms for Combustion Applications,” San Diego Mechanism Web Page, Mechanical and Aerospace Engineering (Combustion Research), University of California at San Diego, San Diego, CA) mechanisms. It is concluded that the GRI-Mech 3.0 (Smith et al.., 2019) better captures the general overall trend of the experimental laminar flame speeds of methane/air/CO2 mixtures at 1 bar and 473 K. Additionally, the dilution, thermal-diffusion, and chemical effects of CO2 on the laminar burning velocities of methane/air mixtures were investigated numerically by diluting the mixtures with both chemically active and inactive CO2 following the determination of the most important elementary reactions on the burning rate through sensitivity analysis. Finally, it was shown that CO2 dilution suppresses the flame instabilities during combustion, which is attributable to the increase in the burned gas Markstein length (Lb) with the addition of diluent.\n",
      "--------------------------------------------------\n",
      "Topic 223: 223_laser_enamel_co2 laser_yag\n",
      "Representative Documents:\n",
      "  -             Introduction: The tooth root surfaces are modified by different agents for better removal of the smear layer, the formation of fibrin clots, and the attachment of blood cells. This in vitro study compared the removal of the smear layer, the formation of fibrin clots and the attachment of blood cells after exposing periodontally compromised root surfaces to ER:YAG and CO2 laser beams. Methods: Eighteen dentin block samples were prepared from freshly extracted periodontally compromised teeth that were deemed hopeless, and they were divided into 3 groups: exposed to Er:YAG laser beams, exposed to CO2 laser beams, and the control group. The samples were evaluated using scanning electron microscopy and micrographs were taken. Smear layer removal and blood cell attachment were scored. Data were analyzed using Kruskal-Wallis and MannWhitney tests. Results: In the Er:YAG laser group, the smear layer was removed completely. In the specimens exposed to blood, better fibrin clot formation and blood cell attachment were observed in the Er:YAG laser group. In the CO2 laser group, the smear layer was also removed; however, there were no significant differences between the CO2 laser and control groups in fibrin clot formation and blood cell attachment. Conclusion: The application of the Er:YAG laser to the root dentin appears to result in the formation of a suitable surface for fibrin clot formation and blood cell attachment. Further clinical studies are necessary to support these results.\n",
      "  -             Introduction: Polyether ether ketone (PEEK) has low surface energy and high resistance to chemical surface treatments. Therefore, different surface treatments such as laser conditioning should be investigated. There is a gap of information regarding the efficacy of laser irradiation in the surface treatment of PEEK, and the efficacy of several laser types needs to be evaluated for this purpose. This study aimed to assess the effect of surface treatment with erbium-doped yttrium aluminum garnet (Er:YAG) and carbon dioxide (CO2) lasers on shear bond strength (SBS) of PEEK to composite resin veneers. Methods: In this experimental study, 60 rectangular-shaped PEEK samples (7 x 7 x 2 mm) were used. The samples were mounted in auto-polymerizing acrylic resin in such a way that only one surface measuring 7x7 mm remained exposed. The samples were then randomly divided into 3 groups (n=20) of control, Er:YAG laser surface treatment (Power=1.5 W, energy density=119.42 J/cm2 , irradiation time=20 s) and CO2 laser surface treatment (Power=4 W, energy density=159.22 J/cm2 , irradiation time=50 s). The bonding agent and PEEK opaque were applied on the surface of samples and they were veneered with a composite resin using a hollow plastic cylinder with an internal diameter of 4 mm. The SBS was then measured and the data were analyzed using one-way ANOVA, Tukey HSD test and Dunnett’s test at 0.05 level of significance. Results: The SBS of the 3 groups was significantly different (P&lt;0.001). The Tukey HSD test revealed that the Er:YAG laser had higher SBS than the CO2 laser group (P&lt;0.001). The Dunnett’s test showed that both Er:YAG and CO2 laser groups yielded higher SBS than the control group (P&lt;0.001). Conclusion: The Er:YAG and CO2 laser treatments can increase the SBS of PEEK to composite resin veneers, although the Er:YAG laser seems to be more effective for this purpose. \n",
      "  - ABSTRACTObjectivesErstwhile studies have emphasized the importance of establishing a secure fibrin linkage between the tooth-soft tissue interface for formation of a new connective attachment. Thus, periodontal regeneration is reliant on the constant adhesion, maturation and absorption of fibrin clots to the root surfaces which are compromised periodontally. Improved fibrin clot formation and blood cell attachment is being aimed by modification of the root surfaces with different agents. Limited studies have evaluated the attachment of blood cell component on various laser treated root surfaces individually.Hence, the aim of this in vitro study was to evaluate and compare the adhesion of blood components on the root surfaces treated with citric acid, Nd:YAG, Er:YAG and CO2 lasers by scanning electron microscopy (SEM).Materials and methodsThe proposed study was conducted on 35 root specimens (5 × 5 × 1 mm) obtained from extracted periodontally compromised permanent teeth. The root specimens were randomly divided in five groups depending upon the type of treatment rendered. Group I: Untreated control group, group II: Citric acid (pH:1), group III: Nd:YAG laser (112.5 m J/pulse), group IV: CO2 laser (12.5 J/cm2), group V: Er:YAG laser (120 m J). Following the respective treatments, fresh human whole peripheral blood obtained from a healthy donor was applied to the external surface of all root specimens. The specimens were then analysed and scored for the adhesion of the blood components with photomicrographs of SEM.ResultsStatistically significant increase in the adhesion of blood components was seen in all the test groups compared to control group both citric acid and Er:YAG laser showed higher adhesion of blood cells to the root surface than the Nd:YAG laser and CO2 laser.ConclusionEr:YAG laser enhanced the adhesion of blood components over the treated root surfaces. Hence, it can be safely used as a root bio-modifier ensuring stable fibrin linkage to promote periodontal regeneration.How to cite this articleSabnis S, Gayathri GV, Chandra KK, Mehta DS. Comparison of Adhesion of Blood Components on Root Surfaces treated with Citric Acid, Nd:YAG, Er:YAG, and CO2 Lasers: An in vitro Analysis. Int J Laser Dent 2016;6(1):18-23.\n",
      "--------------------------------------------------\n",
      "Topic 224: 224_available available_refs_available available available_available\n",
      "Representative Documents:\n",
      "  - Review: 69 refs.\n",
      "  - Review: 37 refs.\n",
      "  - Review: 16 refs.\n",
      "--------------------------------------------------\n",
      "Topic 225: 225_veraison_varieties_flowering veraison_yield\n",
      "Representative Documents:\n",
      "  - The present study is devoted to climate change impact assessment on the phenological development and ripening of cv. Touriga Nacional in the Dão Wine Region, Portugal. For this purpose, the dates of the three main phenological stages (budbreak, flowering and veraison) and two maturity stages are projected for two future periods (2041–2070 and 2071–2100), under two anthropogenic radiative forcing scenarios (RCP4.5 and RCP8.5), and compared against a baseline period (1991–2020). The phenological and maturity stages are simulated using phenological development models (PDMs) and a temperature‐based ripeness model (TRM), respectively. An overall advancement in both phenology and ripening stages are identified under future warmer climates, though site‐dependent. Furthermore, the advancements in phenology are more pronounced (a) for stages between the beginning of veraison and end of ripening than for the earlier stages, (b) for the long‐term future period (2071–2100) under RCP8.5 and (c) for the vineyard site “Viseu.” These changes are due to the combination of budbreak advancement with a shortening of some phenophases. The strongest shortening is found in the ripening period, while no significant changes in flowering timings and duration of the berry development period are projected. The advancement and the shortening of the grapevine growing season will shift ripening to the warmest part of the year. This twofold climate change impact of the air temperature on ripening may affect the sugar and organic acid balance, as well as the colour of the must. The current findings can be used by the regional winemaking sector in planning and implementing suitable climate change adaptation to enhance its climate resiliency and sustainability. Subsequent studies for this wine region should be carried out to assess the climate change impacts on late frost risk, on climatic viticultural zoning, on yield and berry quality at harvest.\n",
      "  - Projections of grapevine phenophases under future climate change scenarios are strategic decision support tools for viticulturists and wine producers. Several phenological models are tested for budburst, flowering, and veraison and for two main grapevine varieties (cv. Touriga Franca and Touriga Nacional) growing in the Douro Demarcated Region. Four forcing models (Growing degree-days, Richardson, Sigmoid, and Wang) and three dormancy models (Bidabe, Smoothed Utah and Chuine), with different parameterizations and combinations, are used. New datasets, combing phenology with weather station data, widespread over the Douro wine region, were used for this purpose. The eight best performing models and parameterizations were selected for each phenophase and variety, based on performance metrics. For both cultivars, results revealed moderate performances (0.4 &lt; R2 &lt; 0.7) for budburst, while high performances (R2 &gt; 0.7) were found for flowering and veraison, particularly when Growing degree-days or Sigmoid models are used, respectively. Climate change projections were based on a two-member climate model ensemble from the EURO-CORDEX project under RCP4.5. Projections depicted an anticipation of phenophase timings by 6, 8 or 10–12 days until the end of the century for budburst, flowering, and veraison, respectively. The inter-model variability is of approximately 2–4 days for flowering and veraison and 4–6 days for budburst. These results establish grounds for the implementation of a decision support system for monitoring and short-term prediction of grapevine phenology, thus promoting a more efficient viticulture.\n",
      "  - With global warming, grapevine is expected to be increasingly exposed to water deficits occurring at various development stages. In this study, we aimed to investigate the potential impacts of projected climate change on water deficits from the flowering to veraison period for two main white wine cultivars (Riesling and Müller-Thurgau) in Germany. A process-based soil-crop model adapted for grapevine was utilized to simulate the flowering-veraison crop water stress indicator (CWSI) of these two varieties between 1976–2005 (baseline) and 2041–2070 (future period) based on a suite of bias-adjusted regional climate model (RCM) simulations under RCP4.5 and RCP8.5. Our evaluation indicates that the model can capture the early-ripening (Müller-Thurgau) and late-ripening (Riesling) traits, with a mean bias of prediction of ≤2 days and a well-reproduced inter-annual variability for more than 60 years. Under climate projections, the flowering stage is advanced by 10–20 days (higher in RCP8.5) between the two varieties, whereas a slightly stronger advancement is found for Müller-Thurgau than for Riesling for the veraison stage. As a result, the flowering-veraison phenophase is mostly shortened for Müller-Thurgau, whereas it is extended by up to two weeks for Riesling in cool and high-elevation areas. The length of phenophase plays an important role in projected changes of flowering-veraison mean temperature and precipitation. The late-ripening trait of Riesling makes it more exposed to increased summer temperature (mainly in August), resulting in a higher mean temperature increase for Riesling (1.5–2.5 °C) than for Müller-Thurgau (1–2 °C). As a result, an overall increased CWSI by up to 15% (ensemble median) is obtained for both varieties, whereas the upper (95th) percentile of simulations shows a strong signal of increased water deficit by up to 30%, mostly in the current winegrowing regions. Intensified water deficit stress can represent a major threat for high-quality white wine production, as only mild water deficits are acceptable. Nevertheless, considerable variabilities of CWSI were discovered among RCMs, highlighting the importance of efforts towards reducing uncertainties in climate change impact assessment.\n",
      "--------------------------------------------------\n",
      "Topic 226: 226_adsorption_porous_co2 adsorption_mmol\n",
      "Representative Documents:\n",
      "  - N-enriched porous carbons have played an important part in CO2 adsorption application thanks to their abundant porosity, high stability and tailorable surface properties while still suffering from a non-efficient and high-cost synthesis method. Herein, a series of N-doped porous carbons were prepared by a facile one-pot KOH activating strategy from commercial urea formaldehyde resin (UF). The textural properties and nitrogen content of the N-doped carbons were carefully controlled by the activating temperature and KOH/UF mass ratios. As-prepared N-doped carbons show 3D block-shaped morphology, the BET surface area of up to 980 m2/g together with a pore volume of 0.52 cm3/g and N content of 23.51 wt%. The optimal adsorbent (UFK-600-0.2) presents a high CO2 uptake capacity of 4.03 mmol/g at 0 °C and 1 bar. Moreover, as-prepared N-doped carbon adsorbents show moderate isosteric heat of adsorption (43–53 kJ/mol), acceptable ideal adsorption solution theory (IAST) selectivity of 35 and outstanding recycling performance. It has been pointed out that while the CO2 uptake was mostly dependent on the textural feature, the N content of carbon also plays a critical role to define the CO2 adsorption performance. The present study delivers favorable N-doped carbon for CO2 uptake and provides a promising strategy for the design and synthesis of the carbon adsorbents.\n",
      "  - In this work, a series of novel rubber seed shell-derived N-doped ultramicroporous carbons (NPCs) were prepared by one-step high-temperature activation (500–1000 °C), using melamine as the nitrogen source and KOH as the activator. The effects of the melamine dosage and the activation temperatures on the surface chemical properties (doped N contents and N species), textural properties (surface area, pore structure, and microporosity), CO2 adsorption capacities, and CO2/N2 selectivity were thoroughly investigated and characterized. These as-prepared NPCs demonstrate controllable BET surface areas (398–2163 m2/g), ultramicroporosity, and doped nitrogen contents (0.82–7.52 wt%). It was found that the ultramicroporosity and the doped nitrogens significantly affected the CO2 adsorption and the separation performance at low pressure. Among the NPCs, highly microporous NPC-600-4 demonstrates the largest CO2 adsorption capacity of 5.81 mmol/g (273 K, 1.0 bar) and 3.82 mmol/g (298 K, 1.0 bar), as well as a high CO2/N2 selectivity of 36.6, surpassing a lot of reported biomass-based porous carbons. In addition, NPC-600-4 also shows excellent thermal stability and recycle performance, indicating the competitive application potential in practical CO2 capture. This work also presents a facile one-pot synthesis method to prepare high-performance biomass-based NPCs.\n",
      "  - CO2 adsorption in porous carbon materials has attracted great interests for alleviating emission of post-combustion CO2. In this work, a novel nitrogen-doped porous carbon material was fabricated by carbonizing the precursor of melamine-resorcinol-formaldehyde resin/graphene oxide (MR/GO) composites with KOH as the activation agent. Detailed characterization results revealed that the fabricated MR(0.25)/GO-500 porous carbon (0.25 represented the amount of GO added in wt.% and 500 denoted activation temperature in °C) had well-defined pore size distribution, high specific surface area (1264 m2·g−1) and high nitrogen content (6.92 wt.%), which was mainly composed of the pyridinic-N and pyrrolic-N species. Batch adsorption experiments demonstrated that the fabricated MR(0.25)/GO-500 porous carbon delivered excellent CO2 adsorption ability of 5.21 mmol·g−1 at 298.15 K and 500 kPa, and such porous carbon also exhibited fast adsorption kinetics, high selectivity of CO2/N2 and good recyclability. With the inherent microstructure features of high surface area and abundant N adsorption sites species, the MR/GO-derived porous carbon materials offer a potentially promising adsorbent for practical CO2 capture.\n",
      "--------------------------------------------------\n",
      "Topic 227: 227_ch4_emissions_ch4 emissions_inventory\n",
      "Representative Documents:\n",
      "  - To effectively address the unprecedented acceleration of climate change, cities across the United States are leading efforts to reduce greenhouse gas emissions. Coherent, aggressive, and lasting mitigation policies in controlling carbon emissions are beginning to be adopted to help strengthen climate resilience across different sectors. However, evaluating the effectiveness of current climate legislation requires careful monitoring of emissions through measurable and verifiable means to inform policy decisions. As a part of this effort, we developed a new method to spatially allocate aircraft-based mass balance carbon dioxide (CO2) emissions. In this work, we conducted 7 aircraft flights, performed downwind of New York City (NYC) to quantify CO2 emissions during the nongrowing seasons between 2018 and 2020. We used an ensemble of emission inventories and transport models to calculate the fraction of enhancements (Φ) produced by sources within the policy-relevant boundaries of the 5 NYC boroughs and then applied that to the bulk emissions calculated using the mass balance approach. We derived a campaign-averaged source-apportioned mass balance CO2 emission rate of (57 ± 24) (1σ) kmol/s for NYC. We evaluated the performance of this approach against other top-down methods for NYC including inventory scaling and inverse modeling, with our mean emissions estimate resulting in a 6.5% difference from the average emission rate reported by the 2 complementary approaches. By combining mass balance and transport model approaches, we improve upon traditional mass balance experiment methods to enable quantification of emissions in complex emission environments. We conducted an assessment using an ensemble of emission inventories and transport models to determine the sources of variability in the final calculated emission rates. Our findings indicate that the choice of inventory accounted for 2.0% of the variability in the emission estimates and that the atmospheric transport model contributed 3.9% at the campaign level. Additionally, on average, at the daily scale, the transport model contributed 7.6% and the inventory accounted for 14.1%. The daily flight-to-flight variability contributed a significant portion, at 42.1%. This approach provides a solution to the difficulty of interpreting aircraft-based mass balance results in complex emission environments.\n",
      "  - Methane (CH4) is the primary component of natural gas and has a larger global warming potential than CO2. Recent top‐down studies based on observations showed CH4 emissions in California's South Coast Air Basin (SoCAB) were greater than those expected from population‐apportioned bottom‐up state inventories. In this study, we quantify CH4 emissions with an advanced mesoscale inverse modeling system at a resolution of 8 km × 8 km, using aircraft measurements in the SoCAB during the 2010 Nexus of Air Quality and Climate Change campaign to constrain the inversion. To simulate atmospheric transport, we use the FLEXible PARTicle‐Weather Research and Forecasting (FLEXPART‐WRF) Lagrangian particle dispersion model driven by three configurations of the Weather Research and Forecasting (WRF) mesoscale model. We determine surface fluxes of CH4 using a Bayesian least squares method in a four‐dimensional inversion. Simulated CH4 concentrations with the posterior emission inventory achieve much better correlations with the measurements (R2 = 0.7) than using the prior inventory (U.S. Environmental Protection Agency's National Emission Inventory 2005, R2 = 0.5). The emission estimates for CH4 in the posterior, 46.3 ± 9.2 Mg CH4/h, are consistent with published observation‐based estimates. Changes in the spatial distribution of CH4 emissions in the SoCAB between the prior and posterior inventories are discussed. Missing or underestimated emissions from dairies, the oil/gas system, and landfills in the SoCAB seem to explain the differences between the prior and posterior inventories. We estimate that dairies contributed 5.9 ± 1.7 Mg CH4/h and the two sectors of oil and gas industries (production and downstream) and landfills together contributed 39.6 ± 8.1 Mg CH4/h in the SoCAB.\n",
      "  - We quantify methane (CH4) emissions in California's San Joaquin Valley (SJV) by using 4 days of aircraft measurements from a field campaign during May–June 2010 together with a Bayesian inversion method and a mass balance approach. For the inversion estimates, we use the FLEXible PARTicle dispersion model (FLEXPART) to establish the source‐receptor relationship between sampled atmospheric concentrations and surface fluxes. Our prior CH4 emission estimates are from the California Greenhouse Gas Emissions Measurements (CALGEM) inventory. We use three meteorological configurations to drive FLEXPART and subsequently construct three inversions to analyze the final optimized estimates and their uncertainty (one standard deviation). We conduct May and June inversions independently and derive similar total CH4 emission estimates for the SJV: 135 ± 28 Mg/h in May and 135 ± 19 Mg/h in June. The inversion result is 1.7 times higher than the prior estimate from CALGEM. We also use an independent mass balance approach to estimate CH4 emissions in the northern SJV for one flight when meteorological conditions allowed. The mass balance estimate provides a confirmation of our inversion results, and these two independent estimates of the total CH4 emissions in the SJV are consistent with previous studies. In this study, we provide optimized CH4 emissions estimates at 0.1° horizontal resolution. Using independent spatial information on major CH4 sources, we estimate that livestock contribute 75–77% and oil/gas production contributes 15–18% of the total CH4 emissions in the SJV. Livestock explain most of the discrepancies between the prior and the optimized emissions from our inversion.\n",
      "--------------------------------------------------\n",
      "Topic 228: 228_adsorption_hnd_langmuir_adsorption capacity\n",
      "Representative Documents:\n",
      "  - Carbon sequestration in unmineable coal seams has been proposed as one of the most attractive technologies to mitigate carbon dioxide (CO2) emissions in which CO2is stored in the microporous structure of the coal matrix in an adsorbed state. The CO2adsorption process is hence considered one of the more effective methodologies in environmental sciences. Thus, adsorption isotherm measurements and modelling are key important scientific measures required in understanding the adsorption system, mechanism, and process optimization in coalbeds. In this paper, three renowned and reliable adsorption isotherm models were employed including Langmuir, Freundlich, and Temkin for pure CO2adsorption data, and the extended-Langmuir model for multicomponent, such as flue gas mixture-adsorption data as investigated in this research work. Also, significant thermodynamics properties including the standard enthalpy change ($$\\Delta H^\\circ$$ΔH∘), entropy change ($$\\Delta S^\\circ$$ΔS∘), and Gibbs free energy ($$\\Delta G^\\circ$$ΔG∘) were assessed using the van’t Hoff equation. The statistical evaluation of the goodness-of-fit was done using three (3) statistical data analysis methods including correlation coefficient (R2), standard deviation (σ), and standard error (SE). The Langmuir isotherm model accurately represent the pure CO2adsorption on the coals than Freundlich and Temkin. The extended Langmuir gives best experimental data fit for the flue gas. The thermodynamic evaluations revealed that CO2adsorption on the South African coals is feasible, spontaneous, and exothermic; and the adsorption mechanism is a combined physical and chemical interaction between the adsorbate and the adsorbent.\n",
      "  - The Paris Agreement and one of its goals, “carbon neutrality,” require intensive studies on CO2 absorption and desorption processes. When searching for ways of reducing the huge energy cost of CO2 desorption in the amine scrubbing process, the combination of blended amine with solid acid catalysts turned out to be a powerful solution in need of further investigation. In this study, the tri-solvent MEA (monoethanolamine) + EAE(2-(ethylamino)ethanol) + AMP(2-amino-2-methyl-1-propanol) was prepared at: 0.2 + 2 + 2, 0.5 + 2 + 2, 0.3 + 1.5 + 2.5 and 0.2 + 1 + 3 mol/L. The heterogeneous catalytic CO2 desorptions were tested with five commercial catalysts: blended γ-Al2O3/H-ZSM-5, H-beta, H-mordenite, HND-8 and HND-580. Desorption experiments were conducted via a recirculation process with direct heating at 363 K or using temperature programming method having a range of 303–363 K. Then, the average CO2 desorption rate, heat duty and desorption factors were studied. After comparison, the order of CO2 desorption performance was found to be HND-8 &gt; HND-580 &gt; H-mordenite &gt; Hβ &gt; blended γ-Al2O3/H-ZSM-5 &gt; no catalyst. Among the other combinations, the 0.2 + 1 + 3 mol/L MEA + EAE + AMP with HND-8 had a minimized heat duty (HD) of 589.3 kJ/mol CO2 and the biggest desorption factor (DF) of 0.0277 × (10−3 mol CO2)3/L2 kJ min. This study provided a kind of tri-solvent with catalysts as an energy-efficient solution for CO2 absorption and desorption in industrial CO2 capture pilot plants.\n",
      "  - To achieve the CO2 emission control as the urgent task of Carbon Peak and Carbon Neutrality, the CO2 desorption experiments were performed with a new tri-solvent MEA-EAE(2-(ethylamino)ethanol)-DEEA(N, N-diethylethanolamine) with five solid acid catalysts: blended catalysts of γ-Al2O3/H-ZSM-5 = 2:1, H-Beta (Hβ), H-mordenite, HND-8, and HND-580 as H2SO4 replacement. A series of sets of experiments were performed in a typical recirculation process by means of both heating directly at 363 K and temperature programming method within 303~358 K to evaluate the key parameters: average desorption rate (ADR), heat duty (HD), and desorption factors (DF). After analyses, the 0.5 + 2 + 2 mol/L MEA-EAE-DEEA with catalyst HND-580 possessed the best CO2 desorption act at relatively low amine regeneration temperatures with minimized HD and the biggest DF among the other catalysts. Comparing with other tri-solvents + catalysts studied, the order of DF was MEA-BEA-DEEA + HND-8 &gt; MEA-EAE-DEEA + HND-580 ≈ MEA-EAE-DEEA + HND-8 &gt; MEA-EAE-AMP + HND-8. This combination has its own advantage of big cyclic capacity and wider operation region of CO2 loading range of lean and rich amine solution (αlean~αrich), which is applicable in an industrial amine scrubbing process of a pilot plant in carbon capture.\n",
      "--------------------------------------------------\n",
      "Topic 229: 229_soa_formation_bsoa_aerosol\n",
      "Representative Documents:\n",
      "  - . A method to quantify concentrations and stable carbon isotope ratios of secondary organic aerosols has been applied to study atmospheric nitrophenols in Toronto, Canada. The sampling of five nitrophenols, all with substantial secondary formation from the photooxidation of aromatic volatile organic compounds (VOCs), was conducted in the gas phase and particulate matter (PM) together and in PM alone. Their concentrations in the atmosphere are in the low ng m−3 range and, consequently, a large volume of air (&gt; 1000 m3) is needed to analyze samples for stable carbon isotope ratios, resulting in sampling periods of typically 24 h. While this extended sampling period increases the representativeness of average values, it at the same time reduces possibilities to identify meteorological conditions or atmospheric pollution levels determining nitrophenol concentrations and isotope ratios. Average measured carbon isotope ratios of the different nitrophenols are between −34 and −33 ‰, which is well within the range predicted by mass balance. However, the observed carbon isotope ratios cover a range of nearly 9 ‰ and approximately 20 % of the isotope ratios of the products have isotope ratios lower than predicted from the kinetic isotope effect of the first step of the reaction mechanism and the isotope ratio of the precursor. This can be explained by isotope fractionation during reaction steps following the initial reaction of the precursor VOCs with the OH radical. Limited evidence for local production of nitrophenols is observed since sampling was done in the Toronto area, an urban center with significant anthropogenic emission sources. Strong evidence for significant local formation of nitrophenols is only found for samples collected in summer. On average, the difference in carbon isotope ratios between nitrophenols in the particle phase and in the gas phase is insignificant, but for a limited number of observations in summer, a substantial difference is observed. This indicates that at high OH radical concentrations, photochemical formation or removal of nitrophenols can be faster than exchange between the two phases. The dependence between the concentrations and isotope ratios of the nitrophenols and meteorological conditions as well as pollution levels (NO2, O3, SO2 and CO) demonstrate that the influence of precursor concentrations on nitrophenol concentrations is far more important than the extent of photochemical processing. While it cannot be excluded that primary emissions contribute to the observed levels of nitrophenols, overall the available evidence demonstrates that secondary formation is the dominant source for atmospheric nitrophenols in Toronto.\n",
      "  - Secondary organic aerosol (SOA) plays a significant role in contributing to atmospheric fine particles, as well as in global air quality and climate. However, the current understanding of the atmospheric formation of SOA and its simulation is still highly uncertain due to the complexity of its precursor VOCs. In our study, SOA formation in different mixed VOC scenarios was investigated using a 30 m3 indoor smog chamber. By comparing SOA formation in individual VOC scenarios, it was found that SOA yield from anthropogenic VOCs (AVOCs) can be positively (+83.9%) affected by coexisting AVOCs, while inhibited (−51.4%) by the presence of isoprene, via the OH scavenging effect. The cross-reactions of peroxyl radical (RO2) generated from different AVOCs were proved to be the main contributor (up to 39.0%) to SOA formation, highlighting the importance of RO2 + RʹO2 reactions in mixed VOC scenarios. Meanwhile, the formation of gas-phase organic intermediates of different volatility categories from the RO2 reactions was also affected by the precursor concentration, and a higher SOA yield was found at lower precursor concentrations due to the larger contribution of intermediates with lower volatility. Our study provides new insights into SOA formation by considering the interactions between intermediate products from mixed VOCs.\n",
      "  - Secondary organic aerosol (SOA) represents a major fraction of atmospheric fine particles. Both biogenic and anthropogenic volatile organic compounds (VOCs) can contribute to SOA through (photo-) oxidation. However, the current understanding of their combined, interactive effect on SOA formation and composition is still limited, challenging the accuracy in assessing global SOA budget, sources, and climate effect. Here we combine laboratory experiments and modelling to show that isoprene can suppress SOA formation from photo-oxidation of anthropogenic aromatics (toluene and p-xylene) with the presence of NOx, and similar SOA suppression phenomena are observed when replacing isoprene with propene. We find that the decreased SOA in such mixed-VOC conditions can be largely attributed to OH scavenging effect, resulting in reduced consumption of parent aromatics. However, various changes in SOA oxidation state (i.e., O/C) and oxidation pathways (i.e., more carbonyls formation) are observed following addition of isoprene, and the SOA chemical composition may not be similar to any single parent hydrocarbon, which implies the existence of complex interactions between the degradation chemistry for alkenes and aromatics. Under the conditions of this work, the OH scavenging effect is largely determined by gas-phase chemistry, which is expected to be widespread in binary or more complex systems in ambient air. More broadly, we infer that the global budget of anthropogenic SOA and its corresponding radiative forcing could be affected by biogenic emission of isoprene, particularly in urban environments with appreciable vegetation coverage.\n",
      "--------------------------------------------------\n",
      "Topic 230: 230_decision_decisions_planning_risk\n",
      "Representative Documents:\n",
      "  - There is increasing concern over deep uncertainty in the risk analysis field as probabilistic models of uncertainty cannot always be confidently determined or agreed upon for many of our most pressing contemporary risk challenges. This is particularly true in the climate change adaptation field, and has prompted the development of a number of frameworks aiming to characterize system vulnerabilities and identify robust alternatives. One such methodology is robust decision making (RDM), which uses simulation models to assess how strategies perform over many plausible conditions and then identifies and characterizes those where the strategy fails in a process termed scenario discovery. While many of the problems to which RDM has been applied are characterized by multiple objectives, research to date has provided little insight into how treatment of multiple criteria impacts the failure scenarios identified. In this research, we compare different methods for incorporating multiple objectives into the scenario discovery process to evaluate how they impact the resulting failure scenarios. We use the Lake Tana basin in Ethiopia as a case study, where climatic and environmental uncertainties could impact multiple planned water infrastructure projects, and find that failure scenarios may vary depending on the method used to aggregate multiple criteria. Common methods used to convert multiple attributes into a single utility score can obscure connections between failure scenarios and system performance, limiting the information provided to support decision making. Applying scenario discovery over each performance metric separately provides more nuanced information regarding the relative sensitivity of the objectives to different uncertain parameters, leading to clearer insights on measures that could be taken to improve system robustness and areas where additional research might prove useful.\n",
      "  - The economic impact of CO2 emissions reduction requirements demands strategic planning to identify low-cost CO2 mitigation pathways from combinations of the many available CO2 emissions reduction options. Different tools have been developed to plan minimal cost CO2 reduction pathways taking into consideration various options such as CO2 capture, utilization, and sequestration (CCUS), shifting from fossil to renewable energy sources, as well as adopting sector-specific low emissions technologies. Current methods used to support strategic planning include high-level tools that cannot account for many possible options or fail to incorporate cost objective, and complex optimization approaches that are capable of identifying detailed low-cost solutions yet are demanding to use and often yield complex solutions in terms of processing schemes that are not easily understood by strategic planners. To address these limitations, a simple and clear methodology is proposed that allows to determine minimum cost CO2 reduction pathways from the rich set of available options. The novel methodology employs an algebraic targeting technique that yields minimum marginal abatement cost (Mini-MAC) curves to clearly represent the low-cost CO2 emissions reduction pathway available. The application of the methodology is illustrated with an example to develop minimum cost emissions reduction pathways considering CCUS, power shifting options, and negative emissions technologies. The benefits of the proposed Mini-MAC curves over alternative methods stem from their richness in terms of assessing CCUS, energy management options, and various integration options. Further, the clarity of the proposed Mini-MAC curves enables planners to easily understand available minimum cost pathways when developing strategies aimed at achieving low-cost CO2 emissions reduction.                Graphical \n",
      "  - Planning water supply infrastructure includes identifying interventions that cost‐effectively secure an acceptably reliable water supply. Climate change is a source of uncertainty for water supply developments as its impact on source yields is uncertain. Adaptability to changing future conditions is increasingly viewed as a valuable design principle of strategic water planning. Because present decisions impact a system's ability to adapt to future needs, flexibility in activating, delaying, and replacing engineering projects should be considered in least‐cost water supply intervention scheduling. This is a principle of Real Options Analysis, which this paper applies to least‐cost capacity expansion scheduling via multistage stochastic mathematical programming. We apply the proposed model to a real‐world utility with many investment decision stages using a generalized scenario tree construction algorithm to efficiently approximate the probabilistic uncertainty. To evaluate the implementation of Real Options Analysis, the use of two metrics is proposed: the value of the stochastic solution and the expected value of perfect information that quantify the value of adopting adaptive and flexible plans, respectively. An application to London's water system demonstrates the generalized approach. The investment decisions results are a mixture of long‐term and contingency schemes that are optimally chosen considering different futures. The value of the stochastic solution shows that by considering uncertainty, adaptive investment decisions avoid £100 million net present value (NPV) cost, 15% of the total NPV. The expected value of perfect information demonstrates that optimal delay and early decisions have £50 million NPV, 6% of total NPV. Sensitivity of results to the characteristics of the scenario tree and uncertainty set is assessed.\n",
      "--------------------------------------------------\n",
      "Topic 231: 231_china_projected_precipitation_surface pm2\n",
      "Representative Documents:\n",
      "  - Based on the multi-model ensemble mean of CMIP6 simulations, the future changes in frequency, intensity and duration of Compound (both daytime and nighttime) heatwaves (HWs) in summer over China at various global warming levels (GWLs) under the SSP3-7.0 and SSP5-8.5 are assessed. HWs over China become more frequent and hotter, and the duration of HWs becomes longer compared to those in the recent climate. The magnitudes of these changes are primarily dependent on GWLs, but they are not very sensitive to the scenarios. At 4 ℃ GWL, the frequency of HWs increases by more than fivefold under both scenarios, and the intensity (duration) of HWs averaged under the two scenarios is 2.28 ℃ hotter (3.59 days longer) than the one in the recent climate over the entire China. Meanwhile, the maximum duration of HW events can reach more than 25 days in summer in comparison with 8 days in the recent climate. The changes in HW properties are regionally dependent at the four GWLs. For example, the largest increase in HW frequency is over the Northwest China, the largest increase in intensity in HWs is seen over the Northeast and Northwest, and the largest increase in HW duration is over the Southwest China. The extreme rare events (50-year and 100-year events) in the recent climate would become the norm over China and four sub-regions at 4 ℃ GWL. Overall, seasonal mean warming dominates the changes in HW properties over China at the different GWLs. The seasonal mean warming in summer across China is related to the increases of longwave radiation, partly due to increase in greenhouse gas forcing and partly resulted from increased water vapor and the increase of shortwave radiation (under the SSP5-8.5) over eastern China related to decreases in aerosols and total cloud cover. Furthermore, the regional variations in the water vapor over China are consistent with atmospheric circulation changes. The seasonal mean surface warming results in enhanced upward sensible and latent heat fluxes, leading to increased summer mean daily maximum and minimum of near-surface air temperature and the enhancement of HWs properties over the entire China. Changes of shortwave radiation tend to play a weaker role for surface warming under the SSP3-7.0 than those under the SSP5-8.5, which is related to increased aerosol changes under the SSP3-7.0.\n",
      "  - The Yellow River Basin (YLRB) and Yangtze River Basin (YZRB) are heavily populated, important grain-producing areas in China, and they are sensitive to climate change. In order to study the temporal and spatial distribution of extreme climate events in the two river basins, seven extreme temperature indices and seven extreme precipitation indices were projected for the periods of 2010–2039, 2040–2069, and 2070–2099 using data from 16 Coupled Model Intercomparison Project Phase 5 (CMIP5) models, and the delta change and reliability ensemble averaging (REA) methods were applied to obtain more robust ensemble values. First, the present evaluation indicated that the simulations satisfactorily reproduced the spatial distribution of temperature extremes, and the spatial distribution of precipitation extremes was generally suitably captured. Next, the REA values were adopted to conduct projections under different representative concentration pathway (RCP) scenarios (i.e., RCP4.5, and RCP8.5) in the 21st century. Warming extremes were projected to increase while cold events were projected to decrease, particularly on the eastern Tibetan Plateau, the Loess Plateau, and the lower reaches of the YZRB. In addition, the number of wet days (CWD) was projected to decrease in most regions of the two basins, but the highest five-day precipitation (Rx5day) and precipitation intensity (SDII) index values were projected to increase in the YZRB. The number of consecutive dry days (CDD) was projected to decrease in the northern and western regions of the two basins. Specifically, the warming trends in the two basins were correlated with altitude and atmospheric circulation patterns, and the wetting trends were related to the atmospheric water vapor content increases in summer and the strength of external radiative forcing. Notably, the magnitude of the changes in the extreme climate events was projected to increase with increasing warming targets, especially under the RCP8.5 scenario.\n",
      "  - This paper evaluates the historical simulated surface concentrations of particulate matter small than 2.5 µm in diameter (PM2.5) and its components (black carbon (BC), dust, SO4, and organic aerosol (OA)) in Asia, which come from Coupled Model Intercomparison Project Phase 6 (CMIP6). In addition, future projected changes of surface PM2.5 and its components, as well as their exposure to population, under the different Shared Socioeconomic Pathway (SSP) scenarios are also provided. Results show that the simulated spatial distribution of surface PM2.5 concentrations is consistent with the Modern-Era Retrospective Analysis for Research and Applications version 2 (MERRA-2) and Socioeconomic Data and Applications Center (SEDAC). The model spreads are small/large over the regions with low/high climatic mean surface PM2.5 concentrations, i.e., Northern Asia/Saudi Arabia, Iran, and Xinjiang Province of China. The multi-model ensemble of CMIP6 reproduces the main features of annual cycles and seasonal variations in Asia and its sub-regions. Under the scenarios of SSP1-2.6, SSP2-4.5, and SSP5-8.5, compared to the present-day period of 1995–2014, annual mean surface PM2.5 concentrations are projected to decrease in Asia, with obvious differences among the scenarios. Meanwhile, the magnitudes and timings of changes at the regional scale are quite different, with the largest decreases in South Asia (SAS). Under SSP3-7.0, the increase of surface PM2.5 concentrations in SAS is the largest, with the increase value of 8 μg/m3 in 2050; while under SSP370-lowNTCF, which assumes stronger levels of air quality control measures relative to the SSP3-7.0, the decreases of surface PM2.5 concentrations in SAS, East Asia (EAS) and Southeast Asia (SEAS) are the largest. The characteristics of seasonal trends are consistent with that of the annual trend. The trends in the concentrations of surface PM2.5 and its components are similar. The population-weighted average values of surface PM2.5 concentrations are projected to decrease in Central Asia (CAS), EAS, North Asia (NAS), and SEAS, and it indicates that the surface PM2.5 concentrations over the most populated area of Asia will decrease. In SAS, because of its large population, the impact of air pollutants on human health is still disastrous in the future. In summary, the surface PM2.5 concentrations over the most area of Asia will decrease, which is beneficial to air quality and human health; under SSP370-lowNTCF, the reduction of short-lived climate forcers (SLCFs) will further improve air quality.\n",
      "--------------------------------------------------\n",
      "Topic 232: 232_ion_batteries_electrolyte_anode\n",
      "Representative Documents:\n",
      "  - With a series of merits, Prussian blue analogs (PBAs) have been considered as superior cathode materials for sodium‐ion batteries (SIBs). Their commercialization, however, still suffers from inferior stability, considerable [Fe(CN)6] defects and interstitial water in the framework, which are related to the rapid crystal growth. Herein, a “water‐in‐salt” nanoreactor is proposed to synthesize highly crystallized PBAs with decreased defects and water, which show both superior specific capacity and rate capability in SIBs. The air‐stability, all‐climate, and full‐cell properties of our PBA have also been evaluated, and it exhibits enhanced electrochemical performance and higher volume yield than its counterpart synthesized via the water‐based co‐precipitation method. Furthermore, their highly reversible sodium‐ion storage behavior has been measured and identified via multiple in situ techniques. This work could pave the way for the PBA‐based SIBs in grid‐scale energy‐storage systems.\n",
      "  - Sluggish storage kinetics and insufficient performance are the major challenges that restrict the transition metal dichalcogenides (TMDs) applied for zinc ion storage, especially at the extreme temperature conditions. Herein, a multiscale interface structure‐integrated modulation concept was presented, to unlock the omnidirectional storage kinetics‐enhanced porous VSe2−x⋅n H2O host. Theory research indicated that the co‐modulation of H2O intercalation and selenium vacancy enables enhancing the interfacial zinc ion capture ability and decreasing the zinc ion diffusion barrier. Moreover, an interfacial adsorption‐intercalation pseudocapacitive storage mechanism was uncovered. Such cathode displayed remarkable storage performance at the wide temperature range (−40–60 °C) in aqueous and solid electrolytes. In particular, it can retain a high specific capacity of 173 mAh g−1 after 5000 cycles at 10 A g−1, as well as a high energy density of 290 Wh kg−1 and a power density of 15.8 kW kg−1 at room temperature. Unexpectedly, a remarkably energy density of 465 Wh kg−1 and power density of 21.26 kW kg−1 at 60 °C also can be achieved, as well as 258 Wh kg−1 and 10.8 kW kg−1 at −20 °C. This work realizes a conceptual breakthrough for extending the interfacial storage limit of layered TMDs to construct all‐climate high‐performance Zn‐ion batteries.\n",
      "  - Sluggish storage kinetics and insufficient performance are the major challenges that restrict the transition metal dichalcogenides (TMDs) applied for zinc ion storage, especially at the extreme temperature conditions. Herein, a multiscale interface structure‐integrated modulation concept was presented, to unlock the omnidirectional storage kinetics‐enhanced porous VSe2−x⋅n H2O host. Theory research indicated that the co‐modulation of H2O intercalation and selenium vacancy enables enhancing the interfacial zinc ion capture ability and decreasing the zinc ion diffusion barrier. Moreover, an interfacial adsorption‐intercalation pseudocapacitive storage mechanism was uncovered. Such cathode displayed remarkable storage performance at the wide temperature range (−40–60 °C) in aqueous and solid electrolytes. In particular, it can retain a high specific capacity of 173 mAh g−1 after 5000 cycles at 10 A g−1, as well as a high energy density of 290 Wh kg−1 and a power density of 15.8 kW kg−1 at room temperature. Unexpectedly, a remarkably energy density of 465 Wh kg−1 and power density of 21.26 kW kg−1 at 60 °C also can be achieved, as well as 258 Wh kg−1 and 10.8 kW kg−1 at −20 °C. This work realizes a conceptual breakthrough for extending the interfacial storage limit of layered TMDs to construct all‐climate high‐performance Zn‐ion batteries.\n",
      "--------------------------------------------------\n",
      "Topic 233: 233_lcz_urban_classification_lcz classification\n",
      "Representative Documents:\n",
      "  - Local climate zone (LCZ) maps have been used widely to study urban structures and urban heat islands. Because remote sensing data enable automated LCZ mapping on a large scale, there is a need to evaluate how well remote sensing resources can produce fine LCZ maps to assess urban thermal environments. In this study, we combined Sentinel-2 multispectral imagery and dual-polarized (HH + HV) PALSAR-2 data to generate LCZ maps of Nanchang, China using a random forest classifier and a grid-cell-based method. We then used the classifier to evaluate the importance scores of different input features (Sentinel-2 bands, PALSAR-2 channels, and textural features) for the classification model and their contribution to each LCZ class. Finally, we investigated the relationship between LCZs and land surface temperatures (LSTs) derived from summer nighttime ASTER thermal imagery by spatial statistical analysis. The highest classification accuracy was 89.96% when all features were used, which highlighted the potential of Sentinel-2 and dual-polarized PALSAR-2 data. The most important input feature was the short-wave infrared-2 band of Sentinel-2. The spectral reflectance was more important than polarimetric and textural features in LCZ classification. PALSAR-2 data were beneficial for several land cover LCZ types when Sentinel-2 and PALSAR-2 were combined. Summer nighttime LSTs in most LCZs differed significantly from each other. Results also demonstrated that grid-cell processing provided more homogeneous LCZ maps than the usual resampling methods. This study provided a promising reference to further improve LCZ classification and quantitative analysis of local climate.\n",
      "  - The tremendous advancement of cities has caused changes to the urban subsurface. Urban climate problems have become increasingly prominent, especially with regard to the intensification of the urban heat island (UHI) effect. The local climate zone (LCZ) is a new quantitative method for analyzing urban climate that is based on the kind of urban surface and can effectively deal with the problem of the hazy distinction between urban and rural areas in UHI effect research. LCZs are widely used in regional climate modeling, urban planning, and thermal comfort surveys. Existing large-scale LCZ classification methods usually use visual features of optical images, such as spectral and textural features. There are many problems with hyperspectral LCZ extraction over large areas. LCZ is an integrated concept that includes features of the geography, society, and economy. Consequently, it makes sense to consider the characteristics of human activity and the visual features of the images to interpret them accurately. ALOS_DEM data can depict the city’s physical characteristics; however, images of nighttime lights are crucial indicators of human activity. These three datasets can be used in combination to portray the urban environment. Therefore, this study proposes a method for fusing daytime and nighttime data for LCZ mapping, i.e., fusing daytime Zhuhai-1 hyperspectral images and their derived feature indices, ALOS_DEM data, and nighttime light data from Luojia-1. By combining daytime and nighttime information, the proposed approach captures the temporal dynamics of urban areas, providing a more complete representation of their characteristics. The integration of the data allows for a more refined identification and characterization of urban land cover. It comprehensively integrates daytime and nighttime data, exploits synergistic information from multiple sources, and provides higher accuracy and resolution for LCZ mapping. First, we extracted various features, namely spectral, red-edge, and textural features, from the Zhuhai-1 images, ALOS_DEM data, and nighttime light data from Luojia-1. Random forest (RF) and XGBoost classifiers were used, and the average impurity reduction method was employed to assess the significance of the variables. All the input variables were optimized to select the best combination of variables. The results from a study of the 5th ring road area of Beijing, China, revealed that the technique achieved LCZ mapping with good precision, with a total accuracy of 87.34%. In addition, to examine and contrast the effects of various feature indices on the LCZ classification accuracy, feature combination methods were used. The results of the study showed that the accuracies of LCZ classification in terms of spectral and textural were improved by 2.33% and 2.19% using the RF classifier, respectively. The radiation brightness value (RBV) (GI value = 0.0212) attained the classification’s highest variable importance value; the DEM also produced a high GI value (0.0159), indicating that night lighting and landform features strongly influence LCZ classification.\n",
      "  - As one of the widely concerned urban climate issues, urban heat island (UHI) has been studied using the local climate zone (LCZ) classification scheme in recent years. More and more effort has been focused on improving LCZ mapping accuracy. It has become a prevalent trend to take advantage of multi-source images in LCZ mapping. To this end, this paper tried to utilize multi-source freely available datasets: Sentinel-2 multispectral instrument (MSI), Sentinel-1 synthetic aperture radar (SAR), Luojia1-01 nighttime light (NTL), and Open Street Map (OSM) datasets to produce the 10 m LCZ classification result using Google Earth Engine (GEE) platform. Additionally, the derived datasets of Sentinel-2 MSI data were also exploited in LCZ classification, such as spectral indexes (SI) and gray-level co-occurrence matrix (GLCM) datasets. The different dataset combinations were designed to evaluate the particular dataset’s contribution to LCZ classification. It was found that: (1) The synergistic use of Sentinel-2 MSI and Sentinel-1 SAR data can improve the accuracy of LCZ classification; (2) The multi-seasonal information of Sentinel data also has a good contribution to LCZ classification; (3) OSM, GLCM, SI, and NTL datasets have some positive contribution to LCZ classification when individually adding them to the seasonal Sentinel-1 and Sentinel-2 datasets; (4) It is not an absolute right way to improve LCZ classification accuracy by combining as many datasets as possible. With the help of the GEE, this study provides the potential to generate more accurate LCZ mapping on a large scale, which is significant for urban development.\n",
      "--------------------------------------------------\n",
      "Topic 234: 234_use cases_test_cases_test cases\n",
      "Representative Documents:\n",
      "  - Heterogeneous test processes with respect to test script languages are an integral part of the development process of mechatronic systems that are carried out in supply chains. Up to now, test cases are not exchangeable between test processes because interoperability is not given. The developed approach enables the source-to-source compiling of test cases between test script languages. With this, the interoperability of test cases is achieved, and seamless integration within the supply chain is possible. The developed approach uses transcompilers as a baseline. In doing so, an interoperability model for test cases is presented. Based on the interoperability model, a source-to-source compiling for test cases is shown. The outcome is a prototype that handles test script languages, which are different with respect to type safety and applied programming paradigms. The approach ensures that test cases are still understandable and usable for test reports. The evaluation confirms the translation capabilities as well as the readability of the generated test case for the high-lift scenario from aviation. The interoperability of test cases within the supply chain enables the formalisation of procedural test knowledge to be used in a broad range of future scenarios, such as test automation, digital twins and predictive maintenance.\n",
      "  - The digitalization of the energy sector enables a broad range of new digital use cases and business models. For instance, blockchain-technology can be used for the verification of tamper-resistant storage of asset data (asset logging) or manipulation-resistant guarantees of origin for electricity (labeling). Yet, it is associated with high implementation and operating effort. But many of these use cases require similar players, interfaces, data sets and data processing, so that synergies can result from a joint implementation. We thus evaluate these synergies in implementation and operating effort for use cases in the field of asset logging and labeling using a bottom-up evaluation of the components based on a methodology of Dossow (Energies 16:2424, 2022). Additionally, we extend this methodology to analyze the scalability of the use cases by assessing the relative effort reduction for an increasing number of players involved. The analysis already shows substantial synergies for combinations of two use cases. Yet, especially for combinations of three or more use cases a high effort reduction potential is derived. The highest synergies are obtained among the asset logging use cases, while a combination of asset logging and labeling use cases shows lower synergies in comparison. The analysis of the scaling of the use cases demonstrates that for labeling use cases the main effort driver is the number of consumers, while for asset logging use cases the number of asset operators shows to be more relevant. Thus, scaling effects outweigh the effort reduction potential of use case combinations especially for combinations of asset logging and labeling cases.\n",
      "  - 5G was designed to enable and unify Industrial Internet communication. Emerging 5G campus networks, in particular, provide a flexible communication infrastructure option addressing the specific needs of industry verticals regarding low latency, resilience, security, and operation models. Network Function Virtualization (NFV) and Edge Computing have paved the way for vendor-independent, customized, and scalable network designs for the past decade. Today, Open Radio Access Network (Open RAN) principles extend this architectural thinking toward an innovative and open 5G end-to-end infrastructure. 5G campus networks, in particular, might benefit from this envisaged openness. One key driver for boosting the global interest in private campus networks was the allocation of a dedicated 5G spectrum in Germany in 2019. In addition to permanent spectrum allocations for static campus network deployments, nomadic ad hoc campus network deployments using novel mechanisms, such as dynamic spectrum access and trading, also emerge. Both network types are enabled by the inherent flexibility of combining or disaggregating the desired open 5G RAN and core components in appropriate network deployments.Building upon years of experience in developing and operating 5G network cores and 5G testbeds, the authors provide an overview of the emerging global campus network market, available spectrum options, use cases for nomadic campus network deployments, and the need for open campus networks and open end-to-end technology testbeds. Utilizing the Fraunhofer FOKUS Open5GCore, the 5G Playground testbed, and the 5G+ Nomadic Node as examples, the paper sketches a blueprint for campus networks for international, applied research and development. Ending with an outlook on the evolution of campus networks, namely the transition toward higher spectrums and the integration of non-terrestrial networks, but also the adoption of more agile software principles and the deeper integration of AI/ML technologies for network control and management, it will become obvious that open campus network innovations will pave the way toward 6G.\n",
      "--------------------------------------------------\n",
      "Topic 235: 235_frequency analysis_nonstationary_frequency_rainfall\n",
      "Representative Documents:\n",
      "  - In this study, the annual maximum rainfall event series were constructed and compared for both the modern flip-bucket type rainfall data, collected since 1961 (the modern data), and the old Chukwooki rainfall data, collected from 1777 to 1910 (the Chukwooki data). First, independent rainfall events were derived, by applying the same rainfall threshold of 2 mm and data collection time interval of 2 hours, to both the Chukwooki and the modern data. Annual maximum rainfall event series were then constructed, by applying Freund's bivariate exponential distribution annually. Finally, bivariate frequency analysis was done for the annual maximum rainfall event series constructed, by applying the bivariate logistic model to evaluate and quantify their characteristics. The results are in summary: (1) characteristics of the Chukwooki rainfall events and modern rainfall events are very similar to each other; (2) the annual maximum rainfall events of modern data are slightly larger than those of the Chukwooki data. The total rainfall depth per rainfall event for any given return period is thus estimated to be a little higher for the modern data than that of the Chukwooki data. However, based on the findings in this study, it could not be concluded that the rainfall characteristics have significantly changed during the last 200 years.\n",
      "  - Stationarity is often assumed for frequency analysis of low flows in water resources management and planning. However, many studies have shown that flow characteristics, particularly the frequency spectrum of extreme hydrologic events, were modified by climate change and human activities. Thus, the conventional frequency analysis that fails to consider the nonstationary characteristics may lead to costly design. The analysis presented in this paper was based on the more than 100 years of daily flow data from the Yichang gauging station 44 km downstream of the Three Gorges Dam. The Mann–Kendall trend test under the scaling hypothesis showed that the annual low flows had a significant monotonic trend, whereas an abrupt change point was identified in 1936 by the Pettitt test. The climate‐informed low‐flow frequency analysis and the divided and combined method were employed to account for the impacts from related climate variables and nonstationarities in annual low flows. Without prior knowledge of the probability density function for the gauging station, six distribution functions including the generalized extreme values (GEV), Pearson Type III, Gumbel, Gamma, Lognormal and Weibull distributions have been tested to find the best fit, in which the local likelihood method is used to estimate the parameters. Analyses show that GEV had the best fit for the observed low flows. This study has also shown that the climate‐informed low‐flow frequency analysis is able to exploit the link between climate indices and low flows, which would account for the dynamic feature for reservoir management and provide more accurate and reliable designs for infrastructure and water supply. Copyright © 2014 John Wiley &amp; Sons, Ltd.\n",
      "  - Both natural climate change and anthropogenic impacts may cause nonstationarities in hydrological extremes. In this study, long-term annual maximum streamflow (AMS) records from 145 stations over Canada were used to investigate the nonstationary characteristics of AMS, which include abrupt changes and monotonic temporal trends. The nonparameteric Pettitt test was applied to detect abrupt changes, while temporal monotonic trend analysis in AMS series was conducted using the nonparameteric Mann–Kendall and Spearman tests, as well as a parametric Pearson test. Nonstationary frequency analysis of the AMS series was done using a group of nonstationary probability distributions. The nonstationary characteristics of Canadian AMS were further investigated in terms of the Hurst exponent (H), which represents the long-term persistence (LTP) of streamflow data. The results presented here indicate that for Canadian AMS data, abrupt changes are detected more frequently than monotonic trends, partly because many rivers began to be regulated in the twentieth century. Drainage basins that have experienced significant land-use changes are more likely to show temporal trends in AMS, compared to pristine basins with stable land-use conditions. The nonstationary characteristics of AMS were accounted for by fitting the data with probability distributions with time-varying parameters. Large H found in almost ⅔ of the Canadian AMS dataset indicates strong LTP, which may partly represent the presence of long-term memories in many Canadian river basins. Furthermore, H values of AMS data are positively correlated with the basin area of Canadian rivers. It seems that nonstationary frequency analysis, instead of the traditional stationary hydrologic frequency analysis, should be employed in the future.\n",
      "--------------------------------------------------\n",
      "Topic 236: 236_building_energy_buildings_cooling\n",
      "Representative Documents:\n",
      "  - Energy performance of buildings is a worldwide increasing investigated field, due to ever more stringent energy standards aimed at reducing the buildings’ impact on the environment. The purpose of this paper is to assess the impact that occupant behavior and climate change have on the heating and cooling needs of residential buildings. With this aim, data of a questionnaire survey delivered in Southern Italy were used to obtain daily use profiles of natural ventilation, heating, and cooling, both in winter and in summer. Three climatic scenarios were investigated: The current scenario (2020), and two future scenarios (2050 and 2080). The CCWorldWeatherGen tool was used to create the weather files of future climate scenarios, and DesignBuilder was applied to conduct dynamic energy simulations. Firstly, the results obtained for 2020 demonstrated how the occupants’ preferences related to the use of natural ventilation, heating, and cooling systems (daily schedules and temperature setpoints) impact on energy needs. Heating energy needs appeared more affected by the heating schedules, while cooling energy needs were mostly influenced by both natural ventilation and usage schedules. Secondly, due to the temperature rise, substantial decrements of the energy needs for heating and increments of cooling energy needs were observed in all the future scenarios where in addition, the impact of occupant behavior appeared amplified.\n",
      "  - The growing concern about global climate change extends to different professional sectors. In the building industry, the energy consumption of buildings becomes a factor susceptible to change due to the direct relationship between the outside temperature and the energy needed to cool and heat the internal space. This document aims to estimate the energy consumption of a Minimum Energy Building (MEB) in different scenarios—past, present, and future—in the subtropical climate typical of seaside cities in Southern Spain. The building energy consumption has been predicted using dynamic building energy simulation software tools. Projected climate data were obtained in four time periods (Historical, the 2020s, 2050s, and 2080s), based on four emission scenarios defined by the Intergovernmental Panel on Climate Change (IPCC): B1, B2, A2, A1F1. This methodology has been mathematically complemented to obtain data in closer time frames (2025 and 2030). In addition, different mitigation strategies have been proposed to counteract the impact of climate change in the distant future. The different energy simulations carried on show clearly future trends of growth in total building energy consumption and how current building designers could be underestimating the problem of air conditioning needs in the subtropical zone. Electricity demand for heating is expected to decrease almost completely, while electricity demand for cooling increases considerably. The changes predicted are significant in all scenarios and periods, concluding an increase of between 28–51% in total primary energy consumption during the building life cycle. The proposed mitigation strategies show improvements in energy demands in a range of 11–14% and they could be considered in the initial stages of project design or incorporated in the future as the impact of climate change becomes more pronounced.\n",
      "  - Climate change impact is one of the most important global concerns at present. In the building environment, climate-responsive design may help to enhance the adaptation capacity through a better building energy performance. In this sense, this study addresses an adaptation strategy to reduce the effects of global warming on low-income houses, for which bioclimatic passive strategies should be prioritized, aiming to improve environmental sustainability. The technique chosen to be analyzed is thermal mass for cooling. Thus, the goal is to evaluate the energy consumption and thermal performance impact of implementing bermed earth-sheltered walls on bedrooms in low-income housing (LIH), considered deployed in tropical climate regions. For that, a base scenario (1961–1990) is considered, alongside two future scenarios: 2020 (2011 to 2040) and 2050 (2041 to 2070), both considering the effects of climate change, according to the Fourth Report (AR4) of the Intergovernmental Panel on Climate Change (IPCC). The methodologies adopted are (i) computational simulation to estimate the annual energy consumption demand and (ii) quantification of the cooling degree-hours (CDH), with the subsequent comparative analysis based on Brazilian regulation for energy efficiency in buildings (RTQ-R). The predictions show that there will be an increase in the energy consumption for cooling and in the CDH in both 2020 and 2050 scenarios, regardless of using a bermed earth-sheltered wall. Nonetheless, this adaptive measure enables the building to be resilient in terms of cooling energy demand in the 2020s, since it is 12.3% lower than in the building without the strategy use, compared with the base scenario. In the 2050s, resilience was almost reached with energy consumption only 10.7% higher, for the same conditions described previously. Therefore, bermed earth-sheltered walls work as a climate-responsive design strategy to face the potential global warming effects, promoting building sustainability in tropical climate regions.\n",
      "--------------------------------------------------\n",
      "Topic 237: 237_fdt_stochastic_gaussian_low frequency\n",
      "Representative Documents:\n",
      "  -                The fluctuation–dissipation theorem (FDT) has been suggested as a method of calculating the response of the climate system to a small change in an external parameter. The simplest form of the FDT assumes that the probability density function of the unforced system is Gaussian and most applications of the FDT have made a quasi-Gaussian assumption. However, whether or not the climate system is close to Gaussian remains open to debate, and non-Gaussianity may limit the usefulness of predictions of quasi-Gaussian forms of the FDT. Here we describe an implementation of the full non-Gaussian form of the FDT. The principle of the quasi-Gaussian FDT is retained in that the response to forcing is predicted using only information available from observations of the unforced system, but in the non-Gaussian case this information must be used to estimate aspects of the probability density function of the unforced system. Since this estimate is implemented using the methods of nonparametric statistics, the new form is referred to herein as a “nonparametric FDT.” Application is demonstrated to a sequence of simple models including a stochastic version of the three-component Lorenz model. The authors show that the nonparametric FDT gives accurate predictions in cases where the quasi-Gaussian FDT fails. Practical application of the nonparametric FDT may require optimization of the method set out here for higher-dimensional systems.\n",
      "  -                The low-frequency response to changes in external forcing or other parameters for various components of the climate system is a central problem of contemporary climate change science. The fluctuation–dissipation theorem (FDT) is an attractive way to assess climate change by utilizing statistics of the present climate; with systematic approximations, it has been shown recently to have high skill for suitable regimes of an atmospheric general circulation model (GCM). Further applications of FDT to low-frequency climate response require improved approximations for FDT on a reduced subspace of resolved variables. Here, systematic mathematical principles are utilized to develop new FDT approximations on reduced subspaces and to assess the small yet significant departures from Gaussianity in low-frequency variables on the FDT response. Simplified test models mimicking crucial features in GCMs are utilized here to elucidate these issues and various FDT approximations in an unambiguous fashion. Also, the shortcomings of alternative ad hoc procedures for FDT in the recent literature are discussed here. In particular, it is shown that linear regression stochastic models for the FDT response always have no skill for a general nonlinear system for the variance response and can have poor or moderate skill for the mean response depending on the regime of the Lorenz 40-model and the details of the regression strategy. New nonlinear stochastic FDT approximations for a reduced set of variables are introduced here with significant skill in capturing the effect of subtle departures from Gaussianity in the low-frequency response for a reduced set of variables.\n",
      "  -                The low-frequency response to changes in external forcing for the climate system is a fundamental issue. In two recent papers the authors developed a new blended response algorithm for predicting the response of a nonlinear chaotic forced-dissipative system to small changes in external forcing. This new algorithm is based on the fluctuation–dissipation theorem and combines the geometrically exact general response formula using integration of a linear tangent model at short response times and the classical quasi-Gaussian response algorithm at longer response times. This algorithm overcomes the inherent numerical instability in the geometric formula arising because of positive Lyapunov exponents at longer times while removing potentially large systematic errors from the classical quasi-Gaussian approximation at moderate times.               Here the new blended method is tested on the low-frequency response for a T21 barotropic truncation on the sphere with realistic topography in two dynamical regimes corresponding to the mean climate behavior at 300- and 500-hPa geopotential height. The 300-hPa regime has robust strongly mixing behavior with a nearly Gaussian equilibrium state distribution, whereas the 500-hPa regime is weakly chaotic with slowly decaying time autocorrelation functions and strongly non-Gaussian climatology. It is found that the blended response algorithm has significant skill beyond the classical quasi-Gaussian algorithm for the response of the climate mean state and its variance. Additionally, the predicted response of the T21 barotropic model in the low-frequency regime for these functionals does not seem to be affected by the model’s structural instability. Thus, the results here suggest the use of the fluctuation–dissipation theorem–based blended response algorithm for more complex nonlinear geophysical models.\n",
      "--------------------------------------------------\n",
      "Topic 238: 238_light_co2_leaf_gas exchange\n",
      "Representative Documents:\n",
      "  -                Lateral diffusion of CO2 was investigated in photosynthesizing leaves with different anatomy by gas exchange and chlorophyll a fluorescence imaging using grease to block stomata. When one-half of the leaf surface of the heterobaric species Helianthus annuus was covered by 4-mm-diameter patches of grease, the response of net CO2 assimilation rate (A) to intercellular CO2 concentration (Ci) indicated that higher ambient CO2 concentrations (Ca) caused only limited lateral diffusion into the greased areas. When single 4-mm patches were applied to leaves of heterobaric Phaseolus vulgaris and homobaric Commelina communis, chlorophyll a fluorescence images showed dramatic declines in the quantum efficiency of photosystem II electron transport (measured as Fq′/Fm′) across the patch, demonstrating that lateral CO2 diffusion could not support A. The Fq′/Fm′ values were used to compute images of Ci across patches, and their dependence on Ca was assessed. At high Ca, the patch effect was less in C. communis than P. vulgaris. A finite-volume porous-medium model for assimilation rate and lateral CO2 diffusion was developed to analyze the patch images. The model estimated that the effective lateral CO2 diffusion coefficients inside C. communis and P. vulgaris leaves were 22% and 12% of that for free air, respectively. We conclude that, in the light, lateral CO2 diffusion cannot support appreciable photosynthesis over distances of more than approximately 0.3 mm in normal leaves, irrespective of the presence or absence of bundle sheath extensions, because of the CO2 assimilation by cells along the diffusion pathway.\n",
      "  - The concentration of CO2 in the chloroplast is less than atmospheric owing to a series of gas-phase and liquid-phase resistances. For a long time it was assumed that the concentration of CO2 in the chloroplasts is the same as in the intercellular spaces (e.g. as measured by gas exchange). There is mounting evidence that this assumption is invalid and that CO2 concentrations in the chloroplasts are significantly less than intercellular CO2. It is now generally accepted that internal conductance (gi) is a significant limitation to photosynthesis, often as large as that due to stomata. Internal conductance describes this decrease in CO2 concentration between the intercellular spaces and chloroplasts as a function of net photosynthesis [gi = A / (Ci – Cc)]. Internal conductance is commonly estimated by simultaneous measurements of gas exchange and chlorophyll a fluorescence or instantaneous discrimination against 13CO2. These common methods are complemented by three alternative methods based on (a) the difference between intercellular and chloroplastic CO2 photocompensation points, (b) the curvature of an A / Ci curve, and (c) the initial slope of an A / Ci curve v. the estimated initial slope of an A / Cc curve. The theoretical basis and protocols for estimating internal conductance are described. The common methods have poor precision with relative standard deviations commonly &gt; 10%; much less is known of the precision of the three alternative methods. Accuracy of the methods is largely unknown because all methods share some common assumptions and no truly independent and assumption-free method exists. Some assumptions can and should be tested (e.g. the relationship of fluorescence with electron transport). Methods generally require knowledge of either the kinetic parameters of Rubisco, or isotopic fractionation by Rubisco. These parameters are difficult to measure, and thus are generally assumed a priori. For parameters such as these a sensitivity analysis is recommended. One means of improving confidence in gi estimates is by using two or more methods, but it is essential that the methods chosen share as few common assumptions as possible. All methods require accurate and precise measurements of A and Ci — these are best achieved by minimising leaks, maximising the signal-to-noise ratio by using a large leaf area and moderate flow rate, and by taking into account cuticular and boundary layer conductances.\n",
      "  -  The concentration of CO2 in the chloroplast is less than atmospheric owing to a series of gas-phase and liquid-phase resistances. For a long time it was assumed that the concentration of CO2 in the chloroplasts is the same as in the intercellular spaces (e.g. as measured by gas exchange). There is mounting evidence that this assumption is invalid and that CO2 concentrations in the chloroplasts are significantly less than intercellular CO2. It is now generally accepted that internal conductance (gi) is a significant limitation to photosynthesis, often as large as that due to stomata. Internal conductance describes this decrease in CO2 concentration between the intercellular spaces and chloroplasts as a function of net photosynthesis [gi = A�/�(Ci – Cc)]. Internal conductance is commonly estimated by simultaneous measurements of gas exchange and chlorophyll a fluorescence or instantaneous discrimination against 13CO2. These common methods are complemented by three alternative methods based on (a) the difference between intercellular and chloroplastic CO2 photocompensation points, (b) the curvature of an A�/�Ci curve, and (c) the initial slope of an A�/�Ci curve v. the estimated initial slope of an A�/�Cc curve. The theoretical basis and protocols for estimating internal conductance are described. The common methods have poor precision with relative standard deviations commonly &gt; 10%; much less is known of the precision of the three alternative methods. Accuracy of the methods is largely unknown because all methods share some common assumptions and no truly independent and assumption-free method exists. Some assumptions can and should be tested (e.g. the relationship of fluorescence with electron transport). Methods generally require knowledge of either the kinetic parameters of Rubisco, or isotopic fractionation by Rubisco. These parameters are difficult to measure, and thus are generally assumed a priori. For parameters such as these a sensitivity analysis is recommended. One means of improving confidence in gi estimates is by using two or more methods, but it is essential that the methods chosen share as few common assumptions as possible. All methods require accurate and precise measurements of A and Ci — these are best achieved by minimising leaks, maximising the signal-to-noise ratio by using a large leaf area and moderate flow rate, and by taking into account cuticular and boundary layer conductances. \n",
      "--------------------------------------------------\n",
      "Topic 239: 239_co2_growth_grown_seed\n",
      "Representative Documents:\n",
      "  - The potential use of C4 biochemical subtypes[nicotinamide adenine dinucleotide phosphate-malic enzyme (NADP-ME),nicotinamide adenine dinucleotide-malic enzyme (NAD-ME) andphosphoenolpyruvate carboxykinase (PCK)] asdelimiters of plant functional types (PFTs) with distinct responses to risingatmospheric CO2 concentrations was investigated inSouth African grass species. Gas exchange and above-ground growth in ambientand elevated CO2 (360 and 660 µmol mol–1 , respectively) were determined in threeNADP-ME species, two NAD-ME species, two PCK species and one C3 species, all excavated from the same field site.Plants were grown in open-top chambers in a greenhouse for 178 d. Net CO2 assimilation rates were only significantly increasedin one NAD-ME species, but stomatal conductances decreased (in six out ofeight species, by a mean of 46%) and instantaneous leaf water-useefficiency increased (in all species, by a mean of 89%) in elevated CO2. These responses did not differ betweenphotosynthetic pathways. Parameters derived from photosynthetic CO2 and light response curves were also not differentiallyinfluenced by CO2 treatment between pathways. Gasexchange responses were generally poorly related to CO2responsiveness. Significant increases in leaf growth and canopy leaf area inelevated CO2 were found in two NADP-ME species, whereasincreases in non-leaf above-ground growth were measured in three speciesrepresenting all three C4 subtypes. Growth responses inelevated CO2 were apparently not simply correlated withbiochemical subtype characteristics, although the most significant responses(particularly at the leaf level) were found for the NADP-ME pathway. Thisresult was more likely attributable to the significant positive correlationfound between CO2 responsiveness of leaf growth andrelative leaf regrowth potential of individual species, the latter beinghigher in the two responsive NADP-ME species. Therefore, categorisation ofPFTs according to relative growth potential may be more appropriate forpredictions of CO2 responsiveness in C4 grasses.\n",
      "  - Indeterminate narrow-leafed lupin (Lupinus angustifoliusL. cv. Merrit) was exposed to enriched atmospheric CO2during pod-filling to enhance the availability of carbon resources forpod-filling in order to determine whether or not seed-filling, yield, andharvest index are limited by the availability of photosynthetic assimilate.Plants were grown in a glasshouse and the flowers painted with an aqueoussolution containing either N6-benzylaminopurine (BAP) orno BAP to generate 2 different numbers of pods per plant. From the time whenpods began to fill seeds (≥5 mg/seed) until maturity, plants wereexposed to either ambient (350–360 L/L) or enriched (700 L/L)CO2 by enclosing them in 2 transparent, box-shapedtunnels with similar temperatures, light, and water conditions. Whether or notBAP was applied to flowers, CO2 enrichment increased thefinal number of pods and the number of pods that filled large seeds (≥150mg) by 20–22 pods/plant. Enriched CO2 reducedto zero the number of pods that had small seeds (≥30–80 mg) andreduced the number of pods with unfilled seeds from 16 to 1 pod/plant.This increased seed yield per plant by 44–66%, but did not affectthe harvest index. Harvest index was unchanged because enrichedCO2, while increasing pod-filling, also increased podset and dry matter accumulation on the developing branches. This indicatesthat an increased availability of carbon resources during-pod filling changedthe allocation of assimilates by filling small seeds and producing newbranches. The 47–56% increase in dry matter per plant wasreflected in the increase in seed yield, which occurred largely through anincreased number of pods and seeds per plant. These data support the idea thatseed-filling and hence seed yield in well-nodulated, indeterminatenarrow-leafed lupin is limited by carbon resources at the stage when the plantis most source-limited, which is during podset and pod-filling.\n",
      "  - Ten contrasting Acacia species were grown in glasshouseswith normal ambient CO2 or ele-vated to 700 µLL–1. Plants were grown in sand with a completenutrient solution, including 5 mМ nitrate. Our objective was to determinethe degree to which photosynthesis, and the efficiency of nitrogen and wateruse, were affected by growth under elevated CO2 incontrasting plant species that differ in specific foliage area (foliage areaper unit foliage dry mass). Photosynthetic characteristics were measured atseveral stages. Growth and measurement of gas exchange under 700 mLL–1 CO2 resulted in enhancedrates of CO2 assimilation per unit foliage area in nineof the species. The degree of enhancement was independent of specific foliagearea. The exception was the slow-growing A. aneura,which had lower rates of CO2 assimilation when grown andmeasured at 700 µL L–1CO2 compared to plants grown and measured at 350µL L–1 CO2, at 50, 78and 93 d after transplanting. Leaf conductance was reduced by growth inelevated CO2 in only six of the species. Overall,elevated CO2 improved the ratio ofCO2 assimi-lation to conductance by 78% andincreased CO2 assimilation per unit of foliage nitrogenby 30% at a given specific foliage area. Detailed study ofA. saligna and A. aneura revealedthat the effects of the CO2 treatment were similarlyevident on all fully expanded phyllodes, regardless of their age.Intercellular CO2 response curves were analysed on fourspecies and revealed no change in the ratio of electron transport to Rubiscoactivities. However, for A. aneura andA. melanoxylon, both electron transport and Rubiscoactivities were reduced per unit foliage nitrogen, by growth under elevatedCO2 . For A. saligna andA. implexa, these activities per unit nitrogen, were notaltered by the elevated CO2 treatment. To relateCO2 assimilation rates to net assimilation rates (drymatter increment per unit foliage area per day) derived from growth analysis,between 30 and 50% of daily photosynthesis appeared to be consumed inrespiration. This proportion was not altered by CO2treatment for seven of the Acacia species, but appearedto be reduced in the other three. The increase in CO2assimilation rate by growth under 700 com-pared to 350 µLL–1 CO2 that was measured(26%, mean of all species from two surveys), matched the increase innet assimilation rate that had been derived from destructive sampling(30%). We conclude that the increase in CO2assimilation rate in the selected Acacia species wasindependent of species, growth rate and foliage area per unit foliage drymass.\n",
      "--------------------------------------------------\n",
      "Topic 240: 240_genes_metabolism_degs_expression\n",
      "Representative Documents:\n",
      "  - Rhizosphere CO2 is vital for crop growth, development, and productivity. However, the mechanisms of plants’ responses to root-zone CO2 are unclear. Oriental melons are sensitive to root-zone gas, often encountering high root-zone CO2 during cultivation. We investigated root growth and nitrogen metabolism in oriental melons under T1 (0.5%) and T2 (1.0%) root-zone CO2 concentrations using physiology and comparative transcriptome analysis. T1 and T2 increased root vigor and the nitrogen content in the short term. With increased treatment time and CO2 concentration, root inhibition increased, characterized by decreased root absorption, incomplete root cell structure, accelerated starch accumulation and hydrolysis, and cell aging. We identified 1280 and 1042 differentially expressed genes from T1 and T2, respectively, compared with 0.037% CO2-grown plants. Among them, 683 co-expressed genes are involved in stress resistance and nitrogen metabolism (enhanced phenylpropanoid biosynthesis, hormone signal transduction, glutathione metabolism, and starch and sucrose metabolism). Nitrogen metabolism gene expression, enzyme activity, and nitrogen content analyses showed that short-term elevated root-zone CO2 mainly regulated plant nitrogen metabolism post-transcriptionally, and directly inhibited it transcriptionally in the long term. These findings provided a basis for further investigation of nitrogen regulation by candidate genes in oriental melons under elevated root-zone CO2.\n",
      "  - To explore the molecular mechanism of the response of Masson pine (Pinus massoniana), the main coniferous tree in southern China, to high CO2 stress, transcriptome sequencing was carried out to analyze the genome-wide responses of annual seedlings under different durations (0 h, 6 h, 12 h and 24 h) of high CO2 stress. The results showed that a total of 3080/1908, 3110/2115 and 2684/1483 genes were up-/down-regulated after 6 h, 12 h and 24 h of treatment, respectively, compared with control check group (CK, 0 h). Kyoto Encyclopedia of Genes and Genomes (KEGG) analysis showed that most of these differentially expressed genes (DEGs) were enriched in energy metabolism, carbohydrate synthesis, cell wall precursor synthesis and hormone regulation pathways. For energy metabolism, the expression of most genes involved in photosynthesis (including the light reaction and Calvin cycle) was generally inhibited, while the expression of genes related glycolysis, the tricarboxylic acid (TCA) cycle and PPP pathway was up-regulated. In addition, the increase in the CO2 concentration induced the up-regulation of gene expression in the sucrose synthesis pathway. Among all starch synthesis genes, GBSS (granule-bound starch synthase) had the highest expression level. On the other hand, during the synthesis of hemicellulose and pectin (cell wall precursor substances), the expression levels of GMD (GDP-mannose 4,6-dehydratase), MGP (Mannose-1-phosphate guanylyl transferase) and RHM (Rhamnose biosynthetic enzyme) were the highest, suggesting that the synthesis of the raw materials hemicellulose and pectin in Masson pine under stress were mainly supplied by GDP-Man, GDP-Fuc and UDP-Rha. Finally, stress inhibited gene expression in the ABA (Abscisic Acid) synthesis pathway and induced gene expression in the GA (Gibberellin), SA (Salicylic acid), BR(Brassinolide) and MeJA (Methyl Jasmonate) pathways. Stomatal switches were regulated by hormonal interactions. This experiment elaborated on the response and molecular mechanism of Masson pine to CO2 stress and aided in screening carbon sequestration genes for the corresponding molecular research of Masson pine in the future.\n",
      "  - Root-zone CO2 is a major factor that affects crop growth, development, nutrient uptake, and metabolism. Oriental melon is affected by root-zone gases during growth, the microstructure, sugar and starch contents, enzymatic activities related to sugar and starch metabolism, and gene expression in the roots of oriental melon seedlings were investigated under three root-zone CO2 concentrations (CK: 0.2%, T1: 0.4%, T2: 1.1%). Elevated root-zone CO2 altered the cellular microstructure, accelerated the accumulation and release of starch grains, disrupted organelle formation, and accelerated root senescence. The sugar and starch contents and metabolic activity in the roots increased within a short duration following treatment. Compared to the control, 232 and 1492 differentially expressed genes (DEGs) were identified on the 6th day of treatment in T1 and T2 plants, respectively. The DEGs were enriched in three metabolic pathways. The majority of genes related to sucrose and starch hydrolysis were upregulated, while the genes related to sucrose metabolism were downregulated. The study revealed that oriental melon seedlings adapt to elevated root-zone CO2 stress by adjusting sugar and starch metabolism at the transcriptome level and provides new insights into the molecular mechanism underlying the response to elevated root-zone CO2 stress.\n",
      "--------------------------------------------------\n",
      "Topic 241: 241_flood_dam_flood risk_water availability\n",
      "Representative Documents:\n",
      "  - This study is concerned with flood risk that can be assessed by integrating GIS, hydraulic modelling and required field information. A critical point in flood risk assessment is that while flood hazard is the same for a given area in terms of intensity, the risk could be different depending on a set of conditions (flood vulnerability). Clearly, risk is a function of hazard and vulnerability. This study aims to introducing a new approach of assessing flood risk, which successfully addresses this above-mentioned critical issue. The flood risk was assessed from flood hazard and vulnerability indices. Two-dimensional flood flow simulation was performed with Delft3D model to compute floodplain inundation depths for hazard assessment. For the purpose of flood vulnerability assessment, elements at risk and flood damage functions were identified and assessed, respectively. Then, finally flood risk was assessed first by combining replacement values assessed for the elements and then using the depth–damage function. Applying this approach, the study finds that areas with different levels of flood risk do not always increase with the increase in return period of flood. However, inundated areas with different levels of flood depth always increase with the increase in return period of flood. The approach for flood risk assessment adopted in this study successfully addresses the critical point in flood risk study, where flood risk can be varied even after there is no change in flood hazard intensity.\n",
      "  - We evaluated different management alternatives to enhance potential water availability for agriculture under climate change scenarios. The management goal involved maximizing potential water availability, understood as the maximum volume of water supplied at a certain point of the river network that satisfies a defined demand, and taking into account specified reliability requirements. We focused on potential water availability for agriculture and assumed two types of demands: urban supply and irrigation. If potential water availability was not enough to satisfy all irrigation demands, management measures were applied aiming at achieving a compromise solution between resources and demands. The methodological approach consisted of estimation and comparison of runoff for current and future period under climate change effects, calculation of water availability changes due to changes in runoff, and evaluation of the adaptation choices that can modify the distribution of water availability, under climate change. Adaptation choices include modifying water allocation to agriculture, increasing the reservoir storage capacity, improving the efficiency of urban water use, and modifying water allocation to environmental flows. These management measures were evaluated at the desired points of the river network by applying the Water Availability and Adaptation Policy Analysis (WAAPA) model. We simulated the behavior of a set of reservoirs that supply water for a set of prioritized demands, complying with specified ecological flows and accounting for evaporation losses. We applied the methodology in six representative basins of southern Europe: Duero-Douro, Ebro, Guadalquivir, Po, Maritsa-Evros, and Struma-Strymon. While in some basins, such as the Ebro or Struma-Strymon, measures can significantly increase water availability and compensate for a fraction of water scarcity due to climate change, in other basins, like the Guadalquivir, water availability cannot be enhanced by applying the management measures analyzed, and irrigation water use will have to be reduced.\n",
      "  - Urban flooding is considered one of the hazardous disasters in metropolitan areas, especially for those located in arid regions. Due to the associated risks of climate change in increasing the frequency of extreme rainfall events, climate-induced migration to urban areas leads to the intensification of urban settlements in arid regions as well as an increase in urban expansion towards arid land outskirts. This not only stresses the available infrastructure but also produces substantial social instability due to unplanned urban growth. Therefore, this study sheds light on the main factors that are increasing the flood risk, through examining the consequences of rapid urban growth and the performance of drainage networks on urban flood volumes and comparing it with the effects induced by climate change on the surface runoff. The effect of urbanization is assessed through land use maps showing the historical urbanization conditions for the past 30 years, while considering the role of urban planning and its effect on exacerbating surface runoff. Six climate projection scenarios adopted from three Global Climate Models under two Representative Concentration Pathways (4.5 and 8.5) during the period (2006–2020) were compared to ground observed rainfall data to identify which climate scenario we are likely following and then evaluate its effects on the current rainfall trends up to the year 2050. The significance of the drainage design in the mitigation or increase of surface runoff is evaluated through capacity-load balance during regular and extreme storms. It is found that using impervious surfaces coupled with poor planning causing the blockage of natural flood plains led to an increase in the total runoff of about 180%, which is three times more than the effect induced by climate change for the same analysis period. Climate change decreased the intensities of 2- and 5-year rainfall events by 6% while increasing the intensities of extreme events corresponds to 100-year by 17%. Finally, the urban drainage had a distinguished role in increasing surface runoff, as 70% of the network performed poorly during the smallest rainfall event of 2-year return period. The study emphasizes the urgency to re-evaluate the existing and future urban drainage design approach: although urban development and climate change have inevitable effects on the increase in urban flood volumes, it could be alleviated through improved infrastructures.\n",
      "--------------------------------------------------\n",
      "Topic 242: 242_socio psychological_psychological_psychological climate_socio psychological climate\n",
      "Representative Documents:\n",
      "  - In the system of measures for the moral and psychological support of the professional activities of employees of the internal affairs bodies, the diagnosis of the socio-psychological climate is becoming increasingly important.&#x0D;Along with understanding the significance of the socio-psychological climate as an important psychological phenomenon, the need for further improvement of the tools and procedures used to measure it is obvious. In addition to utilitarian reasons caused by psychometric shortcomings of the instrumentation, errors in the organization of psychodiagnostic procedures for studying it, there are reasons of a different level.&#x0D;The article is devoted to the analysis of the difficulties that exist in measuring and evaluating the socio-psychological climate in the service teams of the internal affairs bodies. The authors highlight the difficulties of the methodological level, which they see in the complexity of the phenomenon of «sociopsychological climate» and the variety of scientific approaches in its description, as well as the difficulties of the instrumental level, which lie in the fact that in many ways the methods known and used by psychologists of the internal affairs bodies have lost their effect. novelties and their resistance to falsification has decreased,&#x0D;which led to a decrease in the effectiveness of measuring procedures, does not allow to fully identify the reasons for the deterioration of the socio-psychological climate in the unit and predict with a high degree of probability the climate in a certain group in the long term. In the article, the authors substantiate the need to improve the practice of psychological measurement of the socio-psychological climate, describing in detail various theoretical approaches, scientific methods of cognition, particular methods of measurement and evaluation.\n",
      "  - The article is devoted to the study of the process of effective management of the socio-psychological climate in the organization. The author notes that the socio-psychological climate is an indicator of the level of development of the workforce, capable of more efficient work. The aim of the study is to study the factors that ensure a favorable socio-psychological climate in the workforce using modern research methods: analysis, synthesis, grouping methods, tabular; systematization of factors affecting the process of effective management of the socio-psychological climate in the team. The methodological basis of the study was the theoretical provisions for determining the definition of the socio-psychological climate of the team, an analytical review of practical studies of the factors influencing it in modern market conditions. As a result of the study, a systematization of factors affecting the creation of a favorable socio-psychological climate in the team was carried out.\n",
      "  -  The subject of the study is the main directions of studying the socio-psychological climate of the organization. The purpose of the study is to analyze the articles of modern scientists, as well as to identify the main current trends in modern domestic research on the socio-psychological and organizational climate. The results of research conducted in various work collectives are analyzed: in commercial and state organizations, educational institutions, internal affairs bodies, industrial enterprises, etc. Comparative analysis, systematization and classification of the received information is carried out. Special attention is paid to the relationship of a favorable climate with the efficiency and productivity of organizations, as well as factors for optimizing the socio-psychological climate. The results of more than twenty modern studies over the past three years have been analyzed. According to the results of the work, five relevant directions and trends in the study of the socio-psychological climate and the phenomena associated with it were identified: the study of the socio-psychological climate as a factor affecting the effectiveness of the organization; the study of the factors of optimization, improvement and management of the socio-psychological climate; the study of the relationship of the socio-psychological climate with organizational culture; the assessment of the influence of the influence of leadership qualities and management style on the socio-psychological climate of the organization; the study of the relationship of the socio-psychological climate with the characteristics of the behavior of employees in conflict.\t\n",
      "--------------------------------------------------\n",
      "Topic 243: 243_health_education_nursing_medical\n",
      "Representative Documents:\n",
      "  - PurposeThe purpose of this paper is to discuss the existing opportunity to educate future health professionals on the health impacts of climate change in order to facilitate more informed planning and health governance.Design/methodology/approachThe authors provide context for climate and health education and how it can lead to better-informed health governance, discuss how health can be used to motivate climate action, and provide examples of climate and health governance. In addition, they outline the climate and health educational components needed in health profession curricula and provide an example of an effort currently being implemented to support and coordinate climate and health education at health professions institutions.FindingsAlthough action to address the health impacts of climate change is taking place, more climate-health policy and informed governance is needed. In addition, climate and health education must be included in the curricula of all health professions institutions to provide critical know-how on this topic.Originality/valueThe authors seek to advance the discussion around the need for climate and health education in schools and programs of public health, medicine, and nursing to better prepare students for their future roles as health practitioners.\n",
      "  - Introduction:Climate change is intricately related to human health and impacts acute and chronic diseases leading to increased demands on the health care system.Aim:The University of Colorado Graduate Medical Education (GME) Fellowship in Climate Change and Health Science Policy (CCHSP) aims to train and equip a new generation of clinicians knowledgeable in climate science, proficient in climate health education, and facile with advocacy skills in order to become leaders in health policy.The CCHSP fellowship is funded by the Living Closer Foundation and hosted through the University of Colorado Department of Emergency Medicine. It is a one to two-year program tailored to the fellow’s specific goals with the opportunity to earn an MPH or MA. Clinical work is supported through the UCHealth network. Site placement occurs at partnering organizations, including the National Institutes of Health, the Centers for Disease Control and Prevention, and fieldwork throughout the world (via Colorado School of Public Health, Harvard FXB Center for Health and Human Rights).The first fellow was recruited in 2017 and has participated in and completed multiple projects: technical contributor to the US Government’s Fourth National Climate Assessment; advocating for women’s health policy in India; authorship of climate change and health resource documents for the World Bank; climate change leadership within SAEM; advocacy work with local and state governments; multiple research publications.Discussion:As climate change continues to impact human health with widespread consequences, we need effective and articulate leaders to affect policy. Although this Fellowship originated in Emergency Medicine, its competencies and structure are replicable for other clinical specialties. Climate change will be one of the core global health challenges for generations. A strong foundation of clinicians who understand its causes and the strategies for adaptation and mitigations are necessary to optimize health outcomes amidst this growing threat.\n",
      "  - PurposeThe adverse health effects from climate change demand action from the nursing profession. This article examines the calls to action, the status of climate change in nursing education, and challenges and recommendations for nursing education related to climate change and human health.Organizing ConstructDiscussion paper.FindingsThe integration of climate change into nursing education is essential so that knowledge, skills, and insights critical for clinical practice in our climate‐changing world are incorporated in curricula, practice, research, and policy. Our Ecological Planetary Health Model offers a framework for nursing to integrate relevant climate change education into nursing curricula and professional nursing education. Nursing education can offer a leadership role to address the mitigation, adaptation, and resilience strategies for climate change.ConclusionsAn ecological framework is valuable for nursing education regarding climate change through its consideration of political, cultural, economic, and environmental interrelationships on human health and the health of the planet. Knowledge of climate change is important for integration into basic and advanced nursing education, as well as professional education for nurses to address adverse health impacts, climate change responses policy, and advocacy roles.Clinical RelevanceFor current and future nurses to provide care within a climate‐changing environment, nursing education has a mandate to integrate knowledge about climate change issues across all levels of nursing education. Competence in nursing practice follows from knowledge and skill acquisition gained from integration of climate change content into nursing education.\n",
      "--------------------------------------------------\n",
      "Topic 244: 244_organisms_thermal_species_warming\n",
      "Representative Documents:\n",
      "  - Organisms in all domains, Archaea, Bacteria, and Eukarya will respond to climate change with differential vulnerabilities resulting in shifts in species distribution, coexistence, and interactions. The identification of unifying principles of organism functioning across all domains would facilitate a cause and effect understanding of such changes and their implications for ecosystem shifts. For example, the functional specialization of all organisms in limited temperature ranges leads us to ask for unifying functional reasons. Organisms also specialize in either anoxic or various oxygen ranges, with animals and plants depending on high oxygen levels. Here, we identify thermal ranges, heat limits of growth, and critically low (hypoxic) oxygen concentrations as proxies of tolerance in a meta‐analysis of data available for marine organisms, with special reference to domain‐specific limits. For an explanation of the patterns and differences observed, we define and quantify a proxy for organismic complexity across species from all domains. Rising complexity causes heat (and hypoxia) tolerances to decrease from Archaea to Bacteria to uni‐ and then multicellular Eukarya. Within and across domains, taxon‐specific tolerance limits likely reflect ultimate evolutionary limits of its species to acclimatization and adaptation. We hypothesize that rising taxon‐specific complexities in structure and function constrain organisms to narrower environmental ranges. Low complexity as in Archaea and some Bacteria provide life options in extreme environments. In the warmest oceans, temperature maxima reach and will surpass the permanent limits to the existence of multicellular animals, plants and unicellular phytoplankter. Smaller, less complex unicellular Eukarya, Bacteria, and Archaea will thus benefit and predominate even more in a future, warmer, and hypoxic ocean.\n",
      "  - Climate warming is expected to have large effects on ecosystems in part due to the temperature dependence of metabolism. The responses of metabolic rates to climate warming may be greatest in the tropics and at low elevations because mean temperatures are warmer there and metabolic rates respond exponentially to temperature (with exponents &gt;1). However, if warming rates are sufficiently fast in higher latitude/elevation lakes, metabolic rate responses to warming may still be greater there even though metabolic rates respond exponentially to temperature. Thus, a wide range of global patterns in the magnitude of metabolic rate responses to warming could emerge depending on global patterns of temperature and warming rates. Here we use the Boltzmann–Arrhenius equation, published estimates of activation energy, and time series of temperature from 271 lakes to estimate long‐term (1970–2010) changes in 64 metabolic processes in lakes. The estimated responses of metabolic processes to warming were usually greatest in tropical/low‐elevation lakes even though surface temperatures in higher latitude/elevation lakes are warming faster. However, when the thermal sensitivity of a metabolic process is especially weak, higher latitude/elevation lakes had larger responses to warming in parallel with warming rates. Our results show that the sensitivity of a given response to temperature (as described by its activation energy) provides a simple heuristic for predicting whether tropical/low‐elevation lakes will have larger or smaller metabolic responses to warming than higher latitude/elevation lakes. Overall, we conclude that the direct metabolic consequences of lake warming are likely to be felt most strongly at low latitudes and low elevations where metabolism‐linked ecosystem services may be most affected.\n",
      "  - SUMMARYInsects are highly successful animals inhabiting marine, freshwater and terrestrial habitats from the equator to the poles. As a group, insects have limited ability to regulate their body temperature and have thus required a range of strategies to support life in thermally stressful environments, including behavioural avoidance through migration and seasonal changes in cold tolerance. With respect to overwintering strategies, insects have traditionally been divided into two main groups: freeze tolerant and freeze avoiding, although this simple classification is underpinned by a complex of interacting processes, i.e. synthesis of ice nucleating agents, cryoprotectants, antifreeze proteins and changes in membrane lipid composition. Also, in temperate and colder climates, the overwintering ability of many species is closely linked to the diapause state, which often increases cold tolerance ahead of temperature-induced seasonal acclimatisation. Importantly, even though most species can invoke one or both of these responses, the majority of insects die from the effects of cold rather than freezing. Most studies on the effects of a changing climate on insects have focused on processes that occur predominantly in summer (development, reproduction) and on changes in distributions rather than winter survival per se. For species that routinely experience cold stress, a general hypothesis would be that predicted temperature increases of 1°C to 5°C over the next 50-100 years would increase winter survival in some climatic zones. However, this is unlikely to be a universal effect. Negative impacts may occur if climate warming leads to a reduction or loss of winter snow cover in polar and sub-polar areas, resulting in exposure to more severe air temperatures, increasing frequency of freeze—thaw cycles and risks of ice encasement. Likewise, whilst the dominant diapause-inducing cue (photoperiod) will be unaffected by global climate change, higher temperatures may modify normal rates of development, leading to a decoupling of synchrony between diapause-sensitive life-cycle stages and critical photoperiods for diapause induction. In terms of climate warming and potential heat stress, the most recent predictions of summer temperatures in Europe of 40°C or higher in 50-75 years, are close to the current upper lethal limit of some insects. Long-term data sets on insect distributions and the timing of annual migrations provide strong evidence for ‘positive’ responses to higher winter temperatures over timescales of the past 20-50 years in North America, Europe and Asia.\n",
      "--------------------------------------------------\n",
      "Topic 245: 245_australia_record_southern hemisphere_australian region\n",
      "Representative Documents:\n",
      "  - This is a summary of the southern hemisphere atmospheric circulation patterns and meteorological indices for spring 2018; an account of seasonal rainfall and temperature for the Australian region and broader southern hemisphere is also provided. A positive phase of the Indian Ocean Dipole developed during the season, and the central and eastern equatorial Pacific were warmer than average without reaching El Niño thresholds. It was Australia’s driest September on record, before rainfall of closer to average in October and November. It was warmer than average, especially in northern Australia, with coastal Queensland affected by extreme heat and wildfires in November. It was one of the three warmest springs on record for the southern hemisphere as a whole, and was notably dry in southern and eastern Africa.\n",
      "  - This is a summary of the southern hemisphere atmospheric circulation patterns and meteorological indices for winter 2016; an account of seasonal rainfall and temperature for the Australian region and the broader southern hemisphere is also provided. One of the strongest negative phases on record of the Indian Ocean Dipole (IOD) developed during the season, contributing to Australia&amp;apos;s second wettest winter on record, with rainfall above average over the vast majority of the continent. Neutral conditions prevailed in the tropical Pacific following the end of a strong El Niño event in autumn 2016, but the continuing effect of the 2015-16 El Niño was still evident in southern hemisphere temperatures, which were at or near record high levels.\n",
      "  - This is a summary of the southern hemisphere atmospheric circulation patterns and meteorological indices for autumn 2016; an account of seasonal rainfall and temperature for the Australian region is also provided. While autumn began with a weak El Niño signal in the Pacific, the decay of the El Niño was evident with subsurface temperatures in the central and eastern Pacific continuing to cool. Later in the season, the Indian Ocean Dipole (IOD) transitioned to a negative phase. The negative IOD combined with warm water to Australia’s north channeled warm, moisture-laden air over the continent; unseasonable rainfall ensued, over eastern and northern Australia and New Zealand’s western coastal areas during May.Temperatures averaged over the southern hemisphere were record warm for autumn, both for land and ocean areas; separately or combined. For Australia, autumn arrived during a significant and prolonged heatwave that contributed to the warmest autumn on record for Australia.The elevated sea surface temperatures (SSTs) recorded in the Australian region earlier in the year persisted, and were warmest on record for autumn. Warm SSTs led to a global coral bleaching event affecting reefs in tropical waters; while, in extra-tropical waters, diminished kelp forests were observed. In the Australian region, reefs off the northwestern coast and, in northern areas of the Great Barrier Reef, were bleached. The most severe marine heatwave since records began was recorded in the Great Barrier Reef lagoon.\n",
      "--------------------------------------------------\n",
      "Topic 246: 246_adaptation_flood_flood risk_resilience\n",
      "Representative Documents:\n",
      "  -                The hilly regions of India have suffered many disasters, both natural and anthropogenic. In the hilly state like Uttarakhand, the hazards like flash flood, forest fires, and landslide affect the community at the large scale. These hazards cause severe physical injuries, loss of life, and at large scale property damage. To understand the impact of such natural hazards, we need to examine vulnerability of the society, so that we can define vulnerability as the status of a community to prevent, mitigate, prepare for or respond to a natural and a man-made hazard. The absence of coping strategies, which is also known as resilience, has altered the vulnerability of a community. Thus, vulnerability index of a community has to be calculated considering physical, social, economic and environmental factors associated with the community. This research paper tries to find out an integrated social vulnerability factor. The proposed integrated social vulnerability factor is determined by considering various factors, such as physical, social, economic, and environmental. All these factors increase the susceptibility of a community to the impact of hazards. Poverty, occupation, child population, literacy rate, disability, marginalization, and inequities in wealth distribution of a society or community will also change the social vulnerability. Proposed Integrated social vulnerability index for the hilly terrain of Uttarakhand incorporated local technical knowledge insight and skills, so that local people and local administration are able to identify problems and can offer a solution to resist future emergencies i.e. the proposed social vulnerability indicator will support state, local, and traditional disaster management officials to determine areas of the most sensitive populations and better mitigation operation can be performed in case of disaster.\n",
      "  - PurposeThis study aims to explain the existing adaptation practices in an urbanized sub-region in the lower Chao Phraya River basin (CPRB) across different scales and dimensions. It offers an overview of water hazards in urban areas along the river basin to discover ways to deal with and recover from hazards via understanding the implications of existing and potential practice for the mitigation of hydrological hazards.Design/methodology/approachFirst, this study collected current adaptation strategies and measures from interview, focus group discussion, workshop organization, etc. to get the current adaptation strategies/measures for the whole CPRB and each specific area. Second, this study identified a set of criteria for evaluation from review of current publications and official reports. Then, the current adaptation strategies/measures were examined through a set of criteria to obtain the current situation of existing practices. Finally, analysis of key challenges and opportunities was done to propose supporting guidelines to reduce hydrological risks and incorporate further adaptation measures needed to boost resilience in the area.FindingsAdaptation methods should focus on mixed adaptation, which integrates structural, social, organizational and natural adaptation, and to develop multi-dimensional collaboration. The adaption strategy has restricted the usage of some technologies and technical know-how, particularly in the area of climate change. As a result, intentional adaptation to become more inventive is required, to reduce hazards and improve disaster-response capacity. The various adaptation measures should be more integrated or more adaptive and to achieve greater cohesion and mutual benefit of individual measures, such as community-based adaptation or community-driven slum upgrading.Originality/valueHydrological risks are wreaking havoc on social, economic and environmental elements, particularly river flood, flash flood and drought in the Asia-Pacific region. Twenty-two existing adaptation options were evaluated with evaluation criteria such as scales of risks/impacts reduction, benefits of environmental and socio-economic and institutional aspects. The findings highlight the current situation of existing practices, key challenges and opportunities, which emphasized on natural-based solutions, raising knowledge and awareness and lessons learned on adaptation of hydrological risks. The existing adaptation measures will be suggested as supporting guidelines and master plans to minimize the hydrological risks.\n",
      "  - PurposeThe purpose of this paper was to develop an integrated framework for assessing the flood risk and climate adaptation capacity of an urban area and its critical infrastructures to help address flood risk management issues and identify climate adaptation strategies.Design/methodology/approachUsing the January 2011 flood in the core suburbs of Brisbane City, Queensland, Australia, various spatial analytical tools (i.e. digital elevation modeling and urban morphological characterization with 3D analysis, spatial analysis with fuzzy logic, proximity analysis, line statistics, quadrat analysis, collect events analysis, spatial autocorrelation techniques with global Moran’s I and local Moran’s I, inverse distance weight method, and hot spot analysis) were implemented to transform and standardize hazard, vulnerability, and exposure indicating variables. The issue on the sufficiency of indicating variables was addressed using the topological cluster analysis of a two-dimension self-organizing neural network (SONN) structured with 100 neurons and trained by 200 epochs. Furthermore, the suitability of flood risk modeling was addressed by aggregating the indicating variables with weighted overlay and modified fuzzy gamma overlay operations using the Bayesian joint conditional probability weights. Variable weights were assigned to address the limitations of normative (equal weights) and deductive (expert judgment) approaches. Applying geographic information system (GIS) and appropriate equations, the flood risk and climate adaptation capacity indices of the study area were calculated and corresponding maps were generated.FindingsThe analyses showed that on the average, 36 (approximately 813 ha) and 14 per cent (approximately 316 ha) of the study area were exposed to very high flood risk and low adaptation capacity, respectively. In total, 93 per cent of the study area revealed negative adaptation capacity metrics (i.e. minimum of −23 to &lt;0), which implies that the socio-economic resources in the area are not enough to increase climate resilience of the urban community (i.e. Brisbane City) and its critical infrastructures.Research limitations/implicationsWhile the framework in this study was obtained through a robust approach, the following are the research limitations and recommended for further examination: analyzing and incorporating the impacts of economic growth; population growth; technological advancement; climate and environmental disturbances; and climate change; and applying the framework in assessing the risks to natural environments such as in agricultural areas, forest protection and production areas, biodiversity conservation areas, natural heritage sites, watersheds or river basins, parks and recreation areas, coastal regions, etc.Practical implicationsThis study provides a tool for high level analyses and identifies adaptation strategies to enable urban communities and critical infrastructure industries to better prepare and mitigate future flood events. The disaster risk reduction measures and climate adaptation strategies to increase urban community and critical infrastructure resilience were identified in this study. These include mitigation on areas of low flood risk or very high climate adaptation capacity; mitigation to preparedness on areas of moderate flood risk and high climate adaptation capacity; mitigation to response on areas of high flood risk and moderate climate adaptation capacity; and mitigation to recovery on areas of very high flood risk and low climate adaptation capacity. The implications of integrating disaster risk reduction and climate adaptation strategies were further examined.Originality/valueThe newly developed spatially explicit analytical technique, identified in this study as the Flood Risk-Adaptation Capacity Index-Adaptation Strategies (FRACIAS) Linkage/Integrated Model, allows the integration of flood risk and climate adaptation assessments which had been treated separately in the past. By applying the FRACIAS linkage/integrated model in the context of flood risk and climate adaptation capacity assessments, the authors established a framework for enhancing measures and adaptation strategies to increase urban community and critical infrastructure resilience to flood risk and climate-related events.\n",
      "--------------------------------------------------\n",
      "Topic 247: 247_security_housing_law_humanitarian\n",
      "Representative Documents:\n",
      "  -  Our planet is experiencing severe and accelerating climate and ecological breakdown caused by human activity. As professional scientists, we are better placed than most to understand the data that evidence this fact. However, like most other people, we ignore this inconvenient truth and lead our daily lives, at home and at work, as if these facts weren’t true. In particular, we overlook that our own neuroscientific research practices, from our laboratory experiments to our often global travel, help drive climate change and ecosystem damage. We also hold privileged positions of authority in our societies but rarely speak out. Here, we argue that to help society create a survivable future, we neuroscientists can and must play our part. In April 2021, we delivered a symposium at the British Neuroscience Association meeting outlining what we think neuroscientists can and should do to help stop climate breakdown. Building on our talks (Box 1), we here outline what the climate and ecological emergencies mean for us as neuroscientists. We highlight the psychological mechanisms that block us from taking action, and then outline what practical steps we can take to overcome these blocks and work towards sustainability. In particular, we review environmental issues in neuroscience research, scientific computing, and conferences. We also highlight the key advocacy roles we can all play in our institutions and in society more broadly. The need for sustainable change has never been more urgent, and we call on all (neuro)scientists to act with the utmost urgency. \n",
      "  - Today’s global health challenges require a multi-sectoral approach in which health is a fundamental value within global governance and international law. “One Health, One World” provides a unified, harmonious vision of global health governance that supports the wellbeing of humans and animals living in a clean and temperate environment. This article focuses on five legal regimes—trade law, food security law, environmental law, humanitarian law, and refugee law—that play a pivotal role in influencing health outcomes and are integral to achieving the One Health, One World vision. International trade, for example, opens markets not only to life-saving products such as vaccines, medicines, and medical equipment, but also to life-threatening products such as tobacco and asbestos. If strengthened and enforced, environmental law can decrease air and water pollution, major causes of death and disability. World hunger has been exacerbated by the global economic crisis and climate change, increasing the urgency for international law to enhance food security. Humanitarian law must similarly be strengthened to protect civilians adequately as the nature of warfare continues to change. Refugee law plays a pivotal role in protecting the health of deeply vulnerable people who lack food, shelter, and social stability. Higher standards and more effective compliance are necessary for international law to realize its full potential to safeguard the world's population.\n",
      "  -  Local governments can play a pivotal role in the fight against the housing and climate crisis. Through their actions they can deliver healthy, happy, inclusive, sustainable cities, which ensure the protection of our environment. While this is clearly an essential enterprise, it will be no mean feat. To succeed will require a fundamental reimagination of our current housing system and the investment structures behind it.  Globally, housing has become increasingly financialized. Rather than being treated as a fundamental human right—a place where individuals, families, and communities can live in peace, security, and dignity—housing is often primarily valued as a vehicle for generating wealth ( Farha, 2017 ).  Real estate investment has transformed into an extractive industry ( Sassen, 2014 ). It incentivizes the construction of housing, generating greater levels of greenhouse gas emissions, while increasing rents and housing costs, all as a means of generating profit ( Farha et al., 2022 ). To protect our societies and our planet, governments must create policy frameworks that affirm housing as a fundamental human right and centralize the environment, thereby shifting housing investment toward more regenerative practices that contribute to the provision of decent, affordable, and sustainable housing for all. This Policy Guidelines article explores three ways in which the financialization of housing is negatively impacting both the climate and the right to housing and provides policy recommendations based on The Shift Directives: From Financialized to Human Rights Based Housing, to support governments in developing human rights-based policy that can address the climate and housing crises. \n",
      "--------------------------------------------------\n",
      "Topic 248: 248_conflict_conflicts_armed_rebel\n",
      "Representative Documents:\n",
      "  -                Disasters play a key role in debates about climate change, environmental stress, and security. A qualitative comparative analysis (QCA) investigates how major climate-related disasters shape the dynamics of ongoing armed conflicts. Quantitative and qualitative data are presented for twenty-one cases across Africa, Asia, and the Middle East. After climate-related disasters, 29 percent of these armed conflicts escalated, 33 percent de-escalated, and 38 percent did not change. Furthermore, only countries highly vulnerable to disasters experienced changes in conflict dynamics. Armed conflicts tend to escalate when the disaster induces shifts in relative power, whereby one conflict party (usually the rebels) subsequently scales up its military efforts. But if at least one conflict party is weakened by a disaster and the other lacks the capability to exploit this change, armed conflict intensity declines. Findings provide empirical support for a proposed power differential mechanism connecting climate-related disasters to armed conflict dynamics via short-term shifts in power relations between the conflict parties. Climate change can also act as a threat reducer by temporarily causing lower conflict intensity.\n",
      "  -  This article examines the effect of climate change on a type of armed conflict that pits pastoralists (cattle herders) against each other (range wars). Such conflicts are typically fought over water rights and/or grazing rights to unfenced/unowned land. The state is rarely involved directly. The rangeland of East Africa is a region particularly vulnerable to drought and livestock diseases associated with climate change. To analyze the possible effects of climate change on pastoral conflict, we focus our analysis on changes in resource availability, contrasting cases of abundance and scarcity. The role of resources is further contextualized by competing notions of property rights, and the role of the state in defining property and associated rights. We employ a contest success function (CSF) game-theoretic model to analyze the logic of range wars. This CSF approach emphasizes the low-level, non-binary nature of raiding behavior between pastoralist groups over limited natural resources. A central contribution of this approach is that the logic of raiding behavior implies a positive relationship between resources and conflict. This positive relationship is supported by several studies of the rangeland of East Africa, but is generally dismissed by the literature on the ‘resource curse’. This relationship is contingent on other factors examined in the model, producing the following results. First, the level of property rights protection provided by the state generally reduces conflict between pastoralist groups. Second, if property rights protection is provided in a biased manner, then conflict between pastoralist groups increases. Third, severe resource asymmetries between two pastoralist groups will induce the poorer group to become bandits (focusing their efforts on raiding and not producing), while the richer group raids in retaliation. \n",
      "  -  Much of the debate over the security implications of climate change revolves around whether changing weather patterns will lead to future conflict. This article addresses whether deviations from normal rainfall patterns affect the propensity for individuals and groups to engage in disruptive activities such as demonstrations, riots, strikes, communal conflict, and anti-government violence. In contrast to much of the environmental security literature, it uses a much broader definition of conflict that includes, but is not limited to, organized rebellion. Using a new database of over 6,000 instances of social conflict over 20 years – the Social Conflict in Africa Database (SCAD) – it examines the effect of deviations from normal rainfall patterns on various types of conflict. The results indicate that rainfall variability has a significant effect on both large-scale and smaller-scale instances of political conflict. Rainfall correlates with civil war and insurgency, although wetter years are more likely to suffer from violent events. Extreme deviations in rainfall – particularly dry and wet years – are associated positively with all types of political conflict, though the relationship is strongest with respect to violent events, which are more responsive to abundant than scarce rainfall. By looking at a broader spectrum of social conflict, rather than limiting the analysis to civil war, we demonstrate a robust relationship between environmental shocks and unrest. \n",
      "--------------------------------------------------\n",
      "Topic 249: 249_uhi_urban_ahr_uhi intensity\n",
      "Representative Documents:\n",
      "  - The Guangdong‐Hong Kong‐Macao Greater Bay Area (GBA), a cluster of world‐class cities, is undergoing rapid urbanization. However, the heterogeneity of the urban thermal environment resulting from the diversity of urban forms is not yet fully understood. This paper assesses the heterogeneity of the urban heat island (UHI) effect in the GBA using the coupled Weather Research and Forecasting (WRF) model/multi‐layer urban canopy and building energy model (BEP/BEM), with high‐resolution local climate zone (LCZ) map as urban land use/land cover data. The average UHI intensity is found to peak at 1.8 ± 0.4°C in the evening, when the average UHI intensity of LCZ 2 can reach a maximum of 2.4 ± 0.58°C. Properly setting air‐conditioning temperatures can effectively prevent the enhancement of the UHI phenomenon at night by the anthropogenic heat (AH) released from air‐conditioning. The UHI‐induced local circulations and enhanced surface roughness inhibit the penetration of sea breezes inland, and surface wind speed decreases in all LCZs, with a maximum change of more than 0.8 m s−1. However, the increased thermal difference between land and sea leads to enhanced sea breezes offshore, especially in the Pearl River estuary. In addition, a series of sensitivity experiments have been conducted in this paper on initial and boundary conditions, building drag coefficients and urban fractions, which paves the way for further analyzing urban climate in GBA using WRF model and LCZs.\n",
      "  - The spatial and temporal features of urban heat island (UHI) intensity in complex urban terrain are barely investigated. This study examines the UHI intensity variations in mountainous Chongqing using a dense surface monitoring network. The results show that the UHI intensity is closely related to underlying surfaces, and the strongest UHI intensity is confined around the central urban areas. The UHI intensity is most prominent at night and in warm season, and the magnitude could reach ~4.5 °C on summer night. Our quantitative analysis shows a profound contribution of urbanization level to UHI intensity both at night and in summer, with regression coefficient b = 4.31 and 6.65, respectively. At night, the urban extra heat such as reflections of longwave radiation by buildings and release of daytime-stored heat from artificial materials, is added into the boundary layer, which compensates part of urban heat loss and thus leads to stronger UHI intensity. In summer, the urban areas are frequently controlled by oppressively hot weather. Due to increased usage of air conditioning, more anthropogenic heat is released. As a result, the urban temperatures are higher at night. The near-surface wind speed can serve as an indicator predicting UHI intensity variations only in the diurnal cycle. The rural cooling rate during early evening transition, however, is an appropriate factor to estimate the magnitude of UHI intensity both at night and in summer.\n",
      "  - Anthropogenic heat release (AHR) by human activities in cities is a key contributing factor to the generation of the urban heat island (UHI) effect; thus, AHR should be incorporated into urban climate and environmental modeling. In this study, gridded AHR data with high spatial resolution (1 km) were included in the integrated weather research and forecasting (WRF)/urban modeling system to investigate the urban environment of Hangzhou City, which is the capital of Zhejiang Province in east China. The AHR data were estimated for this province based on the significant correlation between energy consumption statistics data and multisensor remote‐sensing data (namely, nighttime light imagery and a vegetation index). The coupled model was evaluated against available observational data derived from a dense automatic weather station network in Hangzhou. The effects of AHR and urban land use on the urban environment were investigated with three sensitivity numerical experiments. Results showed that the mean UHI intensity reached 0.95°C and 1.66°C in winter and in summer, respectively, and that AHR contributed 65.26% and 17.47% to UHI intensity in the two seasons. In winter, AHR significantly impacted the diurnal variation in UHI, and the two UHI intensity peaks ascribed to AHR were detected during rush hours. The impact of AHR on planetary boundary layer (PBL) height was similar to its contribution to UHI effect, with a large contribution in winter. Moreover, UHI enhanced atmospheric vertical motions, which led to precipitation changes, especially during summer. A convective and deep PBL was detected and triggered convective precipitation over or downwind of Hangzhou City during summer. Given the anticipated increase in global urban populations, characterizing the spatial‐temporal variations of AHR and its impacts is essential toward continued progress in urban climate assessment.\n",
      "--------------------------------------------------\n",
      "Topic 250: 250_albopictus_aedes_wnv_transmission\n",
      "Representative Documents:\n",
      "  - During the last decades the disease vector Aedes albopictus (Asian tiger mosquito) has rapidly spread around the globe. Global shipment of goods contributes to its permanent introduction. Invaded regions are facing novel and serious public health concerns, especially regarding the transmission of formerly non-endemic arboviruses such as dengue and chikungunya. The further development and potential spread to other regions depends largely on their climatic suitability. Here, we have developed a tool for identifying and prioritizing European areas at risk for the establishment of Aedes albopictus by taking into account, for the first time, the freight imports from this mosquito’s endemic countries and the climate suitability at harbors and their surrounding regions. In a second step we consider the further transport of containers by train and inland waterways because these types of transport can be well controlled. We identify European regions at risk, where a huge amount of transported goods meet climatically suitable conditions for the disease vector.  The current and future suitability of the climate for Aedes albopictus was modeled by a correlative niche model approach and the Regional Climate Model COSMO-CLM.  This risk assessment combines impacts of globalization and global warming to improve effective and proactive interventions in disease vector surveillance and control actions.\n",
      "  -                                  Background                  Climate change and globalization contribute to the expansion of mosquito vectors and their associated pathogens. Long spared, temperate regions have had to deal with the emergence of arboviruses traditionally confined to tropical regions. Chikungunya virus (CHIKV) was reported for the first time in Europe in 2007, causing a localized outbreak in Italy, which then recurred repeatedly over the years in other European localities. This raises the question of climate effects, particularly temperature, on the dynamics of vector-borne viruses. The objective of this study is to improve the understanding of the molecular mechanisms set up in the vector in response to temperature.                                                Methods                  We combine three complementary approaches by examining Aedes albopictus mosquito gene expression (transcriptomics), bacterial flora (metagenomics) and CHIKV evolutionary dynamics (genomics) induced by viral infection and temperature changes.                                                Results                  We show that temperature alters profoundly mosquito gene expression, bacterial microbiome and viral population diversity. We observe that (i) CHIKV infection upregulated most genes (mainly in immune and stress-related pathways) at 20°C but not at 28°C, (ii) CHIKV infection significantly increased the abundance of Enterobacteriaceae Serratia marcescens at 28°C and (iii) CHIKV evolutionary dynamics were different according to temperature.                                                Conclusion                  The substantial changes detected in the vectorial system (the vector and its bacterial microbiota, and the arbovirus) lead to temperature-specific adjustments to reach the ultimate goal of arbovirus transmission; at 20°C and 28°C, the Asian tiger mosquito Ae. albopictus was able to transmit CHIKV at the same efficiency. Therefore, CHIKV is likely to continue its expansion in the northern regions and could become a public health problem in more countries than those already affected in Europe.               \n",
      "  -                 Background                Impact of climate change on tick-borne encephalitis (TBE) prevalence in the tick-host enzootic cycle in a given region depends on how the region-specific climate change patterns influence tick population development processes and tick-borne encephalitis virus (TBEV) transmission dynamics involving both systemic and co-feeding transmission routes. Predicting the transmission risk of TBEV in the enzootic cycle with projected climate conditions is essential for planning public health interventions including vaccination programs to mitigate the TBE incidence in the inhabitants and travelers. We have previously developed and validated a mathematical model for retroactive analysis of weather fluctuation on TBE prevalence in Hungary, and we aim to show in this research that this model provides an effective tool for projecting TBEV transmission risk in the enzootic cycle.                              Methods                Using the established model of TBEV transmission and the climate predictions of the Vas county in western Hungary in 2021-2050 and 2071-2100, we quantify the risk of TBEV transmission using a series of summative indices - the basic reproduction number, the duration of infestation, the stage-specific tick densities, and the accumulated (tick) infections due to co-feeding transmission. We also measure the significance of co-feeding transmission by observing the cumulative number of new transmissions through the non-systemic transmission route.                              Results                The transmission potential and the risk in the study site are expected to increase along with the increase of the temperature in 2021-2050 and 2071-2100. This increase will be facilitated by the expected extension of the tick questing season and the increase of the numbers of susceptible ticks (larval and nymphal) and the number of infected nymphal ticks co-feeding on the same hosts, leading to compounded increase of infections through the non-systemic transmission.                              Conclusions                The developed mathematical model provides an effective tool for predicting TBE prevalence in the tick-host enzootic cycle, by integrating climate projection with emerging knowledge about the region-specific tick ecological and pathogen enzootic processes (through model parametrization fitting to historical data). Model projects increasing co-feeding transmission and prevalence of TBEV in a recognized TBE endemic region, so human risk of TBEV infection is likely increasing unless public health interventions are enhanced.              \n",
      "--------------------------------------------------\n",
      "Topic 251: 251_pco2_sea co2_air sea co2_sea\n",
      "Representative Documents:\n",
      "  -                Partial pressure of CO2 (pCO2) and dissolved oxygen (DO) in the surface waters of the Amundsen Sea Polynya (ASP) were measured during austral summer 2010–2011 on the Amundsen Sea Polynya International Research Expedition (ASPIRE). Surface pCO2 in the central polynya was as low as 130 µatm, mainly due to strong net primary production. Comparing saturation states of pCO2 and DO distinguished dominant factors (biological activity, temperature, upwelling, and ice melt) controlling pCO2 across regions. Air-sea CO2 flux, estimated using average shipboard winds, showed high spatial variability (-52 to 25 mmol C m-2 d-1) related to these factors. The central region exhibited a high flux of -36 ± 8.4 mmol C m-2 d-1, which is ∼ 50% larger than that reported for the peak of the bloom in the well-studied Ross Sea, comparable to high rates reported for the Chukchi Sea, and significantly higher than reported for most continental shelves around the world. This central region (∼ 20,000 km2) accounted for 85% of the CO2 uptake for the entire open water area. Margins with lower algal biomass accounted for ∼ 15% of regional carbon uptake, likely resulting from pCO2 reductions by sea ice melt. During ASPIRE we also observed pCO2 up to 490 µatm in a small region near the Dotson Ice Shelf with an efflux of 11 ± 5.4 mmol C m-2 d-1 that offset about 3% of the uptake in the much larger central region. Overall, the 2010–2011 ASP was a large net sink for atmospheric CO2 with a spatially averaged flux density of -18 ± 14 mmol C m-2 d-1. This high flux suggests a disproportionate influence on the uptake of CO2 by the Southern Ocean. Since the region has experienced a significant increase in open water duration (1979–2013), we speculate about whether this CO2 sink will increase with future climate-driven change.\n",
      "  - We evaluate the influences of biological carbon export, physical circulation, and temperature‐driven solubility changes on air‐sea CO2 flux across the North Pacific basin (35°N–50°N, 142°E–125°W) throughout the full annual cycle by constructing mixed layer budgets for dissolved inorganic carbon (DIC) and pCO2, determined on 15 container ship transects between Hong Kong and Long Beach, CA, from 2008 to 2012. Annual air‐sea CO2 flux is greatest in the western North Pacific and decreases eastward across the basin (2.7 ± 0.9 mol C m−2 yr−1 west of 170°E, as compared to 2.1 ± 0.3 mol C m−2 yr−1 east of 160°W). East of 160°W, DIC removal by annual net community production (NCP) more than fully offsets the DIC increase due to air‐sea CO2 flux. However, in the region west of 170°E influenced by deep winter mixing, annual NCP only offsets ~20% of the DIC increase due to air‐sea CO2 flux, requiring significant DIC removal by geostrophic advection. Temperature‐driven solubility changes have no net influence on pCO2 and account for &lt;25% of annual CO2 uptake. The seasonal timing of NCP strongly affects its influence on air‐sea CO2 flux. Biological carbon export from the mixed layer has a stronger influence on pCO2 in summer when mixed layers are shallow, but changes in pCO2 have a stronger influence on air‐sea CO2 flux in winter when high wind speeds drive more vigorous gas exchange. Thus, it is necessary to determine the seasonal timing as well as the annual magnitude of NCP to determine its influence on ocean carbon uptake.\n",
      "  - The carbonate chemistry in the Dalton Polynya in East Antarctica (115°–123°E) was investigated in summer 2014/2015 using high‐frequency underway measurements of CO2 fugacity (fCO2) and discrete water column measurements of total dissolved inorganic carbon (TCO2) and total alkalinity. Air‐sea CO2 fluxes indicate this region was a weak net source of CO2 to the atmosphere (0.7 ± 0.9 mmol C m−2 day−1) during the period of observation, with the largest degree of surface water supersaturation (ΔfCO2 = +45 μatm) in ice‐covered waters near the Totten Ice Shelf (TIS) as compared to the ice‐free surface waters in the Dalton Polynya. The seasonal depletion of mixed‐layer TCO2 (6 to 51 μmol/kg) in ice‐free regions was primarily driven by sea ice melt and biological CO2 uptake. Estimates of net community production (NCP) reveal net autotrophy in the ice‐free Dalton Polynya (NCP = 5–20 mmol C m−2 day−1) and weakly heterotrophic waters near the ice‐covered TIS (NCP = −4–0 mmol C m−2 day−1). Satellite‐derived estimates of chlorophyll a (Chl a) and sea ice coverage suggest that the early summer season in 2014/2015 was anomalous relative to the long‐term (1997–2017) record, with lower surface Chl a concentrations and a greater degree of sea ice cover during the period of observation; the implications for seasonal primary production and air‐sea CO2 exchange are discussed. This study highlights the importance of both physical and biological processes in controlling air‐sea CO2 fluxes and the significant interannual variability of the CO2 system in Antarctic coastal regions.\n",
      "--------------------------------------------------\n",
      "Topic 252: 252_ocean_mixing_heat uptake_heat\n",
      "Representative Documents:\n",
      "  -                Convective overturning arising from static instability during winter is thought to play a crucial role in the formation of North Atlantic Deep Water (NADW). In ocean general circulation models (OGCMs), a strong reduction in convective penetration depth arises when horizontal diffusion (HD) is replaced by Gent and McWilliams (GM) mixing to model the effect of mesoscale eddies on tracer advection. In areas of sinking, the role of vertical tracer transport due to convection is largely replaced by the vertical component of isopycnal diffusion along sloping isopycnals. Here, the effect of this change in tracer transport physics on the stability of NADW formation under freshwater (FW) perturbations of the North Atlantic (NA) in a coupled model is examined. It is found that there is a significantly increased stability of NADW to FW input when GM is used in spite of GM experiments exhibiting consistently weaker NADW formation rates in unperturbed steady states. It is also found that there is a significant increase in NADW stability upon the introduction of isopycnal diffusion in the absence of GM. This indicates that isopycnal diffusion of tracer rather than isopycnal thickness diffusion is responsible for the increased NADW stability observed in the GM run. This result is robust with respect to the choice of isopycnal diffusion coefficient. Also, the NADW behavior in the isopycnal run, which includes a fixed background horizontal diffusivity, demonstrates that HD is not responsible in itself for reducing NADW stability when simple horizontal diffusion is used. Our results suggest that care should be taken when interpreting the results of coarse grid models with regard to NADW sensitivity to FW anomalies, regardless of the choice of mixing scheme.\n",
      "  -                A conceptual model of ocean heat uptake is developed as a multilayer generalization of Gnanadesikan. The roles of Southern Ocean Ekman and eddy transports, North Atlantic Deep Water (NADW) formation, and diapycnal mixing in controlling ocean stratification and transient heat uptake are investigated under climate change scenarios, including imposed surface warming, increased Southern Ocean wind forcing, with or without eddy compensation, and weakened meridional overturning circulation (MOC) induced by reduced NADW formation. With realistic profiles of diapycnal mixing, ocean heat uptake is dominated by Southern Ocean Ekman transport and its long-term adjustment controlled by the Southern Ocean eddy transport. The time scale of adjustment setting the rate of ocean heat uptake increases with depth. For scenarios with increased Southern Ocean wind forcing or weakened MOC, deepened stratification results in enhanced ocean heat uptake. In each of these experiments, the role of diapycnal mixing in setting ocean stratification and heat uptake is secondary. Conversely, in experiments with enhanced diapycnal mixing as employed in “upwelling diffusion” slab models, the contributions of diapycnal mixing and Southern Ocean Ekman transport to the net heat uptake are comparable, but the stratification extends unrealistically to the sea floor. The simple model is applied to interpret the output of an Earth system model, the Second Generation Canadian Earth System Model (CanESM2), in which the atmospheric CO2 concentration is increased by 1% yr−1 until quadrupling, where it is found that Southern Ocean Ekman transport is essential to reproduce the magnitude and vertical profile of ocean heat uptake.\n",
      "  - Teleconnections have traditionally been studied for the case of dry dynamical response to a given diabatic heat source. Important anomalies often occur within convective zones, for instance, in the observed remote response to El Niño. The reduction of rainfall and teleconnection propagation in deep convective regions poses theoretical challenges because feedbacks involving convective heating and cloud radiative effects come into play. Land surface feedbacks, including variations of land surface temperature, and ocean surface layer temperature response must be taken into account. During El Niño, descent and negative precipitation anomalies often extend across equatorial South America and the Atlantic intertropical convergence zone. Analysis of simulated mechanisms in a case study of the 1997/98 El Niño is used to illustrate the general principals of teleconnections occurring in deep convective zones, contrasting land and ocean regions. Comparison to other simulated events shows similar behavior. Tropospheric temperature and wind anomalies are spread eastward by wave dynamics modified by interaction with the moist convection zones. The traditional picture would have gradual descent balanced by radiative damping, but this scenario misses the most important balances in the moist static energy (MSE) budget. A small “zoo” of mechanisms is active in producing strong regional descent anomalies and associated drought. Factors common to several mechanisms include the role of convective quasi equilibrium (QE) in linking low-level moisture anomalies to free tropospheric temperature anomalies in a two-way interaction referred to as QE mediation. Convective heating feedbacks change the net static stability to a gross moist stability (GMS) M. The large cloud radiative feedback terms may be manipulated to appear as a modified static stability Meff, under approximations that are quantified for the quasi-equilibrium tropical circulation model used here. The relevant measure of Meff differs between land, where surface energy flux balance applies, and short time scales over ocean. For the time scale of an onsetting El Niño, a mixed layer ocean response is similar to a fixed sea surface temperature (SST) case, with surface fluxes lost into the ocean and Meff substantially reduced over ocean-enhancing descent anomalies. Use of Meff aids analysis of terms that act as the initiators of descent anomalies. Apparently modest terms in the MSE budget can be acted on by the GMS multiplier effect, which yields substantial precipitation anomalies due to the large ratio of the moisture convergence to the MSE divergence. Advection terms enter in several mechanisms, with the leading effects here due to advection by mean winds in both MSE and momentum balances. A Kelvinoid solution is presented as a prototype for how easterly flow enhances moist wave decay mechanisms, permitting relatively small damping terms by surface drag and radiative damping to produce the substantial eastward temperature gradients seen in observations and simulations and contributing to precipitation anomalies. The leading mechanism for drought in eastern equatorial South America is the upped-ante mechanism in which QE mediation of teleconnected tropospheric temperature anomalies tends to produce moisture gradients between the convection zone, where low-level moisture increases toward QE, and the neighboring nonconvective region. Over the Atlantic ITCZ, the upped-ante mechanism is a substantial contributor, but on short time scales several mechanisms referred to jointly as troposphere/SST disequilibrium mechanisms are important. While SST is adjusting during passive SST (coupled ocean mixed layer) experiments, or for fixed SST, heat flux to the ocean is lost to the atmosphere, and these mechanisms can induce descent and precipitation anomalies, although they disappear when SST equilibrates. In simulations here, cloud radiative feedbacks, surface heat fluxes induced by teleconnected wind anomalies, and surface fluxes induced by QE-mediated temperature anomalies are significant disequilibrium contributors. At time scales of several months or longer, remaining Atlantic ITCZ rainfall reductions are maintained by the upped-ante mechanism.\n",
      "--------------------------------------------------\n",
      "Topic 253: 253_mcica_cloud_model_atmosphere\n",
      "Representative Documents:\n",
      "  - We describe the baseline model configuration and simulation characteristics of the Geophysical Fluid Dynamics Laboratory (GFDL)'s Atmosphere Model version 4.1 (AM4.1), which builds on developments at GFDL over 2013–2018 for coupled carbon‐chemistry‐climate simulation as part of the sixth phase of the Coupled Model Intercomparison Project. In contrast with GFDL's AM4.0 development effort, which focused on physical and aerosol interactions and which is used as the atmospheric component of CM4.0, AM4.1 focuses on comprehensiveness of Earth system interactions. Key features of this model include doubled horizontal resolution of the atmosphere (~200 to ~100 km) with revised dynamics and physics from GFDL's previous‐generation AM3 atmospheric chemistry‐climate model. AM4.1 features improved representation of atmospheric chemical composition, including aerosol and aerosol precursor emissions, key land‐atmosphere interactions, comprehensive land‐atmosphere‐ocean cycling of dust and iron, and interactive ocean‐atmosphere cycling of reactive nitrogen. AM4.1 provides vast improvements in fidelity over AM3, captures most of AM4.0's baseline simulations characteristics, and notably improves on AM4.0 in the representation of aerosols over the Southern Ocean, India, and China—even with its interactive chemistry representation—and in its manifestation of sudden stratospheric warmings in the coldest months. Distributions of reactive nitrogen and sulfur species, carbon monoxide, and ozone are all substantially improved over AM3. Fidelity concerns include degradation of upper atmosphere equatorial winds and of aerosols in some regions.\n",
      "  -                The Monte Carlo Independent Column Approximation (McICA) method for computing domain-average radiative fluxes is unbiased with respect to the full ICA, but its flux estimates contain conditional random noise. Results for five experiments are used to assess the impact of McICA-related noise on simulations of global climate made by the NCAR Community Atmosphere Model (CAM). The experiment with the least noise (an order of magnitude below that of basic McICA) is taken as the reference. Two additional experiments help demonstrate how the impact of noise depends on the time interval between calls to the radiation code. Each experiment is an ensemble of seven 15-month simulations.               Experiments with very high noise levels feature significant reductions to cloudiness in the lowermost model layer over tropical oceans as well as changes in highly related quantities. This bias appears immediately, stabilizes after a couple of model days, and appears to stem from nonlinear interactions between clouds and radiative heating. Outside the Tropics, insignificant differences prevail. When McICA sampling is confined to cloudy subcolumns and when, on average, 50% more samples, relative to basic McICA, are drawn for selected spectral intervals, McICA noise is much reduced and the results of the simulation are almost statistically indistinguishable from the reference. This is true both for mean fields and for the nature of fluctuations on scales ranging from 1 day to at least 30 days.               While calling the radiation code once every 3 h instead of every hour allows the CAM additional time to incorporate McICA-related noise, the impact of noise is enhanced only slightly. In contrast, changing the radiative time step by itself produces effects that generally exceed the impact of McICA’s noise.\n",
      "  -                The Monte Carlo Independent Column Approximation (McICA) method for computing domain-average radiative fluxes allows a flexible treatment of unresolved cloud structure, and it is unbiased with respect to the full ICA, but its flux estimates contain conditional random noise. Here, tests of McICA in the ECHAM5 atmospheric GCM are reported. ECHAM5 provides an interesting test bed for McICA because it carries prognostic variables for the subgrid-scale probability distribution of total water content, which allows us to determine subgrid-scale cloud variability directly from the resolved-scale model variables.               Three experiments with differing levels of radiative noise, each consisting of ten 6-yr runs, are performed to estimate the impact of McICA noise on simulated climate. In an experiment that attempted to deliberately maximize McICA noise, a systematic reduction in low cloud fraction occurred. For a more reasonable implementation of McICA, the impact of noise is very small, although statistically discernible.               In terms of the impacts of noise, McICA appears to be a viable approach for use in ECHAM5. However, to improve the simulation of cloud radiative effects, realistic representation of both unresolved and resolved cloud structures is needed, which remains a challenging problem. Comparison of ECHAM5 data with a global cloud system–resolving model dataset and with International Satellite Cloud Climatology Project data suggested two problems related to unresolved cloud structures. First, ECHAM5 appears to underestimate subgrid-scale cloud variability. This problem seems partly related to the use of the beta distribution scheme for total water content in ECHAM5: in its current form, the scheme is unable to generate highly inhomogeneous clouds (relative standard deviation of condensate amount &amp;gt;1). Second, it appears that in ECHAM5, overcast cloud layers occur too frequently and partially cloudy layers too rarely. This problem is not unique to the beta distribution scheme; in fact, it is more pronounced when using an alternative, relative humidity–based cloud fraction scheme.\n",
      "--------------------------------------------------\n",
      "Topic 254: 254_phytoplankton_biomass_trophic_marine\n",
      "Representative Documents:\n",
      "  - Climate change impacts on marine life in the world ocean are expected to accelerate over the 21st century, affecting the structure and functioning of food webs. We analyzed a key aspect of this issue, focusing on the impact of changes in biomass flow within marine food webs and the resulting effects on ecosystem biomass and production. We used a modeling framework based on a parsimonious quasi‐physical representation of biomass flow through the food web, to explore the future of marine consumer biomass and production at the global scale over the 21st century. Biomass flow is determined by three climate‐related factors: primary production entering the food web, trophic transfer efficiency describing losses in biomass transfers from one trophic level (TL) to the next, and flow kinetic measuring the speed of biomass transfers within the food web. Using climate projections of three earth system models, we calculated biomass and production at each TL on a 1° latitude ×1° longitude grid of the global ocean under two greenhouse gas emission scenarios. We show that the alterations of the trophic functioning of marine ecosystems, mainly driven by faster and less efficient biomass transfers and decreasing primary production, would lead to a projected decline in total consumer biomass by 18.5% by 2090–2099 relative to 1986–2005 under the “no mitigation policy” scenario. The projected decrease in transfer efficiency is expected to amplify impacts at higher TLs, leading to a 21.3% decrease in abundance of predators and thus to a change in the overall trophic structure of marine ecosystems. Marine animal production is also projected to decline but to a lesser extent than biomass. Our study highlights that the temporal and spatial projected changes in biomass and production would imply direct repercussions on the future of world fisheries and beyond all services provided by Ocean.\n",
      "  - . Pronounced projected 21st century trends in regional oceanic net primary production (NPP) raise the prospect of significant redistributions of marine resources. Recent results further suggest that NPP changes may be amplified at higher trophic levels. Here, we elucidate the role of planktonic food web dynamics in driving projected changes in mesozooplankton production (MESOZP) found to be, on average, twice as large as projected changes in NPP by the latter half of the 21st century under a high emissions scenario in the Geophysical Fluid Dynamics Laboratory's ESM2M–COBALT (Carbon, Ocean Biogeochemistry and Lower Trophics) earth system model. Globally, MESOZP was projected to decline by 7.9% but regional MESOZP changes sometimes exceeded 50%. Changes in three planktonic food web properties – zooplankton growth efficiency (ZGE), the trophic level of mesozooplankton (MESOTL), and the fraction of NPP consumed by zooplankton (zooplankton–phytoplankton coupling, ZPC), explain the projected amplification. Zooplankton growth efficiencies (ZGE) changed with NPP, amplifying both NPP increases and decreases. Negative amplification (i.e., exacerbation) of projected subtropical NPP declines via this mechanism was particularly strong since consumers in the subtropics have limited surplus energy above basal metabolic costs. Increased mesozooplankton trophic level (MESOTL) resulted from projected declines in large phytoplankton production. This further amplified negative subtropical NPP declines but was secondary to ZGE and, at higher latitudes, was often offset by increased ZPC. Marked ZPC increases were projected for high-latitude regions experiencing shoaling of deep winter mixing or decreased winter sea ice – both tending to increase winter zooplankton biomass and enhance grazer control of spring blooms. Increased ZPC amplified projected NPP increases in the Arctic and damped projected NPP declines in the northwestern Atlantic and Southern Ocean. Improved understanding of the physical and biological interactions governing ZGE, MESOTL and ZPC is needed to further refine estimates of climate-driven productivity changes across trophic levels.\n",
      "  - The impact of climate change on the marine food web is highly uncertain. Nonetheless, there is growing consensus that global marine primary production will decline in response to future climate change, largely due to increased stratification reducing the supply of nutrients to the upper ocean. Evidence to date suggests a potential amplification of this response throughout the trophic food web, with more dramatic responses at higher trophic levels. Here we show that trophic amplification of marine biomass declines is a consistent feature of the Coupled Model Intercomparison Project Phase 5 (CMIP5) Earth System Models, across different scenarios of future climate change. Under the business‐as‐usual Representative Concentration Pathway 8.5 (RCP8.5) global mean phytoplankton biomass is projected to decline by 6.1% ± 2.5% over the twenty‐first century, while zooplankton biomass declines by 13.6% ± 3.0%. All models project greater relative declines in zooplankton than phytoplankton, with annual zooplankton biomass anomalies 2.24 ± 1.03 times those of phytoplankton. The low latitude oceans drive the projected trophic amplification of biomass declines, with models exhibiting variable trophic interactions in the mid‐to‐high latitudes and similar relative changes in phytoplankton and zooplankton biomass. Under the assumption that zooplankton biomass is prey limited, an analytical explanation of the trophic amplification that occurs in the low latitudes can be derived from generic plankton differential equations. Using an ocean biogeochemical model, we show that the inclusion of variable C:N:P phytoplankton stoichiometry can substantially increase the trophic amplification of biomass declines in low latitude regions. This additional trophic amplification is driven by enhanced nutrient limitation decreasing phytoplankton N and P content relative to C, hence reducing zooplankton growth efficiency. Given that most current Earth System Models assume that phytoplankton C:N:P stoichiometry is constant, such models are likely to underestimate the extent of negative trophic amplification under projected climate change.\n",
      "--------------------------------------------------\n",
      "Topic 255: 255_categorized_gt_climate change categorized_change categorized\n",
      "Representative Documents:\n",
      "  - This article is categorized under:Perceptions, Behavior, and Communication of Climate Change &gt; Perceptions of Climate Change\n",
      "  - This article is categorized under:Perceptions, Behavior, and Communication of Climate Change &gt; Perceptions of Climate Change\n",
      "  - This article is categorized under:Perceptions, Behavior, and Communication of Climate Change &gt; CommunicationClimate, History, Society, Culture &gt; Ideas and Knowledge\n",
      "--------------------------------------------------\n",
      "Topic 256: 256_pakistan_water_health_human\n",
      "Representative Documents:\n",
      "  - Climate change affects agricultural water requirement, water availability, water quantity and quality. Agriculture is most affected by climate change among other sectors because crop and livestock systems depend critically on climatic variables such as precipitation and temperature. The effect of climate change has been assessed in several special reports from international agencies the United Nations World Water Development (WWD), Food and Agriculture Organization of the United Nations (FAO), the International Food Policy Research Institute (IFPRI), and Intergovernmental Panel on Climate Change (IPCC) etc. These studies all share a common conclusion that climate change affects the availability, quality and quantity of water for basic human needs, thus threatening global food security. Following these global assessments and numerous local and regional studies, this study provides an overview of the state-of-the-art knowledge on the impact of climate change on agriculture and water resources, backed up by climatic data from Nigerian Meteorological Agency, Abuja. The results show that the atmospheric concentration of greenhouse gases (GHGs) is increasing. Consequently, the increasing concentration of GHGs resulted in changing global climate with increasing temperature. The rise in global average temperatures since 1860 now exceeds 0.6OC. In Nigeria, there is a decrease in rainfall (about 90 mm), while temperature increased (about 0.8OC) since 1960. This has led to increased evaporation and evapotranspiration and water stress resulting in the drying up of water bodies such as rivers and lakes. While climate change makes some countries experience an increase in water resources, the majority face serious water stress. The changes in climatic events such as temperature and rainfall significantly affect the yield of crops, because of their sensitivity to weather parameters, thereby causing huge economic impacts on countries that are highly dependent on Agriculture. More research and government policies should focus on a planned adaptation in agricultural water management to facilitate more consistent and more effective responses to climate change, with consideration of the linkage with non-agricultural water uses.\n",
      "  - Aquaculture is the productive activity that will play a crucial role in the challenges of the millennium, such as the need for proteins that support humans and the respect for the environment. Aquaculture is an important economic activity in the Mediterranean basin. A great impact is presented, however, by aquaculture practices as they involve the use of antibiotics for treatment and prophylaxis. As a consequence of the use of antibiotics in aquaculture, antibiotic resistance is induced in the surrounding bacteria in the column water, sediment, and fish-associated bacterial strains. Through horizontal gene transfer, bacteria can diffuse antibiotic-resistance genes and mobile resistance genes further spreading genetic determinants. Once triggered, antibiotic resistance easily spreads among aquatic microbial communities and, from there, can reach human pathogenic bacteria, making vain the use of antibiotics for human health. Climate change claims a significant role in this context, as rising temperatures can affect cell physiology in bacteria in the same way as antibiotics, causing antibiotic resistance to begin with. The Mediterranean Sea represents a ‘hot spot’ in terms of climate change and aspects of antibiotic resistance in aquaculture in this area can be significantly amplified, thus increasing threats to human health. Practices must be adopted to counteract negative impacts on human health, with a reduction in the use of antibiotics as a pivotal point. In the meantime, it is necessary to act against climate change by reducing anthropogenic impacts, for example by reducing CO2 emissions into the atmosphere. The One Health type approach, which involves the intervention of different skills, such as veterinary, ecology, and medicine in compliance with the principles of sustainability, is necessary and strongly recommended to face these important challenges for human and animal health, and for environmental safety in the Mediterranean area.\n",
      "  - Global warming is emerging as one of the biggest threats to earth in this century. It not only has deleterious effects on individuals’ health but could also trigger natural disasters such as floods, famines, droughts and cyclones etc. Intergovernmental Panel on Climate Change reported that industrial revolution of the mid-19th century has caused a 1oC rise in global temperature.  It is further estimated to rise by &gt;1.10°C to 6.40°C over the 21st century.1 This increase in temperature along with loss of biodiversity may lead to devastating effects on health. Increase in earth’s temperature has both short and long term adverse consequences. Global warming is changing the physical, chemical and biological processes of earth that are evident in every continent. To recognize the dangers of global warming, it’s important to identify its deleterious effects on human society and natural environment.  Sea levels are rising, glaciers are shrinking; record high temperatures, severe rainstorms and droughts are becoming increasingly common. Changes in temperatures and rainfall-patterns alter the behavior of both plants and animals and have significant implications on humans as well.2 It’s an established fact that temperature rise of &gt;1.5°C has detrimental effects on health.1 Data revealed that mortality of people above sixty five years age have increased &gt;50% in the past fifty years because of global warming.3 Increased dehydration, derangements in renal function, dermatological malignancies, tropical infections, mental health problems and pregnancy complications, allergies, pulmonary and cardiovascular complications are some of its obvious effects.4,5 Populations at extremes of ages, poor communities and people with underlying health problems are the ones that suffer the most.1,3 A decline of 1.8-5.6% in global production of major crops is observed since 1981. This along with extreme weathers and depletion of soil for harvesting has increased the risk of undernutrition.3 Extensive damage to natural ecosystems, decreasing freshwater resources and rising sea levels, extremes of temperatures and food depletion increases the risks of pandemics.2,6 Pakistan has been ranked among the top ten most affected countries because of global warming in the past twenty years7-9 and expected to have wide-ranging impacts. Agricultural yield, availability of water could be greatly affected and increased coastal erosion, sea water incursion and increased extreme climatic events could occur more frequently.7 Global Climate Risk Index reported that Pakistan has lost 0.53% per unit GDP with economic losses worth US$ 3792.52million. Pakistan witnessed 152 extreme weather events from 1999 to 2018.7,9 Similarly Asian Development Bank reported that socioeconomic costs of environmental degradation are considerable with climate adaptation needs ranging between $7 billion and $14 billion per year.10 In Pakistan, a temperature rise of 0.6°C has been observed over the past century which falls within the allowed limit of global temperature increase. But this century could be devastating and expected rise is between 3°C and 5°C, much higher than the rest of the world.10 Availability and access to food and food quality could be greatly disturbed. Increases in temperature in the caused wheat yield losses. Studies have shown that wheat production in arid areas would be affected by 17% in case of 1-2°C rise in the temperature.7 Similarly, mean annual precipitation has been increased in most parts of the country.7,10 This could be associated with a number of adverse impacts, including the increasing frequency of extreme events (floods, droughts, heatwaves, and cyclonic activity); steady regression of most glaciers and changes in the rainfall patterns.7 During the past ten years, Pakistan has been hit by floods almost every year and floods of 2010 and 2011 have appeared as huge disasters in its history. It is predicted that by 2030 an additional of 1.5 million people may be at risk of river floods annually as a result of climate change.   Infectious diseases (vector, water and food borne) are highly sensitive to temperature changes. During the years 2021–2050 an estimated of 35 million population is at risk of malaria annually (with 1-2°C rise) in Pakistan. It is predicted that by 2030 diarrhea-related deaths in children (&lt;15 years) can increase by 11.7%, while heat-related deaths in elderly are expected to increase by 100% in Pakistan.11 In 2013, 45% of children (&lt;5 years) have stunted growth while underweight and wasting in children (&lt;5 years) was prevailing in 31.6% and 10.5%, respectively.11 Reported data in 2012 showed that out of total deaths (326,100) from cardiac and lung diseases (18+ years), 37% were attributed to household air pollution.11,12 Around 52% of 68200 deaths due to acute lower respiratory infections in children (&lt;5 years) were attributed to household air pollution.12 Forest could play a major role in overcoming pollutions, but Pakistan is a forest poor country. Forests and planted tree area of the Pakistan is 4.2 million ha, which equals to 4.8% of the total land area of Pakistan. This constitutes 0.05 hectares of forest/capita against the world’s average of 1.0 hectares /capita. Every year thousands of hectares of forests are destroyed because of human activities which could lead to a very intense weather in future.13   It’s encouraging that government of Pakistan is taking measures to tackle the temperature changes. These measures include the increased forestation drives in country through projects like billion tree tsunami and ten billion tree tsunami, national and monsoon plantation drives. Moreover, the government is building new dams for irrigation of land, preservation of freshwater habitats (to increase the quality and quantity of food) and production of hydropower to limit the use of oil, coal and gas for production of electricity. Besides this public should be made aware to limit the use of electricity and eat more vegetables, fruits, whole grains and less meat and dairy products as it will results in fewer greenhouse effect. Furthermore, implementation of hybrid busses for mass transit projects, easing import of electric/hybrid vehicles and installation and promotion of solar panels in new buildings are some of the steps towards achieving the goal of climate control. However, Pakistan still needs to put a lot of efforts in preventing the calamities and extend such projects further to produce more green energy and preserve nature. Public should be educated to purchase fewer electronics and other household items and to increase the reuse, repair and recycle already purchased items to reduce carbon emission. In addition to that, government should intervene in redesigning transport systems; city planning; production and distribution of food and household items; reforms in healthcare system, limiting the use of fossil fuels and increasing use of alternate energy sources etc. This vision can only be achieved by increasing awareness and interactive partnerships between the government, society, health professionals and scientists, businessmen etc.\n",
      "--------------------------------------------------\n",
      "Topic 257: 257_altai region_agro climatic_altai_region\n",
      "Representative Documents:\n",
      "  - This research examines the transformation of the agro-climatic conditions of the Altai region as a result of climate change. The climate of the Altai region in Russia is sharply continental and characterized by dry air and significant weather variability, both in individual seasons and years. The current study is determined by the lack of detailed area-related analytical generalizations for the territory of the Altai region over the past 30 years. Most of the published data dealing with an integrated analysis of the agro-climatic conditions in the Altai region date back to the late 1960s and early 1970s; in most cases, this data is from climate reference-books based on the generalized data from the first half of the 20th century. To make accurate forecasts and to efficiently manage agricultural production in the Altai region, area-related data on the state and dynamics of agro-climatic changes have been analysed. The results reveal that in the period between 1964 and 2017, significant climatic changes occurred in the territory of the Altai region. These climatic changes affected the growing season length, which increased due to a shift in the dates of the air temperature transition above 10 °C, to earlier dates in spring and to later dates in autumn. Furthermore, the current study also revealed that the foothills of the Altai Mountains are the most moistened parts of the region and the Kulunda lowland is the most arid part. In the Altai region, the accumulated temperatures and amounts of precipitation during the growing season increased significantly, and the values of integrated coefficients and indices that reflect the moisture supply conditions for the territory also changed significantly. Based upon the results, a schematic map of the current precipitation distribution on the Altai region’s territory has been generated. These results and this map may be used to conduct more detailed studies in the field of agro-climatology and to update the current borders of agro-climatic areas and revision of the agro-climatic zonation scheme.\n",
      "  - Today there is enough scientific research to prove the impact of climate change on agriculture. However, there is no conclusive conclusion as to what is in store for agriculture, its potential will increase or decrease. Significant consequences of the impact of climate change are likely to manifest themselves at the regional level, and this requires additional research for further adaptation of agriculture in the corresponding territory. The aim of the study is to assess changes in agro-climatic indicators at the regional level. The subject is the Komi Republic, located in the extreme northeast of the European part of the country. The chosen research methodology based on statistical processing of agro-climatic indicators for ten meteorological stations in the region for 1960-2018 and economic indicators of productivity and gross harvest of agricultural crops for 1913-2018 due to the large amount of data. Paired regression analysis used accurately interpret the results. The obtained mathematical models evaluated according to the Pearson coefficient, Student’s t-criterion, determination coefficient, F – Fisher’s criterion, so that the results of the study were reliable. For some regions, the consequences of climate change may turn out to be negative in the form of a decrease in food supply, for others - positive, due to an increase in the duration of the growing season and, accordingly, an increase in the potential productivity of agricultural crops. The relevance of the study is because these positive consequences will be especially characteristic for the northern territories. As a result, it revealed that in four agro-climatic regions of the Komi Republic, there were insignificant climatic changes for agriculture over a sixty-year period. An analysis of the yield of vegetables in open ground showed that it increased from 36 to 314 tons per hectare, and the gross yield of the main agricultural crop - potatoes - decreased almost 3 times, but the main reason is the reduction in acreage, and not climate change. However, the trend line for potato yields in the region as a whole shows an upward trend over a 100-year period. The performed paired regression analysis between the selected agro-climatic indicators and the yield of agricultural crops of the republic revealed an average direct relationship only between the yield of vegetables and the duration of the growing season, and the sum of average daily temperatures. Consequently, it is currently impossible to assert that the ongoing climatic changes have a significant impact on agriculture in the Komi Republic\n",
      "  - The article a nalyzes in detail the dynamics of atmospheric precipitation for the entire instrumental period of observations in the territory of the Volyn region at six meteorological stations. The deviation in the parameters of the amount of precipitation in the long-term regime and the climate norm are revealed. For the entire period of observations in the region, the annual amount of precipitation is characterized by significant fluctuations. The highest precipitation was recorded in 2008 (779 mm), the smallest – in 1961 (319 mm). The differences of atmospheric moisture in recent years have been analyzed. It is established that under the conditions of hemodern climates ince the mid-80s of the twentieth century the rehas been a steady in crease in the annual amount of precipitation throughout the Volyn region, which leads to a change in the environmental environment of the formation of the water regime of soils of different granulometric composition. Atmospheric precipitation is a source of replenish men to moisture in the soil, causing water availability of plants. The amount of atmospheric precipitation and the mode of their fallout are of ten the cause of unfavourable conditions in crop production, horticulture, and forestry. Conditions of atmospheric humidification in the vegetation period are characterized. The changes in the amount of precipitation during the growing season in different time slices are analyzed based on the data of instrumental observations and published data of the late 50 of the last century and the beginning of the 21 century in the Agro-climatic reference books. Hydrothermal coefficient of Selyaninov is calculated and its spatial and temporal differences are established. For the first time, the manifestation of climatic changes in the study area and the regional features of the dynamics of atmospheric humidification are shown. The increase in the annual amount of precipitation and its distribution in the warm period of the year in creases the risks of intensifying soil degradation, and therefore the research can be widely used in the study of changes inwater regime and the determination of moisture sources in the soils of the Volyn region. There sultsof the study will be useful for the practice of plant growing and horti culture in agriculture, as well as for forestry, protected areas, which are the canters for the conservation of Polissya biodiversity.Key words: precipitation, long-term dynamics, global and regional climate changes, vegetation period, hydrothermal coefficient of Selyaninov, dry period duration.\n",
      "--------------------------------------------------\n",
      "Topic 258: 258_ch4_vm25_etn_emissions\n",
      "Representative Documents:\n",
      "  - The maximum carboxylation rate (Vcmax) is an important parameter affecting the photosynthesis rate of plant leaves. In terrestrial ecosystem models (TEMs), Vcmax at 25°C (Vm25°) is often assigned as constants according to plant functional types (PFTs), while its variations with leaf temperature and nutrient contents are described using empirical functions. However, Vm25° could itself vary seasonally due to changes in the leaf physiological state that cannot be described by the empirical functions, potentially causing large uncertainties in simulated water and carbon fluxes. So far, the seasonal variation in Vm25° has not been systematically studied. Here, we generated a Vm25° data set of eight main biomes from 2000 to 2020 using eddy covariance (EC) measurements at globally distributed 176 sites. The boreal ecosystem productivity simulator was combined with a light response curve model (BEPS‐LRC) to invert Vm25° from EC data. We investigated seasonal variations of Vm25° and analyzed how different environmental and physiological factors, such as physiological (leaf chlorophyll content, LCC and Rubisco or RuBP) and climatic environment factors, including air temperature (Ta), solar shortwave radiation, CO2 concentration (CO2), and soil water content (SWC), influence this parameter. Vm25° values derived from flux data using BEPS‐LRC correlate well with Vm25° of the reference data set (R2 = 0.74, slope = 0.77, and root mean square error = 24.45 μmol m−2 s−1, p &lt; 0.001). Leaf Vm25° has strong seasonal variations in all PFTs except for in evergreen broadleaf forests, but its seasonal variation patterns differ greatly among eight biomes. Air temperature (Ta) is the most important determinant of Vm25°, followed by SWC. The interactive effects of Ta and SWC on Vm25° vary among different biomes. The seasonal variation of Vm25° was strongly dependent on LCC. After the correction of temperature effect, the contribution of LCC to the seasonal variation of Vm25° averaged 26% among eight biomes. These findings provide useful information for better parameterization of Vm25° in TEMs.\n",
      "  - Soil consumption of atmospheric methane plays an important secondary role in regulating the atmospheric CH4 budget, next to the dominant loss mechanism involving reaction with the hydroxyl radical (OH). Here we used a process‐based biogeochemistry model to quantify soil consumption during the 20th and 21st centuries. We estimated that global soils consumed 32–36 Tg CH4 yr−1 during the 1990s. Natural ecosystems accounted for 84% of the total consumption, and agricultural ecosystems only consumed 5 Tg CH4 yr−1 in our estimations. During the twentieth century, the consumption rates increased at 0.03–0.20 Tg CH4 yr−2 with seasonal amplitudes increasing from 1.44 to 3.13 Tg CH4 month−1. Deserts, shrublands, and xeric woodlands were the largest sinks. Atmospheric CH4 concentrations and soil moisture exerted significant effects on the soil consumption while nitrogen deposition had a moderate effect. During the 21st century, the consumption is predicted to increase at 0.05‐1.0 Tg CH4 yr−2, and total consumption will reach 45–140 Tg CH4 yr−1 at the end of the 2090s, varying under different future climate scenarios. Dry areas will persist as sinks, boreal ecosystems will become stronger sinks, mainly due to increasing soil temperatures. Nitrogen deposition will modestly reduce the future sink strength at the global scale. When we incorporated the estimated global soil consumption into our chemical transport model simulations, we found that nitrogen deposition suppressed the total methane sink by 26 Tg during the period 1998–2004, resulting in 6.6 ppb higher atmospheric CH4 mixing ratios compared to without considering nitrogen deposition effects. On average, a cumulative increase of every 1 Tg soil CH4 consumption decreased atmospheric CH4 mixing ratios by 0.26 ppb during the period 1998–2004.\n",
      "  - Gaseous reactive nitrogen (Nr) emissions from agricultural soils to the atmosphere constitute an integral part of global N cycle, directly or indirectly causing climate change impacts. The extensive use of N fertilizer in crop production will compromise our efforts to reduce agricultural Nr emissions in China. A national inventory of fertilizer N‐induced gaseous Nr emissions from croplands in China remains to be developed to reveal its role in shaping climate change. Here we present a data‐driven estimate of fertilizer N‐induced soil Nr emissions based on regional and crop‐specific emission factors (EFs) compiled from 379 manipulative studies. In China, agricultural soil Nr emissions from the use of synthetic N fertilizer and manure in 2018 are estimated to be 3.81 and 0.73 Tg N yr−1, with a combined contribution of 23%, 20% and 15% to the global agricultural emission total of ammonia (NH3), nitrous oxide (N2O) and nitric oxide (NO), respectively. Over the past three decades, NH3 volatilization from croplands has experienced a shift from a rapid increase to a decline trend, whereas N2O and NO emissions always maintain a strong growth momentum due to a robust and continuous rise of EFs. Regionally, croplands in Central south (1.51 Tg N yr−1) and East (0.99 Tg N yr−1) of China exhibit as hotspots of soil Nr emissions. In terms of crop‐specific emissions, rice, maize and vegetable show as three leading Nr emitters, together accounting for 61% of synthetic N fertilizer‐induced Nr emissions from croplands. The global warming effect derived from cropland N2O emissions in China was found to dominate over the local cooling effects of NH3 and NO emissions. Our established regional and crop‐specific EFs for gaseous Nr forms provide a new benchmark for constraining the IPCC Tier 1 default EF values. The spatio‐temporal insight into soil Nr emission data from N fertilizer application in our estimate is expected to advance our efforts towards more accurate global or regional cropland Nr emission inventories and effective mitigation strategies.\n",
      "--------------------------------------------------\n",
      "Topic 259: 259_restoration_green transition_green_transition\n",
      "Representative Documents:\n",
      "  - Climate change is evident around the globe, which requires bold actions now to achieve UN-SDGs and Paris Agreement. The water sector is dominated by public finance and is almost subsidised. In addition, there is an increased risk perception surrounding climate investments in developing countries. Pricing climate risks is a daunting challenge for investors and the private sector, who must estimate the likelihood of various climate scenarios and their implications for physical, liability and transition risks at the firm, project, national, and regional scales. In addition, there is a building momentum to scale up global climate response. To translate this momentum into action will require significantly greater investments, investments in a different set of inclusive assets that address water security, mobilise the private sector and provides sector-based or economy-wide co-benefits to direct and indirect beneficiaries, e.g., job creation, health benefits, improved resilience and scaling knowledge and harmonise data and methodologies. Notably, climate–water finance is facing a dual challenge. It will have to both reduce the present water infrastructure financing gap and ensure that this new infrastructure/asset is low-carbon, resilient to climate change, and meets the goals of the UNFCCC and the Paris Agreement. Therefore, there is a need for a paradigm shift in the way how water asset is defined, developed, and financed. This paper presents this novel approach concept and its content and financial structure that enable treating water as a new asset class to enable private sector investment and ensure providing water for domestic, municipal, and industrial purposes and allows municipalities to scale their water reuse, sanitation, and desalination projects in partnership with the private sector and/or governments. It is increasingly important to treat water as a new asset class, particularly as nations around the world (particularly developing countries) are set to experience an anticipated 40% shortfall in water by 2030 due to climate change, economic recovery and growth, population growth and resource competition. Investment in water could be one of the ways of tackling this deficit by treating water as a new asset class.\n",
      "  - Green growth and the transition towards green growth are gaining scientific and public interest across Africa at an unprecedented rate. The Paris Agreement ratification by all 54 member states and the African Union (AU) goals in its Agenda 2063 on green economies are sufficient evidence of this. This is in line with the European Green Deal (EGD) aspirations, which envisages making Europe a carbon neutral economy by 2050. One of the EGD’s four main pillars is sustainable food systems. The success of EGD is premised on its ability to inspire and support green transition and effective climate action globally. The borderless nature of climate change necessitates a holistic approach to ensure the EU’s green transition does not come at the cost of development elsewhere. The main challenge is finding Africa’s space and position within the desired holistic approach, as Africa’s economy is agriculturally driven. One key African agricultural sub-sector significantly impacting livelihoods is livestock, which supports up to 80% of the rural livelihoods and which grapples with challenges in satisfying the needs of a fast-growing population. What could the EU green transition mean to this sector? We established that between 2010–2019, the African livestock population grew exponentially, and feed production followed the same path, with the share of land under forests, grasslands and meadows declining drastically. Over the same period, the percentage of land under arable farming increased while the animal-based protein and meat imports curve grew exponentially. This situation puts the continent in a dilemma about finding a sustainable solution for the food–feed and environmental nexus. Against this backdrop, a myriad of questions arises on how the green transition can be established to promote mitigating any loss that might occur in the process. We conducted a detailed sectoral trend analysis based on Food and Agricultural Organization (FAO) statistics to find plausible solutions and pathways to achieve a greener transition. We coupled it with intensive policy mapping to develop science-policy-driven solutions that could promote the green transition sustainably. To sustainably accelerate the sectoral growth trajectory while addressing climate change, we recommend adopting and implementing raft measures geared towards increased sectoral efficiency, effectiveness, innovativeness and a holistic approach to the problem. Adopting transformative policies can promote the sector’s competitiveness through incentivisation, technological adoption, financial support, market support and increased awareness of its importance in sustainable development. However, exercising caution in implementing these practices is crucial to ensure there is no leakage effect in implementing the EGD across Africa and beyond.\n",
      "  - For several years, there has been discussion about whether climate change risk is a fundamentally new type of risk or can be subsumed under market, credit, operational and systemic risk in the financial industry. The European Central Bank’s current ‘climate risk stress test’ is a milestone marking a shift in that discussion, from a normative one to a perspective on actual exposures and quantitative data. This shift is linked with regulatory guidelines about how climate change risk should be integrated into banks’ risk frameworks, but also comes with some expectations for banks to actively steer funding to the green transformation. We now understand climate change better than ever and are able to estimate the physical damages it will cause (ie the estimated probability distribution of damages from additional ‘extreme events’). This can be mapped to credit exposures by region (eg river valleys) and by industry segment (eg agriculture) as elaborated in the ‘climate risk stress test’. This paper provides a first step for extending the approach from actual exposures to expected losses by comparing the effects of ‘normal’ weather events with the additional climate-change-related events. However, sophisticated models are required to separate the climate-change-related excess of rare but severe events from extreme weather events that are not related to climate change. In contrast to the earlier static concept of ‘stranded assets’, a ‘transition risk’ would be the result of ‘disorderly’ pathways to a low carbon economy rather than a transparent and consistent road map. A sudden and abrupt increase in the price of carbon (or of greenhouse gas emissions in general) would travel along a transmission chain in the economy, eventually affecting banks’ credit and market risk exposure. Determining the effect of such a step function on an estimated loss distribution is methodologically challenging, especially because there are limited data on historical events. The actual transmission will be even more complicated as political decisions interact with social acceptance and there is a (new) risk of the lack of societal consensus. This paper discusses this challenge, using a schematic model of the political decision on and societal reaction to carbon prices and the consequences for carbon-intensive industry sectors and consumers and citizens. Finally, regulators have expectations of how banks should contribute to a ‘green deal’ and bridge the gap between political commitments and economic measures. This task for the financial services industry — ‘steering credit’ — turns out to be a new source of risk for the societal ‘licence to operate’, into which more insight is required. This paper disentangles the various elements as a step towards a better understanding of the challenges that climate-changerelated risk poses to banks.\n",
      "--------------------------------------------------\n",
      "Topic 260: 260_sectorization_monitoring_trentino_traffic\n",
      "Representative Documents:\n",
      "  - The Aosta Valley is an alpine region in north-west Italy that is characterized by a high level of naturalness, with extensive uninhabited areas that are distant from artificial sound sources. The Aosta Valley Regional Environmental Protection Agency (ARPA-VdA) has been particularly sensitive to the preservation of the soundscape, which is considered an integral part of the landscape, since the laws on noise pollution were first introduced. The nature of the ski areas in the Aosta mountains, which undergoes changes throughout the year, is surely of great importance, especially during the winter season, when the number of visitors is particularly high. In fact, during the winter, the sounds of nature are replaced by those produced by recreation and sports activities. Mountain and snow tourism, which are developed in sensitive environmental contexts in the Aosta Valley, are sectors of immense social and economic importance. Much of this tourism takes place in ski resorts. Three mountain areas with different characteristics, in terms of attendance and recreational/sport activities, have been examined in this paper, as part of a collaboration between ARPA-VdA and the Politecnico di Torino. Acoustic measurements were performed in order to identify the seasonal variations of sound emissions from both natural and anthropic sound sources. In addition to the standard environmental acoustic descriptors foreseen by European legislation (LAeq, Ln, Lden, etc.), the harmonica (IH) index, which provides a quantitative evaluation of the acoustic quality on a zero to ten numerical scale, was used to qualify the acoustic climate of the three areas. The results presented in the paper provide useful information on a relevant subject—the preservation of the acoustic quality of a mountain area of touristic importance—which has been scarcely investigated so far.\n",
      "  -                 Background                Several climatologists and experts in the renewable energy field agree that GHI and DNI calculation models must be revised because of the increasingly unpredictable and powerful climatic disturbances. The construction of analytical mathematical models for the prediction of these disturbances is almost impossible because the physical phenomena relating to the climate are often complex. We raise the question over the current and future PV system’s sustainable energy production and whether climate disturbances will be affecting this sustainability and resulting in supply decline.                              Methods                In this paper, we tried to use deep learning as a tool to predict the evolution of the future production of any geographic site. This approach can allow for improvements in decision-making concerning the implantation of solar PV or CSP plants. To reach this aim, we have deployed the databases of NASA and the Tunisian National Institute of Meteorology relating to the climatic parameters of the case study region of El Akarit, Gabes, Tunisia. In spite of the colossal amount of processed data that dates back to 1985, the use of deep learning algorithms allowed for the validation of the previously made estimates of the energy potential in the studied region.                              Results                The calculation results suggested an increase in production as it was confirmed by the 2019 measures. The findings obtained from the case study region were reliable and seemed to be very promising. The results obtained using deep learning algorithms were similar to those produced by conventional calculation methods. However, while conventional approaches based on measurements obtained using hardware solutions (ground sensors) are expensive and very difficult to implement, the suggested new approach is cheaper and more convenient.                              Conclusions                In the existence of a protracted controversy over the hypothetical effects of climate change, making advances in artificial intelligence and using new deep learning algorithms are critical procedures to strengthening conventional assessment tools of the production sites of photovoltaic energy and CSP plants.              \n",
      "  - The management of the COVID-19 pandemic presents several unprecedented challenges in different fields, from medicine to biology, from public health to social science, that may benefit from computing methods able to integrate the increasing available COVID-19 and related data (e.g., pollution, demographics, climate, etc.). With the aim to face the COVID-19 data collection, harmonization and integration problems, we present the design and development of COVID-WAREHOUSE, a data warehouse that models, integrates and stores the COVID-19 data made available daily by the Italian Protezione Civile Department and several pollution and climate data made available by the Italian Regions. After an automatic ETL (Extraction, Transformation and Loading) step, COVID-19 cases, pollution measures and climate data, are integrated and organized using the Dimensional Fact Model, using two main dimensions: time and geographical location. COVID-WAREHOUSE supports OLAP (On-Line Analytical Processing) analysis, provides a heatmap visualizer, and allows easy extraction of selected data for further analysis. The proposed tool can be used in the context of Public Health to underline how the pandemic is spreading, with respect to time and geographical location, and to correlate the pandemic to pollution and climate data in a specific region. Moreover, public decision-makers could use the tool to discover combinations of pollution and climate conditions correlated to an increase of the pandemic, and thus, they could act in a consequent manner. Case studies based on data cubes built on data from Lombardia and Puglia regions are discussed. Our preliminary findings indicate that COVID-19 pandemic is significantly spread in regions characterized by high concentration of particulate in the air and the absence of rain and wind, as even stated in other works available in literature.\n",
      "--------------------------------------------------\n",
      "Topic 261: 261_resolution_sbl_upwelling_model\n",
      "Representative Documents:\n",
      "  - Water isotopologues, as natural tracers of the hydrological cycle on Earth, provide a unique way to assess the skill of climate models in representing realistic atmospheric‐terrestrial water pathways. This study presents the newly developed WRF‐Hydro‐iso, which is a version of the coupled atmospheric‐hydrological WRF‐Hydro model enhanced with a joint soil‐vegetation‐atmospheric description of water isotopologue motions. It allows the consideration of isotopic fractionation processes during water phase changes in the atmosphere, the land surface, and the subsurface. For validation, WRF‐Hydro‐iso is applied to two different climate zones, namely Europe and Southern Africa under the present climate conditions. Each case is modeled with a domain employing a 5 km grid‐spacing coupled with a terrestrial subgrid employing a 500 m grid‐spacing in order to represent lateral terrestrial water flow. A 10‐year slice is simulated for 2003–2012, using ERA5 reanalyses as driving data. The boundary condition of isotopic variables is prescribed with mean values from a 10‐year simulation with the Community Earth System Model Version 1. WRF‐Hydro‐iso realistically reproduces the climatological variations of the isotopic concentrations  and  from the Global Network of Isotopes in Precipitation. In a sensitivity analysis, it is found that land surface evaporation fractionation increases the isotopic concentrations in the rootzone soil moisture and slightly decreases the isotopic concentrations in precipitation. Lateral terrestrial water flow minorly affects these isotopic concentrations through changes in evaporation‐transpiration partitioning.\n",
      "  - The Canary current upwelling is one of the major eastern boundary coastal upwelling systems in the world, bearing a high productive ecosystem and commercially important fisheries. The Canary current upwelling system (CCUS) has a large latitudinal extension, usually divided into upwelling zones with different characteristics. Eddies, filaments and other mesoscale processes are known to have an impact in the upwelling productivity, thus for a proper representation of the CCUS and high horizontal resolution are required. Here we assess the CCUS present climate in the atmosphere–ocean regionally coupled model. The regional coupled model presents a global oceanic component with increased horizontal resolution along the northwestern African coast, and its performance over the CCUS is assessed against relevant reanalysis data sets and compared with an ensemble of global climate models (GCMs) and an ensemble of atmosphere-only regional climate models (RCMs) in order to assess the role of the horizontal resolution. The coupled system reproduces the larger scale pattern of the CCUS and its latitudinal and seasonal variability over the coastal band, improving the GCMs outputs. Moreover, it shows a performance comparable to the ensemble of RCMs in representing the coastal wind stress and near-surface air temperature fields, showing the impact of the higher resolution and coupling for CCUS climate modelling. The model is able of properly reproducing mesoscale structures, being able to simulate the upwelling filaments events off Cape Ghir, which are not well represented in most of GCMs. Our results stress the ability of the regionally coupled model to reproduce the larger scale as well as mesoscale processes over the CCUS, opening the possibility to evaluate the climate change signal there with increased confidence.\n",
      "  - Although crucial for the Earth's climate, clouds are poorly represented in current climate models, which operate at too coarse grid resolutions and rely on convection parameterizations. Thanks to advances in high‐performance computing, it is becoming feasible to perform high‐resolution climate simulations with explicitly resolved deep convection. The added value of such convection‐resolving simulations for the representation of precipitation has already been demonstrated in a number of studies, but assessments about clouds are still rare. In the present study, we analyze the representation of clouds in decade‐long convection‐resolving climate simulations (2.2‐km horizontal grid spacing) over a computational domain with 1,536 × 1,536 × 60 grid points covering Europe and compare it against coarser‐resolution convection‐parameterizing simulations (12‐km horizontal spacing). The simulations have been performed with a version of the COSMO model that runs entirely on graphics processing units. The European Centre for Medium‐Range Weather Forecasts Re‐Analysis‐Interim reanalysis‐driven present climate simulations (1999–2008) show that biases in mean summertime cloudiness and top‐of‐the‐atmosphere radiation budget are reduced when convection is resolved instead of parameterized. Especially, the typically underestimated midtropospheric cloud layer is enhanced, thanks to stronger vertical exchange. Future climate simulations (2079–2088) conducted using pseudo global warming experiments for a Representative Concentration Pathway 8.5 scenario show a predominating reduction in low‐level and midlevel cloud cover fraction and an increase in cloud top height, implying positive cloud‐amount and cloud‐height feedbacks. These positive feedbacks are only partly compensated by the negative cloud‐thickness feedback. Although the simulations exhibit substantial differences in terms of clouds in the present climate, the simulated cloud feedbacks are similar between the 2.2‐ and 12‐km models.\n",
      "--------------------------------------------------\n",
      "Topic 262: 262_phytoplankton_sockeye_bloom_nutrient\n",
      "Representative Documents:\n",
      "  - Cold‐water coral (CWC) reefs are recognized as ecologically and biologically significant areas that generate habitats and diversity. The interaction between hydrodynamics and CWCs has been well studied at the Mingulay Reef Complex, a relatively shallow area of reefs found on the continental shelf off Scotland, UK. Within ‘Mingulay Area 01’ a rapid tidal downwelling of surface waters, brought about as an internal wave, is known to supply warmer, phytoplankton‐rich waters to corals growing on the northern flank of an east‐west trending seabed ridge. This study shows that this tidal downwelling also causes short‐term perturbations in the inorganic carbon (CT) and nutrient dynamics through the water column and immediately above the reef. Over a 14 h period, corresponding to one semi‐diurnal tidal cycle, seawater pH overlying the reef varied by ca. 0.1 pH unit, while pCO2 shifted by &gt;60 μatm, a shift equivalent to a ca. 25 year jump into the future, with respect to atmospheric pCO2. During the summer stratified period, these downwelling events result in the reef being washed over with surface water that has higher pH, is warmer, nutrient depleted, but rich in phytoplankton‐derived particles compared to the deeper waters in which the corals sit. Empirical observations, together with outputs from the European Regional Shelf Sea Ecosystem Model, demonstrate that the variability that the CWC reefs experience changes through the seasons and into the future. Hence, as ocean acidification and warming increase into the future, the downwelling event specific to this site could provide short‐term amelioration of corrosive conditions at certain times of the year; however, it could additionally result in enhanced detrimental impacts of warming on CWCs. Natural variability in the CT and nutrient conditions, as well as local hydrodynamic regimes, must be accounted for in any future predictions concerning the responses of marine ecosystems to climate change.\n",
      "  - The Bering Sea ecosystem has undergone profound changes in response to climate regime shifts in the past decades. Here, lower trophic level production is assessed with a vertically one‐dimensional (1‐D) coupled ice‐ocean ecosystem model, which was applied to data collected by a National Oceanic and Atmospheric Administration (NOAA)/Pacific Marine Environmental Laboratory (PMEL) mooring from 1995 to 2005. The physical model is forced by sea surface winds, heat and salt fluxes, tides, and sea ice. The biological model includes coupled pelagic and ice algae components. Model results are validated with daily mooring temperature, fluorometer, and daily Sea‐viewing Wide Field‐of‐view Sensor (SeaWiFS) chlorophyll data. Two distinct ocean conditions and phytoplankton bloom patterns are related to the Pacific Decadal Oscillation (PDO) Index regimes: warmer temperature and later warm‐water phytoplankton species bloom in PDO &gt; 1 year; colder temperature and earlier cold‐water phytoplankton species bloom in PDO &lt; −1 year. Productivity of different phytoplankton species changed dramatically after the 1976 climate shift, but the total annual net primary production (NPP) remained flat over the past four decades under similar nutrient regulation. Climate shift also affected the vertical distribution of lower trophic level production and energy flow to the upper ocean pelagic ecosystem or the benthic community. A long‐term PDO regime shift occurred in 1976, and a short‐term PDO reversal occurred in 1998. Phytoplankton biomass responded promptly to both short‐ and long‐term climate changes. Zooplankton biomass responded more to the long‐term than to the short‐term climate shift. The model results captured observed trends of zooplankton abundance changes from the 1990s to 2004.\n",
      "  - Arid subtropical climates often oscillate between drought and wet conditions, leading to a “flood or famine” paradigm for estuarine freshwater inflow, in which sporadic storm events drive dynamic changes in salinity and nutrient availability. Transitioning from prolonged drought to wet conditions can impact phytoplankton communities. The Mission‐Aransas Estuary, located on the south Texas coast, transitioned from a 5‐yr drought (2010–2015) to wet conditions (2015–2020), punctuated by several large flood events and the direct impact of category 4 Hurricane Harvey. Using an 8‐yr bimonthly sample set (2012–2019), we evaluated particulate organic carbon, chlorophyll a, nutrient concentrations, and accessory pigments to characterize the response of the phytoplankton community to these climate events. We found that phytoplankton biomass was diminished during severe drought and increased during prolonged wet conditions. The phytoplankton community switched from being diatom‐dominated during drought to cyanobacteria‐dominated following estuarine freshening, driven by lower salinity and increased nutrient availability. Seasonal fluctuations between taxa persisted regardless of climate condition. The drought‐to‐wet transition prompted a regime shift of the estuarine phytoplankton community to a new quasi‐steady state in the studied estuary. Globally, changing climate regimes may cause longer periods of extreme drought or wet conditions for estuarine systems. Detailed, long‐term ecosystem monitoring is necessary to fully evaluate ecological responses to extreme weather events, especially links between biogeochemical cycling and ecosystem function. These results suggest that oscillations between distinct wet and dry periods have lasting effects on primary productivity, phytoplankton community composition, and organic matter cycling in subtropical estuaries with long residence times.\n",
      "--------------------------------------------------\n",
      "Topic 263: 263_las_que_para_una\n",
      "Representative Documents:\n",
      "  - Hacia una nueva generación de ensayos genéticos forestales multisitio para anticipar las respuestas de las especies forestales a la crisis climáticaRealizamos un comentario sobre el trabajo de revisión presentado por Leites &amp; Benito‐Garzón (2023) en este número sobre el valor de las redes de ensayos genéticos forestales multi‐sitio para anticipar la distribución y las respuestas de las especies forestales a la actual crisis climática. La persistencia de las masas forestales y de los servicios ecosistémicos que proporcionan necesita de un esfuerzo coordinado sin precedentes de la comunidad científica para comprender, predecir y mitigar los impactos de la crisis climática sobre los bosques templados y boreales. Para ello se necesita información precisa sobre la variación genética, plasticidad fenotípica y la variación genética en plasticidad de las especies forestales. Hacemos una llamada de atención sobre la necesidad urgente de establecer una nueva generación de ensayos genéticos forestales de procedencias replicados multisitio a lo largo del rango de distribución de las especies de interés, y enfocado en la resiliencia al cambio climático. Como científicos debemos facilitar las respuestas evolutivas a los tan rápidos que están viviendo las especies forestales. Debemos ser determinantes en proporcionar información de primera clase a los actores políticos y administradores para desarrollar una gestión forestal basada en la evidencia científica.\n",
      "  - Differential treatment is a key norm in multilateral environmental agreements. Its main objective is to increase compliance and reduce the free-rider problem by apportioning the costs and benefits of implementation more equitably across the parties in an agreement. The question of how to differentiate those burdens is inextricably linked to national interests, and while in some instances differential treatment is well designed and facilitates cooperation, in other cases a rigid divide—or cleavage—leads to a stalemate and constant conflict. This article studies the consequences of differential treatment as institutionalized under the United Nations Framework Convention on Climate Change (UNFCCC). Previous research has shown that the separation of UNFCCC parties into two opposing groups has deepened the polarization in the negotiations. We identify two causal mechanisms that may have driven this polarization, namely socialization through material incentives and the formation of group identity. We draw on an original dataset that records (dis)agreements between country pairs, coded from negotiation summaries between 1995 and 2013. Using a relational events model, we show that the division of UNFCCC parties into Annex I (with obligations) and non-Annex I (without obligations) is related primarily to material incentives and less to group identity formation.El trato diferenciado es una norma fundamental en los acuerdos ambientales multilaterales. Su principal objetivo es aumentar el cumplimiento y reducir el problema de los oportunistas distribuyendo los costos y los beneficios de la implementación de forma más equitativa entre las partes de un acuerdo. La cuestión de cómo diferenciar esas cargas está inextricablemente vinculada a los intereses nacionales y mientras que en algunos casos el trato diferenciado está bien diseñado y facilita la cooperación, en otros casos, una división rígida o escisión conduce a un estancamiento o un conflicto constante. En este artículo se estudian las consecuencias del trato diferenciado institucionalizado en la Convención Marco de las Naciones Unidas sobre el Cambio Climático (CMNUCC). Investigaciones anteriores han demostrado que la separación de las partes de la CMNUCC en dos grupos opuestos ha profundizado la polarización en las negociaciones. Identificamos dos mecanismos causales que pueden haber impulsado esta polarización; a saber, la socialización a través de incentivos materiales y la formación de la identidad de grupo. Nos basamos en un conjunto de datos original que registra los (des)acuerdos entre pares de países, codificados a partir de resúmenes de negociación entre 1995 y 2013. Utilizando un modelo de eventos relacionales, demostramos que la división de las partes de la CMNUCC en Anexo I (con obligaciones) y no Anexo I (sin obligaciones) está relacionada principalmente con los incentivos materiales y no tan relacionada con la formación de la identidad de grupo.Le traitement différencié est une norme clé des accords environnementaux multilatéraux. Son principal objectif est d'accroître la conformité et de réduire le problème de bénéficiaire sans contrepartie en répartissant plus équitablement les coûts et les avantages de la mise en œuvre d'un accord entre les parties qui y sont impliquées. La question de savoir comment différencier ces « fardeaux » est inextricablement liée aux intérêts nationaux, et bien que dans certains cas, le traitement différencié soit bien conçu et facilite la coopération, dans d'autres cas, une séparation rigide—ou clivage—conduit à une impasse et à un conflit permanent. Cet article étudie les conséquences du traitement différencié tel qu'il est institutionnalisé dans la Convention-cadre des Nations unies sur les changements climatiques (CCNUCC). Une recherche précédente a monté que la séparation des parties de la CCNUCC en deux groupes opposés avait accru la polarisation des négociations. Nous avons identifié deux mécanismes causaux qui peuvent avoir entraîné cette polarisation: la socialisation par incitations matérielles et la formation d'une identité de groupe. Nous nous appuyons sur un jeu de données original retraçant les (dés)accords entre paires de pays, qui ont été codés à partir des résumés des négociations qui sont intervenues entre 1995 et 2013. Nous utilisons un modèle d’événements relationnels et montrons que la séparation entre parties de la CCNUCC en pays de l'Annexe I (avec obligations) et pays hors Annexe I (sans obligations) est principalement davantage associée à des incitations matérielles qu’à une formation d'identité de groupe.\n",
      "  - Current policy developments to reduce greenhouse gas (GHG) emissions are falling behind ecological change. The prevalent policy response to mitigate climate change is based on carbon trading mechanisms, which after the 2010 U.S. House of Representatives election and the Cancún climate negotiations, face an uncertain future. After losing its political majority in congress, the Obama Administration has also lost its ability to implement a national cap and trade system in the United States. The inability of climate negotiators to cement clear GHG reduction targets and a firm commitment for a second period for the Kyoto Protocol (KP) in Cancún means that the longevity and widespread applicability of existing carbon trading mechanisms will remain in doubt until the next United Nations Framework Convention on Climate Change (UNFCCC) negotiations in Durban, South Africa, at the end of 2011. These recent developments provide impetus to explore additional strategies to help achieve climate mitigation and the decarbonization of the energy systems of the Americas. Specifically, this article analyzes the feasibility of implementing new collaborative agreements such as the “California‐Chile Partnership for the 21st Century” to advance domestic implementation of renewable energy (RE) initiatives. This article also examines the potential role that new organizations such as the International Renewable Energy Agency (IRENA) can play in enhancing local capacity and policy development in Latin America.El desarrollo de políticas para reducir las emisiones de gases de efecto invernadero (GEI) se están rezagando frente a los cambios en materia ecológica. La principal respuesta al cambio climático está basada en los mercados de carbón que después de las elecciones de congreso y senado en Estados Unidos y de las negociaciones mundiales sobre el cambio climático en Cancún, representan una fórmula que enfrenta un futuro incierto. Después de perder su mayoría en el congreso, la administración del presidente Obama enfrenta también una reducción en sus posibilidades de implementar un sistema de límites y comercio de emisiones en Estados Unidos. Además, el hecho de que representantes gubernamentales no pudieran concretar en Cancún metas claras para reducir las emisiones de GEI o un acuerdo firme para un segundo periodo del Protocolo de Kioto, pondrá en duda hasta las negociaciones de finales de 2011, en Durban, Sudáfrica, la durabilidad y generalización de los mecanismos de comercio de emisiones que son parte del Protocolo de Kioto. Estos eventos recientes incitan a analizar estrategias adicionales que puedan ayudar a mitigar el cambio climático y a mejorar los sistemas energéticos de las Américas. Específicamente este artículo analiza la factibilidad de implementar nuevos acuerdos de colaboración similares al acuerdo “Chile‐California: Una asociación para el siglo XXI” con la meta de avanzar en la implementación de nuevas iniciativas para incrementar el uso de las energías renovables. Este artículo también explora los roles que organizaciones nuevas como la Agencia Mundial de Energías Renovables podrían ejercer para aumentar el conocimiento a nivel local y para ayudar en la gestión de políticas prácticas para el desarrollo de las energías renovables en América Latina.\n",
      "--------------------------------------------------\n",
      "Topic 264: 264_aircraft_climate impact_flight_aviation\n",
      "Representative Documents:\n",
      "  - The WeCare project (Utilizing Weather information for Climate efficient and eco efficient future aviation), an internal project of the German Aerospace Center (Deutsches Zentrum für Luft- und Raumfahrt, DLR), aimed at finding solutions for reducing the climate impact of aviation based on an improved understanding of the atmospheric impact from aviation by making use of measurements and modeling approaches. WeCare made some important contributions to advance the scientific understanding in the area of atmospheric and air transportation research. We characterize contrail properties, show that the aircraft type significantly influences these properties, and how contrail-cirrus interacts with natural cirrus. Aviation NOx emissions lead to ozone formation and we show that the strength of the ozone enhancement varies, depending on where within a weather pattern NOx is emitted. These results, in combination with results on the effects of aerosol emissions on low cloud properties, give a revised view on the total radiative forcing of aviation. The assessment of a fleet of strut-braced wing aircraft with an open rotor is investigated and reveals the potential to significantly reduce the climate impact. Intermediate stop operations have the potential to significantly reduce fuel consumption. However, we find that, if only optimized for fuel use, they will have an increased climate impact, since non-CO2 effects compensate the reduced warming from CO2 savings. Avoiding climate sensitive regions has a large potential in reducing climate impact at relatively low costs. Taking advantage of a full 3D optimization has a much better eco-efficiency than lateral re-routings, only. The implementation of such operational measures requires many more considerations. Non-CO2 aviation effects are not considered in international agreements. We showed that climate-optimal routing could be achieved, if market-based measures were in place, which include these non-CO2 effects. An alternative measure to foster climate-optimal routing is the closing of air spaces, which are very climate-sensitive. Although less effective than an unconstrained optimization with respect to climate, it still has a significant potential to reduce the climate impact of aviation. By combining atmospheric and air transportation research, we assess climate mitigation measures, aiming at providing information to aviation stakeholders and policy-makers to make aviation more climate compatible.\n",
      "  - . Aviation contributes to climate change, and the climate impact of aviation is expected to increase further. Adaptations of aircraft routings in order to reduce the climate impact are an important climate change mitigation measure. The air traffic simulator AirTraf, as a submodel of the European Center HAMburg general circulation model (ECHAM) and Modular Earth Submodel System (MESSy) Atmospheric Chemistry (EMAC) model, enables the evaluation of such measures. For the first version of the submodel AirTraf, we concentrated on the general setup of the model, including departure and arrival, performance and emissions, and technical aspects such as the parallelization of the aircraft trajectory calculation with only a limited set of optimization possibilities (time and distance). Here, in the second version of AirTraf, we focus on enlarging the objective functions by seven new options to enable assessing operational improvements in many more aspects including economic costs, contrail occurrence, and climate impact. We verify that the AirTraf setup, e.g., in terms of number and choice of design variables for the genetic algorithm, allows us to find solutions even with highly structured fields such as contrail occurrence. This is shown by example simulations of the new routing options, including around 100 North Atlantic flights of an Airbus A330 aircraft for a typical winter day.The results clearly show that AirTraf 2.0 can find the different families of optimum flight trajectories (three-dimensional) for specific routing options; those trajectories minimize the corresponding objective functions successfully. The minimum cost option lies between the minimum time and the minimum fuel options. Thus, aircraft operating costs are minimized by taking the best compromise between flight time and fuel use.The aircraft routings for contrail avoidance and minimum climate impact reduce the potential climate impact which is estimated by using algorithmic climate change functions, whereas these two routings increase the aircraft operating costs. A trade-off between the aircraft operating costs and the climate impact is confirmed. The simulation results are compared with literature data, and the consistency of the submodel AirTraf 2.0 is verified.                    \n",
      "  - . Mobility is becoming more and more important to society and hence air transportation is expected to grow further over the next decades. Reducing anthropogenic climate impact from aviation emissions and building a climate-friendly air transportation system are required for a sustainable development of commercial aviation. A climate optimized routing, which avoids climate-sensitive regions by re-routing horizontally and vertically, is an important measure for climate impact reduction. The idea includes a number of different routing strategies (routing options) and shows a great potential for the reduction. To evaluate this, the impact of not only CO2 but also non-CO2 emissions must be considered. CO2 is a long-lived gas, while non-CO2 emissions are short-lived and are inhomogeneously distributed. This study introduces AirTraf (version 1.0) that performs global air traffic simulations, including effects of local weather conditions on the emissions. AirTraf was developed as a new submodel of the ECHAM5/MESSy Atmospheric Chemistry (EMAC) model. Air traffic information comprises Eurocontrol's Base of Aircraft Data (BADA Revision 3.9) and International Civil Aviation Organization (ICAO) engine performance data. Fuel use and emissions are calculated by the total energy model based on the BADA methodology and Deutsches Zentrum für Luft- und Raumfahrt (DLR) fuel flow method. The flight trajectory optimization is performed by a genetic algorithm (GA) with respect to a selected routing option. In the model development phase, benchmark tests were performed for the great circle and flight time routing options. The first test showed that the great circle calculations were accurate to −0.004 %, compared to those calculated by the Movable Type script. The second test showed that the optimal solution found by the algorithm sufficiently converged to the theoretical true-optimal solution. The difference in flight time between the two solutions is less than 0.01 %. The dependence of the optimal solutions on the initial set of solutions (called population) was analyzed and the influence was small (around 0.01 %). The trade-off between the accuracy of GA optimizations and computational costs is clarified and the appropriate population and generation (one iteration of GA) sizing is discussed. The results showed that a large reduction in the number of function evaluations of around 90 % can be achieved with only a small decrease in the accuracy of less than 0.1 %. Finally, AirTraf simulations are demonstrated with the great circle and the flight time routing options for a typical winter day. The 103 trans-Atlantic flight plans were used, assuming an Airbus A330-301 aircraft. The results confirmed that AirTraf simulates the air traffic properly for the two routing options. In addition, the GA successfully found the time-optimal flight trajectories for the 103 airport pairs, taking local weather conditions into account. The consistency check for the AirTraf simulations confirmed that calculated flight time, fuel consumption, NOx emission index and aircraft weights show good agreement with reference data.                    \n",
      "--------------------------------------------------\n",
      "Topic 265: 265_earth_water vapour_atmosphere_radiation\n",
      "Representative Documents:\n",
      "  -  Robust scientific evidence shows the sun angle controls water vapour content of the atmosphere, the main component of back radiation, as it cycles annually. Water vapour content measured as the ratio of the number of water molecules to CO2 molecules varies from 1:1 near the Poles to 97:1 in the Tropics. The effect of back radiation on Earth’s atmosphere is up to 200 times larger than that of CO2 and works in the opposite direction. Thus, if CO2 has any effect on atmospheric temperature and climate change we show it is negligible. Consequently, current government policies to control atmospheric temperature by limiting consumption of fossil fuels will have negligible effect. Measured data reported in IPCC report Climate Change 2013: The Physical Science Basis ( AR5) indicate increased water vapour content of the atmosphere is the cause of the 0.5℃ temperature increase from the mid-1970s to 2011. \n",
      "  -  This study examines the concept of ‘greenhouse gases’ and various definitions of the phenomenon known as the ‘Atmospheric Radiative Greenhouse Effect’. The six most quoted descriptions are as follows: (a) radiation trapped between the Earth’s surface and its atmosphere; (b) the insulating blanket of the atmosphere that keeps the Earth warm; (c) back radiation from the atmosphere to the Earth’s surface; (d) Infra Red absorbing gases that hinder radiative cooling and keep the surface warmer than it would otherwise be – known as ‘otherwise radiation’; (e) differences between actual surface temperatures of the Earth (as also observed on Venus) and those based on calculations; (f) any gas that absorbs infrared radiation emitted from the Earth’s surface towards free space. It is shown that none of the above descriptions can withstand the rigours of scientific scrutiny when the fundamental laws of physics and thermodynamics are applied to them. \n",
      "  -  The Beer-Lambert law does not apply strictly to the relationship between radiative forcing (RF) of CO2 and concentration in the atmosphere, i.e., ΔRF = 5.35ln(C/Co). It is an approximation because water vapour competes unevenly with CO2 over the IR absorption wavelength range. We propose a quadratic model as an improved approximation. It links concentration to RF thereby allowing RF calculation at any concentration, not just ΔRF. For example, at 378 ppmv of CO2, the level in 2005, it calculates RF = 8.67 W m−2, or approximately 2.7% of the total RF of all the greenhouse gases. A second and independent method based on worldwide hourly measurements of atmospheric temperature and relative humidity confirms this percentage. Each method shows that, on average, water vapour contributes approximately 96% of current greenhouse gas warming. Thus, the factors controlling the amount of water vapour in the air also control the earth's temperature. \n",
      "--------------------------------------------------\n",
      "Topic 266: 266_tropical climate model_tropical climate_initial data_equations\n",
      "Representative Documents:\n",
      "  - We obtain the global well-posedness of classical solutions to a tropical climate model with only the dissipation of the first baroclinic model of the velocity (−ηΔv) under small initial data. This model is a modified version of the original system derived by Frierson-Majda-Pauluis in Frierson et al. [Commun. Math. Sci. 2, 591-626 (2004)]. The main difficulty is the absence of thermal diffusion. To overcome it, we exploit the structure of the equations coming from the coupled terms, dissipation term, and damp term. Then, we find the hidden thermal diffusion. In addition, based on the Littlewood-Paley theory, we establish a generalized commutator estimate, which may be applied to other partial differential equations.\n",
      "  - It is well known, by now, that the three-dimensional non-viscous planetary geostrophic model, with vertical hydrostatic balance and horizontal Rayleigh friction/damping, coupled to the heat diffusion and transport, is mathematically ill-posed. This is because the no-normal flow physical boundary condition implicitly produces an additional boundary condition for the temperature at the lateral boundary. This additional boundary condition is different, because of the Coriolis forcing term, than the no-heat-flux physical boundary condition. Consequently, the second order parabolic heat equation is over-determined with two different boundary conditions. In a previous work we proposed one remedy to this problem by introducing a fourth-order artificial hyper-diffusion to the heat transport equation and proved global regularity for the proposed model. A shortcoming of this higher-oder diffusion is the loss of the maximum/minimum principle for the heat equation. Another remedy for this problem was suggested by R. Salmon by introducing an additional Rayleigh-like friction/damping term for the vertical component of the velocity in the hydrostatic balance equation. In this paper we prove the global, for all time and all initial data, well-posedness of strong solutions to the three-dimensional Salmon’s planetary geostrophic model of ocean dynamics. That is, we show global existence, uniqueness and continuous dependence of the strong solutions on initial data for this model. Unlike the 3D viscous PG model, we are still unable to show the uniqueness of the weak solution. Notably, we also demonstrate in what sense the additional damping term, suggested by Salmon, annihilate the ill-posedness in the original system; consequently, it can be viewed as “regularizing” term that can possibly be used to regularize other related systems.\n",
      "  - Tropical climate model derived by Frierson et al. (Commun Math Sci 2:591–626, 2004) and its modified versions have been investigated in a number of papers [see, e.g., Li and Titi (Discrete Contin Dyn Syst Series A 36(8):4495–4516, 2016), Wan (J Math Phys 57(2):021507, 2016), Ye (J Math Anal Appl 446:307–321, 2017) and more recently Dong et al. (Discrete Contin Dyn Syst Ser B 24(1):211–229, 2019)]. Here, we deal with the 2D tropical climate model with fractional dissipative terms in the equation of the barotropic mode u and in the equation of the first baroclinic mode v of the velocity, but without diffusion in the temperature equation, and we establish a regularity criterion for this system.\n",
      "--------------------------------------------------\n",
      "Topic 267: 267_curr_rm_circ_text\n",
      "Representative Documents:\n",
      "  - We evaluate how hotspots of different types of extreme summertime heat change under global warming increase of up to $$4\\,^\\circ \\hbox {C}$$4∘C; and which level of global warming allows us to avert the risk of these hotspots considering the irreducible range of possibilities defined by well-sampled internal variability. We use large samples of low-probability extremes simulated by the 100-member Max Planck Institute Grand Ensemble (MPI-GE) for five metrics of extreme heat: maximum absolute temperatures, return periods of extreme temperatures, maximum temperature variability, sustained tropical nights, and wet bulb temperatures. At $$2\\,^\\circ \\hbox {C}$$2∘C of warming, MPI-GE projects maximum summer temperatures below $$50\\,^\\circ \\hbox {C}$$50∘C over most of the world. Beyond $$2\\,^\\circ \\hbox {C}$$2∘C, this threshold is overshot in all continents, with the maximum projected temperatures in hotspots over the Arabic Peninsula. Extreme 1-in-100-years pre-industrial temperatures occur every 10–25 years already at $$1.5\\,^\\circ \\hbox {C}$$1.5∘C of warming. At $$4\\,^\\circ \\hbox {C}$$4∘C, these 1-in-100-years extremes are projected to occur every 1 to 2 years over most of the world. The range of maximum temperature variability increases by 10–50% at $$2\\,^\\circ \\hbox {C}$$2∘C of warming, and by 50–100% at $$4\\,^\\circ \\hbox {C}$$4∘C. Beyond $$2\\,^\\circ \\hbox {C}$$2∘C, heat stress is aggravated substantially over non-adapted areas by hot and humid conditions that occur rarely in a pre-industrial climate; while extreme pre-industrial tropical night conditions become common-pace already at $$1.5\\,^\\circ \\hbox {C}$$1.5∘C. At $$4\\,^\\circ \\hbox {C}$$4∘C of warming, tropical night hotspots spread polewards globally, and are sustained during more than 99% of all summer months in the tropics; whilst extreme monthly mean wet bulb temperatures beyond $$26\\,^\\circ \\hbox {C}$$26∘C spread both over large tropical as well as mid-latitude regions.\n",
      "  - The equilibrium climate sensitivity (ECS, in K) to $$\\hbox {CO}_{2}$$CO2 doubling is a large source of uncertainty in projections of future anthropogenic climate change. Estimates of ECS made from non-equilibrium states or in response to radiative forcings other than $$\\hbox {2}\\times \\hbox {CO}_{2}$$2×CO2 are called “effective climate sensitivity” (EffCS, in K). Taking a “perfect-model” approach, using coupled atmosphere–ocean general circulation model (AOGCM) experiments, we evaluate the accuracy with which $$\\hbox {CO}_{2}$$CO2 EffCS can be estimated from climate change in the “historical” period (since about 1860). We find that (1) for statistical reasons, unforced variability makes the estimate of historical EffCS both uncertain and biased; it is overestimated by about 10% if the energy balance is applied to the entire historical period, 20% for 30-year periods, and larger factors for interannual variability, (2) systematic uncertainty in historical radiative forcing translates into an uncertainty of $${\\pm }\\,30\\, {\\rm to} \\,45\\%$$±30to45% (standard deviation) in historical EffCS, (3) the response to the changing relative importance of the forcing agents, principally $$\\hbox {CO}_{2}$$CO2 and volcanic aerosol, causes historical EffCS to vary over multidecadal timescales by a factor of two. In recent decades it reached its maximum in the AOGCM historical experiment (similar to the multimodel-mean $$\\hbox {CO}_{2}$$CO2 EffCS of 3.6 K from idealised experiments), but its minimum in the real world (1.6 K for an observational estimate for 1985–2011, similar to the multimodel-mean value for volcanic forcing). The real-world variations mean that historical EffCS underestimates $$\\hbox {CO}_{2}$$CO2 EffCS by 30% when considering the entire historical period. The difference for recent decades implies that either unforced variability or the response to volcanic forcing causes a much stronger regional pattern of sea surface temperature change in the real world than in AOGCMs. We speculate that this could be explained by a deficiency in simulated coupled atmosphere–ocean feedbacks which reinforce the pattern (resembling the Interdecadal Pacific Oscillation in some respects) that causes the low EffCS. We conclude that energy-balance estimates of $$\\hbox {CO}_{2}$$CO2 EffCS are most accurate from periods unaffected by volcanic forcing. Atmosphere GCMs provided with observed sea surface temperature for the 1920s to the 1950s, which was such a period, give a range of about 2.0–4.5 K, agreeing with idealised $$\\hbox {CO}_{2}$$CO2 AOGCM experiments; the consistency is a reason for confidence in this range as an estimate of $$\\hbox {CO}_{2}$$CO2 EffCS. Unless another explosive volcanic eruption occurs, the first 30 years of the present century may give a more accurate energy-balance historical estimate of this quantity.\n",
      "  - ABSTRACTMass-balance measurements of Icelandic glaciers are sparse through the 20th century. However, the large archive of stereo images available allows estimates of glacier-wide mass balance ($\\dot{B}$) in decadal time steps since 1945. Combined with climate records, they provide further insight into glacier–climate relationship. This study presents a workflow to process aerial photographs (1945–1995), spy satellite imagery (1977–1980) and modern satellite stereo images (since 2000) using photogrammetric techniques and robust statistics in a highly automated, open-source pipeline to retrieve seasonally corrected, decadal glacier-wide geodetic mass balances. In our test area, Eyjafjallajökull (S-Iceland, ~70 km2), we obtain a mass balance of$&lt;![CDATA[ $ \\dot{\\curr B}_{\\curr 1945}^{\\curr 2014} \\curr = -0.27 \\pm 0.03\\,{\\rm \\curr m\\ w}{\\rm. \\curr e}{\\rm.} {\\rm \\curr a}^{{\\rm \\ndash \\curr 1}}$, with a maximum and minimum of$\\dot{\\curr B}_{\\curr 1984}^{\\curr 1989} \\curr = 0.77 \\curr \\pm 0.19\\,{\\rm \\curr m\\ \\curr w}{\\rm\\curr . e}{\\rm\\curr .} {\\rm\\curr a}^{{\\rm\\curr \\ndash 1}}$and$\\dot{\\curr B}_{\\curr 1994}^{\\curr 1998}\\curr = -1.94 \\curr \\pm 0.34\\,{\\rm \\curr m\\ w}{\\rm\\curr . e}{\\rm\\curr .} {\\rm \\curr a}^{{\\rm\\curr \\ndash 1}}$, respectively, attributed to climatic forcing, and$\\dot{\\curr B}_{\\curr 2009}^{\\curr 2010} \\curr = -3.39{\\rm \\;} \\curr \\pm {\\rm \\;} \\curr 0.43\\,{\\rm \\curr m\\ w}{\\rm\\curr . e}{\\rm\\curr .} {\\rm\\curr a}^{{\\rm\\curr \\ndash 1}}$, mostly caused by the April 2010 eruption. The reference-surface mass balances correlate with summer temperature and winter precipitation, and linear regression accounts for 80% of the mass-balance variability, yielding a static sensitivity of mass balance to summer temperature and winter precipitation of − 2.1 ± 0.4 m w.e.a–1K–1and 0.5 ± 0.3 m w.e.a–1(10%)–1, respectively. This study serves as a template that can be used to estimate the mass-balance changes and glaciers' response to climate.\n",
      "--------------------------------------------------\n",
      "Topic 268: 268_irrigated crop yields_irrigated crop_key pointsclimate socioeconomic_phenomenon life europe\n",
      "Representative Documents:\n",
      "  - In trying to explain such a complex phenomenon, Life in Europe Under Climate Change does well in emphasising the anthropogenic factors of today’s modern climate.\n",
      "  - This narrative highlights the possible unintended consequences of relief programmes by considering local responses to aid following Cyclone Pam in Vanuatu.\n",
      "  - Key PointsClimate and socioeconomic changes will increase water shortages and strongly reduce irrigated crop yields in specific regions or cropsGHG mitigation has the potential to alleviate the effect of water stress on irrigated crop yields\n",
      "--------------------------------------------------\n",
      "Topic 269: 269_forests_forest_tree_boreal\n",
      "Representative Documents:\n",
      "  - Assessing potential future changes in arctic and boreal plant species productivity, ecosystem composition, and canopy complexity is essential for understanding environmental responses under expected altered climate forcing. We examined potential changes in the dominant plant functional types (PFTs) of the sedge tundra, shrub tundra, and boreal forest ecosystems in ecotonal northern Alaska, USA, for the years 2003–2100. We compared energy feedbacks associated with increases in biomass to energy feedbacks associated with changes in the duration of the snow‐free season. We based our simulations on nine input climate scenarios from the Intergovernmental Panel on Climate Change (IPCC) and a new version of the Terrestrial Ecosystem Model (TEM) that incorporates biogeochemistry, vegetation dynamics for multiple PFTs (e.g., trees, shrubs, grasses, sedges, mosses), multiple vegetation pools, and soil thermal regimes. We found mean increases in net primary productivity (NPP) in all PFTs. Most notably, birch (Betulaspp.) in the shrub tundra showed increases that were at least three times larger than any other PFT. Increases in NPP were positively related to increases in growing‐season length in the sedge tundra, but PFTs in boreal forest and shrub tundra showed a significant response to changes in light availability as well as growing‐season length. Significant NPP responses to changes in vegetation uptake of nitrogen by PFT indicated that some PFTs were better competitors for nitrogen than other PFTs. While NPP increased, heterotrophic respiration (RH) also increased, resulting in decreases or no change in net ecosystem carbon uptake. Greater aboveground biomass from increased NPP produced a decrease in summer albedo, greater regional heat absorption (0.34 ± 0.23 W·m−2·10 yr−1[mean ± SD]), and a positive feedback to climate warming. However, the decrease in albedo due to a shorter snow season (−5.1 ± 1.6 d/10 yr) resulted in much greater regional heat absorption (3.3 ± 1.24 W·m−2·10 yr−1) than that associated with increases in vegetation. Through quantifying feedbacks associated with changes in vegetation and those associated with changes in the snow season length, we can reach a more integrated understanding of the manner in which climate change may impact interactions between high‐latitude ecosystems and the climate system.\n",
      "  - Biomass change of the world's forests is critical to the global carbon cycle. Despite storing nearly half of global forest carbon, the boreal biome of diverse forest types and ages is a poorly understood component of the carbon cycle. Using data from 871 permanent plots in the western boreal forest of Canada, we examined net annual aboveground biomass change (ΔAGB) of four major forest types between 1958 and 2011. We found that ΔAGB was higher for deciduous broadleaf (DEC) (1.44 Mg ha−1 year−1, 95% Bayesian confidence interval (CI), 1.22–1.68) and early‐successional coniferous forests (ESC) (1.42, CI, 1.30–1.56) than mixed forests (MIX) (0.80, CI, 0.50–1.11) and late‐successional coniferous (LSC) forests (0.62, CI, 0.39–0.88). ΔAGB declined with forest age as well as calendar year. After accounting for the effects of forest age, ΔAGB declined by 0.035, 0.021, 0.032 and 0.069 Mg ha−1 year−1 per calendar year in DEC, ESC, MIX and LSC forests, respectively. The ΔAGB declines resulted from increased tree mortality and reduced growth in all forest types except DEC, in which a large biomass loss from mortality was accompanied with a small increase in growth. With every degree of annual temperature increase, ΔAGB decreased by 1.00, 0.20, 0.55 and 1.07 Mg ha−1 year−1 in DEC, ESC, MIX and LSC forests, respectively. With every cm decrease of annual climatic moisture availability, ΔAGB decreased 0.030, 0.045 and 0.17 Mg ha−1 year−1 in ESC, MIX and LSC forests, but changed little in DEC forests. Our results suggest that persistent warming and decreasing water availability have profound negative effects on forest biomass in the boreal forests of western Canada. Furthermore, our results indicate that forest responses to climate change are strongly dependent on forest composition with late‐successional coniferous forests being most vulnerable to climate changes in terms of aboveground biomass.\n",
      "  - Boreal wildfires are increasing in intensity, extent, and frequency, potentially intensifying carbon emissions and transitioning the region from a globally significant carbon sink to a source. The productive southern boreal forests of central Canada already experience relatively high frequencies of fire, and as such may serve as an analog of future carbon dynamics for more northern forests. Fire–carbon dynamics in southern boreal systems are relatively understudied, with limited investigation into the drivers of pre‐fire carbon stocks or subsequent combustion. As part of NASA's Arctic‐Boreal Vulnerability Experiment, we sampled 79 stands (47 burned, 32 unburned) throughout central Saskatchewan to characterize above‐ and belowground carbon stocks and combustion rates in relation to historical land use, vegetation characteristics, and geophysical attributes. We found southern boreal forests emitted an average of 3.3 ± 1.1 kg C/m2from field sites. The emissions from southern boreal stands varied as a function of stand age, fire weather conditions, ecozone, and soil moisture class. Sites affected by historical timber harvesting had greater combustion rates due to faster carbon stock recovery rates than sites recovering from wildfire events, indicating that different boreal forest land use practices can generate divergent carbon legacy effects. We estimate the 2015 fire season in Saskatchewan emitted a total of 36.3 ± 15.0 Tg C, emphasizing the importance of southern boreal fires for regional carbon budgets. Using the southern boreal as an analog, the northern boreal may undergo fundamental shifts in forest structure and carbon dynamics, becoming dominated by stands &lt;70 years old that hold 2–7 kg C/m2less than current mature northern boreal stands. Our latitudinal approach reinforces previous studies showing that northern boreal stands are at a high risk of holding less carbon under changing disturbance conditions.\n",
      "--------------------------------------------------\n",
      "Topic 270: 270_reconstructions_proxy_paleoclimate_ifa\n",
      "Representative Documents:\n",
      "  - . Reconstructions of past temperature and precipitation are fundamental to modeling the Greenland Ice Sheet and assessing its sensitivity to climate. Paleoclimate information is sourced from proxy records and climate-model simulations; however, the former are spatially incomplete while the latter are sensitive to model dynamics and boundary conditions. Efforts to combine these sources of information to reconstruct spatial patterns of Greenland climate over glacial–interglacial cycles have been limited by assumptions of fixed spatial patterns and a restricted use of proxy data. We avoid these limitations by using paleoclimate data assimilation to create independent reconstructions of mean-annual temperature and precipitation for the last 20 000 years. Our method uses oxygen isotope ratios of ice and accumulation rates from long ice-core records and extends this information to all locations across Greenland using spatial relationships derived from a transient climate-model simulation. Standard evaluation metrics for this method show that our results capture climate at locations without ice-core records. Our results differ from previous work in the reconstructed spatial pattern of temperature change during abrupt climate transitions; this indicates a need for additional proxy data and additional transient climate-model simulations. We investigate the relationship between precipitation and temperature, finding that it is frequency dependent and spatially variable, suggesting that thermodynamic scaling methods commonly used in ice-sheet modeling are overly simplistic. Our results demonstrate that paleoclimate data assimilation is a useful tool for reconstructing the spatial and temporal patterns of past climate on timescales relevant to ice sheets.                    \n",
      "  - Paleoclimate data assimilation has recently emerged as a promising technique to estimate past climate states. Here we test two of the underlying assumptions of paleoclimate data assimilation as applied so far: (1) climate proxies can be modeled as linear, univariate recorders of temperature and (2) structural errors in GCMs can be neglected. To investigate these two points and related uncertainties, we perform a series of synthetic, paleoclimate data assimilation‐based reconstructions where “pseudo” proxies are generated with physically based proxy system models (PSMs) for coral δ18O, tree ring width, and ice core δ18O using two isotope‐enabled atmospheric general circulation models. For (1), we find that linear‐univariate models efficiently capture the GCM's climate in ice cores and corals and do not lead to large losses in reconstruction skill. However, this does not hold for tree ring width, especially in regions where the trees' response is dominated by moisture supply; we quantify how the breakdown of this assumption lowers reconstruction skill for each proxy class. For (2), we find that climate model biases can introduce errors that greatly reduce reconstruction skill, with or without perfect proxy system models. We explore possible strategies for mitigating structural modeling errors in GCMs and discuss implications for paleoclimate reanalyses.\n",
      "  - . Because of the relatively brief observational record, the climate dynamics that drive multiyear to centennial hydroclimate variability are not adequately characterized and understood. Paleoclimate reconstructions based on data assimilation (DA) optimally fuse paleoclimate proxies with the dynamical constraints of climate models, thus providing a coherent dynamical picture of the past. DA is therefore an important new tool for elucidating the mechanisms of hydroclimate variability over the last several millennia. But DA has so far remained untested for global hydroclimate reconstructions. Here we explore whether or not DA can be used to skillfully reconstruct global hydroclimate variability along with the driving climate dynamics. Through a set of idealized pseudoproxy experiments, we find that an established DA reconstruction approach can in principle be used to reconstruct hydroclimate at both annual and seasonal timescales. We find that the skill of such reconstructions is generally highest near the proxy sites. This set of reconstruction experiments is specifically designed to estimate a realistic upper bound for the skill of this DA approach. Importantly, this experimental framework allows us to see where and for what variables the reconstruction approach may never achieve high skill. In particular for tree rings, we find that hydroclimate reconstructions depend critically on moisture-sensitive trees, while temperature reconstructions depend critically on temperature-sensitive trees. Real-world DA-based reconstructions will therefore likely require a spatial mixture of temperature- and moisture-sensitive trees to reconstruct both temperature and hydroclimate variables. Additionally, we illustrate how DA can be used to elucidate the dynamical mechanisms of drought with two examples: tropical drivers of multiyear droughts in the North American Southwest and in equatorial East Africa. This work thus provides a foundation for future DA-based hydroclimate reconstructions using real-proxy networks while also highlighting the utility of this important tool for hydroclimate research.\n",
      "--------------------------------------------------\n",
      "Topic 271: 271_hydrate_ch4_hydrates_co2\n",
      "Representative Documents:\n",
      "  - This article presents gas hydrate experimental measurements for mixtures containing methane (CH4), carbon dioxide (CO2) and nitrogen (N2) with the aim to better understand the impact of water (H2O) on the phase equilibrium. Some of these phase equilibrium experiments were carried out with a very high water-to-gas ratio that shifts the gas hydrate dissociation points to higher pressures. This is due to the significantly different solubilities of the different guest molecules in liquid H2O. A second experiment focused on CH4-CO2 exchange between the hydrate and the vapor phases at moderate pressures. The results show a high retention of CO2 in the gas hydrate phase with small pressure variations within the first hours. However, for our system containing 10.2 g of H2O full conversion of the CH4 hydrate grains to CO2 hydrate is estimated to require 40 days. This delay is attributed to the shrinking core effect, where initially an outer layer of CO2-rich hydrate is formed that effectively slows down the further gas exchange between the vapor phase and the inner core of the CH4-rich hydrate grain.\n",
      "  - The global occurrences of natural gas hydrates lead to the conclusion that tremendous amounts of hydrocarbons are bonded in these hydrate-bearing sediments, serving as a potential energy resource. For the release of the hydrate-bonded CH4 from these reservoirs, different production methods have been developed during the last decades. Among them, the chemical stimulation via injection of CO2 is considered as carbon neutral on the basis of the assumption that the hydrate-bonded CH4 is replaced by CO2. For the investigation of the replacement process of hydrate-bonded CH4 with CO2 on a µm-scale, we performed time-resolved in situ Raman spectroscopic measurements combined with microscopic observations, exposing the CH4 hydrates to a CO2 gas phase at 3.2 MPa and 274 K. Single-point Raman measurements, line scans and Raman maps were taken from the hydrate phase. Measurements were performed continuously at defined depths from the surface into the core of several hydrate crystals. Additionally, the changes in composition in the gas phase were recorded. The results clearly indicated the incorporation of CO2 into the hydrate phase with a concentration gradient from the surface to the core of the hydrate particle, supporting the shrinking core model. Microscopic observations, however, indicated that all the crystals changed their surface morphology when exposed to the CO2 gas. Some crystals of the initial CH4 hydrate phase grew or were maintained while at the same time other crystals decreased in sizes and even disappeared over time. This observation suggested a reformation process similar to Ostwald ripening rather than an exchange of molecules in already existing hydrate structures. The experimental results from this work are presented and discussed in consideration of the existing models, providing new insights on a µm-scale into the transformation process of CH4 hydrates to CO2-rich mixed hydrates.\n",
      "  - In this contribution, a method based on a solid solution theory of clathrate hydrate for multiple cage occupancy, host lattice relaxation, and guest-guest interactions is presented to estimate hydrate formation conditions of binary and ternary gas mixtures. We performed molecular modeling of the structure, guest distribution, and hydrate formation conditions for the CO2 + CH4 and CO2 + CH4 + N2 gas hydrates. In all considered systems with and without N2, at high and medium content of CO2 in the gas phase, we found that CO2 was more favorable in occupying clathrate hydrate cavities than CH4 or N2. The addition of N2 to the gas phase increased the ratio concentration of CO2 in comparison with the concentration of CH4 in clathrate hydrates and made gas replacement more effective. The mole fraction of CO2 in the CO2 + CH4 + N2 gas hydrate rapidly increased with the growth of its content in the gas phase, and the formation pressure of the CO2 + CH4 + N2 gas hydrate rose in comparison to the formation pressure of the CO2 + CH4 gas hydrate. The obtained results agreed with the known experimental data for simple CH4 and CO2 gas hydrates and the mixed CO2 + CH4 gas hydrate.\n",
      "--------------------------------------------------\n",
      "Topic 272: 272_communication_carbon removal_science_climate science\n",
      "Representative Documents:\n",
      "  - PurposeThe purpose of this paper is to explain the US society’s insignificant mitigation of climate change using Niklas Luhmann’s (1989) autopoietic social systems theory in ecological communication. Specifically, the author’s analysis falls within the context of Luhmann re-moralized while focusing on particular function systems’ binary codes and their repellence of substantive US climate change mitigation policy across systems.Design/methodology/approachThe author achieves this purpose by resituating Luhmann’s conception of evolution to forgo systems teleology and better contextualize the spatial-temporal scale of climate change; reinforcing complexity reduction and differentiation by integrating communication and media scholar John D. Peters’s (1999) “communication chasm” concept as one mechanism through which codes sustain over time; and applying these integrated concepts to prominent the US climate change mitigation attempts.FindingsThe author concludes that climate change mitigation efforts are the amalgamation of the systems’ moral communications. Mitigation efforts have relegated themselves to subsystems of the ten major systems given the polarizing nature of their predominant care/harm moral binary. Communication chasms persist because these moral communications cannot both adhere to the systems’ binary codes and communicate the climate crisis’s urgency. The more time that passes, the more codes force mitigation organizations, activist efforts and their moral communications to adapt and sacrifice their actions to align with the encircling systems’ code.Social implicationsIn addition to the conceptual contribution, the social implication is that by identifying how and why climate change mitigation efforts are subsumed by the larger systems and their codes, climate change activists and practitioners can better tool their tactics to change the codes at the heart of the systems if serious and substantive climate change mitigation is to prevail.Originality/valueTo the author’s knowledge, there has not been an integration of a historical communication concept into, and sociological application of, ecological communication in the context of climate change mitigation.\n",
      "  - Climate change has been the subject of increasing efforts by scientists to understand its causes and implications; it has been of growing interest to policymakers, international bodies, and a variety of nongovernment organizations; and it has attracted varied amounts of attention from traditional and, increasingly, online media. These developments have been aligned with shifts in the nature of climate change communication, with changes in how researchers study it and how a variety of actors try to influence it. This article situates the theory and practice of climate change communication within developments that have taken place since we first reviewed the field in 2009. These include the rise of new social media conduits for communication, research, and practice aimed at fine tuning communication content, and the rise to prominence of scientific consensus as part of that content. We focus in particular on continuing tensions between a focus on the part of communicators to inform the public and more dialogic strategies of public engagement. We also consider the tension between efforts to promote consensus and certainty in climate science and approaches that attempt to engage with uncertainty more fully. We explore the lessons to be learnt from climate communication since 2009, highlighting how the field remains haunted by the deficit model of science communication. Finally, we point to more fruitful future directions for climate change communication, including more participatory models that acknowledge, rather than ignore, residual uncertainties in climate science in order to stimulate debate and deliberation. WIREs Clim Change 2015, 6:613–626. doi: 10.1002/wcc.366This article is categorized under:Perceptions, Behavior, and Communication of Climate Change &gt; Communication\n",
      "  - Appreciable advances have been made in recent years in raising climate change awareness and enhancing support for climate and energy policies. There also has been considerable progress in understanding of how to effectively communicate climate change. This progress raises questions about the future directions of communication research and practice. What more is there to say? Through a selective literature review, focused on contributions since a similar stock‐taking exercise in 2010,1 the article delineates significant advances, emerging trends and topics, and tries to chart critical needs and opportunities going forward. It describes the climate communication landscape midway through the second decade of the 21st century to contextualize the challenges faced by climate change communication as a scientific field. Despite the important progress made on key scientific challenges laid out in 2010, persistent challenges remain (superficial public understanding of climate change, transitioning from awareness and concern to action, communicating in deeply politicized and polarized environments, and dealing with the growing sense of overwhelm and hopelessness). In addition, new challenges and topics have emerged that communication researchers and practitioners now face. The study reflects on the crucial need to improve the interaction between climate communication research and practice, and calls for dedicated science‐practice boundary work focused on climate change communication. A set of new charges to climate communicators and researchers are offered in hopes to move climate change communication to a new place—at once more humble yet also more ambitious than ever before, befitting to the crucial role it could play in the cultural work humanity faces with climate change. WIREs Clim Change 2016, 7:345–369. doi: 10.1002/wcc.403This article is categorized under:Perceptions, Behavior, and Communication of Climate Change &gt; Communication\n",
      "--------------------------------------------------\n",
      "Topic 273: 273_extremes_extreme_ecoregions_cdhe events\n",
      "Representative Documents:\n",
      "  - Two tropical cyclones (TCs) that make landfall close together can induce sequential hazards to coastal areas. Here we investigate the change in sequential TC hazards in the historical and future projected climates. We find that the chance of sequential TC hazards has been increasing over the past several decades at many US locations. Under the high (moderate) emission scenario, the chance of hazards from two TCs impacting the same location within 15 days may substantially increase, with the return period decreasing over the century from 10–92 years to ~1–2 (1–3) years along the US East and Gulf coasts, due to sea-level rise and storm climatology change. Climate change can also cause unprecedented compounding of extreme hazards at the regional level. A Katrina-like TC and a Harvey-like TC impacting the United States within 15 days of each other, which is non-existent in the control simulation for over 1,000 years, is projected to have an annual occurrence probability of more than 1% by the end of the century under the high emission scenario.\n",
      "  - Climate change and global urbanization have often been anticipated to increase future population exposure (frequency and intensity) to extreme weather over the coming decades. Here we examine how changes in urban land extent, population, and climate will respectively and collectively affect spatial patterns of future population exposures to climate extremes (including hot days, cold days, heavy rainfalls, and severe thunderstorm environments) across the continental U.S. at the end of the 21st century. Different from common impressions, we find that urban land patterns can sometimes reduce rather than increase population exposures to climate extremes, even heat extremes, and that spatial patterns instead of total quantities of urban land are more influential to population exposures. Our findings lead to preliminary suggestions for embedding long-term climate resilience in urban and regional land-use system designs, and strongly motivate searches for optimal spatial urban land patterns that can robustly moderate population exposures to climate extremes throughout the 21st century.\n",
      "  -             The current rate of warming due to increases in greenhouse gas (GHG) emissions is very likely unprecedented over the last 10,000 y. Although the majority of countries have adopted the view that global warming must be limited to &lt;2 °C, current GHG emission rates and nonagreement at Copenhagen in December 2009 increase the likelihood of this limit being exceeded by 2100. Extensive evidence has linked major changes in biological systems to 20th century warming. The “Global 200” comprises 238 ecoregions of exceptional biodiversity [Olson DM, Dinerstein E (2002)            Ann Mo Bot Gard            89:199–224]. We assess the likelihood that, by 2070, these iconic ecoregions will regularly experience monthly climatic conditions that were extreme in 1961–1990. Using &gt;600 realizations from climate model ensembles, we show that up to 86% of terrestrial and 83% of freshwater ecoregions will be exposed to average monthly temperature patterns &gt;2 SDs (2σ) of the 1961–1990 baseline, including 82% of critically endangered ecoregions. The entire range of 89 ecoregions will experience extreme monthly temperatures with a local warming of &lt;2 °C. Tropical and subtropical ecoregions, and mangroves, face extreme conditions earliest, some with &lt;1 °C warming. In contrast, few ecoregions within Boreal Forests and Tundra biomes will experience such extremes this century. On average, precipitation regimes do not exceed 2σ of the baseline period, although considerable variability exists across the climate realizations. Further, the strength of the correlation between seasonal temperature and precipitation changes over numerous ecoregions. These results suggest many Global 200 ecoregions may be under substantial climatic stress by 2100.          \n",
      "--------------------------------------------------\n",
      "Topic 274: 274_correction 10_correction 10 1038_10 1038_1038\n",
      "Representative Documents:\n",
      "  - A Correction to this paper has been published: https://doi.org/10.1038/s41467-021-22025-2\n",
      "  - A Correction to this paper has been published: https://doi.org/10.1038/s41467-021-22237-6\n",
      "  - A Correction to this paper has been published: https://doi.org/10.1038/s41467-021-21827-8\n",
      "--------------------------------------------------\n",
      "Topic 275: 275_sea_coupled_rom_regional\n",
      "Representative Documents:\n",
      "  -                Based on observational and modeling analyses, this study aims to assess the potential influence of land surface conditions (soil moisture, in particular) on the Australian surface temperature variations. At first, a simple linear regression method is used to largely remove the ENSO influence from 50-yr observational surface temperature and precipitation datasets. Then, lag and partial correlations of the residuals are analyzed. The impacts of precipitation on the forthcoming surface temperature variations are largely attributed to the soil storage of precipitation water and the slow-varying soil moisture process. Results from partial correlations between precipitation and temperature variations suggest that when responding to anomalous atmospheric forcing, the land surface can introduce some slow-varying processes that can in turn affect the mean state of the atmosphere at monthly or longer scales and increase the predictability of the climate system.               Following the observational analysis, results from 16 Atmospheric Model Intercomparison Project Phase 2 (AMIP2) AGCM simulations are analyzed to assess whether land surface modeling can affect the model-simulated climate variability. Lag-correlation analysis reveals that “climatic memory” of soil moisture has different features in the 16 models. Models with simple bucket-type schemes tend to have a rapid decay rate in the retention of soil moisture anomalies and show rapid feedback between land surface and the overlying atmosphere, with a much weaker influence of soil moisture conditions on surface climate variations. In contrast, most models using nonbucket schemes in which more physical processes are introduced in simulating soil water evaporation and soil water movement tend to show slow-varying soil moisture processes, affecting the model integrations at longer time scales. Different characteristics for translating soil moisture memory into climate variability and predictability are seen across the models, and more detailed studies are needed to further explore how land surface processes affect climate variability and predictability.\n",
      "  - . We analyze extreme sea levels (ESLs) and related uncertainty in an ensemble of regional climate change scenarios for the Baltic Sea.The ERA-40 reanalysis and five Coupled Model Intercomparison Project phase 5 (CMIP5) global general circulation models (GCMs) have been dynamically downscaled with the coupled atmosphere–ice–ocean model RCA4-NEMO (Rossby Centre regional atmospheric model version 4 – Nucleus for European Modelling of the Ocean).The 100-year return levels along the Swedish coast in the ERA-40 hindcast are within the 95 % confidence limits of the observational estimates, except those on the west coast. The ensemble mean of the 100-year return levels averaged over the five GCMs shows biases of less than 10 cm.A series of sensitivity studies explores how the choice of different parameterizations, open boundary conditions and atmospheric forcing affects the estimates of 100-year return levels. A small ensemble of different regional climate models (RCMs) forced with ERA-40 shows the highest uncertainty in ESLs in the southwestern Baltic Sea and in the northeastern part of the Bothnian Bay. Some regions like the Skagerrak, Gulf of Finland and Gulf of Riga are sensitive to the choice of the RCM. A second ensemble of one RCM forced with different GCMs uncovers a lower sensitivity of ESLs against the variance introduced by different GCMs. The uncertainty in the estimates of 100-year return levels introduced by GCMs ranges from 20 to 40 cm at different stations and includes the estimates based on observations. It is of similar size to the 95 % confidence limits of 100-year return levels from tide gauge records.                    \n",
      "  - The majority of regional climate change assessments for the Euro-CORDEX region is based on high resolution atmosphere models. These models use prescribed lower boundary conditions, such as sea surface temperatures (SST) from global ocean General Circulation Models (GCMs), that do not respond to changes simulated by the regional atmosphere model, thus lacking an important feedback to the atmosphere. However, research during the past decade indicated that the use of coupled atmosphere–ocean models can lead to significantly altered model solutions compared to standalone atmosphere models for the present day climate imposing some uncertainty on the widely used uncoupled future scenarios. We here present the first multi-model and multi scenario (RCP2.6, RCP4.5, RCP8.5) ensemble of future climate change scenarios downscaled with a coupled atmosphere—ocean model in which sea surface temperature and sea ice fields are explicitly simulated by a coupled state-of-the-art high resolution ocean model and communicated to the atmosphere at 3-hourly time steps. Our ensemble generally confirms results of previous uncoupled ensembles over land areas implying that the coupling effect is restricted mainly to the coupled area and the adjacent coastal zone. By contrast, over the North Sea and Baltic Sea small scale processes point to important coupling effects that mediate the response to climate change and that can not be simulated by uncoupled models. Our results therefore impose general uncertainty on the usage of regional climate change data from uncoupled ensembles over marine areas such as for purposes of offshore wind or mussel farming, the planing of marine protected areas, and marine recreation along the coastal zone. It further sets in question the usage of uncoupled scenario data (such as Euro-CORDEX) to force high resolution ocean models. Comparing coupled and uncoupled hindcast simulations reveals that the coupling effect over land is most pronounced during the warm season when prescribed and modelled sea surface temperatures (SST) differ strongest. In addition, a generally weaker wind regime in summer damps the heat dispersion in the atmosphere so that air temperature anomalies can extent further over land compared to winter. Future projections are discussed under consideration of land-sea warming characteristics for selected climate indices as well as mean seasonal climate change. At the end of the century a clear land-sea pattern is seen in all scenarios with stronger warming over land than over open sea areas. On average land areas warm at a rate 1.5 times faster than areas over the open ocean. Over the coupled area, i.e. the North Sea and Baltic Sea tropical nights are impacted strongest and the Baltic Sea turns out to be a hot spot in future climate. This has been unrecognized in previous studies using high resolution atmosphere models with prescribed SSTs from global models which do not represent small scale ocean processes in the Baltic Sea adequately.\n",
      "--------------------------------------------------\n",
      "Topic 276: 276_stomatal_arabidopsis_stomatal opening_co2\n",
      "Representative Documents:\n",
      "  -                Light-induced stomatal opening stimulates CO2 uptake and transpiration in plants. Weak blue light under strong red light effectively induces stomatal opening. Blue light-dependent stomatal opening initiates light perception by phototropins, and the signal is transmitted to a plasma membrane H+-ATPase in guard cells via BLUE LIGHT SIGNALING 1 (BLUS1) kinase. However, it is unclear how BLUS1 transmits the signal to H+-ATPase. Here, we characterized BLUS1 signaling in Arabidopsis thaliana, and showed that the BLUS1 C-terminus acts as an auto-inhibitory domain and that phototropin-mediated Ser-348 phosphorylation within the domain removes auto-inhibition. C-Terminal truncation and phospho-mimic Ser-348 mutation caused H+-ATPase activation in the dark, but did not elicit stomatal opening. Unexpectedly, the plants exhibited stomatal opening under strong red light and stomatal closure under weak blue light. A decrease in intercellular CO2 concentration via red light-driven photosynthesis together with H+-ATPase activation caused stomatal opening. Furthermore, phototropins caused H+-ATPase dephosphorylation in guard cells expressing constitutive signaling variants of BLUS1 in response to blue light, possibly for fine-tuning stomatal opening. Overall, our findings provide mechanistic insights into the blue light regulation of stomatal opening.\n",
      "  - Rapid stomatal closure induced by changes in the environment, such as elevation of CO2, reduction of air humidity, darkness, and pulses of the air pollutant ozone (O3), involves the SLOW ANION CHANNEL1 (SLAC1). SLAC1 is activated by OPEN STOMATA1 (OST1) and Ca2+-dependent protein kinases. OST1 activation is controlled through abscisic acid (ABA)-induced inhibition of type 2 protein phosphatases (PP2C) by PYRABACTIN RESISTANCE/REGULATORY COMPONENTS OF ABA RECEPTOR (PYR/RCAR) receptor proteins. To address the role of signaling through PYR/RCARs for whole-plant steady-state stomatal conductance and stomatal closure induced by environmental factors, we used a set of Arabidopsis (Arabidopsis thaliana) mutants defective in ABA metabolism/signaling. The stomatal conductance values varied severalfold among the studied mutants, indicating that basal ABA signaling through PYR/RCAR receptors plays a fundamental role in controlling whole-plant water loss through stomata. PYR/RCAR-dependent inhibition of PP2Cs was clearly required for rapid stomatal regulation in response to darkness, reduced air humidity, and O3. Furthermore, PYR/RCAR proteins seem to function in a dose-dependent manner, and there is a functional diversity among them. Although a rapid stomatal response to elevated CO2 was evident in all but slac1 and ost1 mutants, the bicarbonate-induced activation of S-type anion channels was reduced in the dominant active PP2C mutants abi1-1 and abi2-1. Further experiments with a wider range of CO2 concentrations and analyses of stomatal response kinetics suggested that the ABA signalosome partially affects the CO2-induced stomatal response. Thus, we show that PYR/RCAR receptors play an important role for the whole-plant stomatal adjustments and responses to low humidity, darkness, and O3 and are involved in responses to elevated CO2.\n",
      "  - Changes in the stomatal aperture in response to CO2 levels allow plants to manage water usage, optimize CO2 uptake and adjust to environmental stimuli. The current study reports that sub-ambient CO2 up-regulated the low temperature induction of the C-repeat Binding Factor (CBF)-dependent cold signaling pathway in Arabidopsis (Arabidopsis thaliana) and the opposite occurred in response to supra-ambient CO2. Accordingly, cold induction of various downstream cold-responsive genes was modified by CO2 treatments and expression changes were either partially or fully CBF-dependent. Changes in electrolyte leakage during freezing tests were correlated with CO2′s effects on CBF expression. Cold treatments were also performed on Arabidopsis mutants with altered stomatal responses to CO2, i.e., high leaf temperature 1-2 (ht1-2, CO2 hypersensitive) and β-carbonic anhydrase 1 and 4 (ca1ca4, CO2 insensitive). The cold-induced expression of CBF and downstream CBF target genes plus freezing tolerance of ht1-2 was consistently less than that for Col-0, suggesting that HT1 is a positive modulator of cold signaling. The ca1ca4 mutant had diminished CBF expression during cold treatment but the downstream expression of cold-responsive genes was either similar to or greater than that of Col-0. This finding suggested that βCA1/4 modulates the expression of certain cold-responsive genes in a CBF-independent manner. Stomatal conductance measurements demonstrated that low temperatures overrode low CO2-induced stomatal opening and this process was delayed in the cold tolerant mutant, ca1ca4, compared to the cold sensitive mutant, ht1-2. The similar stomatal responses were evident from freezing tolerant line, Ox-CBF, overexpression of CBF3, compared to wild-type ecotype Ws-2. Together, these results indicate that CO2 signaling in stomata and CBF-mediated cold signaling work coordinately in Arabidopsis to manage abiotic stress.\n",
      "--------------------------------------------------\n",
      "Topic 277: 277_disease_ceranae_infection_pear\n",
      "Representative Documents:\n",
      "  - This study was conducted to analyze the effect of genotype and climate on the resistance of honey bee (Apis mellifera) colonies to parasitic and viral diseases. The prevalence and intensity of parasitism by Varroa destructor, or infection by Nosema spp., and four honey bee viruses were determined in 365 colonies of predominantly European or African ancestry (descendants of A. m. scutellata) in subtropical and temperate regions of Mexico. Varroa destructor was the most prevalent parasite (95%), whilst N. ceranae was the least prevalent parasite (15%). Deformed wing virus (DWV) and black queen cell virus (BQCV) were the only viruses detected, at frequencies of 38% and 66%, respectively. Varroa destructor was significantly more prevalent in colonies of European ancestry (p &lt; 0.05), and the intensity of parasitism by V. destructor or infection by DWV and BQCV was also significantly higher in colonies of European descent than in African descent colonies (p &lt; 0.01), although no genotype–parasite associations were found for N. ceranae. Additionally, significant and positive correlations were found between V. destructor and DWV levels, and the abundance of these pathogens was negatively correlated with the African ancestry of colonies (p &lt; 0.01). However, there were no significant effects of environment on parasitism or infection intensity for the colonies of both genotypes. Therefore, it is concluded that the genotype of honey bee colonies, but not climate, influences their resistance to DWV, BQCV, and V. destructor.\n",
      "  - ABSTRACT                      Nosema ceranae            and            Nosema apis            are two fungal pathogens belonging to the phylum Microsporidia and infecting the European honeybee,            Apis mellifera            . Recent studies have suggested that            N. ceranae            is more virulent than            N. apis            both at the individual insect level and at the colony level. Severe colony losses could be attributed to            N. ceranae            infections, and an unusual form of nosemosis is caused by this pathogen. In the present study, data from a 5-year cohort study of the prevalence of            Nosema            spp. in Germany, involving about 220 honeybee colonies and a total of 1,997 samples collected from these colonies each spring and autumn and analyzed via species-specific PCR-restriction fragment length polymorphism (RFLP), are described. Statistical analysis of the data revealed no relation between colony mortality and detectable levels of infection with            N. ceranae            or            N. apis            . In addition,            N. apis            is still more prevalent than            N. ceranae            in the cohort of the German bee population that was analyzed. A possible explanation for these findings could be the marked decrease in spore germination that was observed after even a short exposure to low temperatures (+4°C) for            N. ceranae            only. Reduced or inhibited            N. ceranae            spore germination at low temperatures should hamper the infectivity and spread of this pathogen in climatic regions characterized by a rather cold winter season.          \n",
      "  -  Brown spot of pear, caused by the fungus Stemphylium vesicarium, is an emerging disease of economic importance in several pear-growing areas in Europe. In recent years, new control strategies combining sanitation practices and fungicide applications according to developed forecasting models have been introduced to manage the disease. However, the pathogenic and saprophytic behavior of this pathogen makes it difficult to manage the disease. In addition, climate change can also result in variations in the severity and geographical distribution of the disease. In this study, ecological and epidemiological aspects of brown spot of pear disease related to inoculum characterization and climate change impact were elucidated. The pathogenic variation in S. vesicarium populations from pear orchards and its relationship to inoculum sources (air samples, leaf debris, and infected host and nonhost tissues) was determined using multivariate analysis. In total, six variables related to infection and disease development on cultivar Conference pear detached leaves of 110 S. vesicarium isolates were analyzed. A high proportion of isolates (42%) were nonpathogenic to pear; 85% of these nonpathogenic isolates were recovered from air samples. Most isolates recovered from lesions (93%) and pseudothecia (83%) were pathogenic to pear. A group of pathogenic isolates rapidly infected cultivar Conference pear leaves resulted in disease increase that followed a monomolecular model, whereas some S. vesicarium isolates required a period of time after inoculation to initiate infection and resulted in disease increase that followed a logistic model. The latter group was mainly composed of isolates recovered from pseudothecia on leaf debris, whereas the former group was mainly composed of isolates recovered from lesions on pear fruit and leaves. The relationship between the source of inoculum and pathogenic/aggressiveness profile was confirmed by principal component analysis. The effect of climate change on disease risk was analyzed in two pear-growing areas of Spain under two scenarios (A2 and B1) and for three periods (2005 to 2009, 2041 to 2060, and 2081 to 2100). Simulations showed that the level of risk predicted by BSPcast model increased to high or very high under the two scenarios and was differentially distributed in the two regions. This study is an example of how epidemiological models can be used to predict not only the onset of infections but also how climate change could affect brown spot of pear.  [Formula: see text] Copyright © 2018 The Author(s). This is an open-access article distributed under the CC BY-NC-ND 4.0 International license . \n",
      "--------------------------------------------------\n",
      "Topic 278: 278_reconstructions_proxy_simulations_proxy data\n",
      "Representative Documents:\n",
      "  - Systematic comparisons of proxy-based reconstructions and climate model simulations of past millennium temperature variability offer insights into climate sensitivity and feedback mechanisms, besides allowing model evaluation independently from the period covered by instrumental data. Such simulation–reconstruction comparisons can help to distinguish more skillful models from less skillful ones, which may subsequently help to develop more reliable future projections. This study evaluates the low-frequency simulation–reconstruction agreement within the past millennium through assessing the amplitude of temperature change between the Medieval Climate Anomaly (here, 950–1250 CE) and the Little Ice Age (here, 1450–1850 CE) in PMIP3 model simulations compared to proxy-based local and continental-scale reconstructions. The simulations consistently show a smaller temperature change than the reconstructions for most regions in the Northern Hemisphere, but not in the Southern Hemisphere, as well as a partly different spatial pattern. A cost function analysis assesses how well the various simulations agree with reconstructions. Disregarding spatial correlation, significant differences are seen in the agreement with the local temperature reconstructions between groups of models, but insignificant differences are noted when compared to continental-scale reconstructions. This result points toward a limited possibility to “rank” models by means of their low-frequency temperature variability alone. The systematically lower amplitude of simulated versus reconstructed temperature change indicates either too-small simulated internal variability or that the analyzed models lack some critical forcing or have missing or too-weak feedback mechanisms. We hypothesize that too-cold initial ocean conditions in the models—in combination with too-weak internal variability and slow feedbacks over longer time scales—could account for much of the simulation–reconstruction disagreement.\n",
      "  - . We undertake a study in two parts, where the overall aim is to quantitatively compare results from climate proxy data with results from several climate model simulations from the Paleoclimate Modelling Intercomparison Project for the mid-Holocene period and the pre-industrial, conditions for the pan-arctic region, north of 60° N. In this first paper, we survey the available published local temperature and precipitation proxy records. We also discuss and quantifiy some uncertainties in the estimated difference in climate between the two periods as recorded in the available data. The spatial distribution of available published local proxies has a marked geographical bias towards land areas surrounding the North Atlantic sector, especially Fennoscandia. The majority of the reconstructions are terrestrial, and there is a large over-representation towards summer temperature records. The available reconstructions indicate that the northern high latitudes were warmer in both summer, winter and the in annual mean temperature at the mid-Holocene (6000 BP ± 500 yrs) compared to the pre-industrial period (1500 AD ± 500 yrs). For usage in the model-data comparisons (in Part 1), we estimate the calibration uncertainty and also the internal variability in the proxy records, to derive a combined minimum uncertainty in the reconstructed temperature change between the two periods. Often, the calibration uncertainty alone, at a certain site, exceeds the actual reconstructed climate change at the site level. In high-density regions, however, neighbouring records can be merged into a composite record to increase the signal-to-noise ratio. The challenge of producing reliable inferred climate reconstructions for the Holocene cannot be underestimated, considering the fact that the estimated temperature and precipitation fluctuations during this period are in magnitude similar to, or lower than, the uncertainties the reconstructions. We advocate a more widespread practice of archiving proxy records as most of the potentially available reconstructions are not published in digital form.                    \n",
      "  - . We compare the ocean temperature evolution of the Holocene as simulated by climate models and reconstructed from marine temperature proxies. We use transient simulations from a coupled atmosphere–ocean general circulation model, as well as an ensemble of time slice simulations from the Paleoclimate Modelling Intercomparison Project. The general pattern of sea surface temperature (SST) in the models shows a high-latitude cooling and a low-latitude warming. The proxy dataset comprises a global compilation of marine alkenone- and Mg/Ca-derived SST estimates. Independently of the choice of the climate model, we observe significant mismatches between modelled and estimated SST amplitudes in the trends for the last 6000 yr. Alkenone-based SST records show a similar pattern as the simulated annual mean SSTs, but the simulated SST trends underestimate the alkenone-based SST trends by a factor of two to five. For Mg/Ca, no significant relationship between model simulations and proxy reconstructions can be detected. We test if such discrepancies can be caused by too simplistic interpretations of the proxy data. We explore whether consideration of different growing seasons and depth habitats of the planktonic organisms used for temperature reconstruction could lead to a better agreement of model results with proxy data on a regional scale. The extent to which temporal shifts in growing season or vertical shifts in depth habitat can reduce model–data misfits is determined. We find that invoking shifts in the living season and habitat depth can remove some of the model–data discrepancies in SST trends. Regardless whether such adjustments in the environmental parameters during the Holocene are realistic, they indicate that when modelled temperature trends are set up to allow drastic shifts in the ecological behaviour of planktonic organisms, they do not capture the full range of reconstructed SST trends. Results indicate that modelled and reconstructed temperature trends are to a large degree only qualitatively comparable, thus providing a challenge for the interpretation of proxy data as well as the model sensitivity to orbital forcing.\n",
      "--------------------------------------------------\n",
      "Topic 279: 279_intention_intentions_behavioral_attitude\n",
      "Representative Documents:\n",
      "  - This study sought to elucidate the antecedents that may influence the effect of people's purchase behavior on the Earth's sustainable development. It included people's perceived moral obligation and sustainability self‐identity in the theory of planned behavior (TPB) model to investigate attitudes among the Taiwanese public's attitude toward purchasing sustainability‐labeled coffee and their purchase intentions. The moderating effect of climate change skepticism is also considered in this study. A total of 745 nationwide and self‐reported questionnaire valid data was collected in Taiwan. Hierarchical and moderated regression analysis results indicated that the components of the TPB model had positive influences on the public's purchase intention. The public's perceived moral obligation and sustainability self‐identity, proposed for inclusion in the TPB model, had significant and positive influences on purchase intention. The extended TPB model has higher explanatory power than that of the original model. The positive relationship between sustainability self‐identity and intention to purchase sustainability‐labeled coffee was moderated by climate change skepticism. This study provides marketers and the players in the supply chain with a comprehensive framework for understanding the influence of perceived moral obligation and sustainability self‐identity on purchase intention toward sustainability‐labeled products. In addition, this study responds to a call for a more thorough investigation of the effect of people's skepticism about climate change in the context of ethical and sustainable consumption decision‐making processes.\n",
      "  - Understanding the perceptions of young people is a critical issue in the formulation and implementation of climate change mitigation strategies. Based on cognitive hierarchy theory, the present study aims to investigate the factors that motivate or hinder young people’s perception of forestation as a strategy to mitigate climate change in post-conflict Somalia. This study hypothesized a model in which climate change knowledge, risk perception and forest value orientations (anthropocentric/biocentric) influence attitude toward forestation and attitude, in turn, predicts behavioral intentions. We randomly surveyed students from three universities in three different regions of Somalia and collected 434 structured survey questionnaires. Using structural equation modeling, the results showed that climate change knowledge is a significant predictor of behavioral intention but not attitude toward forestation. The results also revealed that young people’s perception toward forestation as a strategy to mitigate climate change is significantly influenced by biocentric value orientation both directly and indirectly through attitude toward forestation. Contrary to previous studies, our results indicate that attitude partially mediates the relationship between biocentric value orientation and behavioral intentions and fully mediates the relationship between anthropocentric value orientation, risk perception and behavioral intentions, while it did not show any mediation results between climate change knowledge and behavioral intention. We found that the young people’s climate action or inaction is mainly shaped by climate change knowledge, biocentric value orientation, and attitude toward forestation. Finally, climate change mitigation efforts should avoid relying solely on attitude for behavioral decision-making formation and instead incorporate other factors into a more comprehensive framework.\n",
      "  - The purpose of this study is to develop a better understanding of what makes consumers reduce waste in order to address climate change, particularly when dining out. To accomplish this goal, this research constructs an extended theory of planned behavior model, using four main constructs of attitude, subjective norm, perceived behavioral control, and behavioral intention and incorporating climate change awareness and mitigation pursuing actions, anticipated pride and guilt, and high and low levels of dining expenses. An online survey was conducted of 482 respondents aged 20 years old or over who had dined in restaurants in the previous month in 2019. A partial least squares-structural (PLS) equation modeling analysis has been utilized with multi-group analysis. Results reveal that climate change awareness has significant effects on attitude and behavior intention, and climate change mitigation pursuing actions positively influence attitude and behavioral intention to reduce waste. Consumers’ anticipated emotions lead to their behavioral intention. Diners’ behavioral intention to reduce waste is significantly influenced by their attitude, subjective norms, and perceived behavioral control on waste reduction in restaurants. The levels of dining expenses significantly moderate seven out of nine hypotheses. Research on consumers’ waste reduction in relation to climate change is not sufficiently conducted in the foodservice sector. Using an extended theory of planned behavior (TPB) to understand diner behavior related to waste reduction and climate change, this study therefore makes an important contribution to improving sustainability in foodservices, especially in the Asian context.\n",
      "--------------------------------------------------\n",
      "Topic 280: 280_resilience_urban_risk_cities\n",
      "Representative Documents:\n",
      "  - The impact of climate change in recent years has caused considerable risks to both urban and rural systems. How to mitigate the damage caused by extreme weather events has attracted much attention from countries in recent years. However, most of the previous studies on resilience focused on either urban areas or rural areas, and failed to clearly identify the difference between urban and rural resilience. In fact, the exploration of the difference between the resilience characteristics of cities and villages under climate change can help to improve the planning strategy and the allocation of resources. In this study, the indicators of resilience were firstly built through a literature review, and then a Principal Component Analysis was conducted to construct an evaluation system involving indicators such as “greenland resilience”, “community age structure resilience”, “traditional knowledge resilience”, “infrastructure resilience” and “residents economic independence resilience”. Then the analysis of Local Indicators of Spatial Association showed some resilience abilities are concentrated in either urban or rural. Binary logistic regression was performed, and the results showed urban areas have more prominent abilities in infrastructure resilience (the coefficient value is 1.339), community age structure resilience (0.694), and greenland resilience (0.3), while rural areas are more prominent in terms of the residents economic independence resilience (−0.398) and traditional knowledge resilience (−0.422). It can be seen that urban areas rely more on the resilience of the socio-economic structure, while rural areas are more dependent on their own knowledge and economic independence. This result can be used as a reference for developing strategies to improve urban and rural resilience.\n",
      "  - Facing climate risks has become a common problem for mankind and a topic of great importance for the Chinese government. To thoroughly implement the overall requirements for the construction of an ecological civilization and effectively improve the capacity of cities to adapt to climate change, China launched the pilot construction of “Climate Resilient Cities” in 2017. In this paper, 16 prefecture level cities in Anhui Province of China were selected as the research objects, and the multi-level grey system evaluation method was used to measure the climate resilience of these regions. We used the difference in differences method to evaluate the effect of the pilot policy of “Climate Resilient Cities.” The pilot policies of the “Climate Resilient Cities” showed a significant contribution to the regional climate resilience, and, after isolating the impact of other factors on the regional climate resilience, the pilot policies of the “Climate Resilient Cities” increased the climate resilience of the pilot cities by four percentage points. The pilot policies of the “Climate Resilient Cities” had a significant contribution to the urban infrastructure development and ecological space optimization, as well as non-significant impacts to the urban water security, emergency management capacity-building, and science and technology innovation initiatives.\n",
      "  -  In recent years, the issue of what kinds of policies and practices cities should adopt to strengthen their resilience and climate adaptability has aroused remarkable interest among researchers in urban and environmental studies at home and abroad. The Chinese government has conducted a series of pilot programs in building climate-adaptive cities. A sound description and evaluation of the climate adaptability of a city, regardless of the size, provides the basis for adaptation planning and decision-making. Taking Beijing as an example, the authors analyze the adaptability of its subordinate 16 districts during the 2010–2014 period by establishing an indicator system for climate adaptability. The result shows imbalanced development in terms of economic support, level of social development, natural resources, technological support and risk management capacity of the districts in Beijing. The analysis also finds that the general adaptability is consistent with the city’s functional areas, indicating that function orientation of each district exerts potential influence on its development and adaptability. The core urban area boasts prominent advantages in general adaptability as it features a sound development basis. The newly developed area, facing such pressures as weak infrastructure, shortage of natural resource, and increasingly stringent requirements for environmental governance, shows the lowest general adaptability. The municipal government of the climate adaptive city should play its leading role in building the city’s climate resilience. More specifically, this calls for forward-looking adaptation planning that is aimed at improving the resilience and general adaptability of the city by facilitating coordinated development of different districts, and strengthening the functional complementarity and coordination between the city’s central and peripheral areas. \n",
      "--------------------------------------------------\n",
      "Topic 281: 281_ha_mg ha_soil_carbon\n",
      "Representative Documents:\n",
      "  - In the current era of global warming, the Himalayan forests are under tremendous pressure due to intensified anthropogenic activity, resulting in the loss of forest diversity. However, the potential of carbon (C) sinks for increasing carbon storage and/or sequestration is still uncertain. Therefore, the present study was undertaken to examine the C‐sequestration and mitigation potential of eight different tree plantations, namely: Pinus roxburghii, Quercus leucotrichophora, Acacia mollissima, Acacia catechu, Alnus nitida, Albizia procera, Ulmus villosa, and Eucalyptus tereticornis in the mid‐hills of the Indian Himalayas. The soil samples used in our study  (humus, 0–20cm, 20–40cm, and 40–100 cm) were used to determine the soil and ecosystem C‐density. The analysis revealed that the maximum tree biomass (300.19 Mg ha−1), vegetation biomass (305.43 Mg ha−1), vegetation carbon (153.59 Mg ha−1), and total ecosystem C density (369.93 Mg ha−1) occurred under U. villosa plantation. Similarly, P. roxburghii plantations had the maximum detritus C‐density (7.25 Mg ha−1), whereas A. nitida (224.71 Mg ha−1) had the maximum soil C‐density. The highest C‐sequestration was recorded under U. villosa (183.0 Mg ha−1). A significantly higher and lower rate of C‐sequestration and CO2 mitigation was observed in Ulmus villosa (5.9 and 21.64 Mg ha−1 yr−1) and Eucalyptus tereticornis (3.9 and 14.3 Mg ha−1 yr−1). Our study found that indigenous tree species such as U. villosa, A. procera, A. nitida, and Q. leucotrichophora should be encouraged for afforestation on degraded lands to support climate change mitigation strategies in the sub‐temperate forest ecosystem.\n",
      "  - It is essential to assess the soil organic carbon pool (SOCP) in dry environments to apply appropriate management techniques that address sustainable development. A significant opportunity for sustaining agricultural output and reducing climate change is the storage of soil organic carbon in agricultural soil. The goal of this study was to measure the spatial variability of SOCP content, and determine the effects of soil texture, changes in land use, and land cover on SOCP in surface soil samples. The study additionally investigated the relationships between SOCP and other characteristics, including the normalized vegetation index (NDVI) and land surface temperature (LST), as well as the effects of increasing soil organic carbon on the amount of greenhouse gases. To accomplish this goal, 45 soil surface samples were collected to a depth of 30 cm at the Fayoum depression in Egypt, and analyzed. The soil samples were representative of various soil textures and land uses. The average SOCP concentration in cultivated regions is 32.1 and in bare soils it is 6.5 Mg ha−1, with areas of 157,112.94 and 16,073.27 ha, respectively. According to variances in soil textures, sandy soils have the lowest SOCP (1.8 Mg ha−1) and clay loam soils have the highest concentrations (49 Mg ha−1). Additionally, fruit-growing regions have the greatest SOCP values and may therefore be better suited for carbon sequestration. The overall average SOCP showed 32.12 Mg C ha−1 for cultivated areas. A rise in arable land was accompanied by a 112,870.09 Mg C rise in SOCP. With an increase in soil organic carbon, stored carbon dioxide emissions (greenhouse gases) would be reduced by 414,233.24 Mg CO2. We should consider improving fertilization, irrigation methods, the use of the multiple cropping index, decreasing desertion rates, appropriate crop rotation, and crop variety selection. The research highlights the significance of expanding cultivated areas towards sustainable carbon sequestration and the climate-change-mitigation potential.\n",
      "  - Private forests offer diverse ecosystem services, including carbon sequestration and biodiversity conservation, which are crucial for Nepal. However, there is a notable absence of comprehensive research on these services. Assessing carbon sequestration in private forests can have economic advantages for forest owners by promoting resource conservation and contributing to greenhouse gas reduction. This study aims to estimate and compare carbon stocks in private forests located in two distinct physiographic regions of Nepal while also identifying the factors influencing these carbon stocks. The analysis focuses on 16 private forests (with 0.1 to 0.5 hectares) each from Chitwan district (Terai region) and Kavrepalanchok district (Hilly region). Field data collection involved direct measurements of tree and sapling diameter at breast height (DBH), as well as height and class of trees and poles, utilizing a total enumeration method. These collected values were utilized to calculate aboveground biomass (AGTB), aboveground sapling biomass (AGSB), belowground biomass, and carbon stock. Private forests of Terai region were dominated by Shorea borneensis, Tectona grandis, and Dalbergia sissoo, whereas the Hilly region was dominated by Pinus patula, Alnus nepalensis, Schima wallichii, and Quercus leucotrichophora. The aboveground biomass carbon in the Terai region’s private forests was estimated to be 83.53 t·ha−1, while in the Hilly region, it was 37.32 t·ha−1. The belowground biomass carbon in the Terai region’s private forests was found to be 21.72 t·ha−1, compared to 9.70 t·ha−1 in the Hilly region. Consequently, the estimated total carbon stock in the Terai and Hilly regions’ private forests was 105.25 t·ha−1 (386.26 t·ha−1 CO2-eq) and 47.02 t·ha−1 (172.57 t·ha−1 CO2-eq), respectively. Carbon sequestration in the Terai region’s private forests was discovered to be 2.24 times higher than that in the Hilly region. These findings underscore the significant potential of private forests, which can generate economic benefits through carbon trading and leverage mechanisms such as REDD+/CDM to promote sustainable conservation practices.\n",
      "--------------------------------------------------\n",
      "Topic 282: 282_wave coupling_wave_downward wave_downward wave coupling\n",
      "Representative Documents:\n",
      "  -  Downward wave coupling dominates the intraseasonal dynamical coupling between the stratosphere and troposphere in the Southern Hemisphere. The coupling occurs during late winter and spring when the stratospheric basic state forms a well-defined meridional waveguide, which is bounded above by a reflecting surface. This basic-state configuration is favorable for planetary wave reflection and guides the reflected waves back down to the troposphere, where they impact wave structures. In this study decadal changes in downward wave coupling are analyzed using the Modern Era Retrospective-Analysis for Research and Applications (MERRA) dataset.  A cross-spectral correlation analysis, applied to geopotential height fields, and a wave geometry diagnostic, applied to zonal-mean zonal wind and temperature data, are used to understand decadal changes in planetary wave propagation. It is found that downward wave 1 coupling from September to December has increased over the last three decades, owing to significant increases at the beginning and end of this 4-month period. The increased downward wave coupling is caused by both an earlier onset of the vertically bounded meridional waveguide configuration and a persistence of this configuration into December. The latter is associated with the observed delay in vortex breakup. The results point to an additional dynamical mechanism whereby the stratosphere has influenced the tropospheric climate in the Southern Hemisphere. \n",
      "  -                The nature of downward wave coupling between the stratosphere and troposphere in both hemispheres is analyzed using the 40-yr European Centre for Medium-Range Weather Forecasts (ECMWF) Re-Analysis (ERA-40) dataset. Downward wave coupling occurs when planetary waves reflected in the stratosphere impact the troposphere, and it is distinct from zonal-mean coupling, which results from wave dissipation and its subsequent impact on the zonal-mean flow. Cross-spectral correlation analysis and wave geometry diagnostics reveal that downward wave-1 coupling occurs in the presence of both a vertical reflecting surface in the mid-to-upper stratosphere and a high-latitude meridional waveguide in the lower stratosphere. In the Southern Hemisphere, downward wave coupling occurs from September to December, whereas in the Northern Hemisphere it occurs from January to March. A vertical reflecting surface is also present in the stratosphere during early winter in both hemispheres; however, it forms at the poleward edge of the meridional waveguide, which is not confined to high latitudes. The absence of a high-latitude waveguide allows meridional wave propagation into the subtropics and decreases the likelihood of downward wave coupling. The results highlight the importance of distinguishing between wave reflection in general, which requires a vertical reflecting surface, and downward wave coupling between the stratosphere and troposphere, which requires both a vertical reflecting surface and a high-latitude meridional waveguide.               The relative roles of downward wave and zonal-mean coupling in the Southern and Northern Hemispheres are subsequently compared. In the Southern Hemisphere, downward wave-1 coupling dominates, whereas in the Northern Hemisphere downward wave-1 coupling and zonal-mean coupling are found to be equally important from winter to early spring. The results suggest that an accurate representation of the seasonal cycle of the wave geometry is necessary for the proper representation of downward wave coupling between the stratosphere and troposphere.\n",
      "  -                The impact of stratospheric ozone changes on downward wave coupling between the stratosphere and troposphere in the Southern Hemisphere is investigated using a suite of Goddard Earth Observing System chemistry–climate model (GEOS CCM) simulations. Downward wave coupling occurs when planetary waves reflected in the stratosphere impact the troposphere. In reanalysis data, the climatological coupling occurs from September to December when the stratospheric basic state has a well-defined high-latitude meridional waveguide in the lower stratosphere that is bounded above by a reflecting surface, called a bounded wave geometry. Reanalysis data suggests that downward wave coupling during November–December has increased during the last three decades.               The GEOS CCM simulation of the recent past captures the main features of downward wave coupling in the Southern Hemisphere. Consistent with the Modern Era Retrospective-Analysis for Research and Application (MERRA) dataset, wave coupling in the model maximizes during October–November when there is a bounded wave geometry configuration. However, the wave coupling in the model is stronger than in the MERRA dataset, and starts earlier and ends later in the seasonal cycle. The late season bias is caused by a bias in the timing of the stratospheric polar vortex breakup.               Temporal changes in stratospheric ozone associated with past depletion and future recovery significantly impact downward wave coupling in the model. During the period of ozone depletion, the spring bounded wave geometry, which is favorable for downward wave coupling, extends into early summer, due to a delay in the vortex breakup date, and leads to increased downward wave coupling during November–December. During the period of ozone recovery, the stratospheric basic state during November–December shifts from a spring configuration back to a summer configuration, where waves are trapped in the troposphere, and leads to a decrease in downward wave coupling. Model simulations with chlorine fixed at 1960 values and increasing greenhouse gases show no significant changes in downward wave coupling and confirm that the changes in downward wave coupling in the model are caused by ozone changes. The results reveal a new mechanism wherein stratospheric ozone changes can affect the tropospheric circulation.\n",
      "--------------------------------------------------\n",
      "Topic 283: 283_women_farmers_livelihoods_adaptation\n",
      "Representative Documents:\n",
      "  - Climate change is expected to shift seasonality in Tanzania, while smallholder farmers' livelihoods and the economy rely upon the success of rainfed agriculture. However, we should not a priori assume doomsday climate vulnerability scenarios of drought and devastation in the rural global South nor, on the other hand, that farmers will optimally employ local knowledge for effective adaptation. Drawing from qualitative fieldwork in two Tanzanian communities, I question these grand narratives of devastation and local adaptive capacity and introduce an approach that brings inequality to the center. Poorer nations are most vulnerable to climate change, but they are not homogenous and neither are the smallholder farmers living within them. I present evidence on the crucial context-specific dimensions of socio-ecological vulnerability for these smallholder farmers—1) water resources and access to them; 2) agricultural knowledge, including farmers' own knowledge and their interactions with sources like government-run agricultural extension and NGOs; and 3) existing drought-coping strategies—and the heterogeneity among farmers across these dimensions. Ultimately, this case demonstrates how climate change can reproduce existing inequalities within nations by drawing upon how farmers currently respond to drought as evidence. I present the difficult and somewhat bleak contexts within which the farmers are coping, but also illustrate the agency that farmers exhibit in response to these conditions and the adaptive capacity they possess. Finally, I call for more sub-national research on climate and inequality by sociologists and draw connections among within-nation inequality, climate change, and agricultural development initiatives.\n",
      "  - One billion vulnerable subsistence farmers across the global south depend on risky livelihoods in need of adaptation to climate change impacts. Simultaneously, their aggregated emission of greenhouse gases from land use and fuelwood consumption is substantial. Synergies between adaptation to climate change and mitigation should therefore be actively promoted. In the context of poverty, such synergies should ideally be designed specifically for the poorest of the poor who are notoriously difficult to reach by policies and projects. In this experimental case on subsistence farming in western Kenya we assume that only the poorest inhabit the most degraded lands and use the simplest form of cooking over open fire. As the study location is typical of sub‐Saharan areas affected by drought, flooding, land degradation, diseases and persistent poverty, findings can be scaled up, transferred to and tested in similar settings. Seeking multiple synergies of adaptation, mitigation, and social change while using sustainability science in intervention research, we reframed peasant farmers from vulnerable victims into agents fighting livelihood stressors and climate change impacts. In collaboration with them we performed small‐scale experiments on agricultural production practices and domestic energy efficiency resulting in multiple synergies. Findings show that the ‘smokeless kitchen’ and carbon sequestration from improved land management can mitigate climate change while increasing energy efficiency, health standards, food security, and community‐based adaptive capacity. Preferably, climate policy should therefore explicitly address synergies and support peasant farmers' efforts to create synergies when the ‘food imperative’ limits their agency to fight climate change alone. Copyright © 2010 John Wiley &amp; Sons, Ltd.This article is categorized under:Vulnerability and Adaptation to Climate Change &gt; Learning from Cases and AnalogiesClimate and Development &gt; Sustainability and Human Well‐Being\n",
      "  - Climate change loss and damage (L&amp;D) presents an existential threat to the Fiji Islands. This case study examines how rural Indo-Fijian sugarcane farming communities face challenges in minimising, averting, and addressing L&amp;D from cyclones. In-depth semi-structured interviews (n = 68) were conducted with 40 sugarcane farmers in two Indo-Fijian sugarcane communities, Barotu and Toko settlements in Western Viti Levu, Fiji, and with 28 key stakeholders from government ministries, academia, and climate change response services. Despite implementing climate change adaptation measures, Fiji’s sugar industry has faced devastating L&amp;D from frequent and severe cyclones. Much of the climate change L&amp;D to crops, property, and income was irreversible and unavoidable. Non-economic loss and damage (NELD) was found insurmountable in both field sites, including the loss of homes and places of worship, cascading and flow-on effects as well as the heightening of uncertainty, fear, and trauma. Evidence suggests that L&amp;D, including NELD, is highly context specific, and UNFCCC’s broad NELD categories do not fully capture L&amp;D at the local level. The systematic documentation of L&amp;D within vulnerable communities would improve understanding of L&amp;D, including NELD, and assist to facilitate the mobilisation of immediate support and action to address L&amp;D in countries that lack the capacities to respond independently. This paper recommends crucial policy interventions such as livelihood diversification, integration of disaster risk reduction and climate change adaptation, land tenure policy reforms, and the operationalisation of the Santiago Network for Loss and Damage.\n",
      "--------------------------------------------------\n",
      "Topic 284: 284_managers_recreation_adaptation_management\n",
      "Representative Documents:\n",
      "  - Climate change will alter opportunities and demand for outdoor recreation through altered winter weather conditions and season length, climate-driven changes in user preferences, and damage to recreational infrastructure, among other factors. To ensure that outdoor recreation remains sustainable in the face of these challenges, natural resource managers may need to adapt their recreation management. One of the major challenges of adapting recreation to climate change is translating broad concepts into specific, tangible actions. Using a combination of in-depth interviews of recreational managers and a review of peer-reviewed literature and government reports, we developed a synthesis of impacts, strategies, and approaches, and a tiered structure that organizes this information. Six broad climate adaptation strategies and 25 more specific approaches were identified and organized into a “recreation menu”. The recreation menu was tested with two national forests in the US in multi-day workshops designed to integrate these concepts into real-world projects that were at the beginning stages of the planning process. We found that the recreation menu was broad yet specific enough to be applied to recreation-focused projects with different objectives and climate change impacts. These strategies and approaches serve as stepping stones to enable natural resource and recreation managers to translate broad concepts into targeted and prescriptive actions for implementing adaptation.\n",
      "  - Assessing the drought resilience of snow‐fed river dependent communities in the arid  Western United States has taken on critical importance in response to changing climatic conditions.  The process of assessing drought resiliency involves understanding the extent to which snow‐fed  dependent communities can absorb the effects of uncertain and variable water supplies while  acknowledging and encouraging their capacity for adaptation. Participatory research approaches  are particularly well suited to assess resiliency in this context because they rely upon local water  managers’ knowledge and perspectives. The research presented here provides measured insight  into local water managers’ perceptions of drought resiliency in the Truckee‐Carson River System in  northwestern Nevada. These findings are reported in the context of the collaborative modeling  research design developed for this case study. The objectives of this study are: (1) to define  resiliency and present a rationale for a participatory approach to assess drought resiliency in  snow‐fed arid river basins in the Western United States; (2) to outline collaborative modeling as a  participatory research design developed for the Truckee‐Carson River System case study area; (3)  to  describe  the  development and implementation of a resiliency  assessment  undertaken  to  implement this research design; (4) to highlight selected results of the assessment, summarizing  interviews with 66 water managers in the case study area; (5) to discuss the use of assessment  findings to inform collaborative modeling toward adaptation strategies; and (6) to review lessons  learned  to  date  from  the  collaborative  modeling  case  study  and  note  opportunities  for  further  exploration.  According to  water managers  surveyed,  climate  change  is  very  important  and  is  mobilizing  adaptation  strategies that include improvements in communication and coordination with  other water managers,  monitoring and  data collection,and planning. The majority of water managers  indicate  that future adaptation  requires modifying institutionalized water management regimes to  allow  for  temporary  water  leasing  programs,  water right stacking on the  most  productive  agricultural lands while  fallowing  marginal  lands,incentivizing water conservation, reducing or  eliminating  residential  landscaping, and recruiting less water intensive industry to the region.\n",
      "  - Climate change presents a major challenge to natural resource managers both because of the magnitude of potential effects of climate change on ecosystem structure, process, and function, and because of the uncertainty associated with those potential ecological effects. Concrete ways to adapt to climate change are needed to help natural resource managers take the first steps to incorporate climate change into management and take advantage of opportunities to balance the negative effects of climate change. We initiated a climate change adaptation case study at Olympic National Forest and Olympic National Park to determine how to adapt management of federal lands on the Olympic Peninsula to climate change. As a part of the case study process, we conducted a vulnerability assessment that involved a review of available climate model projections to determine likely levels of exposure to climate change on the Olympic Peninsula, and a review of relevant literature and available effects model projections to identify likely climate change sensitivities in each of four focus areas on the Olympic Peninsula, including hydrology and roads, fish, vegetation, and wildlife. We also identified management constraints at the forest and park to evaluate some aspects of institutional capacity to implement adaptive actions. The vulnerability assessment process set the stage for development of adaptation options through scientist-manager workshops.The case study process produced concrete adaptation options for Olympic National Forest and Park and illustrated the utility of place-based vulnerability assessments and scientist-manager workshops in adapting to climate change. A key finding of the assessment was that the current general management at the forest and park, with restoration as a primary goal, is consistent with managing for resilience to prepare ecosystems for a changing climate. However, the effort highlighted some potential issues related to climate change that challenge current precepts and management guidelines, and helped to identify new potential actions, and actions that could be increased and re-prioritized. For example, the case study process identified numerous ways to maintain ecosystem function and biodiversity, and increase resilience to climate change. However, the looming questions of when to consider assisted migration or when and how to redefine exotic species remain for discussion. Although questions remain, the case study process was an essential first step for Olympic National Forest and Olympic National Park in preparing for climate change. The process used and ideas produced can be used to help other natural resource managers in adapting to climate change.\n",
      "--------------------------------------------------\n",
      "Topic 285: 285_maize_production_crops_rainfall\n",
      "Representative Documents:\n",
      "  - Most studies on the responsiveness of maize production to various variables have dwelled on the responsiveness of maize production to variations in precipitation or temperature. This study seeks to verify the response of maize production in Cameroon to both climate trends and land use change. Therefore, for the first time, our study presents findings on the relative influence of both climate and land use change on maize production in Cameroon. The data used in this analysis are essentially time series data spanning the period 1961–2006. The data on quantity of maize produced, area of maize harvested and number of maize seeds planted was taken from (http://faostat.fao.org). The mean maize growing season temperature and precipitation data were collected from the 0.5° × 0.5° gridded collaborative datasets of the UNEP and the School of Geography and Environment at Oxford University and from the global crop calendar dataset. The data were analyzed using the average rate of change, detrended simulations, the multiple linear regression technique, correlation coefficient and the coefficient of determination. The results show that maize production in Cameroon is more likely responsive to land use change (forest area change) than rainfall and temperature. However, for the climatic variables, maize production is more responsive to temperature variations than precipitation. In other words, the greater the land use change (forest area loss) the more likely the long run losses in the current maize production gains while rising temperatures were found to be more suitable for maize production. Even though the 1990s marked the period of recovering rainfall levels in most of the Sahel, large fluctuations were still recorded.\n",
      "  -  This study has examined the effects of climatic factors on mean yields and yield variability of four primary crops (rice, cotton, jowar and groundnut) in Telangana state by applying the Just and Pope production function over a period of 1956–2015. Using the three-stage feasible generalised least squares estimation procedure, we have estimated the production function of four crops. The empirical results have revealed that the effects of changes in climatic factors vary among crops under study. Maximum temperature has a significant adverse effect on rice, cotton and groundnut yields. Minimum temperature has a substantial positive effect on rice, cotton and groundnut. Further, rainfall is adversely related to cotton and groundnut yields. Maximum temperature has appeared as a risk-reducing factor for all study crops while minimum temperature as a risk-enhancing factor for rice, cotton and jowar. Lastly, rainfall has been found as a risk-enhancing factor for rice and groundnut whereas it is a risk-reducing factor for jowar and cotton. Results from the study have important implications on how Telangana’s farming sector will adapt to climate variability and change for sustainable agricultural development.  JEL Codes: C23, Q18, Q51, Q54 \n",
      "  - This study evaluated the impact of climate change on yield and net revenue of beans productionin Nigeria using Feasible Generalised Least Square and Hedonic Ricardian Approach. Secondarydata were used for this study; monthly rainfall and temperature data from 1981 to 2019 wereobtained from Nigeria Meteorological agency while data on socioeconomic and demographiccharacteristics as well as farm production for 2000 beans farmers across the six agro-ecologicalzones were obtained from General household survey wave IV. The study reveals that beans cropis sensitive to infinitesimal change in temperature than rainfall. The marginal impact analysis ofincreasing temperature and rainfall indicated that a unit increase in rainfall decreased the netrevenue of beans by N14,997 per hectare, while a unit increase in temperature increased the netrevenue of the beans production in Nigeria by N15,316 per hectare. The adjusted mean yield ofbeans will increase by 1.058kg per hectare with a unit increase in temperature while it will reduce0.173 per hectare with a unit increase in rainfall. The study also examined the impact of predictedclimate scenarios from two models namely Canadian Climate Change and Parallel Climate Modelon net revenue for the years 2050 and 2100. All these models indicated increasing temperaturewould have a positive impact on the net revenue from beans production for the year 2050 but theimpact will be negative by year 2100. This means there will be more profit from beans productionin year 2050 while in 2100 the beans farmers will produce at loss. Nigeria government shouldtherefore consider designing and implementing adaptation policies to counteract the harmfulimpacts of climate change on beans production.\n",
      "--------------------------------------------------\n",
      "Topic 286: 286_census_counties_heat_extreme heat\n",
      "Representative Documents:\n",
      "  - House‐Peters, Lily, Bethany Pratt, and Heejun Chang, 2010. Effects of Urban Spatial Structure, Sociodemographics, and Climate on Residential Water Consumption in Hillsboro, Oregon. Journal of the American Water Resources Association (JAWRA) 46(3):461‐472. DOI: 10.1111/j.1752‐1688.2009.00415.x:  In the Portland metropolitan area, suburban growth in cities such as Hillsboro is projected to increase as people seek affordable housing near a burgeoning metropolis. The most significant determinants for increases in water demand are population growth, climate change, and the type of urban development that occurs. This study analyzes the spatial patterns of single family residential (SFR) water consumption in Hillsboro, Oregon, at the census block scale. The following research questions are addressed: (1) What are the significant determinants of SFR water consumption in Hillsboro, Oregon? (2) Is SFR water demand sensitive to drought conditions and interannual climate variation? (3) To what magnitude do particular census blocks react to drought conditions and interannual climate variation? Using ordinary least squares multiple regression and spatial regression methods, we found that base use, representing indoor water use, is dependent on household size and that seasonal use, representing external water use is dependent on both education level and the size of the property’s outdoor space. Spatial analysis techniques determined that although the water demand of the study area as a whole is not sensitive to drought conditions, certain individual census blocks do respond with a higher magnitude of water use. The most climate‐sensitive census blocks tend to contain newer and larger homes, and have higher property values and more affluent and well‐educated residents.\n",
      "  -                Extreme heat is the leading weather-related killer in the United States. Vulnerability to extreme heat has previously been identified and mapped in urban areas to improve heat morbidity and mortality prevention efforts. However, only limited work has examined vulnerability outside of urban locations. This study seeks to broaden the geographic context of earlier work and compute heat vulnerability across the state of Georgia, which offers diverse landscapes and populations with varying sociodemographic characteristics. Here, a modified heat vulnerability index (HVI) developed by Reid et al. is used to characterize vulnerability by county. About half of counties with the greatest heat vulnerability index scores contain the larger cities in the state (i.e., Athens, Atlanta, Augusta, Columbus, Macon, and Savannah), while the other half of high-vulnerability counties are located in more rural counties clustered in southwestern and east-central Georgia. The source of vulnerability varied between the more urban and rural high-vulnerability counties, with poverty and population of nonwhite residents driving vulnerability in the more urban counties and social isolation/population of elderly/poor health the dominant factor in the more rural counties. Additionally, the effectiveness of the HVI in identifying vulnerable populations was investigated by examining the effect of modification of the vulnerability index score with mortality during extreme heat. Except for the least vulnerable categories, the relative risk of mortality increases with increasing vulnerability. For the highest-vulnerability counties, oppressively hot days lead to a 7.7% increase in mortality.\n",
      "  - Major wildfires and heatwaves have begun to increase in frequency throughout much of the United States, particularly in western states such as California, causing increased risk to public health. Air pollution is exacerbated by both wildfires and warmer temperatures, thus adding to such risk. With climate change and the continued increase in global average temperatures, the frequency of major wildfires, heat days, and unhealthy air pollution episodes is projected to increase, resulting in the potential for compounding risks. Risks will likely vary by region and may disproportionately impact low-income communities and communities of color. In this study, we processed daily particulate matter (PM) data from over 18,000 low-cost PurpleAir sensors, along with gridMET daily maximum temperature data and government-compiled wildfire perimeter data from 2018–2020 in order to examine the occurrence of compound risk (CR) days (characterized by high temperature and high PM2.5) at the census tract level in California, and to understand how such days have been impacted by the occurrence of wildfires. Using American Community Survey data, we also examined the extent to which CR days were correlated with household income, race/ethnicity, education, and other socioeconomic factors at the census tract level. Results showed census tracts with a higher frequency of CR days to have statistically higher rates of poverty and unemployment, along with high proportions of child residents and households without computers. The frequency of CR days and elevated daily PM2.5 concentrations appeared to be strongly related to the occurrence of nearby wildfires, with over 20% of days with sensor-measured average PM2.5 &gt; 35 μg/m3 showing a wildfire within a 100 km radius and over two-thirds of estimated CR days falling on such days with a nearby wildfire. Findings from this study are important to policymakers and government agencies who preside over the allocation of state resources as well as organizations seeking to empower residents and establish climate resilient communities.\n",
      "--------------------------------------------------\n",
      "Topic 287: 287_bu_bir_iklim_ile\n",
      "Representative Documents:\n",
      "  - Amaç –Bu çalışmanın amacı, çalışanların iş yerlerinde gerçekleştirdikleri çevre dostu davranışlar ile yeşil iş yeri iklimi algıları arasındaki ilişkide algılanan tüketici etkinliğinin düzenleyici rolünün incelenmesidir. Yöntem –Çalışma kapsamında yeşil iş yeriiklimi algısının çevreci davranışlara etkisi ile bu ilişkide algılanan tüketici etkinliğinin düzenleyici rolünü ele alan bir model geliştirilerek, elde edilen veriler doğrultusunda modelin anlamlılığı ve geçerliliği ele alınmıştır. Çalışmada, 23 ildeki 412 kamu ve özel sektör çalışanından çevrim içi anket yöntemi aracılığıyla veri elde edilmiştir.Oluşturulan modelin geçerliliğinin  ölçülmesi  amacıyla  AMOS  programı  aracılığıyla  doğrulayıcı  faktör  analizi gerçekleştirilmiştir. Elde edilen veriler ışığında; yeşil iş yeri iklimi algısının çevreci davranışlara olumlu etkisinin incelenmesinde SPSS programı aracılığıyla basit doğrusal regresyon analizinden, bahse konu ilişkide algılanan tüketici etkinliğinin düzenleyici rolünün incelenmesinde ise düzenleyici değişken içeren regresyon analizinden faydalanılmıştır. Bulgular –Araştırma sonucunda, çalışanların yeşil iş yeri iklimi algılarının iş yerlerinde sergiledikleri çevre dostu davranışlar üzerinde olumlu ve anlamlı bir etkide bulunduğu görülmüştür. Algılanan tüketici etkinliği faktörü ise bu ilişkide düzenleyici bir rol üstlenmektedir. Tartışma –Elde edilen sonuçlar ışığında, yeşil iş yeri iklimi algısının çevreci davranışları olumlu yönde  etkilemesi  nedeniyle işletme yöneticilerinin tasarruf veya geri dönüşüm  gibi  çevre  dostu faaliyetleri desteklediklerini ve çalışma ortamlarını buna uygun düzenlediklerini çalışanlara etkin bir dille aktarabilmelerinin önem arz ettiği, birim yöneticilerinin çevre dostu davranışlarda bulunmakla ilgili liderlik rolünü üstlenmeleri gerektiği ortaya koyulmuştur. Bunun yanı sıra; işletme birimlerinin çevre dostu davranışlarının sonuçlarından diğer çalışanların haberdar edilmesi amacıyla kurum içi iletişimin  arttırılması  gerektiği,  böylece  sosyal  normun  etkisinin  kuvvetlendirilebileceği düşünülmektedir.  Bireylerin  çalışma  ortamlarında  da  tüketici  rollerini  sürdürdükleri  dikkate alındığında işletme tarafından  çalışanlara yönlendirilecek teşvik  edici mesajlar  ve faaliyetlerde tüketici  etkinliğinin  vurgulanmasının  ve  çevreci  davranışlarhususunda    bireysel    hedefler koyulmasının da algılanan tüketici etkinliği kavramının etkisini artırabileceği sonucuna varılmıştır.\n",
      "  - Amaç–Bu çalışmanın amacı, iş görenlerin örgütsel etik iklim algılarının iş gören motivasyonuna etkisinde, örgütsel özdeşleşmenin ve iş tatmininin aracılık rolünü belirlemektir. Çalışanların örgütsel etik iklim, iş tatmini ve örgütsel özdeşleşme düzeylerinin, motivasyon düzeylerine olan etkisini belirlemek, ilgili  değişkenlerin,  iş  gören  motivasyonuna  nasıl  etki  ettiğini  belirlemekte  araştırmanın  amaçları arasında yer almaktadır.Yöntem–Değişkenler arasındaki etkileşimlerin belirlenmesine yönelik olarak ilişkisel tarama modelinin kullanıldığı bu araştırmada, kamu kurumlarında görev yapan 575 çalışandan elde edilen verilerinanalizi için SPSS ve AMOS programları kullanılmıştır. Değişkenler arasındaki ilişkilerin analizinde ve aracı değişken etkisinin olup olmadığının test edilmesinde Yapısal Eşitlik Modellemesi tercih edilmiştir.Bulgular–Araştırma sonucunda, bireylerin örgütsel etik iklim algıları ile motivasyon düzeyleri arasında bir ilişki olduğu; olumlu bir örgütsel etik iklim algısının iş gören motivasyonunu pozitif etkilediği belirlenmiştir. Ayrıca etik iklimin iş tatminini, örgütsel özdeşleşmenin iş gören motivasyonunuve benzer şekilde iş tatmininin de iş gören motivasyonunu yordadığı, örgütsel etik iklimin işgören motivasyonuna etkisinde örgütsel özdeşleşme ve iş tatmininin kısmi aracılık etkisinin olduğu tespit edilmiştir. Tartışma–Bu çalışmanın; etik iklimin iş gören motivasyonu, örgütsel bağlılık, iş tatmini ve iş gören performansını pozitif yönde ve anlamlı olarak etkilediği yönündeki bulguları ilgili literatürü destekler niteliktedir. Bu doğrultuda olumlu algılanan bir etik iklimde, iş görenlerin motivasyonlarının yükselmesi ve neticede iş tatmini ve örgütsel özdeşleşme düzeyine de olumlu etkileri olacağı değerlendirilmektedir\n",
      "  - Çağımızın en önemli küresel sorunlarından biri haline gelen iklim değişikliği, pek çok sektörde olduğu  gibi  turizm  sektörü  üzerinde  de  hem  etkisini  göstermekte  hem  de  sektöre  bağlı gerçekleşen faaliyetlerden etkilenmektedir. Turizm sektörü ile iklim değişikliği arasındaki bu iki yönlü ilişki turizm literatüründe sosyal, ekonomik ve ekolojik açıdan da tartışılmaktadır. Bilimsel çalışmaların yanı sıra iklim değişikliği konusunda toplumsal bir farkındalığın oluşması da önem arz  etmektedir.  Kitle  iletişim  araçları  ise  bu  farkındalığın  oluşmasında  önemli  bir  rol oynamaktadır. Bu bağlamda çalışmanın amacı, kitle iletişim araçlarından biri olan gazetelerde turizm ve iklim değişikliğine ilişkin haberleri incelemektir. Araştırmanın amacı doğrultusunda Türkiye’de en yüksek tiraja sahip 10 gazetenin internet siteleri üzerinden 2022 yılı 15 Ağustos-15 Eylül tarihleri arasında iklim değişikliği ve turizme ilişkin içeriklere sahip haberler incelenmiştir.Erişilen 187 haber metni üzerinde karma içerik analizi yapılmıştır.Sonuçlar, doğrudan iklim değişikliği  ve  turizm  ile  ilgili  sınırlı  sayıda  haber  (13  haber)  olduğunu  göstermiştir.  İklim değişikliği ile ilgili haberlerin ise daha çok kuraklık, orman yangınları, biyoçeşitlilik kaybı gibi iklim değişikliğinin genel etkileri, iklim değişikliğinin insan ve diğer canlı türleri üzerindeki etkileri ve sıcaklık artışı kapsamında ele alındığı tespit edilmiştir. Turizm ve iklim değişikliğini bir arada ele alan sınırlı sayıda haber metni, iklim değişikliğinin genel etkilerine ilişkin haberlerle içerik olarak paralellik göstermiştir. Bu çalışma Van Yüzüncü Yıl Üniversitesi Uluslararası Avrasya İklim Değişikliği Kongresi’nde (EURACLI’2022) özet bildiri olarak yayımlanmıştır.\n",
      "--------------------------------------------------\n",
      "Topic 288: 288_delta_kaoping_dike system_delta cities\n",
      "Representative Documents:\n",
      "  - This dissertation argues that the floods following extreme precipitation result not only from very heavy rainfall but also from the significant impact of human activities on natural water systems. While most literature emphasises that the increasing magnitude of storm rainfall extends beyond the original protection standards of hydrologic facilities in highly populated delta cities. Based on the knowledge of urban morphology, this study analyses how human systems have affected the transformation of natural water processes in the Kaoping River Delta. The relationship between human environments and natural landscape is illustrated via a 3-layer analytical framework which consists of a natural landscape layer, an infrastructure layer and an occupation layer. This layer-based approach views landscapes as a whole system in which each element interacts with the others. In order to transcend the limitations of traditional urban morphology and the overlay-mapping method, this research initiates an analysis framework with the delta scale from a deductive perspective. Furthermore, it argues that the significant progress of infrastructure technology is the crucial factor to dominate the transformation of modern urban pattern. This influence could be identified by the analytic process of the 3-layer approach from the perspective of the delta or regional scale. This new starting point of a theoretical framework for analysing urban forms has been proved in the Kaoping Delta case. Furthermore, it could be a new and valid theoretical background to extend the knowledge of urban morphology.The formal transformation of the Kaoping Delta is divided into four main periods, which reveals human activities have affected the operation of natural systems since a century ago. From a delta scale perspective, those effects interacting between different layers can be identified in six different topographies (in italics) of the whole river catchment area.A. The dike system along the main stream in the plains protects delta cities against floods, which enables rapid urbanisation. Population growth in delta cities increases food demand, which causes the intensive agricultural cultivation of mountain areas.B. The dike system narrows the original riverbed in the river basin, which raises the water level of the river during storms. This situation blocks the drainage outlets of delta cities and induces higher frequencies of urban inundations.C. The dike system along the main stream in the plains has significantly changed the surface flowing path of river and dramatically decreased the recharge of groundwater in foothills. It causes serious land subsidence in coastal areas when the ground cannot obtain sufficient groundwater.D. The dike system and the bridges of transportation crossing river has resulted in the lag-sedimentation of the river in the river basin. When a significant amount of river sand deposits in the riverbed rather than being transited to the estuary to supply the demand for sand along the coast, it induces serious erosion in the coast.  Following this context, this study organised a five day workshop in Kaohsiung, ‘Workshop on Water Environment Development in Kaohsiung’ in 2012 to further examine the results derived from Chapters 3 and 4, and to demonstrate how a 3-layer approach can work between multiple disciplines as a platform for collaboration. This workshop followed the theoretical framework of the 3-layers to explore the entire Kaoping River catchment area and its two tributary basins as the chosen local-scale sites: the Meinong River and the Love River. This workshop gives the best demonstration of how to practically utilise the 3-layer approach to organise multiple- disciplinary work, and then to make an integrated plan. The results and process of this workshop are also generalised as a framework, which could be applied to other cases. \n",
      "  - This dissertation argues that the floods following extreme precipitation result not only from very heavy rainfall but also from the significant impact of human activities on natural water systems. While most literature emphasises that the increasing magnitude of storm rainfall extends beyond the original protection standards of hydrologic facilities in highly populated delta cities. Based on the knowledge of urban morphology, this study analyses how human systems have affected the transformation of natural water processes in the Kaoping River Delta. The relationship between human environments and natural landscape is illustrated via a 3-layer analytical framework which consists of a natural landscape layer, an infrastructure layer and an occupation layer. This layer-based approach views landscapes as a whole system in which each element interacts with the others. In order to transcend the limitations of traditional urban morphology and the overlay-mapping method, this research initiates an analysis framework with the delta scale from a deductive perspective. Furthermore, it argues that the significant progress of infrastructure technology is the crucial factor to dominate the transformation of modern urban pattern. This influence could be identified by the analytic process of the 3-layer approach from the perspective of the delta or regional scale. This new starting point of a theoretical framework for analysing urban forms has been proved in the Kaoping Delta case. Furthermore, it could be a new and valid theoretical background to extend the knowledge of urban morphology.The formal transformation of the Kaoping Delta is divided into four main periods, which reveals human activities have affected the operation of natural systems since a century ago. From a delta scale perspective, those effects interacting between different layers can be identified in six different topographies (in italics) of the whole river catchment area.A. The dike system along the main stream in the plains protects delta cities against floods, which enables rapid urbanisation. Population growth in delta cities increases food demand, which causes the intensive agricultural cultivation of mountain areas.B. The dike system narrows the original riverbed in the river basin, which raises the water level of the river during storms. This situation blocks the drainage outlets of delta cities and induces higher frequencies of urban inundations.C. The dike system along the main stream in the plains has significantly changed the surface flowing path of river and dramatically decreased the recharge of groundwater in foothills. It causes serious land subsidence in coastal areas when the ground cannot obtain sufficient groundwater.D. The dike system and the bridges of transportation crossing river has resulted in the lag-sedimentation of the river in the river basin. When a significant amount of river sand deposits in the riverbed rather than being transited to the estuary to supply the demand for sand along the coast, it induces serious erosion in the coast.  Following this context, this study organised a five day workshop in Kaohsiung, ‘Workshop on Water Environment Development in Kaohsiung’ in 2012 to further examine the results derived from Chapters 3 and 4, and to demonstrate how a 3-layer approach can work between multiple disciplines as a platform for collaboration. This workshop followed the theoretical framework of the 3-layers to explore the entire Kaoping River catchment area and its two tributary basins as the chosen local-scale sites: the Meinong River and the Love River. This workshop gives the best demonstration of how to practically utilise the 3-layer approach to organise multiple- disciplinary work, and then to make an integrated plan. The results and process of this workshop are also generalised as a framework, which could be applied to other cases. \n",
      "  - This dissertation argues that the floods following extreme precipitation result not only from very heavy rainfall but also from the significant impact of human activities on natural water systems. While most literature emphasises that the increasing magnitude of storm rainfall extends beyond the original protection standards of hydrologic facilities in highly populated delta cities. Based on the knowledge of urban morphology, this study analyses how human systems have affected the transformation of natural water processes in the Kaoping River Delta. The relationship between human environments and natural landscape is illustrated via a 3-layer analytical framework which consists of a natural landscape layer, an infrastructure layer and an occupation layer. This layer-based approach views landscapes as a whole system in which each element interacts with the others. In order to transcend the limitations of traditional urban morphology and the overlay-mapping method, this research initiates an analysis framework with the delta scale from a deductive perspective. Furthermore, it argues that the significant progress of infrastructure technology is the crucial factor to dominate the transformation of modern urban pattern. This influence could be identified by the analytic process of the 3-layer approach from the perspective of the delta or regional scale. This new starting point of a theoretical framework for analysing urban forms has been proved in the Kaoping Delta case. Furthermore, it could be a new and valid theoretical background to extend the knowledge of urban morphology.The formal transformation of the Kaoping Delta is divided into four main periods, which reveals human activities have affected the operation of natural systems since a century ago. From a delta scale perspective, those effects interacting between different layers can be identified in six different topographies (in italics) of the whole river catchment area.A. The dike system along the main stream in the plains protects delta cities against floods, which enables rapid urbanisation. Population growth in delta cities increases food demand, which causes the intensive agricultural cultivation of mountain areas.B. The dike system narrows the original riverbed in the river basin, which raises the water level of the river during storms. This situation blocks the drainage outlets of delta cities and induces higher frequencies of urban inundations.C. The dike system along the main stream in the plains has significantly changed the surface flowing path of river and dramatically decreased the recharge of groundwater in foothills. It causes serious land subsidence in coastal areas when the ground cannot obtain sufficient groundwater.D. The dike system and the bridges of transportation crossing river has resulted in the lag-sedimentation of the river in the river basin. When a significant amount of river sand deposits in the riverbed rather than being transited to the estuary to supply the demand for sand along the coast, it induces serious erosion in the coast.  Following this context, this study organised a five day workshop in Kaohsiung, ‘Workshop on Water Environment Development in Kaohsiung’ in 2012 to further examine the results derived from Chapters 3 and 4, and to demonstrate how a 3-layer approach can work between multiple disciplines as a platform for collaboration. This workshop followed the theoretical framework of the 3-layers to explore the entire Kaoping River catchment area and its two tributary basins as the chosen local-scale sites: the Meinong River and the Love River. This workshop gives the best demonstration of how to practically utilise the 3-layer approach to organise multiple- disciplinary work, and then to make an integrated plan. The results and process of this workshop are also generalised as a framework, which could be applied to other cases. \n",
      "--------------------------------------------------\n",
      "Topic 289: 289_fire_fires_fire years_pdo\n",
      "Representative Documents:\n",
      "  - Understanding relationships between variability in historical fire occurrence and ocean–atmosphere oscillations provides opportunities for fire forecasting and projecting changes in fire regimes under climate change scenarios. We analysed tree-ring reconstructed regional climate teleconnections and fire–climate relationships in upper elevation forests (&gt;2700m) from 16 sites in eight mountain ranges in the south-western USA. Climate teleconnections were identified by testing for associations between regional Palmer Drought Severity Index (PDSI) and individual and combined phases of El Niño–Southern Oscillation (ENSO), Pacific Decadal Oscillation (PDO) and Atlantic Multidecadal Oscillation (AMO) indices for both the fire exclusion (1905–1978) and reconstructed fire periods (1700–1904). Fire–climate relationships were identified by comparing reconstructed fires (84 fire years) in three classes (all, synchronous and stand-replacing fires) with PDSI, precipitation, temperature, and individual and combined phases of ENSO, PDO and AMO indices. Individual and phase combinations of ENSO, PDO and AMO were associated with variability in regional PDSI. Upper elevation fire occurrence was related to variability in regional drought, ENSO phase and phase combinations of ENSO and PDO. We conclude that ENSO most consistently influenced variability in moisture and upper elevation fire occurrence, including stand-replacing fires, but this relationship was potentially modulated by phases of the PDO.\n",
      "  - Aim  To identify the influence of interannual and interdecadal climate variation on the occurrence and extent of fires in montane conifer forests of north‐western Mexico.Location  This study was conducted in Jeffrey pine (Pinus jeffreyi Grev. &amp; Balf.)‐dominated mixed‐conifer forests in the central and northern plateau of the Sierra San Pedro Mártir, Baja California, Mexico.Methods  Fire occurrence was reconstructed for 12 dispersed sites for a 290‐year period (1700–1990) from cross‐dated fire‐scarred samples extracted from live trees, snags and logs. Superposed epoch analysis was used to examine the relationships of tree‐ring reconstructions of drought, the El Niño/Southern Oscillation (ENSO) and the Pacific Decadal Oscillation (PDO) with fire occurrence and extent.Results  Years with no recorded fire scars were wetter than average. In contrast, years of widespread fires were dry and associated with phase changes of the PDO, usually from positive (warm) to negative (cold). The influence of the PDO was most evident during the La Niña phase of the ENSO. Widespread fires were also associated with warm/wet conditions 5 years before the fire. We hypothesize that the 5‐year lag between warm/wet conditions and widespread fires may be associated with the time necessary to build up sufficient quantity and continuity of needle litter to support widespread fires. Two periods of unusually high fire activity (1770–1800 and 1920–1950) were each followed by several decades of unusually low fire activity. The switch in each case was associated with strong phase changes in both PDO and ENSO.Main conclusions  Climate strongly influences fire regimes in the mountains of north‐western Mexico. Wet/warm years are associated with little fire activity. However, these years may contribute to subsequent fire years by encouraging the production of sufficient needle litter to support more widespread fires that occur in dry/cool years.\n",
      "  -  High fire activity in western North America is associated with drought. Drought and fire prevail under negative El Niño Southern Oscillation (ENSO) and Pacific Decadal Oscillation (PDO) phases in the Southwest and with positive phases in the Northwest. Here, I infer climate effects on historic fire patterns in the geographically intermediate, eastern Great Basin and seek out evidence of human influence on reconstructed fire regimes. Surface fire chronologies were constructed for 10 sites using tree-ring-based fire scars. Regional (67) and local (247) fire years and no-fire (187) years were identified from 1400 to 1900 CE. I compared fire chronologies with indices of the Palmer Drought Severity Index (PDSI), ENSO, and PDO. Regionally, fires were significantly more common during drought and were associated with negative ENSO and positive-to-negative PDO transitions while no-fire years were associated with positive ENSO and negative-to-positive PDO transitions. Conditions were significantly wetter 2 years prior to regional fire years and drier 4 years prior to no-fire years, providing evidence that fires were historically fuel limited. Local fire years occurred under a broad range of climate conditions. Most sites showed either persistent late or bimodal (early and late) fire seasonality patterns. These patterns are distinct from the mid-season peak observed for modern lightning-caused fires, suggesting a human influence on historical ignition patterns. Results demonstrate that climate was an important synchronizer of fire at the regional scale and that locally fire regimes were the product of climate-regulated fuels and some combination of human and lightning ignition patterns. \n",
      "--------------------------------------------------\n",
      "Topic 290: 290_adsorption_coal_ch4_shale\n",
      "Representative Documents:\n",
      "  - To gain a better understanding of the enhanced shale gas recovery by CO2 gas injection (CO2-ESGR) technique, the dynamic displacement mechanism of CO2–CH4, the CO2 enhanced shale gas recovery (RCH4), and CO2 storage capacity (VCO2) were studied based on transport properties of CO2 and CH4. Experiments of CO2 injection into shale gas reservoir preadsorbed by CH4 were performed in a fixed bed. Breakthrough curves were obtained under different test conditions and simulated by one-dimension advection-dispersion (AD) model. It was found that dispersion coefficient (K1) rather than molecular diffusivity of CO2 dominated its transport in shale. K1 together with advection velocity (υ) of CO2 during CH4 displacement controls RCH4 and VCO2. When transporting in shale gas reservoir, CO2 had larger dynamic adsorption amount and υ, but smaller K1 than CH4. The competitive transport and adsorption behavior of CO2 and CH4 made it possible for CO2 to store in shale reservoir and to drive the in-place CH4 out of shale reservoir. The transfer zone of CO2–CH4 displacement (CCD) was very wide. High RCH4 and VCO2 were reached at low injection CO2 gas pressure and for small shale particles. Higher injection flow rates of CO2 and temperatures ranging from 298 K to 338 K had a little effect on RCH4 and VCO2. For field conditions, high CO2 injection pressure has to be used because the pore pressure of shale reservoir and adsorption amount of CH4 increase with the increase in depth of shale gas reservoir, but RCH4 is still not high.\n",
      "  - The adsorption behavior and the mechanism of a CO2/CH4 mixture in shale organic matter play significant roles to predict the carbon dioxide sequestration with enhanced gas recovery (CS-EGR) in shale reservoirs. In the present work, the adsorption performance and the mechanism of a CO2/CH4 binary mixture in realistic shale kerogen were explored by employing grand canonical Monte Carlo (GCMC) and molecular dynamics (MD) simulations. Specifically, the effects of shale organic type and maturity, temperature, pressure, and moisture content on pure CH4 and the competitive adsorption performance of a CO2/CH4 mixture were investigated. It was found that pressure and temperature have a significant influence on both the adsorption capacity and the selectivity of CO2/CH4. The simulated results also show that the adsorption capacities of CO2/CH4 increase with the maturity level of kerogen. Type II-D kerogen exhibits an obvious superiority in the adsorption capacity of CH4 and CO2 compared with other type II kerogen. In addition, the adsorption capacities of CO2 and CH4 are significantly suppressed in moist kerogen due to the strong adsorption strength of H2O molecules on the kerogen surface. Furthermore, to characterize realistic kerogen pore structure, a slit-like kerogen nanopore was constructed. It was observed that the kerogen nanopore plays an important role in determining the potential of CO2 subsurface sequestration in shale reservoirs. With the increase in nanopore size, a transition of the dominated gas adsorption mechanism from micropore filling to monolayer adsorption on the surface due to confinement effects was found. The results obtained in this study could be helpful to estimate original gas-in-place and evaluate carbon dioxide sequestration capacity in a shale matrix.\n",
      "  - CO2 enhanced shale gas recovery (CO2-ESGR) draws worldwide attentions in recent years with having significant environmental benefit of CO2 geological storage and economic benefit of shale gas production. This paper is aimed at reviewing the state of experiment and model studies on gas adsorption, competitive adsorption of CO2/CH4, and displacement of CO2-CH4 in shale in the process of CO2-ESGR and pointing out the related challenges and opportunities. Gas adsorption mechanism in shale, influencing factors (organic matter content, kerogen type, thermal maturity, inorganic compositions, moisture, and micro/nano-scale pore), and adsorption models are described in this work. The competitive adsorption mechanisms are qualitatively ascertained by analysis of unique molecular and supercritical properties of CO2 and the interaction of CO2 with shale matrix. Shale matrix shows a stronger affinity with CO2, and thus, adsorption capacity of CO2 is larger than that of CH4 even with the coexistence of CO2-CH4 mixture. Displacement experiments of CO2-CH4 in shale proved that shale gas recovery is enhanced by the competitive adsorption of CO2 to CH4. Although the competitive adsorption mechanism is preliminary revealed, some challenges still exist. Competitive adsorption behavior is not fully understood in the coexistence of CO2 and CH4 components, and more experiment and model studies on adsorption of CO2-CH4 mixtures need to be conducted under field conditions. Coupling of competitive adsorption with displacing flow is key factor for CO2-ESGR but not comprehensively studied. More displacement experiments of CO2-CH4 in shale are required for revealing the mechanism of flow and transport of gas in CO2-ESGR.\n",
      "--------------------------------------------------\n",
      "Topic 291: 291_sowing_yield_grain_wheat\n",
      "Representative Documents:\n",
      "  - Cultivar and sowing date selection are major factors in determining the yield potential of any crop and in any region. To explore how climate change affects these choices, this study performed a regional scale analysis using the well-validated APSIM-maize model for the Northeast China Plain (NEC) which is the leading maize (Zea mays L.) producing area in China. Results indicated that high temperature had a significantly negative effect on grain yield, while effective accumulated temperature and solar radiation had significant positive effects on grain yield and kernel number. Cloudy and rainy weather in flowering stage had significant negative effects on kernel number. Delayed sowing led to less cloudy and rainy weather during flowering and reduced the negative effect on kernel number. Higher diurnal thermal range and less precipitation during the grain-filling stage also increased the 1000-kernel weight. Delayed sowing, however, also significantly increased the risk of early senescence and frost (&gt;80%) in middle and high latitude areas. In the middle and high latitude areas of the NEC, the grain yield of a long-season cultivar (LS) under early sowing (I) (6.2–19.9%) was significantly higher than under medium sowing (II) or late sowing (III), and higher than that of an early sown (I) short-season (SS) and medium-season cultivar (MS). In the low latitude area of the NEC, the grain yield of MS under medium sowing date (II) was higher than that under I and III, meanwhile, this was also higher than that of SS and LS. Therefore, under climate warming, LS sown earlier in high and medium latitudes and MS sown medium in low latitude were the appropriate cultivar and sowing date choices, which could mitigate the stress of high temperatures and reduce the risk of early senescence and frost. Cultivar and sowing date selection are effective measures to alleviate negative effects of climate change on maize production in the NEC, and provides valuable advice for breeders on cultivar selection, and the choice of varieties and sowing dates for farmers in actual production.\n",
      "  - SUMMARYCrop production in the Northeast Farming Region of China (NFR) is affected considerably by variation in climatic conditions. Data on crop yield and weather conditions from a number of agro-meteorological stations in NFR were used in a mixed linear model to evaluate the impacts of climatic variables on the yield of maize (Zea mays L.), rice (Oryza sativa L.), soybean (Glycine max L. Merr.) and spring wheat (Triticum aestivum L.) in different crop growth phases. The crop growing season was divided into three growth phases based on the average crop phenological dates from records covering 1981 and 2010 at each station, comprising pre-flowering (from sowing to just prior to flowering), flowering (20 days around flowering) and post-flowering (10 days after flowering to maturity). The climatic variables were mean minimum temperature, thermal time (which is used to indicate changes in the length of growth cycles), average daily solar radiation, accumulated precipitation, aridity index (which is used to assess drought stress) and heat degree-days index (HDD) (which is used to indicate heat stress) were calculated for each growth phase and year. Over the 1961–2010 period, the minimum temperature increased significantly in each crop growth phase, the thermal time increased significantly in the pre-flowering phase of each crop and in the post-flowering phases of maize, rice and soybean, and HDD increased significantly in the pre-flowering phase of soybean and wheat. Average solar radiation decreased significantly in the pre-flowering phase of all four crops and in the flowering phase of soybean and wheat. Precipitation increased during the pre-flowering phase leading to less aridity, whereas reduced precipitation in the flowering and post-flowering phases enhanced aridity. Statistical analyses indicated that higher minimum temperature was beneficial for maize, rice and soybean yields, whereas increased temperature reduced wheat yield. Higher solar radiation in the pre-flowering phase was beneficial for maize yield, in the post-flowering phase for wheat yield, whereas higher solar radiation in the flowering phase reduced rice yield. Increased aridity in the pre-flowering and flowering phases severely reduced maize yield, higher aridity in the flowering and post-flowering phases reduced rice yield, and aridity in all growth phases reduced soybean and wheat yields. Higher HDD in all growth phases reduced maize and soybean yield and HDD in the pre-flowering phase reduced rice yield. Such effects suggest that projected future climate change may have marked effects on crop yield through effects of several climatic variables, calling for adaptation measures such as breeding and changes in crop, soil and agricultural water management.\n",
      "  - In China, the main sugarcane (Saccharum spp.) planting areas can be found in the low-latitude plateau (21° N–25° N, 97° E–106° E), which has most of the natural ecological types. However, there is limited information on the climate conditions of this region and their influence on sugarcane yield and sucrose content. Monthly variations in the main climate factors, namely, average air temperature (AAT), average relative humidity (ARH), average rainfall amount (ARA), and average sunshine duration (ASD), from 2000 to 2019 and sugarcane yield and sucrose content of 26 major sugarcane-producing areas from 2001/2002 to 2018/2019 were collected from the low-latitude plateau in Yunnan for studying the impact of climate variations on sugarcane yield and sucrose content. The results showed that AAT in the mid-growth season had a significant positive correlation with sucrose content (p &lt; 0.05), and AAT in the late-growth season had a very significant positive correlation with sucrose content (p &lt; 0.01). ARH in the mid-growth season had a significant positive correlation with sugarcane yield (p &lt; 0.05). ARA in the early-growth season showed a significant positive correlation with sugarcane yield (p &lt; 0.05). ASD in the late-growth season had a significant positive correlation with sugarcane yield (p &lt; 0.05) and sucrose content (p &lt; 0.01). The rainy and humid sugarcane areas were characterized by high ARA and ARH during the entire growth period, low AAT and ASD in the mid-growth season, and low AAT in the late-growth season, contributing to a high sugarcane yield, but not a high sucrose content. The low temperature and sunshine semi-humid sugarcane areas were characterized by the lowest AAT in the early and middle stages of sugarcane growth, less ASD in the early and middle stages, and less ARA in the early and late stages, which are unfavorable for sugarcane yield and sucrose content. The high temperature and humidity sugarcane areas were characterized by higher AAT and ARA, and moderate ASD during the entire growth period, resulting in good sugarcane growth potential and contributing to the sugarcane yield and sucrose content. The semi-humid and multi-sunshine sugarcane areas were characterized by the lowest ARH in the entire growth period, the lowest ARA in the middle and late seasons, and the longest ASD, contributing to an increase in sucrose content. The humid and sunny areas were characterized by the longest ASD and high ARH in the early and late seasons of sugarcane growth and moderate AAT and ARA during the entire growth season, which are beneficial for high sugarcane yield and sucrose content. Overall, these findings suggest that the sugarcane variety layout should be based on the climate type (of which there are five in the plateau), and corresponding cultivation practices should be used to compensate for the climatic conditions in various growth stages.\n",
      "--------------------------------------------------\n",
      "Topic 292: 292_electrical_optimal_demand_energy\n",
      "Representative Documents:\n",
      "  -                The operation of the electrical systems is a major problem for electrical companies’ subject to uncertainties threatening. In this study, the optimal management of the energy demand in the electrical distribution grid is done by interval optimization approach under electrical price uncertainty. The management of the energy demand is implemented via incentive-based modelling of the demand response programs (DRPs). The incentive-based modelling as reserve, and based on bid price for reduction of the electrical demand at peak hours is proposed. The interval optimization approach is used for the minimization of the electrical price uncertainty effects. The main objective in the proposed approach is minimizing operation cost; epsilon-constraint method is utilized to solve the problem. Finally, an electrical distribution grid has been used at various case studies to numerical simulation results and positive effects of the proposed modelling under uncertainties.\n",
      "  -                In this study, multi-objective optimal scheduling of smart energy Hub system (SEHS) in the day ahead is proposed. A SEHS is comprising of interconnected energy hybrid system infrastructures such as electrical, thermal, wind, solar, natural gas and other fuels to supply many types of electrical and thermal loads in a two-way communication platform. All objectives in this paper, are minimized and consist of 1) operation cost and emission polluting in generation side, 2) loss of energy supply probability (LESP) in demand side, and 3) deviation of electrical and thermal loads with the optimal level of electrical and thermal profile in the day ahead. The third objective to flatten electrical and thermal demand profile using Demand Side Management (DSM) by the optimal shifting of electrical and thermal shiftable loads (SLs) is proposed. Also, stochastic modelling of renewable energy sources (RESs) and electrical and thermal loads by Monte Carlo technique is modelled. Using GAMS optimization software, proposed approach by ε -constraint method for obtaining to non-dominated Pareto solutions of objectives is implemented. Moreover, by the decision-making method, the best solution of non-dominated Pareto solutions is selected. Finally, two case studies and sensitivity analysis in case studies for confirmation of the proposed approach are analysed.\n",
      "  -                The energy management in energy systems is the main solution for energy companies in order to provide minimization of the energy generation costs and emission polluting. In this work, a multi-criteria optimization model is implemented for minimizing the generation cost and emission in a smart micro grid (SMG) at day-ahead planning. In this modelling, the demand side participates in optimal energy management through two strategies such as demand shifting and onsite generation by the energy storage system (ESS). The optimal participation of demand side is modelled based on energy price in energy market. Implementation of the proposed approach in GAMS software is done, and weight sum method (WSM) is employed for solving multi-criteria optimization. The desired optimal solution of multi-criteria objectives is found via the max-min fuzzy procedure. Finally, confirmation of the proposed approach is analysed by numerical simulation in two case studies.\n",
      "--------------------------------------------------\n",
      "Topic 293: 293_maize_yield_rice_maize yield\n",
      "Representative Documents:\n",
      "  - The agro-pastoral ecotone of Northwestern China (APENC) is one of the major agricultural production areas in China and a region where climate change is evident. Maize is a widely cultivated crop in the APENC, but the potential impact of climate change on maize, and potential adaptation strategies in response to this, are poorly understood. In this study, we used the Cropping System Model (CSM)-CERES-Maize to evaluate the impacts of climate change on maize yield, as well as the feasibility of 2 adaptation strategies; namely, adjusting the planting date and supplying irrigation. CSM-CERES-Maize was driven by an ensemble of 20 global climate models under 2 Representative Concentration Pathways (RCPs: RCP4.5 and RCP8.5) from the Coupled Model Intercomparison Project Phase 5 (CMIP5). CSM-CERES-Maize performed well in simulating phenology, leaf area index (LAI), maize yield, and soil water dynamics. The results showed that irrigated maize yield would change by +3.9, -16.3, and -20.4% under the RCP4.5 scenario and +0.1, -31.2, and -53.1% under the RCP8.5 scenario in the 2030s, 2060s, and 2090s, respectively. Rainfed maize yield during the 2030s, 2060s, and 2090s would change by +21.7, +16.4, and +12.6% under the RCP4.5 scenario and +25.1, +4.8, and -12.3% under the RCP8.5 scenario, respectively. Evaluation of adaptation strategies suggests that delaying planting dates and supplying irrigation at the tasseling and grain filling stages are the best strategies to increase maize yield under climate change. These results will provide comprehensive information for local policymakers to combat the adverse impacts of climate change.\n",
      "  - Core IdeasThe CERES‐Maize model was applied to estimate the impacts of climate change under RCP scenarios and the effectiveness of three typical adaptation measures for maize production in Northeast China.Maize yield would decline under the future climatic conditions if no adaptation measures were adopted.Changing planting dates, switching to later‐maturing cultivars and breeding new cultivars could mitigate the negative impacts of climate change to varying degrees.Northeast China (NEC) is an important region for maize (Zea mays L.) production in China, and is the country's most significant commercial food base. However, NEC is also one of the areas that are most significantly affected by climate change in this country. Maize is sensitive to climatic changes, and to develop effective strategies for guaranteeing regional food security, it is essential to understand the mechanisms of the impacts of climate change and the effectiveness of adaptation measures in NEC. In this study, the Crop‐Environment Resource Synthesis (CERES)‐Maize v4.5 model, coupled with newly released data for Representative Concentration Pathway (RCP) scenarios, RCP4.5 and RCP8.5, was applied to simulate maize yields for future periods (2020s, 2050s, and 2080s) and to estimate the effect of CO2 fertilization and the effectiveness of three typical adaptation measures for maize production in NEC. The results indicated a trend of a continuing decline in maize yield for both RCP scenarios, and the decrease in maize yield under RCP8.5 was predicted to be greater than that under RCP4.5. The effect of CO2 fertilization was forecast to be too small to offset the negative impacts of climate change. Three adaptation measures—changing planting dates, switching to later‐maturing cultivars, and breeding new cultivars with high thermal time requirements—could mitigate negative climate change impacts to varying degrees; switching cultivars may exert the most significant effect on increasing maize yields.\n",
      "  - Maize plays an important role in the Agro‐pastoral ecotone of Northwestern China (APENC), where highly sensitive to changes in climate conditions. However, little is reported on the impacts of climate change on crops in the region. In this study, we used Decision Support System for Agrotechnology Transfer model driven by future climate data from 20 general circulations models under two representative concentration pathways (RCPs: RCP4.5 and RCP8.5) from the Coupled Model Intercomparison Project Phase 5 (CMIP5) to project the effects of climate change on maize yield and water use efficiency (WUE) in eight future time periods (interval: 10 years; from 2020s to 2100s). The model was first calibrated based on field observation for phenology, leaf area index, maize yield and calibrated and evaluated results were reasonably good. Simulated results showed that without and with consideration of CO2 effects, maize yield at the end of the 21st century will decrease by 11.7% and 10.3% under the RCP4.5 scenario, and by 22.1% and 21.2% under the RCP8.5 scenario, respectively. We found that there is a significant correlation between maize yield reduction and warming. Specifically, when the increment of annual average temperature reaches 1°C, the maize yield begins to decrease by 11.27% and 10.8% per 1°C warming without and with consideration of CO2 effects, respectively. Furthermore, high temperature not only affects maize yield but also has a negative effect on WUE. The WUE would change by −8.1% and −18.8% under RCP4.5 and RCP8.5, respectively. But if we consider the effects of CO2, the WUE will improve 1.5% under RCP4.5 and 2.2% under RCP8.5, in comparison to those without consideration of CO2 effects. Overall, future climate warming will seriously affect maize yield and WUE. Although the increase of CO2 concentration is beneficial to raise maize yield and WUE, it is hard to offset the negative effects of the increase in temperature. Besides, change in the planting date can be beneficial for the adaptation of maize to climate change in the APENC. These results will provide comprehensive information to support local policy and decision‐making in agricultural production and water resources management.\n",
      "--------------------------------------------------\n",
      "Topic 294: 294_ice_sea ice_arctic_sea\n",
      "Representative Documents:\n",
      "  -                To examine the long-term stability of Arctic and Antarctic sea ice, idealized simulations are carried out with the climate model ECHAM5/Max Planck Institute Ocean Model (MPI-OM). Atmospheric CO2 concentration is increased over 2000 years from preindustrial levels to quadrupling, is then kept constant for 5940 years, is afterward decreased over 2000 years to preindustrial levels, and is finally kept constant for 3940 years.               Despite these very slow changes, the sea ice response significantly lags behind the CO2 concentration change. This lag, which is caused by the ocean's thermal inertia, implies that the sea ice equilibrium response to increasing CO2 concentration is substantially underestimated by transient simulations. The sea ice response to CO2 concentration change is not truly hysteretic and is in principle reversible.               The authors find no lag in the evolution of Arctic sea ice relative to changes in annual-mean Northern Hemisphere surface temperature. The summer sea ice cover changes linearly with respect to both CO2 concentration and temperature, while the Arctic winter sea ice cover shows a rapid transition to a very low sea ice coverage. This rapid transition of winter sea ice is associated with a sharply enhanced ice–albedo feedback and a sudden onset of convective-cloud feedback in the Arctic.               The Antarctic sea ice cover retreats continuously without any rapid transition during the warming. Compared to Arctic sea ice, Antarctic sea ice shows a much more strongly lagged response to changes in CO2 concentration. It even lags behind the surface temperature change, which is caused by a different response of ocean deep convection during the warming and the cooling periods.\n",
      "  - This study isolates the influence of sea ice mean state on pre‐industrial climate and transient 1850–2100 climate change within a fully coupled global model: The Community Earth System Model version 2 (CESM2). The CESM2 sea ice model physics is modified to increase surface albedo, reduce surface sea ice melt, and increase Arctic sea ice thickness and late summer cover. Importantly, increased Arctic sea ice in the modified model reduces a present‐day late‐summer ice cover bias. Of interest to coupled model development, this bias reduction is realized without degrading the global simulation including top‐of‐atmosphere energy imbalance, surface temperature, surface precipitation, and major modes of climate variability. The influence of these sea ice physics changes on transient 1850–2100 climate change is compared within a large initial condition ensemble framework. Despite similar global warming, the modified model with thicker Arctic sea ice than CESM2 has a delayed and more realistic transition to a seasonally ice free Arctic Ocean. Differences in transient climate change between the modified model and CESM2 are challenging to detect due to large internally generated climate variability. In particular, two common sea ice benchmarks—sea ice sensitivity and sea ice trends—are of limited value for comparing models with similar global warming. More broadly, these results show the importance of a reasonable Arctic sea ice mean state when simulating the transition to an ice‐free Arctic Ocean in a warming world. Additionally, this work highlights the importance of large initial condition ensembles for credible model‐to‐model and observation‐model comparisons.\n",
      "  - With Arctic summer sea ice potentially disappearing halfway through this century, the surface albedo and insulating effects of Arctic sea ice will decrease considerably. The ongoing Arctic sea ice retreat also affects the strength of the Planck, lapse rate, cloud, and surface albedo feedbacks together with changes in the heat exchange between the ocean and the atmosphere, but their combined effect on climate sensitivity has not been quantified. This study presents an estimate of all Arctic sea ice related climate feedbacks combined. We use a new method to keep Arctic sea ice at its present-day (PD) distribution under a changing climate in a 50-yr CO2 doubling simulation, using a fully coupled global climate model (EC-Earth, version 2.3). We nudge the Arctic Ocean to the (monthly dependent) year 2000 mean temperature and minimum salinity fields on a mask representing PD sea ice cover. We are able to preserve about 95% of the PD mean March and 77% of the September PD Arctic sea ice extent by applying this method. Using simulations with and without nudging, we estimate the climate response associated with Arctic sea ice changes. The Arctic sea ice feedback globally equals 0.28 ± 0.15 W m−2 K−1. The total sea ice feedback thus amplifies the climate response for a doubling of CO2, in line with earlier findings. Our estimate of the Arctic sea ice feedback agrees reasonably well with earlier CMIP5 global climate feedback estimates and shows that the Arctic sea ice exerts a considerable effect on the Arctic and global climate sensitivity.\n",
      "--------------------------------------------------\n",
      "Topic 295: 295_ecmf_habitat_species_shifts\n",
      "Representative Documents:\n",
      "  - AimCold‐adapted species are considered vulnerable to climate change. However, our understanding of how climate‐induced changes in habitat and weather patterns will influence habitat suitability remains poorly understood, particularly for species at high latitudes or elevations. Here, we assessed potential future distributions for a climate‐sensitive genus, Lagopus, and the effectiveness of protected areas in tracking shifting distributions.LocationBritish Columbia, Canada.MethodsUsing community science observations from 1970 to 2020, we built species distribution models for white‐tailed (L. leucura), rock (L. muta) and willow ptarmigan (L. lagopus) across British Columbia, a globally unique region harbouring all three ptarmigan species. We assessed the impact of climate (direct) and climate‐induced habitat change (indirect) on potential future distributions of ptarmigan.ResultsWhite‐tailed and rock ptarmigan were associated with colder temperatures and tundra‐like open habitats and willow ptarmigan with open, shrub habitats. Future projections based on climate and vegetation scenarios indicated marked losses in suitable habitat by the 2080s (RCP +8.5 W/m2), with range declines of 85.6% and 79.5% for white‐tailed and rock ptarmigan, respectively, and a lower 61.3% for willow ptarmigan. Predicted current and future suitable habitat occurred primarily outside of current protected areas (67%–82%), yet range size declined at a less pronounced rate within protected areas suggesting a capacity to buffer habitat loss.Main conclusionsPtarmigan are predicted to persist at higher elevations and latitudes than currently occupied, with the magnitude of elevation shifts consistent with trends observed elsewhere in the Holarctic. Our spatially explicit assessment of potential current and future distributions of ptarmigan species provides the first comprehensive evaluation of climate change effects on the distribution of three congeneric, cold‐adapted species with different habitat preferences and life‐history traits. We also highlight the potential role of protected areas in preserving suitable future sites for ptarmigan and other climate‐sensitive or high‐elevation species.\n",
      "  - AimUnderstanding the relative importance of climatic and non‐climatic distribution drivers for co‐occurring, functionally similar species is required to assess potential consequences of climate change. This understanding is, however, lacking for most ecosystems. We address this knowledge gap and forecast changes in distribution for habitat‐forming seaweeds in one of the world's most species‐rich temperate reef ecosystems.LocationThe Great Southern Reef. The full extent of Australia's temperate coastline.MethodsWe assessed relationships between climatic and non‐climatic environmental data known to influence seaweed, and the presence of 15 habitat‐forming seaweeds. Distributional data (herbarium records) were analysed with MAXENT and generalized linear and additive models, to construct species distribution models at 0.2° spatial resolution, and project possible distribution shifts under the RCP 6.0 (medium) and 2.6 (conservative) emissions scenarios of ocean warming for 2100.ResultsSummer temperatures, and to a lesser extent winter temperatures, were the strongest distribution predictors for temperate habitat‐forming seaweeds in Australia. Projections for 2100 predicted major poleward shifts for 13 of the 15 species, on average losing 78% (range: 36%–100%) of their current distributions under RCP 6.0 and 62% (range: 27%–100%) under RCP 2.6. The giant kelp (Macrocystis pyrifera) and three prominent fucoids (Durvillaea potatorum, Xiphophora chondrophylla and Phyllospora comosa) were predicted to become extinct from Australia under RCP 6.0. Many species currently distributed up the west and east coasts, including the dominant kelp Ecklonia radiata (71% and 49% estimated loss for RPC 6.0 and 2.6, respectively), were predicted to become restricted to the south coast.Main conclusionsIn close accordance with emerging observations in Australia and globally, our study predicted major range contractions of temperate seaweeds in coming decades. These changes will likely have significant impacts on marine biodiversity and ecosystem functioning because large seaweeds are foundation species for 100s of habitat‐associated plants and animals, many of which are socio‐economically important and endemic to southern Australia.\n",
      "  - AimClimate change is predicted to alter the distribution and abundance of marine species, including canopy‐forming seaweeds which provide important ecosystem functions and services. We asked whether continued warming will affect the distribution of six common canopy‐forming species: mid‐intertidal fucoids (Ascophyllum nodosum, Fucus vesiculosus), low‐intertidal Irish moss (Chondrus crispus), subtidal laminarian kelps (Saccharina latissima, Laminaria digitata) and the invasive Codium fragile.LocationNorthwest Atlantic.MethodsWe used occurrence records and the correlative presence‐only species distribution model Maxent to determine present‐day distribution. This distribution was compared to each species’ warm‐water physiological thresholds indicating areas of stable or reduced growth and mortality. Present‐day models were then projected to mid‐century (2040–2050) and end‐century (2090–2100) using two contrasting carbon emission scenarios (RCP2.6 and 8.5) and two global climate models from CMIP5 based on changes in ocean temperatures.ResultsProjected range shifts were minimal under low emissions (RCP2.6), but substantial species‐specific range shifts were projected under high emissions (RCP8.5), with all species except C. fragile predicted to experience a northward shift in their southern (warm) edge of ≤406 km by the year 2100. Northward expansions outweighed southern extirpations for fucoids and C. crispus leading to overall range expansions, while range contractions were projected for kelps and C. fragile. Model projections generally agreed with physiological thresholds but were more conservative suggesting that range shifts for kelps may be underpredicted.Main conclusionsOur results highlight the benefits to be gained from strong climate change mitigation (RCP2.6), which would limit changes in rocky shore community distribution and composition. The business‐as‐usual RCP8.5 scenario projected major range shifts, seaweed community reorganization and transitions in dominant species south of Newfoundland by 2100 (~47°N). As canopy‐forming seaweeds provide essential habitat, carbon storage, nutrient cycling and commercial value, understanding their response to continued climate warming is critical to inform coastal management and conservation planning.\n",
      "--------------------------------------------------\n",
      "Topic 296: 296_announced_polykemi_hydrocarbon resources_renewable\n",
      "Representative Documents:\n",
      "  -                This article examines and analyses the environmental civil public interest litigation system in the protection of climate change in China through two cases, the All-China Environment Protection Federation v Zhenhua Co, Ltd for air pollution and Friends of Nature v State Grid Gansu Electric Power Corporation for full-purchase of all on-grid power produced by renewable energy.\n",
      "  -                In India, effective use of hydrocarbon fuels are essential for achieving energy security, economic growth, climate goals and to bridge the implementation delays in the renewable energy sector. Based on the published data, the paper reviews the role of hydrocarbon resources in the Indian energy sector and the need for an innovation-centered ecosystem in the areas of clean-coal usage, natural gas, sequestration and utilizing unconventional hydrocarbon resources.\n",
      "  -  The European Clean Hydrogen Alliance is targeting an ambitious deployment of hydrogen technologies by 2030, bringing together renewable and low-carbon hydrogen production, demand in industry, mobility and other sectors, and hydrogen transmission and distribution. The European Union sees the Alliance as helping to build its global leadership in this domain, supporting its commitment to reaching carbon neutrality by 2050. \n",
      "--------------------------------------------------\n",
      "Topic 297: 297_degassing_volcanic_co2 flux_volcano\n",
      "Representative Documents:\n",
      "  - Volcanic eruptions are often preceded by precursory increases in the volcanic carbon dioxide (CO2) flux. Unfortunately, the traditional techniques used to measure volcanic CO2 require near-vent, in situ plume measurements that are potentially hazardous for operators and expose instruments to extreme conditions. To overcome these limitations, the project BRIDGE (BRIDging the gap between Gas Emissions and geophysical observations at active volcanoes) received funding from the European Research Council, with the objective to develop a new generation of volcanic gas sensing instruments, including a novel DIAL-Lidar (Differential Absorption Light Detection and Ranging) for remote (e.g., distal) CO2 observations. Here we report on the results of a field campaign carried out at Mt. Etna from 28 July 2016 to 1 August 2016, during which we used this novel DIAL-Lidar to retrieve spatially and temporally resolved profiles of excess CO2 concentrations inside the volcanic plume. By vertically scanning the volcanic plume at different elevation angles and distances, an excess CO2 concentration of tens of ppm (up to 30% above the atmospheric background of 400 ppm) was resolved from up to a 4 km distance from the plume itself. From this, the first remotely sensed volcanic CO2 flux estimation from Etna’s northeast crater was derived at ≈2850–3900 tons/day. This Lidar-based CO2 flux is in fair agreement with that (≈2750 tons/day) obtained using conventional techniques requiring the in situ measurement of volcanic gas composition.\n",
      "  - The Fangaia mud pool provides a “window” into the hydrothermal system underlying the degassing Solfatara crater, which is the most active volcanic centre inside the restless Campi Flegrei caldera, Southern Italy. The present study aimed at unravelling the degassing dynamics of CO2 and H2S flushing through the pH 1.2 steam-heated Fangaia mud pool, an ideal field laboratory as a proxy of an active crater lake. Our results from MultiGAS measurements above Fangaia’s surface show that H2S scrubbing, demonstrated by high CO2/H2S ratios, was most efficient in the portions of the basin affected by diffusive degassing. Convective bubbling degassing instead was the most effective mechanism to release gas in quantitative terms, with lower CO2/H2S ratios, similar to the Solfatara crater fumaroles, the high-T end member of the hydrothermal system. Unsurprisingly, total estimated CO2 and H2S fluxes from the small Fangaia pool (~184 m2 in June 2017) were at least two orders of magnitude lower (CO2 flux &lt; 64 t/d, H2S flux &lt; 0.5 t/d) than the total CO2 flux of the Campi Flegrei caldera (up to 3000 t/d for CO2), too low to affect the gas budget for the caldera, and hence volcano monitoring routines. Given the role of the rising gas as “sediment stirrer”, the physical and chemical processes behind gas migration through a mud pool are arguably the creating processes giving origin to Fangaia. Follow-up studies of this so far unique campaign will help to better understand the fast dynamics of this peculiar degassing feature.\n",
      "  - There have been substantial advances in the ability to monitor the activity of hazardous volcanoes in recent decades. However, obtaining early warning of eruptions remains challenging, because the patterns and consequences of volcanic unrests are both complex and nonlinear. Measuring volcanic gases has long been a key aspect of volcano monitoring since these mobile fluids should reach the surface long before the magma. There has been considerable progress in methods for remote and in-situ gas sensing, but measuring the flux of volcanic CO2—the most reliable gas precursor to an eruption—has remained a challenge. Here we report on the first direct quantitative measurements of the volcanic CO2 flux using a newly designed differential absorption lidar (DIAL), which were performed at the restless Campi Flegrei volcano. We show that DIAL makes it possible to remotely obtain volcanic CO2 flux time series with a high temporal resolution (tens of minutes) and accuracy (&lt;30%). The ability of this lidar to remotely sense volcanic CO2 represents a major step forward in volcano monitoring and will contribute improved volcanic CO2 flux inventories. Our results also demonstrate the unusually strong degassing behavior of Campi Flegrei fumaroles in the current ongoing state of unrest.\n",
      "--------------------------------------------------\n",
      "Topic 298: 298_forest_forests_es_management\n",
      "Representative Documents:\n",
      "  - Developing adaptive forest management strategies is essential to maintain the provisioning of forest goods and services (FGS) under future climate change. We assessed how climate change and forest management affect forest development and FGS for a diverse case‐study landscape in Central Europe. Using a process‐based forest model (LandClim) we simulated forest dynamics and FGS under a range of climate change and management scenarios in the Black Forest, Germany, which is shaped by various management practices. We focused on the interdependencies between timber production and forest diversity, the most valued FGS in this region.We found that the conversion to more drought‐adapted forest types is required to prevent climate change‐induced forest dieback and that this conversion must be the target of any adaptive management, especially in areas where monocultures of drought‐sensitive Norway spruce (Picea abies) were promoted in the past. Forest conversion takes up to 120 years, however, with past and future adaptive management being the key drivers of timber and forest diversity provision. The conversion of drought‐sensitive conifer monocultures maintains timber production in the short term and enhances a range of forest diversity indices. Using uneven‐aged forest management that targets a drought‐adapted, diverse, and resilient species mixture, high species diversity can be combined with timber production in the long term. Yet, the promotion of mature‐stand attributes requires management restrictions. Selecting future adaptive management options thus implies the consideration of trade‐offs between forest resource use and environmental objectives, but also the exploitation of synergies between FGS that occur during forest conversion. Lastly, the large impact of past management practices on the spatial heterogeneity of forest dynamics underpins the need to assess FGS provisioning at the landscape scale.\n",
      "  - Restoring degraded forest ecosystems is an important element in the ongoing challenge to sustain the integrity and functioning of the biosphere. However, the evaluation of restoration success is hampered by long lead times of management measures in forests. Moreover, forest change is accelerating also in the absence of management because of ongoing climate change. Yet, because a counterfactual is frequently missing, it remains unclear whether restoration measures are aided or impeded by climate change.Here, we analysed the pace and success of forest restoration under climate change, combining field data and simulation modelling. We focused on the management zone of Berchtesgaden National Park (BGNP), Germany, where restoration aims to restore homogeneous Norway spruce (Picea abies) forests to structurally diverse mixed mountain forests. We evaluated three alternative restoration strategies: Two active strategies focused on planting the currently underrepresented silver fir (Abies alba) and European beech (Fagus sylvatica) but differing in the creation of gap‐cuts, and a third passive restoration strategy without interventions. Strategies were simulated with the forest landscape model iLand from 2020 to 2100 under different climate scenarios (historic, RCP 2.6, 4.5, and 8.5).The forests of BGNP developed into structurally diverse and mixed forests under all evaluated management strategies, and differences between active and passive restoration were generally small. While restoration goals for forest structure were largely met by 2100, forest composition remained far from target in all strategies. Climate change aided restoration by significantly increasing the prevalence of silver fir and European beech (+104.2% to +258.6%). Field data on short‐term restoration effects were in line with simulated long‐term trajectories.Synthesis and applications: We here show that forest restoration efforts in Central European mountain forests will likely be accelerated by climate change. Nonetheless, the slow pace of restoration underscores the need for taking action. Our study highlights that active restoration measures such as tree planting can bring the system closer to restoration targets. However, it also demonstrates that passive restoration (no intervention) is a viable option for management, highlighting the need to evaluate restoration measures against the counterfactual of a no intervention strategy.\n",
      "  - SummaryEcosystem services (ES) from mountain forests are highly relevant for human societies. ES with a direct economic support function (e.g. timber production), regulatory services (e.g. protection from natural hazards) and cultural services (e.g. recreation) are likely to be affected strongly by a rapidly changing climate. To evaluate whether adverse climate change effects on ES can be counteracted by adapting management, dynamic models and indicator‐based assessments are needed.We applied a forest dynamic model in case study areas of four European mountain regions and evaluated the future supply of four ES – timber production, carbon sequestration, biodiversity and protection against natural hazards – using state‐of‐the‐art ES indicators. Forest dynamics were simulated under three management scenarios (no management, business‐as‐usual and alternative management) and five climate change projections for selected representative stand types in each region. We analysed potential trade‐offs and synergies between ES and evaluated future changes among regions, forest stands, climate and management scenarios.Impacts of climate change on the provision of multiple ES were found to be highly heterogeneous and to depend on the region, site and future climate. In the absence of large‐scale natural disturbance (not considered), protection services, carbon stock and deadwood abundance (proxy for biodiversity) benefitted from no management in all regions. Negative impacts of climate change were evident for the provision of multiple ES but limited to the most severe climate scenarios and low‐elevation stands. Synergies and trade‐offs between the majority of ES were found to be sensitive to the choice of management strategy and – in some regions – to climate change.Synthesis and applications. Management regimes in European mountain forests should be regionally adapted to stand and site conditions. Although in some cases alternative management regimes may be more suitable than current management for supporting multiple ecosystem services, adaptation options should be evaluated carefully at the local scale due to the highly different magnitude of the impacts of climate change in different regions and along elevation gradients.\n",
      "--------------------------------------------------\n",
      "Topic 299: 299_card10_nudging_regional_tmecsr\n",
      "Representative Documents:\n",
      "  -                This study evaluates interior nudging techniques using the Weather Research and Forecasting (WRF) model for regional climate modeling over the conterminous United States (CONUS) using a two-way nested configuration. NCEP–Department of Energy Atmospheric Model Intercomparison Project (AMIP-II) Reanalysis (R-2) data are downscaled to 36 km × 36 km by nudging only at the lateral boundaries, using gridpoint (i.e., analysis) nudging and using spectral nudging. Seven annual simulations are conducted and evaluated for 1988 by comparing 2-m temperature, precipitation, 500-hPa geopotential height, and 850-hPa meridional wind to the 32-km North American Regional Reanalysis (NARR). Using interior nudging reduces the mean biases for those fields throughout the CONUS compared to the simulation without interior nudging. The predictions of 2-m temperature and fields aloft behave similarly when either analysis or spectral nudging is used. For precipitation, however, analysis nudging generates monthly precipitation totals, and intensity and frequency of precipitation that are closer to observed fields than spectral nudging. The spectrum of 250-hPa zonal winds simulated by the WRF model is also compared to that of the R-2 and NARR. The spatial variability in the WRF model is reduced by using either form of interior nudging, and analysis nudging suppresses that variability more strongly than spectral nudging. Reducing the nudging strengths on the inner domain increases the variability but generates larger biases. The results support the use of interior nudging on both domains of a two-way nest to reduce error when the inner nest is not otherwise dominated by the lateral boundary forcing. Nevertheless, additional research is required to optimize the balance between accuracy and variability in choosing a nudging strategy.\n",
      "  - Over the past few years, a new type of global climate model (GCM) has emerged in which a two‐dimensional or small three‐dimensional cloud resolving model is embedded into each grid cell of a GCM. This approach is frequently called the multiscale modeling framework (MMF) but is also known as a cloud‐resolving convection parameterization or a superparameterization. In this article, we compare joint histograms of cloud top height and optical depth from the MMF with those being produced by the International Satellite Cloud Climatology Project (ISCCP) and from the Multiangle Imaging Spectroradiometer (MISR). While the form of the ISCCP and MISR data sets is conceptually similar, the satellite sensors and the algorithms differ, with the result that the joint histograms can differ quite significantly even when viewing exactly the same clouds. The analysis takes advantages of the strengths of each data set, as well as the differences in these data (which, for example, allow one to characterize the amount of some multilayer clouds). MMF simulation runs with three different resolutions are analyzed. One simulation is run using a 4 km horizontal grid with 26 vertical levels (on a stretched grid), a second simulation is run with a 1 km horizontal grid and the same 26 vertical levels, and a third simulation is run with a 1 km horizontal grid and 52 vertical levels. The analysis shows that the MMF reproduces the broad pattern of tropical convergence zones, subtropical belts, and midlatitude storm tracks as observed by ISCCP and MISR. However, the model has several significant shortcomings. Perhaps most seriously, it significantly underpredicts the amount of low‐level cloud in most regions. The simulation with a 1 km horizontal grid and 52 vertical layers is found to improve modestly several aspect of the MMF low‐level cloud cover. The model output is obtained using ISCCP and MISR instrument simulators and the role of horizontal resolution in the instrument simulators is examined.\n",
      "  -                The California Reanalysis Downscaling at 10 km (CaRD10) was compared with the North American Regional Reanalysis (NARR), which is a data assimilation regional analysis at 32-km resolution and 3-hourly output using the Eta Model for the period 1979 through the present using the NCEP/Department of Energy (DOE) reanalysis as lateral boundary conditions. The objectives of this comparison are twofold: 1) to understand the efficacy of regional downscaling and horizontal resolution and 2) to estimate the uncertainties in regional analyses due to system differences.               The large-scale component of atmospheric analysis is similar in CaRD10 and NARR. The CaRD10 daily winds fit better to station observations than NARR over ocean where daily variability is large and over land. The daily near-surface temperature comparison shows a similar temporal correlation with observations in CaRD10 and NARR. Several synoptic examples such as the Catalina eddy, coastally trapped wind reversal, and Santa Ana winds are better produced in CaRD10 than NARR. These suggest that the horizontal resolution of the model has a large influence on the regional analysis, and the near-surface observation is not properly assimilated in the current state-of-the-art regional data assimilation system.               The CaRD10 near-surface temperature and winds on monthly and hourly scales are similar to NARR with more regional details available in CaRD10. The Southwestern monsoon is poorly reproduced in CaRD10 because of the position of the lateral boundary. The spatial pattern of the two precipitation analyses is similar, but CaRD10 shows smaller-scale features despite a positive bias. The trends of 500-hPa height and precipitation are similar in the two analyses but the near-surface temperature trend spatial patterns do not agree, suggesting the importance of regional topography, model physics, and land surface schemes. A comparison of a major storm event shows that both analyses suffer from budget residual. CaRD10’s large precipitation is related to wind direction, spatial distribution of precipitable water, and a large moisture convergence.               Dynamical downscaling forced by a global analysis is a computationally economical approach to regional-scale long-term climate analysis and can provide a high-quality climate analysis comparable to current state-of-the-art data-assimilated regional reanalysis. However, uncertainties in regional analyses can be large and caution should be exercised when using them for climate applications.\n",
      "--------------------------------------------------\n",
      "Topic 300: 300_heavy oil_co2 heavy oil_co2 heavy_oil\n",
      "Representative Documents:\n",
      "  - SummaryIn this paper, techniques have been developed to examine the enhanced swelling effect and viscosity reduction of CO2-saturated heavy oil with the addition of either solvent C3H8 or solvent n-C4H10. Experimentally, pressure/volume/temperature (PVT) tests are conducted to measure the saturation pressure, swelling factor, and viscosity of the C3H8/heavy-oil system, the C3H8/CO2/heavy-oil system, and the n-C4H10/CO2/heavy-oil system, respectively, in the overall temperature range of 280.45 to 391.55 K. It has been found that an increased swelling effect of heavy oil is obtained by adding the gas solvent C3H8 or n-C4H10 into the CO2 stream. An enhanced viscosity reduction of the CO2/heavy-oil system is also achieved in the presence of either C3H8 or n-C4H10. The enhanced swelling effect and viscosity reduction caused by adding either C3H8 or n-C4H10 into the CO2 stream are particularly favorable for achieving a higher heavy-oil recovery compared with pure-CO2 processes. Theoretically, three binary-interaction-parameter (BIP) correlations in the Peng-Robinson (PR) equation of state (EOS) (PR-EOS) method have been proposed for respectively characterizing CO2/heavy-oil binaries, C3H8/heavy-oil binaries, and n-C4H10/heavy-oil binaries by treating each oil sample as a single pseudocomponent with its molecular weight (MW) and specific gravity (SG). The BIP correlations (together with the PR-EOS) can be used to predict the saturation pressures and swelling factors of the C3H8/CO2/heavy-oil system and the n-C4H10/CO2/heavy-oil system with a generally good accuracy.\n",
      "  - SummaryBy coupling heat and mass transfer for C3H8/n-C4H10/CO2/heavy-oil systems as well as by treating heavy oil as multiple pseudocomponents, a new technique together with its computational scheme has been developed to determine individual diffusion coefficients of alkane solvents and CO2 in heavy oil at high pressures and elevated temperatures by dynamic volume analysis (DVA). Experimentally, well-designed diffusion tests have been conducted for an n-C4H10/heavy-oil system, a CO2/heavy-oil system, an n-C4H10/CO2/heavy-oil system, and a C3H8/n-C4H10/CO2/heavy-oil system by using a visualized pressure/volume/temperature (PVT) setup. The volume change of liquid phase is monitored and recorded during the measurements, whereas the gas-chromatography (GC) method is used to determine the compositions of gas mixtures at the beginning and the end of the diffusion tests. Theoretically, the volume-translated Peng-Robinson (PR) equation of state (EOS) characterizing heavy oil as multiple pseudocomponents has been incorporated to develop a 2D heat-and-mass-transfer model for the aforementioned systems. The alternating-direction-implicit algorithm is applied to solve the 2D difference equations into which a moving gas/liquid interface has been successfully incorporated. The discrepancy between the measured and calculated dynamic-volume change and the discrepancy between the measured and calculated gas compositions at the end of diffusion tests have been minimized to determine the individual diffusion coefficients. Alkane solvents diffuse faster than CO2 in heavy oil, whereas addition of alkane solvent(s) into the CO2 stream not only enhances mass transfer, but also achieves an improved swelling effect of heavy oil. Among the four diffusion tests, the largest dynamic swelling factor at the end of the diffusion test is measured to be 1.118 for the C3H8/n-C4H10/CO2/heavy-oil system.\n",
      "  - Summary               A novel methodology was developed to determine the molecular-diffusion coefficient for each component of the solvent/CO2 mixture in heavy oil under reservoir conditions on the basis of the pressure-decay theory. Experimentally, molecular-diffusion tests for the solvent/CO2/heavy-oil systems (i.e., pure-CO2/heavy-oil system, C3H8/CO2/heavy-oil system, and n-C4H10/CO2/heavy-oil system) are performed with a DBR pressure/volume/temperature system at constant temperature and decayed pressure. Theoretically, the Peng-Robinson equation of state combined with a 1D diffusion model is developed to describe the diffusion process of solvent/CO2 mixture in heavy oil. The composition analysis in the beginning and the end of pressure-decay experiments for the solvent/CO2/heavy-oil system indicate that the gas-phase solvent fraction decreases as diffusion proceeds, whereas the gas-phase CO2 fraction increases during the tests. One can determine the individual molecular-diffusion coefficient for each component in the mixture by minimizing the discrepancy between the measured composition change and the calculated composition change with the diffusion model. The newly developed methodology is successfully validated with the diffusion tests on the two solvent/CO2 mixtures: C3H8/CO2/heavy-oil system and n-C4H10/CO2/heavy-oil system. As for the solvent/CO2 mixtures tested, the molecular-diffusion coefficient of solvent in heavy oil is found to be significantly larger than that of CO2 in heavy oil. At similar test conditions, the C3H8/CO2/heavy-oil system ends up with a swelling factor of 1.058 after 168 hours of diffusion test, in comparison to 1.031 for the CO2/heavy-oil system.\n",
      "--------------------------------------------------\n",
      "Topic 301: 301_responsibility_us_must_voices\n",
      "Representative Documents:\n",
      "  - Why does climate change continue to be a forceful idea which divides people? What does this tell us about science, about culture, and about the future? Despite disagreement, how might the idea of climate change nevertheless be used creatively? In this essay I develop my investigation of these questions using four lines of argument. First, the future risks associated with human‐caused climate change are severely underdetermined by science. Scientific predictions of future climates are poorly constrained; even more so the consequences of such climates for evolving human socio‐technological and natural ecosystems. Second, I argue that to act politically in the world, people have to pass judgments on the facts of science; facts do not speak for themselves. Third, because these judgments are different, the strategic goals of policy interventions developed in response to risks associated with future climate change are inevitably multiple and conflicting. Finally, reconciling and achieving diverse goals requires political contestation. “Moving forward” on climate change then becomes a task of investing in the discursive and procedural preconditions for an agonistic politics to work constructively, to enable ways of implementing policies when people disagree.\n",
      "  - Public discourse and political climate policymaking are based on scientific reports and propose technological solutions to solve the crisis, primarily by changing fossil fuels to renewable energy. Rather than questioning growth and the overuse of natural resources—which has been at the core of green concern for decades—green growth is the motor in an economy that aims for continuous economic spin, driven by new technological innovations that will enable us to go on as before, simply by replacing energy sources. It is no surprise that in such a discourse, the alternative voices—such as religious or spiritual responses—are left out, but to go from that and conclude that no such voices exist would be to rush to conclusions. I suggest that if we want to search for enchantment in times of climate change, we must look elsewhere. Searching for these voices means leaving the discourse framed by scientific rationalistic measurements because we can find an enchanted alter‐tale beyond this disenchanted tale. In this article, I account for voices from my field and answer the question: What motivates people to turn to spirituality in times of climate change?\n",
      "  - The author counters the prevailing pessimism about the environment, which he calls “Romantic Declinism,” with his own “Enlightenment humanism,” which is informed by science and belief in the possibility of progress. While sharing environmentalists’ goal of protecting the air and water, species, and ecosystems, the author begins with the conviction that environmental problems can be solved, given the right knowledge and proper use of it. Economic growth, while no doubt contributing to the problem, is also a major and essential part of the solution. Where Romantic Declinists see modern humans as “vile despoilers of a pristine planet,” the author views human ingenuity and technology as the path not to ecological suicide, but to a more prosperous, and eventually greener, global society.Enlightened environmentalism recognizes the human need to produce energy to lift itself out of poverty, and seeks the means to do so while minimizing the damage to the planet and the living world. As recounted by the author, the 200‐year trend of energy decarbonization provides clear evidence that, as the world gets richer and more technologically advanced, it “dematerializes, decarbonizes, and densifies,” thereby sparing land and species. And new technology, notably nuclear power, holds out the promise of generating electricity with little or no carbon emitted, while carbon capture holds out the possibility of removing CO2 from the atmosphere. As the author sums up this approach,Problems are solvable. That does not mean that they will solve themselves, but it does mean that we can solve them if we sustain the benevolent forces of modernity that have allowed us to solve problems so far, including societal prosperity, wisely regulated markets, international governance, and investments in science and technology.\n",
      "--------------------------------------------------\n",
      "Topic 302: 302_briefing_edge research case_pinpoint practical_latest management\n",
      "Representative Documents:\n",
      "  - PurposeThis paper aims to review the latest management developments across the globe and pinpoint practical implications from cutting-edge research and case studies.Design/methodology/approachThis briefing is prepared by an independent writer who adds their own impartial comments and places the articles in context.FindingsThe findings reported suggest that management support for fun and co-worker socializing at the office level are negatively and significantly related to turnover but not fun activities.Originality/valueThe briefing saves busy executives, strategists and researchers hours of reading time by selecting only the very best, most pertinent information and presenting it in a condensed and easy-to-digest format.\n",
      "  - PurposeThis paper aims to review the latest management developments across the globe and pinpoint practical implications from cutting-edge research and case studies.Design/methodology/approachThis briefing is prepared by an independent writer who adds their own impartial comments and places the articles in context.FindingsThe authors of the study find that servant leadership encourages employee creativity by supporting the development of a climate of creativity, which sets the right conditions for employees to engage in creative behaviors.Originality/valueThe briefing saves busy executives, strategists and researchers hours of reading time by selecting only the very best, most pertinent information and presenting it in a condensed and easy-to-digest format.\n",
      "  - PurposeThis paper aims to review the latest management developments across the globe and pinpoint practical implications from cutting-edge research and case studies.Design/methodology/approachThis briefing is prepared by an independent writer who adds their own impartial comments and places the articles in context.FindingsAuthentic leadership has a significant direct effect on innovative work behavior and readiness for change partially mediates the relationship between authentic leadership and innovative work behavior.Originality/valueThe briefing saves busy executives, strategists and researchers hours of reading time by selecting only the very best, most pertinent information and presenting it in a condensed and easy-to-digest format.\n",
      "--------------------------------------------------\n",
      "Topic 303: 303_enso_easr_niño_el niño\n",
      "Representative Documents:\n",
      "  -  There is a significant relationship between the preceding winter El Niño–Southern Oscillation (ENSO) and the subsequent East Asian summer rainfall (EASR), and this relationship is helpful for seasonal forecasting in East Asia. This study investigated the relationship between the preceding winter ENSO and EASR in the phase 5 of the Coupled Model Intercomparison Project (CMIP5) models and compared the results with those from the CMIP3 models. In general, the CMIP5 models capture the ENSO–EASR relationship more realistically than the CMIP3 models. For instance, approximately two-thirds of the CMIP5 models capture the ENSO–EASR relationship, whereas fewer than one-third of the CMIP3 models capture the relationship. Further investigation suggests that the improvement could be attributed to simulating the physical processes of ENSO’s impact on the EASR more realistically in the CMIP5 models, particularly the effect of ENSO on tropical Indian Ocean SST and the effect of Indian Ocean SST anomalies on the atmospheric convection over the Philippine Sea. However, there is large diversity in the ENSO–EASR relationship in the CMIP5 models, and most of the models underestimate the relationship. This underestimation comes from the underestimation of the physical processes, particularly from the underestimated impact of the atmospheric convection over the Philippine Sea on the EASR. The CMIP5 models that capture the ENSO–EASR relationship well (badly) also show high (low) skill in representing the physical processes. \n",
      "  -                Within the framework of the Zebiak–Cane model, the approach of conditional nonlinear optimal perturbation (CNOP) is used to study the effect of model parameter errors on El Niño–Southern Oscillation (ENSO) predictability. The optimal model parameter errors are obtained within a reasonable error bound (i.e., CNOP-P errors), which have the largest effect on the results of El Niño predictions. The resultant prediction errors were investigated in depth. The CNOP-P errors do not cause a noticeable prediction error of the sea surface temperature anomaly averaged over the Niño-3 region and do not show an obvious season-dependent evolution of the prediction errors. Consequently, the CNOP-P errors do not cause a significant spring predictability barrier (SPB) for El Niño events. In contrast, the initial errors that have the largest effect on the results of the predictions (i.e., the CNOP-I errors) show a season-dependent evolution, with the largest error increase in spring, and also cause a large prediction error, thereby generating a significant SPB. The initial errors play a more important role than the parameter errors in generating a significant SPB for El Niño events. To further validate this result, the authors investigated the situation in which CNOP-I and CNOP-P errors are simultaneously superimposed in the model, which may be a more credible approach because the initial errors and model parameter errors coexist under realistic predictions. The combined mode of CNOP-I and CNOP-P errors shows a similar season-dependent evolution to that of CNOP-I errors and yields a large prediction error, thereby inducing a significant SPB. The inference, therefore, is that initial errors play a more important role than model parameter errors in generating a significant SPB for El Niño predictions of the Zebiak–Cane model. This result helps to clarify the roles of the initial error and parameter error in the development of an SPB, and highlights the role of initial errors, which demonstrates that the SPB could be markedly reduced by improving the initial conditions. The results provide a theoretical basis for improving data assimilation in ENSO predictions.\n",
      "  - The El Niño-Southern Oscillation (ENSO) in the preceding winter (December-January-February) is one of the key factors affecting subsequent East Asian summer (June-July-August) rainfall (EASR). However, current models face great challenges in reproducing ENSO’s impact on the EASR. This study attempts to reveal the factors that determine whether a model in phase 6 of the Coupled Model Intercomparison Project (CMIP6) can successfully reproduce this relationship by analyzing the outputs of historical climate simulation in 20 CMIP6 models. The results show that most of the models that overestimated ENSO interannual variability reproduced significant ENSO-EASR relationships, whereas all models that underestimated ENSO variability failed to reproduce this relationship. Further analyses show that models with stronger ENSO variability tended to simulate more realistic physical processes linking ENSO and EASR, i.e. the connections between ENSO and the tropical Indian Ocean (TIO) sea surface temperature (SST), between TIO SST and the Philippine Sea convection (PSC), and between PSC and EASR. Moreover, among the models that overestimated ENSO variability, only those that successfully captured significant TIO SST-PSC connections reproduced the observed ENSO-EASR relationship, although all these models captured ENSO-TIO SST and PSC-EASR teleconnections well. Therefore, simulating stronger ENSO interannual variability is the first necessary precondition for a CMIP6 model to capture the delayed effect of ENSO on EASR; reproducing a realistic TIO SST-PSC teleconnection is the second necessary precondition. This study will help models to improve their skills in simulation and prediction of EASR.\n",
      "--------------------------------------------------\n",
      "Topic 304: 304_health_debriefing_gaming debriefing_simulation gaming debriefing\n",
      "Representative Documents:\n",
      "  - Two of this century's most significant public health challenges are climate change and healthy aging. The future of humanity will be both warmer and older than it is today. Is it socially responsible, in a warming planet of a population exceeding 8 billion people, for science to aspire to develop gerotherapeutic drugs that aim to reduce the burden of aging‐related diseases that may also increase lifespan? This question is the “elephant in the room” for geroscience advocacy. Science communication concerning what constitutes empirically valid and morally defensible ways of navigating the dual public health predicaments of climate change and healthy aging must be sensitive to both the interdependence of the environment (including planetary health) and the mechanisms of aging, as well as the common (mis)perceptions about the potential conflict between the goals of climate science and geroscience. Geroscience advocacy can transcend narratives of intergenerational conflict by highlighting the shared aspirations of climate science and geroscience, such as the goals of promoting health across the lifespan, redressing health disparities, and improving the economic prospects of current and future generations.\n",
      "  - Together with other stressors, interactions between fire and climate change are expressing their potential to drive ecosystem shifts and losses in biodiversity. Closely linked to human well-being in most regions of the globe, fires and their consequences should no longer be regarded as repeated surprise events. Instead, we should regard fires as common and enduring components of most terrestrial systems, including their social context. At the global scale, too much fire and the wrong kinds of fire are trumping not enough fire as the most influential fire problems we must address. Intensified fire suppression and government prohibition of burning is not a long-term solution at the global scale. Acknowledging the importance of programs to reduce emissions from deforestation and forest degradation, I propose that fire ecologists come together to elevate attention on four less-discussed priorities: ecological systems in which people depend on fire for survival and well-being; systems in which governments unwisely insist on command and control approaches to fire; places where peatlands are burning; and, places where climate-driven changes in fire will cause type conversion. Finally, I propose holding a worldwide fire summit to debate these priorities and to create fire management goals at the global scale. Taken all together, these proposed steps could enable fire ecologists to mount a worldwide offensive to shape the future of fire in the era of climate change.\n",
      "  -  This editorial outlines a number of connections between climate change and simulation/gaming/debriefing. First, the development of this symposium is mentioned, including appreciation for contributors, especially Klaus Eisenack, James E. Hansen, Dennis Meadows, and Diana Reckien. Second, a wide range of climate change dimensions is outlined, with emphasis on the increasingly important role that simulation/gaming and debriefing should play in educating people to combat climate change. Climate issues include anthropogenic warming, due largely to ever-increasing greenhouse gas emissions, resulting in massive and irreversible upheaval of the biosphere and the socioeconomic system. Given the massive direct and indirect negative impact of climate change on health and mortality, due largely to the lethargy of politicians and big business, such people, in a saner world, could be facing accusation of crimes against humanity. The topic of climate change needs to become the backbone of education round the world, with simulation/gaming and debriefing being one of the main methods for learning to survive in ‘pockets of resilience’. Topics for simulation/games and debriefing could include resilience, urgency, climate change science, indicators, and effects (feedback loops, rising sea levels, storm severity, food scarcity and security, water, war, denial, nuclear power, irresponsibility of politicians, etc.). Third, the absurdities of the push for growth in a finite world and of the burning of more coal are highlighted. Simulation/gaming and debriefing provide opportunities for learning to survive with a dangerously changing climate. \n",
      "--------------------------------------------------\n",
      "Topic 305: 305_geoengineering_policy_ce_stern\n",
      "Representative Documents:\n",
      "  - Although solar geoengineering (alternatively ‘solar radiation management’ or ‘solar radiation modification’) appears to offer a potentially effective, inexpensive and technologically feasible additional response to climate change, it would pose serious physical risks and social challenges. Governance of its research, development and deployment is thus salient. This article reviews proposals for governing solar geoengineering. Its research may warrant dedicated governance to facilitate effectiveness and to reduce direct and socially mediated risks. Because states are not substantially engaging with solar geoengineering, non-state actors can play important governance roles. Although the concern that solar geoengineering would harmfully lessen abatement of greenhouse gas emissions is widespread, what can be done to reduce such displacement remains unclear. A moratorium on outdoor activities that would surpass certain scales is often endorsed, but an effective one would require resolving some critical, difficult details. In the long term, how to legitimately make decisions regarding whether, when and how solar geoengineering would be used is central, and suggestions how to do so diverge. Most proposals to govern commercial actors, who could provide goods and services for solar geoengineering, focus on intellectual property policy. Compensation for possible harm from outdoor activities could be through liability or a compensation fund. The review closes with suggested lines of future inquiry.\n",
      "  - The prospect of climate engineering (CE) – also known as geoengineering, referring to modification of the global environment to partly offset climate change and impacts from elevated atmospheric greenhouse gases – poses major, disruptive challenges to international policy and governance. If full global cooperation to manage climate change is not initially achievable, adding CE to the agenda has major effects on the challenges and risks associated with alternative configurations of participation – for example, variants of partial cooperation, unilateral action, and exclusion. Although the risks of unilateral CE by small states or non-state actors have been over-stated, some powerful states may be able to pursue CE unilaterally, risking international destabilization and conflict. These risks are not limited to future CE deployment, but may also be triggered by unilateral research and development (R&amp;D), secrecy about intentions and capabilities, or assertion of legal rights of unilateral action. They may be reduced by early cooperative steps, such as international collaboration in R&amp;D and open sharing of information. CE presents novel opportunities for explicit bargaining linkages within a complete climate response. Four CE-mitigation linkage scenarios suggest how CE may enhance mitigation incentives, and not weaken them as commonly assumed. Such synergy appears to be challenging if CE is treated only as a contingent response to a future climate crisis, but may be more achievable if CE is used earlier and at lower intensity, either to reduce peak near-term climate disruption in parallel with a programme of deep emission cuts or to target regional climate processes linked to acute global risks.\n",
      "  -                The impacts of climate change are not distributed equally. Some people will experience natural disasters first hand, some will be affected more gradually over time, and some will experience only indirect impacts. There are data from the United nations that show the interest of youth on climate change. Close to half a million youth around the world have taken action on climate change through SGP [small grants programmes] projects in their homes, schools and communities. (UNDP, 2015). 84% of the surveyed young people agree that they need more information to prevent climate change. (UNEP, 2011). Furthermore, about 73% of surveyed youth say they currently feel the effects climate change. (UNEP, GlobeScan Survey, 2008). Some 89% of youth respondents say young people can make a difference on climate change. [UNEP, 2008]. But only 9% of youth are very confident the world will act quickly enough to address climate change. [UNEP, 2008]. Young people are key actors in raising awareness, running educational programmes, promoting sustainable lifestyles, conserving nature, supporting renewable energy, adopting environmentally-friendly practices and implementing adaptation and mitigation projects[UNFCCC]. Action by youth, as protest school strikes or speeches to the UN by Greta Thunberg, urge immediate action from governments, business leaders and school leaders. There are different reasons for this action by youth. The psycho-social impacts of a changing climate are generally under lighted in these reasons. Are the responses by society enough to minimize suffering and promote resilience of youth in the face of the challenging impacts of climate change? Or do governments and businesses enough while they increasingly seem to be moving toward action on climate change, as they proclaim to cut their own emissions or be active in their energy transition? It is not clear whether those actions are enough to satisfy the next generation of customers, employees and decision makers.\n",
      "--------------------------------------------------\n",
      "Topic 306: 306_water_insurance_drainage_sustainable drainage\n",
      "Representative Documents:\n",
      "  - Climate change is challenging the conventional approaches for water systems planning. Two main approaches are commonly implemented in the design of climate change adaptation plans: impact-oriented top-down approaches and vulnerability-oriented bottom-up approaches. In order to overcome the shortcomings of both approaches and take advantage of their strengths, we propose an integrative methodology to define adaptation strategies at basin scale, identifying and combining potential changes in water demand and water supply infrastructure along with climate variability and change. The impact of climate change on future local water availability is assessed applying a top-down approach. Local knowledge is used through a participatory bottom-up approach to foresee future scenarios of evolution of the agricultural sector and agricultural water demand, and to identify locally relevant adaptation strategies. A hydroeconomic model integrates the information from both approaches to identify a socially acceptable and cost-effective program of measures for each climate scenario. This method was applied to the Jucar basin, a highly regulated basin with a tight equilibrium between water resources and demands. The results show an important variability of climate change impacts across the basin, with main inflow reductions in the headwaters. The stakeholders prioritized the adaptation options of change to drip irrigation, use of non-conventional resources, and changes in water governance. The results obtained from the hydroeconomic model show that the portfolio of selected adaptation measures could significantly reduce the system’s average annual deficit and cost.\n",
      "  - With a wide spectrum of data, case studies, monitoring, and experimental and numerical simulation techniques, the multidisciplinary approach of material, environmental, and computer science applied to the conservation of cultural heritage offers several opportunities for the heritage science and conservation community to map and monitor the state of the art of the knowledge referring to natural and human-induced climate change impacts on cultural heritage—mainly constituted by the built environment—in Europe and Latin America. The special issue “Preservation of Cultural Heritage and Resources Threatened by Climate Change” of Geosciences—launched to take stock of the existing but still fragmentary knowledge on this challenge, and to enable the community to respond to the implementation of the Paris agreement—includes 10 research articles. These papers exploit a broad range of data derived from preventive conservation monitoring conducted indoors in museums, churches, historical buildings, or outdoors in archeological sites and city centers. Case studies presented in the papers focus on a well-assorted sample of decay phenomena occurring on heritage materials—e.g., surface recession and biomass accumulation on limestone, depositions of pollutant on marble, salt weathering on inorganic building materials, and weathering processes on mortars in many local- to regional-scale study areas in the Scandinavian Peninsula, the United Kingdom, Belgium, France, Italy, Greece, and Panama. Besides monitoring, the methodological approaches that are showcased include, but are not limited to, original material characterization, decay product characterization, and climate and numerical modelling on material components for assessing environmental impact and climate change effects.\n",
      "  - Floods portray a severe problem in the riverine areas of West Africa while more frequent and intense heavy precipitation events are projected under climatic change scenarios. Already, floods cause manifold impacts, leaving the population to cope with the financial impacts of floods through their own means. As formal risk transfer mechanisms (e.g., insurance) are not yet widely available to the population, efforts to increase their accessibility are being intensified. However, studies assessing flood insurance demand currently mostly focus on regions with more established markets. Also, they are majorly applying conventional statistical modeling approaches that consider only a small number of parameters. Contrarily, this study aims to provide an approach for assessing flood insurance in a context of low previous exposure to such products, to allow for a better consideration of the research context. Therefore, a parameter selection framework is provided and machine learning and deep learning models are applied to selected parameters from an existing household survey data set. In addition, the deep learning sequential neural networks outperformed all machine learning models achieving an accuracy between 93.5—100% depending on the loss function and optimizer used. The risk to be covered, insurance perception, no access to any source, access to support from community solidarity funds, access to governmental support, or drawing upon own resources for financial coping, financial recovery time, lack of means and prioritizing more essential needs emerged as important model parameters in researching insurance demand. Future roll-out campaigns could consider the parameters pointed out by this study.\n",
      "--------------------------------------------------\n",
      "Topic 307: 307_scientific reports number_reports number_scientific reports_updated\n",
      "Representative Documents:\n",
      "  - Scientific Reports 6: Article number: 32813; published online: 09 September 2016; updated: 10 July 2017. This Article contained errors. In the original version, Affiliations 2 and 4 were incorrectly listed as 4 and 2 respectively. The correct affiliations are listed below: 2 CAS Center for Excellence in Tibetan Plateau Earth Sciences, Beijing 100101, China.\n",
      "  - Scientific Reports 7: Article number: 45242; published online: 27 March 2017; updated: 26 May 2017. This Article contains an error in Figure 1a, where the y-axis ‘Temperature (K)’ is incorrectly labelled as ‘Temperature (°C)’. The correct Figure 1 appears below.\n",
      "  - Nature Communications 8: Article number: 15875 (2017); Published 20 June 2017; Updated 22 December 2017 In Fig. 2 of the original Article, information indicating the extent of the lagged correlations between low-passed and detrended time series was inadvertently omitted during the production process. The correct version of this figure appears below as Fig.\n",
      "--------------------------------------------------\n",
      "Topic 308: 308_waste_wood waste_biogas_wood\n",
      "Representative Documents:\n",
      "  -                Global annual textile consumption has doubled in the last two decades and is expected to keep increasing. Since the textile system operates primarily in a linear way, it is highly polluting and creates a lot of waste. But nevertheless, it has a high potential for circularity since most textile products can be recycled or reused. Today most of the waste ends up in landfills, and less than 1 % is recycled back into textiles. This study aims to gather information and evaluate which textile product group has the highest potential for circular economy growth. It covers three main textile product streams: fashion, home, and technical textiles. The groups were compared using fifteen criteria: environmental impact, washes, landfilled waste, recycled waste, origin of fabric, projected lifetime, market demand, production volume, international trade, labour productivity, value added, energy efficiency of production technologies, innovation capacity, employment, and enterprises. Input values have been found for each sustainability indicator by using and mathematically transforming data from the scientific literature. The evaluation method used in this study was multi-criteria decision analysis. The results indicated that the fashion textile group has the most significant potential for circular economy development, mainly because it is the largest textile product stream, and the development of a circular economy could be cost-effective.\n",
      "  -                Polymer-based matrix composite materials are in high demand in many different fields: aeronautics, pressure vessel manufacturing, wind turbine blade manufacturing, and others. Due to the great mechanical properties of fiber reinforced plastics, it is a desirable material for various applications, but at the same time its heterogenic structure makes the composite waste hard to recycle. This paper focuses on different fiber reinforced plastics (FRP) waste recycling methods and their comparison by carrying out literature review and using multi-criteria decision making analysis (MCDA). Four polymer matrix composite waste recycling methods are compared to calculate which one has the best sustainability performance based on the chosen criteria. Analytical Hierarchy Process and TOPSIS are applied for criteria weighing and method comparison. Sensitivity analysis is used to evaluate the obtained results. It is concluded that more studies concerning different FRP waste recycling method sustainability performance need to be done, to derive more data, that would make MCDA more reliable and also other FRP waste recycling methods could be compared. Another conclusion is that different methods have different strengths which makes it hard to compare them. While FRP waste recycling is getting more broadly used, there still is a lot of work to establish wide spread effective system of FRP waste recycling that is both economically viable and gives the best results concerning recycled material quality.\n",
      "  -                Wood is an increasingly demanded biomaterial used in many industries, including construction, materials, furniture, packaging and energy production. Consumption trend indicates a significant increase in wood waste production, which could potentially be harnessed in various processes. In Europe, about 53 % of wood waste is incinerated while the 46 % is recycled. In Italy, almost the 95 % of wood waste is used in the production of chipboard and particleboard. There are many other processes available for enhancing wood recycling, but it is crucial to understand how to treat wood waste, depending on its source matrix. Wood waste is a heterogeneous material that may contain contaminants, pollutants and additives. Therefore, effective wood waste management relies on the analysis of its material composition, which provides valuable insights for waste management strategies. To address this need, a decision tool (DT) has been proposed for determining the destiny of wood waste based on its chemical composition. The DT provides quick recommendations by categorizing wood waste into four quality grades, primarily based on pollutant analysis. It assesses cellulose, lignin, hemicellulose content, and Lower Heating Value (LHV) to suggest recycling or incineration options for wood waste. Subsequently, this paper provides a brief overview of wood waste utilization. Finally, a case study is presented in which the DT was applied to wood waste obtained from a local waste management company in Perugia, Italy.\n",
      "--------------------------------------------------\n",
      "Topic 309: 309_term quality changes_term quality_water_quality changes\n",
      "Representative Documents:\n",
      "  - Water suppliers worldwide are challenged by climate variations, but so far only the qualitative change in boundary conditions has become clear but not yet the degree and impact on the water supply systems. Short-term quality changes in surface waters can, e.g. be caused by extreme rainfalls after dry periods. Longer heat periods without rain can induce middle-term quality changes in surface waters due to lacking dilution. Furthermore, unsustainable management of groundwater can lead to long-term quality changes and to water shortages, especially in times with higher water demand. Depending on the individual situation, the expected effects on the supply system differ widely, so a general adaptation strategy will not suit the individual problems. The purpose of our work is to enable water supply companies to systematically identify potential risks resulting from climate change and other external factors in a water safety plan approach, and to adapt the supply system in a most effective way by taking advantage of ongoing modernization measures and ‘no-regret’-measures. A suitable adaptation strategy should address climate change conditions as well as other external factors like changing water demand and also to take into account possible effects on every part of the supply system.\n",
      "  -                Adverse weather events occurring at sensitive stages of plant growth can cause substantial yield losses in crop production. Agricultural insurance schemes can help farmers to protect their income against downside risks. While traditional indemnity-based insurance schemes need governmental support to overcome market failure caused by asymmetric information problems, weather index–based insurance (WII) products represent a promising alternative. In WII the payout depends on a weather index serving as a proxy for yield losses. However, the nonperfect correlation of yield losses and the underlying index, the so-called basis risk, constitutes a key challenge for these products. This study aims to contribute to the reduction of basis risk and thus to the addition of risk-reducing properties of WII. More specifically, the study tests whether grid data for precipitation (vs weather station data) and phenological observations (vs fixed time windows for index determination) that are provided by public institutions can reduce spatial and temporal basis risk and thus improve the performance of WII. An empirical example of wheat production in Germany is used.               No differences were found between using gridded and weather station precipitation, whereas the use of phenological observations significantly increases expected utility. However, even if grid data do not yet reduce basis risk, they enable overcoming several disadvantages of using station data and are thus useful for WII applications. Based on the study’s findings and the availability of these data in other countries, a massive potential for improving WII can be concluded.\n",
      "  - . The design and evaluation of solutions for integrated surface water quality management requires an integrated modelling approach. Integrated models have to be comprehensive enough to cover the aspects relevant for management decisions, allowing for mapping of larger-scale processes such as climate change to the regional and local contexts. Besides this, models have to be sufficiently simple and fast to apply proper methods of uncertainty analysis, covering model structure deficits and error propagation through the chain of sub-models. Here, we present a new integrated catchment model satisfying both conditions. The conceptual iWaQa model was developed to support the integrated management of small streams. It can be used to predict traditional water quality parameters, such as nutrients and a wide set of organic micropollutants (plant and material protection products), by considering all major pollutant pathways in urban and agricultural environments. Due to its simplicity, the model allows for a full, propagative analysis of predictive uncertainty, including certain structural and input errors. The usefulness of the model is demonstrated by predicting future surface water quality in a small catchment with mixed land use in the Swiss Plateau. We consider climate change, population growth or decline, socio-economic development, and the implementation of management strategies to tackle urban and agricultural point and non-point sources of pollution. Our results indicate that input and model structure uncertainties are the most influential factors for certain water quality parameters. In these cases model uncertainty is already high for present conditions. Nevertheless, accounting for today's uncertainty makes management fairly robust to the foreseen range of potential changes in the next decades. The assessment of total predictive uncertainty allows for selecting management strategies that show small sensitivity to poorly known boundary conditions. The identification of important sources of uncertainty helps to guide future monitoring efforts and pinpoints key indicators, whose evolution should be closely followed to adapt management. The possible impact of climate change is clearly demonstrated by water quality substantially changing depending on single climate model chains. However, when all climate trajectories are combined, the human land use and management decisions have a larger influence on water quality against a time horizon of 2050 in the study.                    \n",
      "--------------------------------------------------\n",
      "Topic 310: 310_energy_ghg_emissions_ccas\n",
      "Representative Documents:\n",
      "  - Solar photovoltaic (PV) technology is a cornerstone of the global effort to transition towards cleaner and more sustainable energy systems. This paper explores the pivotal role of PV technology in reducing greenhouse gas emissions and combatting the pressing issue of climate change. At the heart of its efficacy lies the efficiency of PV materials, which dictates the extent to which sunlight is transformed into electricity. Over the last decade, substantial advancements in PV efficiency have propelled the widespread adoption of solar PV technology on a global scale. The efficiency of PV materials is a critical factor, determining how effectively sunlight is transformed into electricity. Enhanced efficiency, achieved through a decade of progress, has driven the global expansion of solar PV. Multi-junction photovoltaic materials have now exceeded 40% efficiency in lab tests. China leads the world in solar PV installations, boasting over 253 GW of installed capacity by the end of 2021. Other prominent countries in this sector are the United States, Japan, Germany, and India. Photovoltaic (PV) cell technologies are rapidly improving, with efficiencies reaching up to 30% and costs falling below $0.50/W, making PV a competitive source of energy in many countries around the world. Solar PV technology holds immense potential for creating a cleaner, reliable, scalable, and cost-effective electricity system. To expedite its deployment and foster a more sustainable energy future, continued investment in research and development along with supportive policies and market mechanisms is essential. This paper underscores the pivotal role of solar PV technology in the global energy transition and advocates for a concerted effort to unlock its full potential in achieving a more sustainable and resilient energy future.\n",
      "  - Despite a lack of action at the national level, the transition to carbon-free energy is becoming a reality across the United States. At the local level, community choice aggregators (CCAs)—which offer communities public control over their electricity purchasing decisions—are accelerating this transition. By forming these electricity providers, member cities and counties can choose how much renewable energy is offered to their residents and businesses. In California, CCAs have become an effective policy tool at accelerating the transition to clean energy. Across the state, 182 cities and counties have become members of one of the 23 CCAs, with additional communities planning to join or form CCAs in the next few years. These CCAs have been effective at unlocking market demand largely stifled by an investor-owned utility monopoly by giving cities and counties greater choice and access to renewable energy. The vast majority of these CCAs procure more renewable energy than the investor-owned utilities they compete with. As a result, CCAs purchased 204% of the renewable energy required by the state from 2011 to 2019. By achieving California’s carbon-free energy targets more quickly than mandated, the state benefits from a cumulatively larger reduction in greenhouse gas emissions each year. The success of CCAs in California demonstrates the power of promoting carbon-free energy at the grassroots, enabled by public, local choice in electricity supply. With six states considering CCA-enabling legislation, and with hundreds of cities and counties across the United States working toward a 100% carbon-free energy goal, policies like California Assembly Bill 117 (2002) that enabled CCAs can provide a valuable tool to accelerate the transition to carbon-free energy. The purpose of this paper is to assess how CCA-enabling policy can support the clean energy transition using California as a case study. We assess three conditions that affect a CCA’s ability to accelerate the clean energy transition: CCA customer characteristics, CCA design features, and their policy and regulatory context. We conclude with a discussion of policy recommendations important to ensure CCAs can continue to support clean energy goals.\n",
      "  -  Historical records have documented considerable changes to the global climate, with significant health, economic, and environmental consequences. Climate projections predict more intense hurricanes; increased sea level rise; and more frequent and more intense natural disasters such as heat waves, heavy rainfall, and drought in the future (1; 2). The coast along the Gulf of Mexico is particularly vulnerable to many of these environmental hazards and at particular risk when several strike simultaneously—such as a hurricane disrupting electricity transmission during a heat wave.  Due to its significant contribution to global greenhouse gas (GHG) emissions, the building sector already plays an important role in climate change mitigation efforts (e.g., reducing emissions). For example, voluntary programs such as the LEED (Leadership in Energy and Environmental Design) Rating System (3), the Architecture 2030 Challenge (4), the American College and University Presidents' Climate Commitment (5), and the Clinton Climate Initiative (6) focus almost exclusively on reducing energy consumption and increasing renewable energy generation. Mandatory regulations such as the International Energy Conservation Code (7), the International Green Building Code (8), and CalGreen (9) also emphasize GHG emission reduction targets.  This leadership role is necessary. After all, the United States EPA estimates that the building sector accounts for 62.7% of total annual GHG emissions in the U.S., when the construction sector, facility operations, and transportation are factored in. In fact, the construction sector alone is the third largest industrial emitter of GHGs after the oil and gas and chemical industries, contributing 1.7% of total annual emissions (10; 11).  As significant as these contributions appear, the built environment's true contribution to climate change is much larger than the GHG emissions attributed to building construction and operations. It is also a major determinant of which populations are vulnerable to climate change-related hazards, such as heat waves and flooding (12; 13). Architecture and land use planning can therefore be used as tools for building community resilience to the climate-related environmental changes underway (13).  Climate change regulations and voluntary programs have begun to incorporate requirements targeting the built environment's ability to work in tandem with the natural environment to both reduce greenhouse gas emissions and protect its occupants from the health consequences of a changing climate. For example, 11 states have incorporated climate change adaptation goals into their climate action plans (14). In 2010, the not-for-profit organization ICLEI: Local Governments for Sustainability launched a climate change adaptation program (15) to complement their existing mitigation program, which supports municipalities who have signed the U.S. Conference of Mayors' Climate Protection Agreement (16).  New tools have been introduced to measure community vulnerability to the impacts of climate change. One of these tools, Health Impact Assessments (or HIAs), has emerged over the past decade as a powerful methodology to provide evidence-based recommendations to decision makers and community planning officials about the likely health co-benefits and co-harms associated with proposed policies and land use development proposals (17). While HIAs are becoming a more common feature of community planning efforts, this paper introduces them as an approach to designing climate change resilience into specific building projects.  HIAs have been used in Europe and other parts of the world for decades to provide a science-based, balanced assessment of the risks and benefits to health associated with a proposed policy or program (18). In the U.S., they have been used over the past decade to evaluate transit-oriented developments, urban infill projects, and California's capand-trade legislation, among other topics (17; 19). To date, HIAs have been used mainly to inform large-scale community planning, land use, industrial, and policy decisions. However, the recommendations generated through the HIA process often bring to light previously unforeseen vulnerabilities, whether due to existing infrastructure, building technology, or socio-economic conditions.  Designers can make use of the HIA process and its resulting recommendations to prioritize design/retrofit interventions that will result in the largest co-benefits to building owners, the surrounding community, and the environment. An HIA focused on the health impacts of climate change will likely generate recommendations that could enhance the longevity of a building project's useful life; protect its property value by contributing to the resilience of the surrounding community; and result in design decisions that prioritize strategies that maximize both short-term efficiencies and long-term environmental, economic, and social value. \n",
      "--------------------------------------------------\n",
      "Topic 311: 311_cod_stock_recruitment_larvae\n",
      "Representative Documents:\n",
      "  -  The interplay between temperature-related processes and predation in determining age-1 recruitment strength between 1992 and 2006 was analysed for North Sea cod ( Gadus morhua ) and Norway pout ( Trisopterus esmarkii ). For this purpose, an predation impact index (PI) was calculated out of survey data. PI was assumed to depend on the abundance of the predators and on the spatial overlap between predator and prey populations. Generalized additive models (GAMs) were created with spawning stock biomass (SSB) and sea surface temperature (SST) in the respective spawning and nursery areas and PI as explaining variables. SSB had no significant impact on recruitment during this time period for both species. SSTs during spring and PI explained the interannual variability in recruitment strength to a large extent (88% of the total variance for cod and 68% for Norway pout). The SST during spring determined the overall level of recruitment. At SSTs above a certain level, however, the effect on recruitment was no longer significant. In these temperature ranges, predation was the dominant effect. Therefore, the fate of North Sea cod and Norway pout stocks under global-warming conditions will be strongly influenced by the status of the North Sea food web. \n",
      "  - Climate change and deoxygenation are affecting fish stocks on a global scale, but disentangling the impacts of these stressors from the effects of overfishing is a challenge. This study was conducted to distinguish between climate change and mismanagement as possible causes for the drastic decline in spawning stock size and reproductive success in cod (Gadus morhua) and herring (Clupea harengus) in the Western Baltic Sea, when compared with the good or satisfactory status and reproductive success of the other commercial species in the area. Available data on water temperature, wind speed, and plankton bloom during the spawning season did not reveal conclusive correlations between years with good and bad reproductive success of cod or herring. Notably, the other commercial species in the area have very similar life history traits suggesting similar resilience against stress caused by climate change or fishing. The study concludes that severe, sustained overfishing plus inappropriate size selectivity of the main fishing gears have caused the decline in spawning stock biomass of cod and herring to levels that are known to have a high probability of impaired reproductive success. It is pointed out that allowed catches were regulated by management and adhered to by the fishers, meaning that unregulated fishing did not occur. Thus, mismanagement (quotas that were too high and gears that selected too small sizes) and not climate change appears to be the primary cause of the bad status of cod and herring in the Western Baltic Sea.\n",
      "  - While a few North Atlantic cod stocks are stable, none have increased and many have declined in recent years. Although overfishing is the main cause of most observed declines, this study shows that in some regions, climate by its influence on plankton may exert a strong control on cod stocks, complicating the management of this species that often assumes a constant carrying capacity. First, we investigate the likely drivers of changes in the cod stock in the North Sea by evaluating the potential relationships between climate, plankton and cod. We do this by deriving a Plankton Index that reflects the quality and quantity of plankton food available for larval cod. We show that this Plankton Index explains 46.24% of the total variance in cod recruitment and 68.89% of the variance in total cod biomass. Because the effects of climate act predominantly through plankton during the larval stage of cod development, our results indicate a pronounced sensitivity of cod stocks to climate at the warmer, southern edge of their distribution, for example in the North Sea. Our analyses also reveal for the first time, that at a large basin scale, the abundance of Calanus finmarchicus is associated with a high probability of cod occurrence, whereas the genus Pseudocalanus appears less important. Ecosystem‐based fisheries management (EBFM) generally considers the effect of fishing on the ecosystem and not the effect of climate‐induced changes in the ecosystem state for the living resources. These results suggest that EBFM must consider the position of a stock within its ecological niche, the direct effects of climate and the influence of climate on the trophodynamics of the ecosystem.\n",
      "--------------------------------------------------\n",
      "Topic 312: 312_indices_oscillation_nao_index\n",
      "Representative Documents:\n",
      "  - Oceanic-atmospheric phenomena of different time scales concurrently might affect the streamflow in several basins around the world. The Atrato River Basin (ARB) and Patía River Basin (PRB) of the Colombian Pacific region are examples of such basins. Nevertheless, the relations between the streamflows in the ARB and PRB and the oceanic-atmospheric factors have not been examined considering different temporal scales. Hence, this article studies the relations of the climate indices and the variability of the streamflows in the ARB and PRB at interannual and decadal timescales. To this, the streamflow variability modes were obtained from the principal component analysis (PCA); furthermore, their linear dependence with indices of the El Niño/Southern Oscillation (ENSO), precipitation (PRP), the Choco low-level jet (CJ), and other indices were quantified through (a) Pearson and Kendall’s tau correlations, and (b) wavelet transform. The PCA presented a single significant mode for each basin, with an explained variance of around 80%. The correlation analyses between the PC1s of the ARB and PRB, and the climate indices showed significant positive (negative) high correlations with PRP, CJ, and Southern Oscillation Index (SOI) (ENSO indices). The wavelet coherence analysis showed significant coherencies between ENSO and ARB: at interannual (2–7 years) and decadal scale (8–14), preferably with the sea surface temperature (SST) in the east and west Tropical Pacific Ocean (TPO). For PRB with the SST in the central and western regions of the TPO in the interannual (4–8 years) and decadal (8–14 years) scales, the decreases (increases) in streamflow precede the El Niño (La Niña) events. These results indicate multiscale relations between the basins’ streamflow and climate phenomena not documented in previous works, relevant to forecast the extreme flow events in the Colombian Pacific rivers and for planning and implementing strategies for the sustainable use of water resources in the basins studied.\n",
      "  - Given that the analysis of past monthly rainfall variability is highly relevant for the adequate management of water resources, the relationship between the climate-oceanographic indices, and the variability of monthly rainfall in Southwestern Colombia at different time scales was chosen as the research topic. It should also be noted that little-to-no research has been carried out on this topic before. For the purpose of conducting this research, we identified homogeneous rainfall regions while using Non-Linear Principal Component Analysis (NLPCA) and Self-Organizing Maps (SOM). The rainfall variability modes were obtained from the NLPCA, while their teleconnection in relation to the climate indices was obtained from Pearson’s Correlations and Wavelet Transform. The regionalization process clarified that Nariño has two regions: the Andean Region (AR) and the Pacific Region (PR). The NLPCA showed two modes for the AR, and one for the PR, with an explained variance of 75% and 48%, respectively. The correlation analyses between the first nonlinear components of AR and PR regarding climate indices showed AR high significant positive correlations with Southern Oscillation Index (SOI) index and negative correlations with El Niño/Southern Oscillation (ENSO) indices. PR showed positive ones with Niño1 + 2, and Niño3, and negative correlations with Niño3.4 and Niño4, although their synchronous relationships were not statistically significant. The Wavelet Coherence analysis showed that the variability of the AR rainfall was influenced principally by the Niño3.4 index on the 3–7-year inter-annual scale, while PR rainfall were influenced by the Niño3 index on the 1.5–3-year inter-annual scale. The El Niño (EN) events lead to a decrease and increase in the monthly rainfall on AR and PR, respectively, while, in the La Niña (LN) events, the opposite occurred. These results that are not documented in previous studies are useful for the forecasting of monthly rainfall and the planning of water resources in the area of study.\n",
      "  - Recent studies show an increase in the frequency of compound extremes in air temperature and precipitation in many parts of the world, especially under dry and hot conditions. Compound extremes have a significant impact on all spheres of human activity, such as health, agriculture, and energy. Features of atmospheric circulation are closely related to the occurrence of anomalies in air temperature and precipitation. The article analyzes the relationship of atmospheric circulation modes with compound extremes that have had the greatest impact on the Atlantic–European region over the territory of Eastern Europe over the past 60 years on extreme air temperature and precipitation. Combinations of extreme temperature and humidity conditions (indices)—cold-dry (CD), cold-wet (CW), warm-dry (WD) and warm-wet (WW)—were used as compound extremes. Indices of compound extremes were calculated according to the E-OBS reanalysis data. Estimates of the relationship between two time series were carried out using standard correlation and composite analyses, as well as cross wavelet analysis. Phase relationships and time intervals for different climatic indices were different. The period of most fluctuations in the indices of compound extremes was from 4 to 12 years and was observed during 1970–2000. The coherent fluctuations in the time series of the WD and WW indices and the North Atlantic oscillation (NAO) index occurred rather in phase, those in the time series of the CD and WD indices and the Arctic oscillation (AO) index occurred in antiphase, and those in the time series of the WD and WW indices and the Scandinavia pattern (SCAND) index occurred in antiphase. Statistically significant increase in the number of warm compound extremes was found for the northern parts of the study region in the winter season with positive NAO and AO phases.\n",
      "--------------------------------------------------\n",
      "Topic 313: 313_vehicle_vehicles_co2 emissions_emission\n",
      "Representative Documents:\n",
      "  - Controlling NOx and CO2 emissions from heavy-duty diesel vehicles (HDDVs) is receiving increasing attention. Accurate measurement of HDDV NOx and CO2 emissions is the prerequisite for HDDV emission control. Vehicle emission regulations srecommend the measurement of NOx and CO2 emissions from vehicles using an emission analyzer, which is expensive and unsuitable to measure a large number of vehicles in a short time. The on-board diagnostics (OBD) data stream of HDDVs provides great convenience for calculating vehicle NOx and CO2 emissions by providing the engine fuel flow rate, NOx sensor output, and air mass flow. The calculated vehicle NOx and CO2 emissions based on the OBD data were validated by testing a heavy-duty truck’s emissions on the chassis dynamometer over the CHTC-HT driving cycle, showing that the calculated NOx and CO2 emissions based on the OBD data are consistent with the measured results by the emission analyzer. The calculated vehicle fuel consumptions based on the OBD data were close to the calculated results based on the carbon balance method and the measured results by the fuel flowmeter. The experimental results show that accessing vehicle NOx and CO2 emissions based on the OBD data is a convenient and applicable method.\n",
      "  - In order to reduce vehicle emitted greenhouse gases (GHGs) on a global scale, the scope of consideration should be expanded to include the manufacturing, fuel extraction, refinement, power generation, and end-of-life phases of a vehicle, in addition to the actual operational phase. In this paper, the CO2 emissions of conventional gasoline and diesel internal combustion engine vehicles (ICV) were compared with mainstream alternative powertrain technologies, namely battery electric vehicles (BEV), using life-cycle assessment (LCA). In most of the current studies, CO2 emissions were calculated assuming that the region where the vehicles were used, the lifetime driving distance in that region and the CO2 emission from the battery production were fixed. However, in this paper, the life cycle CO2 emissions in each region were calculated taking into consideration the vehicle’s lifetime driving distance in each region and the deviations in CO2 emissions for battery production. For this paper, the US, European Union (EU), Japan, China, and Australia were selected as the reference regions for vehicle operation. The calculated results showed that CO2 emission from the assembly of BEV was larger than that of ICV due to the added CO2 emissions from battery production. However, in regions where renewable energy sources and low CO2 emitting forms of electric power generation are widely used, as vehicle lifetime driving distance increase, the total operating CO2 emissions of BEV become less than that of ICV. But for BEV, the CO2 emissions for replacing the battery with a new one should be added when the lifetime driving distance is over 160,000 km. Moreover, it was shown that the life cycle CO2 emission of ICV was apt to be smaller than that of BEV when the CO2 emissions for battery production were very large.\n",
      "  -                 Background                An intersection is an area with more energy consumption and emissions by motor vehicles, and the energy consumption and emissionsof vehicles at intersections should be reduced in road planning and traffic control to improve the urban traffic environment.                              Objectives                In order to analyze the influence of signal timing on CO2 emission of traffic flow under the mixed traffic environment of fuel vehicles and electric vehicles.                              Methods                A set of CO2 incremental emission models is established to estimate the CO2 emissions of fuel vehicles and electric vehicles at signalized intersections. Then, a signal timing model with minimum CO2 emissions is established, and the influence of signal timing with minimum CO2 emissions on vehicle control delay and stop rates under different traffic conditions is analyzed.                              Conclusions                The case study shows that optimizing of the timing parameters of intersections from the perspective of vehicle CO2 emissions is different from the perspective of control delay or stop rate; the model’s timing optimization will effectively balance the CO2 emissions generated by vehicles during the acceleration, deceleration and idling stages, essentially achieving a comprehensive consideration of vehicle control delay and stop rates. When the road section speed and the mixed proportion of electric vehicles are low, the timing results tend to reduce the vehicle delay at intersections, but when the road section speed and the mixed proportion of electric vehicles are high, the timing results tend to reduce the vehicle stop rate.              \n",
      "--------------------------------------------------\n",
      "Topic 314: 314_allergic_respiratory_allergy_asthma\n",
      "Representative Documents:\n",
      "  - The impact of climate change on the environment, biosphere, and biodiversity has become more evident in the recent years. Human activities have increased atmospheric concentrations of carbon dioxide (CO2) and other greenhouse gases. Change in climate and the correlated global warming affects the quantity, intensity, and frequency of precipitation type as well as the frequency of extreme events such as heat waves, droughts, thunderstorms, floods, and hurricanes. Respiratory health can be particularly affected by climate change, which contributes to the development of allergic respiratory diseases and asthma. Pollen and mold allergens are able to trigger the release of pro‐inflammatory and immunomodulatory mediators that accelerate the onset the IgE‐mediated sensitization and of allergy. Allergy to pollen and pollen season at its beginning, in duration and intensity are altered by climate change. Studies showed that plants exhibit enhanced photosynthesis and reproductive effects and produce more pollen as a response to high atmospheric levels of carbon dioxide (CO2). Mold proliferation is increased by floods and rainy storms are responsible for severe asthma. Pollen and mold allergy is generally used to evaluate the interrelation between air pollution and allergic respiratory diseases, such as rhinitis and asthma. Thunderstorms during pollen seasons can cause exacerbation of respiratory allergy and asthma in patients with hay fever. A similar phenomenon is observed for molds. Measures to reduce greenhouse gas emissions can have positive health benefits.\n",
      "  - SummaryA body of evidence suggests that major changes involving the atmosphere and the climate, including global warming induced by human activity, have an impact on the biosphere and the human environment. Studies on the effects of climate change on respiratory allergy are still lacking and current knowledge is provided by epidemiological and experimental studies on the relationship between asthma and environmental factors, such as meteorological variables, airborne allergens and air pollution. However, there is also considerable evidence that subjects affected by asthma are at an increased risk of developing obstructive airway exacerbations with exposure to gaseous and particulate components of air pollution. It is not easy to evaluate the impact of climate change and air pollution on the prevalence of asthma in general and on the timing of asthma exacerbations. However, the global rise in asthma prevalence and severity suggests that air pollution and climate changes could be contributing. Pollen allergy is frequently used to study the interrelationship between air pollution, rhinitis and bronchial asthma. Epidemiological studies have demonstrated that urbanization, high levels of vehicle emissions and westernized lifestyle are correlated to an increase in the frequency of pollen‐induced respiratory allergy, prevalent in people who live in urban areas compared with those who live in rural areas. Meteorological factors (temperature, wind speed, humidity, etc.) along with their climatological regimes (warm or cold anomalies and dry or wet periods, etc.), can affect both biological and chemical components of this interaction. In addition, by inducing airway inflammation, air pollution overcomes the mucosal barrier priming allergen‐induced responses. In conclusion, climate change might induce negative effects on respiratory allergic diseases. In particular, the increased length and severity of the pollen season, the higher occurrence of heavy precipitation events and the increasing frequency of urban air pollution episodes suggest that environmental risk factors will have a stronger effect in the following decades.\n",
      "  -             Purpose of review            Respiratory allergy correlates strictly with air pollution and climate change. Due to climate change, the atmospheric content of trigger factors such as pollens and moulds increase and induce rhinitis and asthma in sensitized patients with IgE-mediated allergic reactions.            Pollen allergy is frequently used to evaluate the relationship between air pollution and allergic respiratory diseases. Pollen allergens trigger the release of immunomodulatory and pro-inflammatory mediators and accelerate the onset of sensitization to respiratory allergens in predisposed children and adults. Lightning storms during pollen seasons can exacerbate respiratory allergy and asthma not only in adults but also in children with pollinosis. In this study, we have focalized the trigger (chemical and biologic) factors of outdoor air pollution.                                Recent findings            Environmental pollution and climate change have harmful effects on human health, particularly on respiratory system, with frequent impact on social systems.            Climate change is characterized by physic meteorological events inducing increase of production and emission of anthropogenic carbon dioxide (CO2) into the atmosphere. Allergenic plants produce more pollen as a response to high atmospheric levels of CO2. Climate change also affects extreme atmospheric events such as heat waves, droughts, thunderstorms, floods, cyclones and hurricanes. These climate events, in particular thunderstorms during pollen seasons, can increase the intensity of asthma attacks in pollinosis patients.                                Summary            Climate change has important effects on the start and pathogenetic aspects of hypersensitivity of pollen allergy. Climate change causes an increase in the production of pollen and a change in the aspects increasing their allergenic properties. Through the effects of climate change, plant growth can be altered so that the new pollen produced are modified affecting more the human health. The need for public education and adoption of governmental measures to prevent environmental pollution and climate change are urgent. Efforts to reduce greenhouse gases, chemical and biologic contributors to air pollution are of critical importance. Extreme weather phenomena such as thunderstorms can trigger exacerbations of asthma attacks and need to be prevented with a correct information and therapy.          \n",
      "--------------------------------------------------\n",
      "Topic 315: 315_cloud_aerosol_ice_microphysics\n",
      "Representative Documents:\n",
      "  - In this study, an aerosol‐dependent ice nucleation scheme has been implemented in an aerosol‐enabled Multiscale Modeling Framework (PNNL MMF) to study ice formation in upper troposphere cirrus clouds through both homogeneous and heterogeneous nucleation. The MMF model represents cloud scale processes by embedding a cloud‐resolving model (CRM) within each vertical column of a GCM grid. By explicitly linking ice nucleation to aerosol number concentration, CRM‐scale temperature, relative humidity and vertical velocity, the new MMF model simulates the persistent high ice supersaturation and low ice number concentration (10–100/L) at cirrus temperatures. The new model simulates the observed shift of the ice supersaturation PDF toward higher values at low temperatures following the homogeneous nucleation threshold. The MMF model predicts a higher frequency of midlatitude supersaturation in the Southern Hemisphere and winter hemisphere, which is consistent with previous satellite and in situ observations. It is shown that compared to a conventional GCM, the MMF is a more powerful model to simulate parameters that evolve over short time scales such as supersaturation. Sensitivity tests suggest that the simulated global distribution of ice clouds is sensitive to the ice nucleation scheme and the distribution of sulfate and dust aerosols. Simulations are also performed to test empirical parameters related to auto‐conversion of ice crystals to snow. Results show that with a value of 250 μm for the critical diameter, Dcs, that distinguishes ice crystals from snow, the model can produce good agreement with the satellite‐retrieved products in terms of cloud ice water path and ice water content, while the total ice water is not sensitive to the specification of Dcs value.\n",
      "  - A new Zhang and McFarlane (ZM) cumulus scheme includes a two‐moment cloud microphysics parameterization for convective clouds. This allows aerosol effects to be investigated more comprehensively by linking aerosols with microphysical processes in both stratiform clouds that are explicitly resolved and convective clouds that are parameterized in climate models. This new scheme is implemented in the Weather Research and Forecasting model, coupled with the physics and aerosol packages from the Community Atmospheric Model version 5. A case of July 2008 during the East Asian summer monsoon is selected to evaluate the performance of the new ZM and to investigate aerosol effects on monsoon precipitation. The precipitation and radiative fluxes simulated by the new ZM show a better agreement with observations compared to simulations with the original ZM that does not include convective cloud microphysics and aerosol‐convective cloud interactions. Detailed analysis suggests that an increase in detrained cloud water and ice mass by the new ZM is responsible for this improvement. Aerosol impacts on cloud properties, precipitation, and radiation are examined by reducing the primary aerosols and anthropogenic emissions to 30% of those in the present (polluted) condition. The simulated surface precipitation is reduced by 9.8% from clean to polluted environment, and the reduction is less significant when microphysics processes are excluded from the cumulus clouds. Cloud fraction is reduced by the increased aerosols due to suppressed convection, except during some heavy precipitation periods when cloud fraction, cloud top height, and rain rate are increased due to enhanced convection.\n",
      "  - Ice and mixed‐phase cloud representation and simulation in global climate models are challenging with large uncertainties and biases. Sharing similar growth paths, no distinct separation exists in nature between cloud ice and snow. Different from conventional microphysics schemes separating cloud ice from snow, a single prognostic category is used to represent the whole spectrum of solid hydrometeors. Instead of using fixed physical properties for separate ice classes, e.g., the mass, area, and fall velocity, we consider the particle shape and riming impacts on ice properties. This approach simplifies several ice‐related microphysical processes and eliminates the ambiguity and uncertainty associated with parameterizing cloud ice to snow conversion. The modifications were implemented in the Morrison‐Gettelman (MG08) scheme and tested in Community Atmosphere Model. Evaluation using single column simulations indicated that the new approach increased the ice water content (IWC) in high clouds during dry period, which is improved compared to available retrievals. Global atmospheric simulations using the new approach give an overall comparable mean climate with notable improvement in terms of clouds and their radiative forcing. Both longwave and shortwave cloud forcing are closer to observations due to more realistic IWC, liquid water content, and cloud top height. Furthermore, the new approach yields slightly better representation of mixed‐phase clouds when a smaller capacitance for nonspherical particles is used in the ice depositional growth parameterization. Overall, the physically based single‐ice approach is a promising direction for future GCM microphysics development given its simplified representation of microphysical processes and flexible description of ice particle properties.\n",
      "--------------------------------------------------\n",
      "Topic 316: 316_caribou_connectivity_habitat_refugia\n",
      "Representative Documents:\n",
      "  - As climatic conditions shift in coming decades, persistence of many populations will depend on their ability to colonize habitat newly suitable for their climatic requirements. Opportunities for such range shifts may be limited unless areas that facilitate dispersal under climate change are identified and protected from land uses that impede movement. While many climate adaptation strategies focus on identifying refugia, this study is the first to characterize areas which merit protection for their role in promoting climate connectivity at a continental extent. We identified climate connectivity areas across North America by delineating paths between current climate types and their future analogs that avoided nonanalogous climates, and used centrality metrics to rank the contribution of each location to facilitating dispersal across the landscape. The distribution of connectivity areas was influenced by climatic and topographic factors at multiple spatial scales. Results were robust to uncertainty in the magnitude of future climate change arising from differing emissions scenarios and general circulation models, but sensitive to analysis extent and assumptions concerning dispersal behavior and maximum dispersal distance. Paths were funneled along north‐south trending passes and valley systems and away from areas of novel and disappearing climates. Climate connectivity areas, where many potential dispersal paths overlapped, were distinct from refugia and thus poorly captured by many existing conservation strategies. Existing protected areas with high connectivity values were found in southern Mexico, the southwestern US, and western and arctic Canada and Alaska. Ecoregions within the Isthmus of Tehuantepec, Great Plains, eastern temperate forests, high Arctic, and western Canadian Cordillera hold important climate connectivity areas which merit increased conservation focus due to anthropogenic pressures or current low levels of protection. Our coarse‐filter climate‐type‐based results complement and contextualize species‐specific analyses and add a missing dimension to climate adaptation planning by identifying landscape features which promote connectivity among refugia.\n",
      "  - Caribou ( Rangifer tarandus (L., 1758)) play a central role in the ecology and culture of much of Canada, where they were once the most abundant cervid. Most populations are currently declining, and some face extirpation. In southern Canada, caribou range has retreated considerably over the past century. The ultimate reason for their decline is habitat alterations by industrial activities. The proximate causes are predation and, to a lesser extent, overharvest. The most southerly populations of “Mountain” caribou are at imminent risk of extirpation. Mountain caribou are threatened by similar industrial activities as Boreal caribou, and face increasing harassment from motorized winter recreational activities. Most populations of “Migratory Tundra” caribou are currently declining. Although these caribou fluctuate in abundance over decades, changing harvest technologies, climate change, increasing industrial development and human presence in the North raise doubts over whether recent declines will be followed by recoveries. The Peary caribou ( Rangifer tarandus pearyi J.A. Allen, 1902), a distinct subspecies endemic to Canada’s High Arctic, has suffered drastic declines caused by severe weather, hunting and predation. It faces an increasing threat from climate change. While some questions remain about the reasons for the decline of Migratory Tundra caribou, research has clearly identified several threats to the persistence of “Boreal”, Mountain, and Peary caribou. Scientific knowledge, however, has neither effectively influenced policies nor galvanized public opinion sufficiently to push governments into effective actions. The persistence of many caribou populations appears incompatible with the ongoing pace of industrial development.\n",
      "  - Habitat loss is often the ultimate cause of species endangerment and is also a leading factor inhibiting species recovery. For this reason, species‐at‐risk legislation, policies and plans typically focus on habitat conservation and restoration as mechanisms for recovery. To assess the effectiveness of these instruments in decelerating habitat loss, we evaluated spatiotemporal habitat changes for an iconic endangered species, woodland caribou (Rangifer tarandus caribou). We quantified changes in forest cover, a key proxy of caribou habitat, for all caribou subpopulations in Alberta and British Columbia, Canada. Despite efforts under federal and provincial recovery plans, and requirements listed under Canada's Species at Risk Act, caribou subpopulations lost twice as much habitat as they gained during a 12‐year period (2000–2012). Drivers of habitat loss varied by ecotype, with Boreal and Northern Mountain caribou affected most by forest fire and Southern Mountain caribou affected more by forest harvest. Our case study emphasizes critical gaps between recovery planning and habitat management actions, which are a core expectation under most species‐at‐risk legislation. Loss of caribou habitat from 2000 to 2018 has accelerated. Linear features within caribou ranges have also increased over time, particularly seismic lines within Boreal caribou ranges, and we estimated that only 5% of seismic lines have functionally regenerated. Our findings support the idea that short‐term recovery actions such as predator reductions and translocations will likely just delay caribou extinction in the absence of well‐considered habitat management. Given the magnitude of ongoing habitat change, it is clear that unless the cumulative impacts of land‐uses are effectively addressed through planning and management actions that consider anthropogenic and natural disturbances, we will fail to achieve self‐sustaining woodland caribou populations across much of North America.\n",
      "--------------------------------------------------\n",
      "Topic 317: 317_stressor_water_stressor response_water availability\n",
      "Representative Documents:\n",
      "  - This study was motivated by the high reliance on hydropower plants (HPPs) developed and planned along the river Nile and the fact that drought events are the most imminent and drastic threats to Uganda’s power production. The study aimed to assess HPPs’ resilience and the effectiveness of selected adaptation measures. The climate, land, energy, and water system (CLEWs) framework was employed to assess resilience amidst competing water demands and stringent environmental flow requirements. Under extreme dry conditions, power generation could plummet by 91% over the next 40 years, which translates into an annual per capita consumption of 19 kWh, barely sufficient to sustain a decent socioeconomic livelihood. During arid conditions, climate models predicted an increase in streamflow with increasing radiative forcing. Restricting the ecological flow to 150 m3/s could improve generation by 207%. In addition, if planned power plants were to be built 5 years ahead of schedule, the normalized mean annual plant production could increase by 23%. In contrast, increasing reservoir volumes for planned power plants will have no significant impact on generation. The path to HPP resilience could entail a combination of diversifying the generation mix, installing generators with varying capacities, and incorporating adjustable orifices on reservoirs.\n",
      "  -                Stormwater harvesting systems are a viable option to adapt cities to cope with climate change and reduce pressure on water supply services. This is particularly crucial in the event of natural disasters (e.g., earthquakes, floods), where large parts of cities may become disconnected from a secure water supply for prolonged time periods. We demonstrate how optimum location, density and storage size can be determined using UrbanBEATS, a spatial planning-support system for planning and design of sustainable Blue-Green Infrastructure strategies. We investigate the Ōtākaro/Avon River catchment, Christchurch, New Zealand for the time periods 2011–2020, 2041–2050 and 2091–2100 (for the RCP 8.5 climate change scenario). For targets of 30% of potable water substitution and 70% storage volumetric reliability, we found that stormwater harvesting systems in all climate scenarios required a larger capacity compared to the baseline. Most storages achieved their set targets and were larger than the municipality's recommended 9 m3 for flood inundation, indicating that the identified storages would also reduce minor flooding while ensuring water savings. A shift in the spatial layout of modelled systems from highly distributed to more centralised, however, raises a potential conflict with disaster resilience where more local solutions would be preferable.\n",
      "  - The Ili-Balkhash basin (IBB) is considered a key region for agricultural development and international transport as part of China’s Belt and Road Initiative (BRI). The IBB is exemplary for the combined challenge of climate change and shifts in water supply and demand in transboundary Central Asian closed basins. To quantify future vulnerability of the IBB to these changes, we employ a scenario-neutral bottom-up approach with a coupled hydrological-water resource modelling set-up on the RiverWare modelling platform. This study focuses on reliability of environmental flows under historical hydro-climatic variability, future hydro-climatic change and upstream water demand development. The results suggest that the IBB is historically vulnerable to environmental shortages, and any increase in water consumption will increase frequency and intensity of shortages. Increases in precipitation and temperature improve reliability of flows downstream, along with water demand reductions upstream and downstream. Of the demand scenarios assessed, extensive water saving is most robust to climate change. However, the results emphasize the competition for water resources among up- and downstream users and between sectors in the lower Ili, underlining the importance of transboundary water management to mitigate cross-border impacts. The modelling tool and outcomes may aid decision-making under the uncertain future in the basin.\n",
      "--------------------------------------------------\n",
      "Topic 318: 318_linked pdf_pdf versions error_linked pdf versions_versions error\n",
      "Representative Documents:\n",
      "  - A correction to this article has been published and is linked from the HTML and PDF versions of this paper. The error has not been fixed in the paper.\n",
      "  - A correction to this article has been published and is linked from the HTML and PDF versions of this paper. The error has not been fixed in the paper.\n",
      "  - A correction to this article has been published and is linked from the HTML and PDF versions of this paper. The error has been fixed in the paper.\n",
      "--------------------------------------------------\n",
      "Topic 319: 319_winter wheat_wheat_yield_winter\n",
      "Representative Documents:\n",
      "  - The North China Plain is a major grain-producing area, but faces water scarcity, which directly threatens food security. The problem is more severe under climate change and the seasonal impact of climate change on winter wheat is different. Thus, it is of great importance to explore the spatiotemporal characteristics of irrigation requirements (IR) and the factors influencing IR in different growth periods of winter wheat, but it has not received much attention. Therefore, we used relative contribution, partial correlation and path analyses to assess the spatiotemporal characteristics of the IR and primary factors influencing the IR of winter wheat in various growing stages in the North China Plain. The results indicated that wind speed and net solar radiation showed a significant downward trend; no prominent trend was noted in IR (multiyear average, 302.3 mm). Throughout the growing season of winter wheat, IR increased gradually from the southern to northern extent of the North China Plain. The irrigation demand of winter wheat in stage P2 (green-up to heading) was the largest. Furthermore, the dominant drivers of IR in terms of spatial distribution and inter-annual variation were phenological period (Phe), effective precipitation (Pe) and relative humidity (RH); however, the degree of their effects varied across the growth stages and growing regions of winter wheat. Each factor exerted both direct and indirect effects on IR and Phe exhibited the strongest indirect effect on IR. The major factors contributing most to IR were Pe and RH in the P1 stage (sowing to green-up) and Phe, Pe and RH in the P2 and P3 (heading to maturity) stages. Pe and RH limited IR, whereas Phe promoted it. Our findings will help improve agricultural water management in the future.\n",
      "  - BACKGROUNDThe Huang–Huai–Hai Plain (3HP) is the main agricultural area in China. Although climate change (CC) and crop management (CM) are considered factors affecting the winter wheat net primary production (NPP) in this region, their effects remain unclear. In the present study, we evaluated the relative contributions of CC and CM to winter wheat aboveground NPP (ANPP) in the 3HP and the relationships between climatic factors and ANPP using the first‐order difference method from 2000 to 2020.RESULTSCM had a greater influence on the ANPP of winter wheat than did CC. However, the relative contribution of CM to ANPP gradually decreased in humid and dry sub‐humid regions with the development of winter wheat. Furthermore, in areas characterized by low temperatures and limited precipitation, CC became the dominant factor contributing to ANPP, indicating that varieties resilient to drought and cold should be selected in these regions. Minimum and average temperatures were the dominant factors driving spatiotemporal variations in ANPP during the early stage of winter wheat growth, whereas maximum temperature constrained growth throughout the winter wheat growth cycle. When winter wheat entered the vigorous growth stage, precipitation and solar radiation replaced temperature as the driving factors influencing winter wheat growth.CONCLUSIONThe results of the present study provide guidance for optimizing winter wheat crop management in the 3HP. © 2023 Society of Chemical Industry.\n",
      "  - The knowledge of climate change effects on variations of winter wheat yields are crucial for productions. Our objectives were to investigate the relationship between yield-related indices of winter wheat and the related climatic variables (selected using variance inflation factors) at the 20 sites of Xinjiang, China over 1981–2017. The background of climate and yield changes was analyzed from temporal and spatial respects. The number of independent climatic variables was selected with the variance inflation factor method to remove the multicollinear feature. The Pearson correlation was conducted between the first difference values of climatic variables and yield-related indices of winter wheat (namely plant height, growth period duration, 1000-kernel weight, kernel number per ear, biomass and yield) to find the key climatic variables that impacted winter wheat growth and yields. The multi-variate linear and nonlinear functions were established step by step using the selected key climatic variables. The best function was determined for each site (significant for p &lt; 0.05). From the results, there were general wetter and warmer trends of the climatic variables. Correspondingly, shortened winter wheat phenology and increased growth and yields were observed for most sites. Still, the climatic trends had mixed effects on winter wheat yields. The effects of precipitation, mean air temperature and relative humidity on plant height and growth period duration agreed well. Different sites had different major climatic drivers for winter wheat growth or yields, and the best functions of growth and yields could be linearly or nonlinearly, mostly described by multi-variate functions. The winter wheat growth or yield indices were also found to be closely connected with the soil water content status at the eight sites. The relationship between winter wheat growth or yield and climate provided useful references for forecasting crop production and for projecting the impact of future climate changes.\n",
      "--------------------------------------------------\n",
      "Topic 320: 320_drought_index_drought index_standardized\n",
      "Representative Documents:\n",
      "  - ABSTRACTTwo distinct approaches can be employed in the classification and divisions of wet/dry climate. The first is the rule‐driven strategy with predefined threshold values representing climate division boundaries, which is usually performed by Aridity Index (AI). The second is an automated method in a data‐driven fashion, avoiding the direct specification of classification rules while utilizing some forms of cluster analysis. However, various methods for climate classifications raise issues on their applicability and quality. Therefore, evaluation and comparative studies are needed to handle such issues first, in order to analyze their performance and second, to better understand climate characteristics in a region. This article makes a comprehensive analysis and comparison among five classification methods, including four rule‐driven methods based on different categories [Penman‐Monteith (PM), Thornthwaite, Holdridge, Sahin's method] and one data‐driven method (factor‐cluster analysis). With the meteorological data for long‐term period (1981–2010), the wet/dry climate divisions were performed for 191 meteorological stations in Northwest China (NW). The results indicated that the overall climate regimes were in agreement for five classifications, but boundaries of wet/dry climate divisions in a data‐driven fashion showed a better consistency with topographic features. PM classifications displayed more arid climate types in NW, while the Thornthwaite approach showed an underestimate in arid environments. All wet/dry climate types corresponding to Holdridge and Sahin's classifications were represented in NW, but Holdridge classification is more easily affected by topography and elevation. Complete comparisons among rule‐driven methods are difficult to conduct due to different class definitions and low coincident classes. Class definition of climate types for different rule‐driven classifications thus needs further investigation. This article highlights the importance of acknowledging the limitations and advantages of different classification systems as well as the dry and wet climate conditions in NW in hope to provide a reference for a similar geographical region.\n",
      "  - ABSTRACTNumerous drought indices based on single or multiple variables have been developed for the assessment of drought. This study aimed to detect the variability of droughts by applying four drought indices, the standardized precipitation index, the reconnaissance drought index, the standardized precipitation evaporative drought index and the effective drought index, at five meteorological stations in the Songhua River basin (SRB) in China during 1962–2013 and at two meteorological stations in the Indus River basin (IRB) during 1980–2013 using different timescales (3, 6, 9 and 12 months). Moreover, a Mann−Kendall trend test at the 5% significance level was used for the assessment of drought trends in the basins. The results indicated that the 12 month data series for the SRB and the 6 month data series for the IRB were appropriate for assessing dry conditions and for comparing the drought indices. Pearson's correlation analyses between the drought indices results and the meteorological variables revealed that the standardized precipitation index is a better drought index for the assessment of drought in the SRB (r = 0.99). The results also showed that the standardized precipitation evaporative drought index versus the reconnaissance drought index is better at identifying drought in the IRB with a Pearson's correlation value r of 0.98. Severe and extremely dry conditions prevailed between 1990 and 2001 in the SRB, and there were extreme drought conditions with an intensity of −2.00 in the IRB during 2001–2002. Overall, this study provides insights into choosing the appropriate time interval and drought index for a specific region to identify the severity of droughts.\n",
      "  - Droughts cause critical and major risk to ecosystems, agriculture, and social life. While attempts have been made globally to understand drought characteristics, data scarcity in developing countries often challenges detailed analysis, including climatic, environmental, and social aspects. Therefore, this study developed a framework to investigate regional drought analysis (RDA) using regional drought intensity-duration-frequency (RD-IDF) curves and regional drought risk assessment (RDRA) based on the drought hazard indicator (DHI) and drought vulnerability indicator (DVI) for scarce data regions in Afghanistan. The drought characteristics were analyzed using the regional standardized-precipitation-index (SPI), and standardized precipitation-deficit distribution (SPDD). Further, L-moment statistics were used to classify different homogenous regions based on regional frequency analysis (RFA). The historical monthly precipitation data from 23 rainfall stations for the years 1970 to 2016 were collected from the Ministry of Water and Energy of Afghanistan. Based on the analysis performed, the area was classified into six homogeneous regions R-1, R-2, R-3, R-4, R-5, and R-6. The drought was very consistent—almost 50% of the years—irrespective of the homogeneous region classified. R-4, located in the northeast of the country, had a one-year extreme drought with high resiliency and low risk to drought compared to other regions. As R-1, R-3 and R-5 are located in the southwest, center and southeast parts of Afghanistan, they experience moderate drought with low resiliency and high drought risk due to long period of droughts. Moreover, the uniform distribution of precipitation deficit (Dm), was less in arid climate regions. In contrast, the semi-arid climate regions showed higher values of Dm. Furthermore, in the results in all the regions, the IDF curves showed a high drought intensity with increasing drought return periods. In contrast, the intensity significantly decreased when the time scale increased, and fewer were enhanced within the increasing drought return period. However, the outcome of this study may contain essential information for end users to make spatially advanced planning for drought effect mitigation in Afghanistan.\n",
      "--------------------------------------------------\n",
      "Topic 321: 321_japan_anchovy_gray mullet_japanese\n",
      "Representative Documents:\n",
      "  - Global climate change occurs not only at the ocean surface but also at the ocean bottom, which is the main habitat of demersal fish. To clarify the current status of bottom temperature warming off the Pacific coast of northeastern Japan, we examined gridded bottom temperature fields from 2003 to 2019. These fields were created by a newly developed gridding method using flexible Gaussian filter weighting with time, distance, and depth. Spatially averaged bottom temperature had a strong, significant warming trend of 0.083 to 0.115°C yr-1 in depth zones of 150-300 m, indicating bottom temperature warming. Corresponding to the warming, increases in landing amounts were found for warm-water species such as searobin in the middle region of our study area (37°50’-39°N). Seasonal catch amounts suggest that ribbon fish and swimming crab recently began to overwinter and reproduce in the area. The distribution shifts of non-target species in fisheries were also analyzed using bottom otter trawl survey data from the area from 2003 to 2019. Northward distribution shifts and increases in density were observed in blackbelly lantern shark and bighand grenadier, indicating that bottom temperature warming led to habitat expansion. Conversely, darkfin sculpin and jelly eelpout shifted northward with decreasing density, suggesting that bottom temperature warming had a negative effect on them. Deepsea bonefish shifted deeper into colder waters with increasing density and mean body weight. Thus, changes and responses of demersal fish to bottom temperature warming in the area were revealed.\n",
      "  - . Coastal warming, acidification, and deoxygenation are progressing primarily due to the increase in anthropogenic CO2. Coastal acidification has been reported to have effects that are anticipated to become more severe as acidification progresses, including inhibiting the formation of shells of calcifying organisms such as shellfish, which include Pacific oysters (Crassostrea gigas), one of the most important aquaculture resources in Japan. Moreover, there is concern regarding the combined impacts of coastal warming, acidification, and deoxygenation on Pacific oysters. However, spatiotemporal variations in acidification and deoxygenation indicators such as pH, the aragonite saturation state (Ωarag), and dissolved oxygen have not been observed and projected in oceanic Pacific oyster farms in Japan. To assess the present impacts and project future impacts of coastal warming, acidification, and deoxygenation on Pacific oysters, we performed continuous in situ monitoring, numerical modeling, and microscopic examination of Pacific oyster larvae in the Hinase area of Okayama Prefecture and Shizugawa Bay in Miyagi Prefecture, Japan, both of which are famous for their Pacific oyster farms. Our monitoring results first found Ωarag values lower than the critical level of acidification for Pacific oyster larvae in Hinase, although no impact of acidification on larvae was identified by microscopic examination. Our modeling results suggest that Pacific oyster larvae are anticipated to be affected more seriously by the combined impacts of coastal warming and acidification, with lower pH and Ωarag values and a prolonged spawning period, which may shorten the oyster shipping period and lower the quality of oysters.\n",
      "  -                Tian, Y., Nashida, K., and Sakaji, H. 2013. Synchrony in the abundance trend of spear squid Loligo bleekeri in the Japan Sea and the Pacific Ocean with special reference to the latitudinal differences in response to the climate regime shift. – ICES Journal of Marine Science, 70: 968–979. Spear squid Loligo bleekeri is widely distributed in the Japanese coastal waters. The fisheries depend largely on four stocks: the southern and northern stocks both in the Japan Sea and the coastal regions of the Pacific. The catch per unit effort (cpue) for the northern stock in the Japan Sea decreased substantially during the 1980s but increased during the 1990s, while the abundance index for the southern stock showed the opposite trend. The cpue for the southern and northern stocks in the Pacific coast showed a similar pattern to that in the Japan Sea. The synchrony in the abundance trends between the Japan Sea and the Pacific Ocean, and latitudinal differences between the northern and southern stocks indicate the impact of the climate regime shift. Generalized additive model analysis identified significant effects of environmental factors. Increased water temperature had a positive effect on the northern stock but a negative effect on the southern stock in the Japan Sea and the Pacific, whereas El Niño–southern oscillation events and the Asian monsoon had additional significant effects on the Pacific stocks. These results suggest that the abundance trends of spear squid were largely forced by environmental factors with latitudinal differences in the response to the climate regime shift.\n",
      "--------------------------------------------------\n",
      "Topic 322: 322_member states_eu_energy_member\n",
      "Representative Documents:\n",
      "  - BackgroundPhosphorus (P) is a vital and non-substitutable nutrient for agricultural production. However, P is often used inefficiently in European agriculture. To ensure food security while avoiding environmental damage caused by improper fertilization, a sustainable P management is required. Although P-related problems are partly addressed by existing agricultural and environmental legislation, e.g., in the EU, the current regulation lacks sufficient governance effect. In addition, the existing legal framework is strongly characterized by detailed command-and-control provisions and thus suffers from governance problems such as enforcement deficits, rebound and shifting effects. This paper focuses on how these challenges could be addressed by economic instruments. The article highlights not only the impact of the instruments on P management, but also on adjacent environmental areas. We pay particular attention to the governance effects on reaching international binding climate and biodiversity objectives, for which fertilization and agriculture play a major role.ResultsThe analysis builds on two economic instruments that ensure compliance with the climate target of the Paris Agreement and the Aichi targets of the Biodiversity Convention: a cap-and-trade scheme for fossil fuels and a cap-and-trade scheme for livestock products. We state that both instruments simultaneously address a large part of P-related problems. Moreover, if the two emissions trading schemes are combined with a livestock-to-land ratio at farm level, only little need for regulatory supplementation relating to P remains. The latter includes in particular a threshold value for contaminants in P-containing fertilizers. Furthermore, we discuss an almost complete phasing-out of fertilizers containing rock phosphate by means of a further certificate trading scheme.ConclusionsThe article shows that a wide variety of problems can be tackled with a few overarching instruments. This is true even for very specific and diverse problems such as those related to P use in agriculture.\n",
      "  - The Great Recession that began in 2008 hit the economy of the European Union extremely hard. The year 2009 brought decline to the majority of the member states, inducing a desperate crisis management process. The few common EU-level crisis management measures that were implemented have brought about little success due to the modest volume of the common budget and the inertia of decision making attempting to harmonize often contradicting interests. As there was no credible crisis management at the EU level, most member states introduced their own set of measures. The efficiency of these was influenced by the economic performance of primary trading and investing partners, and by the volatility of the bond markets. In terms of economic performance, member states of the EU followed various paths and experienced various levels of recession in 2009, then various levels of upswing in 2010–2011, only to be hit by a second wave of recession of various extents after 2011. Although many member states took their own measures, general tendencies in crisis management can be defined. At first, the restoration of the functioning of the markets was targeted by generating additional demand through fiscal stimulus, but was then gradually replaced by imperative fiscal consolidation and austerity measures. The effectiveness of austerity programs is questionable: while the bond markets’ volatility called for the correction of fiscal balances, tax hikes and governmental spending cuts tendentiously pushed back economic performance and postponed recovery, making economic growth possible only by increasing public debts. In this study, I present arguments in favour of the view that, in the current economic climate of the EU, prosperity could not be restored exclusively by austerity. Accordingly, I present case studies of the three member states with the largest increases in public debts: Ireland, Cyprus and Greece. My aim is to assess the efficiency of these member states’ crisis management procedures: whether state interventions financed by public debt could result in economic recovery. I also argue that, given the current economic situation, the recovery in these member states in times of crisis is not foreseen.\n",
      "  - The European Commission introduced a package of measures to accelerate the shift to low-carbon energy transition in Europe. In 2014, EU member states agreed to reduce greenhouse gas emissions by at least 40% by 2030 compared to 1990 levels. The binding greenhouse gas emission targets for Member States from 2021 to 2030 for the transport, buildings, agriculture, waste, and land-use and forestry sectors were established. EU Member States should decide on their own how to meet the agreed upon 2030 target and implement climate-change-mitigation measures. All EU MSs have committed to prepare national energy and climate plans based on regulation on the governance of the energy union and climate action (EU)2018/1999, agreed as part of the Clean Energy for All Europeans package approved in 2019. The national plans outline how the EU Member States intend to implement the GHG reduction target by increasing their in energy efficiency, use of renewables, greenhouse-gas-emission reductions, interconnections, and research and innovation. This paper analyzes the energy and climate plans of the Baltic States and systematizes the main climate-change-mitigation policies in the energy sector targeting the household sector. The background of energy and climate planning is provided from a theoretical point of view, encompassing regional, local, and national energy and climate plans. The diffusion levels of renewables in the Baltic States were determined and the energy-climatic-friendly policies followed, by them, they were identified.\n",
      "--------------------------------------------------\n",
      "Topic 323: 323_vulnerability_indicators_flood vulnerability_flood\n",
      "Representative Documents:\n",
      "  - The goal of this study is to derive water resource vulnerability characteristics  for South Korea according to individual district populations in a changing climate. The definition of water resource vulnerability in this study consists of potential flood damage and potential water scarcity. To quantify these vulnerabilities, key factors, or indicators affecting vulnerability, are integrated with a technique for order of preference by similarity to ideal solution (TOPSIS), which is a multi-criteria decision-making approach to determine the optimal alternative by considering both the best and worst solutions. The weight for each indicator is determined based on both the Delphi technique and Shannon’s entropy, which are employed to reduce the uncertainty in the process of determining the weights. The Delphi technique reflects expert opinions, and Shannon’s entropy reflects the uncertainty of the performance data. Under A1B climate change scenarios, medium-sized districts (200,000–300,000 inhabitants) are the most vulnerable regarding potential flood damage; the largest districts (exceeding 500,000 inhabitants) are found to be the most vulnerable with respect to potential water scarcity. This result indicates that the local governments of cities or districts with more than 200,000 inhabitants should implement better preventative measures for water resources. In addition, the Delphi and entropy methods show the same rankings for flood vulnerability; however, these approaches produce slightly different rankings regarding water scarcity vulnerability. Therefore, it is suggested that rankings from not only subjective but also objective weights should be considered in making a final decision to implement specific adaptive measures to climate change.\n",
      "  - Different risks are associated with the operation and maintenance of wind farms in cold climate regions, mainly due to the harsh weather conditions that wind farms experience in that region such as the (i) increased stoppage rate of wind turbines due to harsh weather conditions, (ii) limited accessibility to wind farms due to snow cover on roads, and (iii) cold stress to workers at wind farms. In addition, there are risks that are caused by wind farms during their operation, which impact the surrounding environment and community such as the (iv) risk of ice throw from wind turbines, (v) environmental risks caused by the wind farms, and (vi) social opposition risk to installing wind farms in cold climate regions, such as the Arctic. The analysis of these six risks provides an overall view of the potential risks encountered by designers, operators, and decision makers at wind farms. This paper presents a methodology to quantify the aforementioned risks using fuzzy logic method. At first, two criteria were established for the probability and the consequences of each risk; with the use of experts’ judgments, membership functions were graphed to reflect the two established criteria, which represented the input to the risk analysis process. Furthermore, membership functions were created for the risk levels, which represented the output. To test the proposed methodology, a wind farm in Arctic Norway was selected as a case study to quantify its risks. Experts provided their assessments of the probability and consequences of each risk on a scale from 0–10, depending on the description of the wind farm provided to them. Risk levels were calculated using MATLAB fuzzy logic toolbox and ranked accordingly. Limited accessibility to the wind farm was ranked as the highest risk, while the social opposition to the wind farm was ranked as the lowest. In addition, to demonstrate the effects of the Arctic operating conditions on performance and safety of the wind farm, the same methodology was applied to a wind farm located in a non-cold-climate region, which showed that the risks ranked differently.\n",
      "  -                This paper has developed a cost-efficient framework for flood vulnerability assessment at a local scale using a multi-parametric approach integrated with the Open Source Geographical Information System (GIS) and Open Remote Sensing data. The study focuses on generating a set of criteria considering three dimensions of flood vulnerability: exposure, sensitivity, and adaptive capacity (AC) on an index-based approach. These indicators were decided based on a robust analysis considering the physical and socio-economic conditions of the study area. The flood exposure was generated from the geomorphological and hydrological parameters integrated with the flood water depth, the distance to river channels, and the Modified Normalized Difference Water Index. The flood sensitivity was determined by the aggregation of local income, land use, poverty index, population density, and other parameters reflecting the socio-economic condition. The AC has been evaluated based on the Normalized Difference Vegetation Index, the density of the community service facilities, and other factors related to the coping capacity to flood. Finally, the flood vulnerability at the local scale was determined based on the integration of its contributing factors using the Analytical Hierarchical Process-based aggregated model. Results indicated that a total of 20 parameters impacted the flood vulnerability of the research area. The findings also confirmed that among the indicators of flood vulnerability of Da Nang City, the flood depth, land-use condition, and drainage system are the key factors affecting the vulnerability level. The empirical assessment showed that the study area is significantly affected by flood vulnerability with more than 60% of the area having the vulnerability level from moderate to very high. In addition, this paper points out that the vulnerability research should be localized and is not always based on the administrative units. This practice can make the decision-making process and adaptation plan more appropriate locally. Especially, this study attempted to evaluate the accuracy of the flood vulnerability map for the first time by using field survey data and the statistical report on flood damage that most of the previous studies have not conducted yet. This framework provides a valuable toolkit for flood management in data-scarce regions all over the world.\n",
      "--------------------------------------------------\n",
      "Topic 324: 324_runaway_runaway greenhouse_greenhouse_nuclear\n",
      "Representative Documents:\n",
      "  -                 The threat of dangerous climate change from anthropogenic global warming has decreased. Global temperature rose from 1975 to 1998, but since then has levelled off. Sea level is now rising at about 1.5mm per year based on tide gauges, and satellite data suggests it may even be falling. Coral islands once allegedly threatened by drowning have actually increased in area. Ice caps cannot possibly slide into the sea (the alarmist model) because they occupy kilometres-deep basins extending below sea level. Deep ice cores show a succession of annual layers of snow accumulation back to 760,000 years and in all that time never melted, despite times when the temperature was higher than it is today. Sea ice shows no change in 30 years in the Arctic. Emphasis on the greenhouse effect stresses radiation and usually leads to neglect of important factors like convection. Water is the main greenhouse gas. The CO2 in the ocean and the atmosphere are in equilibrium: if we could remove CO2 from the atmosphere the ocean would give out more to restore the balance. Increasing CO2 might make the ocean less alkaline but never acid. The sun is now seen as the major control of climate, but not through greenhouse gases. There is a very good correlation of sunspots and climate. Solar cycles provide a basis for prediction. Solar Cycle 24 has started and we can expect serious cooling. Many think that political decisions about climate are based on scientific predictions but what politicians get are projections based on computer models. The UN’s main adviser, the IPCC, uses adjusted data for the input, their models and codes remain secret, and they do not accept responsibility for their projections.\n",
      "  - Nuclear winter is the term for a theory describing the climatic effects of nuclear war. Smoke from the fires started by nuclear weapons, especially the black, sooty smoke from cities and industrial facilities, would be heated by the Sun, lofted into the upper stratosphere, and spread globally, lasting for years. The resulting cool, dark, dry conditions at Earth's surface would prevent crop growth for at least one growing season, resulting in mass starvation over most of the world. In addition, there would be massive ozone depletion, allowing enhanced ultraviolet radiation. More people could die in the noncombatant countries than in those where the bombs were dropped, because of these indirect effects. Nuclear proliferation is now expanding the threat. A nuclear war between India and Pakistan could produce so much smoke that it would produce global environmental change unprecedented in recorded human history. Although the number of nuclear weapons in the world has fallen from 70,000 at its peak in the 1980s to less than 10,000 currently deployed, a nuclear war between the United States and Russia could still produce nuclear winter. This theory cannot be tested in the real world. However, analogs can inform us about parts of the theory, and there are many that give support to the theory. They include the seasonal cycle, the diurnal cycle, forest, fires, volcanic eruptions, and dust storms on Mars. The only way to be sure to prevent the climatic effects of nuclear war is to rid the world of nuclear weapons. Copyright © 2010 John Wiley &amp; Sons, Ltd.This article is categorized under:Climate Models and Modeling &gt; Knowledge Generation with ModelsAssessing Impacts of Climate Change &gt; Evaluating Future Impacts of Climate Change\n",
      "  - The ultimate climate emergency is a ‘runaway greenhouse’: a hot and water-vapour-rich atmosphere limits the emission of thermal radiation to space, causing runaway warming. Warming ceases only after the surface reaches approximately 1400 K and emits radiation in the near-infrared, where water is not a good greenhouse gas. This would evaporate the entire ocean and exterminate all planetary life. Venus experienced a runaway greenhouse in the past, and we expect that the Earth will in around 2 billion years as solar luminosity increases. But could we bring on such a catastrophe prematurely, by our current climate-altering activities? Here, we review what is known about the runaway greenhouse to answer this question, describing the various limits on outgoing radiation and how climate will evolve between these. The good news is that almost all lines of evidence lead us to believe that is unlikely to be possible, even in principle, to trigger full a runaway greenhouse by addition of non-condensible greenhouse gases such as carbon dioxide to the atmosphere. However, our understanding of the dynamics, thermodynamics, radiative transfer and cloud physics of hot and steamy atmospheres is weak. We cannot therefore completely rule out the possibility that human actions might cause a transition, if not to full runaway, then at least to a much warmer climate state than the present one. High climate sensitivity might provide a warning. If we, or more likely our remote descendants, are threatened with a runaway greenhouse, then geoengineering to reflect sunlight might be life's only hope. Injecting reflective aerosols into the stratosphere would be too short-lived, and even sunshades in space might require excessive maintenance. In the distant future, modifying Earth's orbit might provide a sustainable solution. The runaway greenhouse also remains relevant in planetary sciences and astrobiology: as extrasolar planets smaller and nearer to their stars are detected, some will be in a runaway greenhouse state.\n",
      "--------------------------------------------------\n",
      "Topic 325: 325_awards_atmospheric sciences_sciences section_atmospheric sciences section\n",
      "Representative Documents:\n",
      "  - The Atmospheric Sciences section of AGU awards one of the five Ascent Awards to Professor Mark Z. Jacobson of the Department of Civil and Environmental Engineering at Stanford University for his dominating role in the development of models to identify the role of black carbon in climate change.\n",
      "  - The Atmospheric Sciences section of AGU awards one of the five Ascent Awards to Professor Ping Yang of the Department of Atmospheric Sciences at Texas A&amp;M University for significant contributions to atmospheric scattering, radiative transfer, and remote sensing.\n",
      "  - The Atmospheric Sciences section of AGU awards one of the five Ascent Awards to Professor Cecilia M. Bitz of the Atmospheric Sciences Department at the University of Washington for advancing our ability to model climate in numerous ways, especially in relation to sea ice.\n",
      "--------------------------------------------------\n",
      "Topic 326: 326_lps_argo_argo floats_ism\n",
      "Representative Documents:\n",
      "  -                This study evaluates the capability of coupled global climate models (CGCMs) in simulating the prime examples of the forced response (global monsoon) and internal feedback process (El Niño). Emphases are also placed on the fidelity of the year-to-year variability of global monsoon precipitation that is coordinated by the interannual sea surface temperature (SST) fluctuation over the tropics. The latest version of the Model for Interdisciplinary Research on Climate 5 (MIROC5) with advanced physical schemes is compared with the two previous versions (MIROC3.2, high- and medium-resolution versions) and with the 20 CGCMs participating in the third phase of the Coupled Model Intercomparison Project (CMIP3). The climatological annual mean and cycles of precipitation and 850-hPa winds, the key components to demarcate the global monsoon domain, are reproduced better in MIROC5 than in MIROC3 versions. As a consequence, the former considerably outperforms the latter and is generally superior to the CMIP3 CGCMs in replicating the intensity and domain of global monsoon precipitation and circulations. These results highlight the importance of the improved physical parameterization in a model. Analyses of the monthly Niño-3 index suggest that the amplitude and periodicity of El Niño are simulated better in MIROC5 than in the MIROC3 versions. Yet the reality of nonlinear ENSO dynamics measured indirectly by the SST asymmetricity over the equatorial Pacific is unsatisfactory in the MIROC family as well as in the majority of the CMIP3 models. The maximum covariance analysis shows that a significant fraction of the interannual global monsoon rainfall variability is in concert with El Niño. The multimodel results reveal that such coupling is robust across the current CGCMs. More importantly, the fidelity of the global monsoon precipitation significantly relies on the realism of tropical SST. Comparison among the MIROC models suggests that improved El Niño is likely attributable to the more realistic Bjerknes feedback loop, which results from the intensified convective activity over the equatorial central Pacific Ocean.\n",
      "  - The north-northwest-propagating low pressure systems (LPS) are an important component of the Indian summer monsoon (ISM). The objective detection and tracking of LPS in reanalysis products and climate model simulations are challenging because of the weak structure of the LPS compared to tropical cyclones. Therefore, the skill of reanalyses and climate models in simulating the monsoon LPS is unknown. A robust method is presented here to objectively identify and track LPS, which mimics the conventional identification and tracking algorithm based on detecting closed isobars on surface pressure charts. The new LPS tracking technique allows a fair comparison between the observed and simulated LPS. The analysis based on the new tracking algorithm shows that the reanalyses from ERA-Interim and MERRA were able to reproduce the observed climatology and interannual variability of the monsoon LPS with a fair degree of accuracy. Further, the newly developed LPS detection and tracking algorithm is also applied to the climate model simulations of phase 5 of the Coupled Model Intercomparison Project (CMIP5). The CMIP5 models show considerable spread in terms of their skill in LPS simulation. About 60% of the observed total summer monsoon precipitation over east-central India is found to be associated with LPS activities, while in model simulations this ratio varies between 5% and 60%. Those models that simulate synoptic activity realistically are found to have better skill in simulating seasonal mean monsoon precipitation. The model-to-model variability in the simulated synoptic activity is found to be linked to the intermodel spread in zonal wind shear over the Indian region, which is further linked to inadequate representation of the tropical easterly jet in climate models. These findings elucidate the mechanisms behind the model simulation of ISM precipitation, synoptic activity, and their interdependence.\n",
      "  -                The relative roles of buoy and Argo observations in two sea surface temperature (SST) analyses are studied in the global ocean and tropical Pacific Ocean over 2000–16 using monthly Extended Reconstructed SST version 5 (ERSSTv5) and Daily Optimum Interpolation SST version 2 (DOISST). Experiments show an overall higher impact by buoys than Argo floats over the global oceans and an increasing impact by Argo floats. The impact by Argo floats is generally larger in the Southern Hemisphere than in the Northern Hemisphere. The impact on trends and anomalies of globally averaged SST by either one is small when the other is used. The warming trend over 2000–16 remains significant by including either buoys or Argo floats or both. In the tropical Pacific, the impact by buoys was large over 2000–05 when the number of Argo floats was low, and became smaller over 2010–16 when the number and area coverage of Argo floats increased. The magnitude of El Niño and La Niña events decreases when the observations from buoys, Argo floats, or both are excluded. The impact by the Tropical Atmosphere Ocean (TAO) and Triangle Trans-Ocean Buoy Network (TRITON) is small in normal years and during El Niño events. The impact by TAO/TRITON buoys on La Niña events is small when Argo floats are included in the analysis systems, and large when Argo floats are not included. The reason for the different impact on El Niño and La Niña events is that the drifting buoys are more dispersed from the equatorial Pacific region by stronger trade winds during La Niña events.\n",
      "--------------------------------------------------\n",
      "Topic 327: 327_railway_telemonitoring_oil spill_spill\n",
      "Representative Documents:\n",
      "  - Maritime transport is a vital sector for global trade and the world economy. Particularly for islands, there is also an important social dimension of this sector, since island communities strongly rely on it for a connection with the mainland and the transportation of goods and passengers. Furthermore, islands are exceptionally vulnerable to climate change, as the rising sea level and extreme events are expected to induce severe impacts. Such hazards are anticipated to also affect the operations of the maritime transport sector by affecting either the port infrastructure or ships en route. The present study is an effort to better comprehend and assess the future risk of maritime transport disruption in six European islands and archipelagos, and it aims at supporting regional to local policy and decision-making. We employ state-of-the-art regional climate datasets and the widely used impact chain approach to identify the different components that might drive such risks. Larger islands (e.g., Corsica, Cyprus and Crete) are found to be more resilient to the impacts of climate change on maritime operations. Our findings also highlight the importance of adopting a low-emission pathway, since this will keep the risk of maritime transport disruption similar to present levels or even slightly decreased for some islands because of an enhanced adaptation capacity and advantageous demographic changes.\n",
      "  -                In recent decades, changes in climate have caused impacts on natural and human systems on all continents and across the oceans. Climate change has become one of the most critical issues for the sustainable development of human societies and the functioning of ecosystems on Earth. In one hand, climate change threatens our ability to ensure global food security, eradicate poverty and achieve sustainable development. Agriculture and animal production are affected by changing rainfall patterns, drought, flooding and the geographical redistribution of pests and diseases, with consequent implications in the food availability, a key requirement for food security. On the other hand, despite less debated, climate change could also affect food safety, impacting the occurrence of food safety hazards at various stages of food chain, from “farm to fork”. The tendency to increase the use of agrochemicals to balance the effects of more frequent extreme weather events and water scarcity in some regions could become more frequent. In addition to pesticide residues, both chemical and microbiological risks are expected to impair food and feed safety as a consequence of climate change: in particular mycotoxins, marine biotoxins (phycotoxins), trace metals, among others. Humans, animals and the environment are/will be affected by the consequences of climate change, with an expected impact on the food systems. Thus, a One Health perspective, representing a holistic view of the problems, defining and establishing adequate strategies to tackle these challenges, is more than needed. On this presentation, main issues relating the impact of climate change on health of humans, animals and environment and how a One Health perspective, as a holistic approach, represent a key contribution to the definition of proper policies to ensure the public health will be approached and debated.\n",
      "  - Heatwaves affect human health and should be more and more frequent because of global warming and could lead to increase mortality in general population, especially regarding cardiovascular mortality. During the summer 2019, Europe experienced a strong episode of heatwave. Telemonitoring of patients with heart failure (HF) provide an elegant tool to monitor closely the weights, and we assumed to be able to assess our hypothesis through a nationwide telemonitoring system. Here, we hypothesize that (i) there will be a change in patients' weight during the heatwave and (ii) that the telemonitoring would enable us to follow these changes. The change in weight would be a surrogate for clinical worsening (with or without decompensated HF). Briefly, 1420 patients with a median age of 73.0 years and mean weight of 78.1 kg have been included in this analysis. The relationship between temperature and weight is very strong (P &lt; 10−7). The magnitude of the effect seems clinically relevant with a variation of 1.5 kg during a short period. This could expose patients to increased symptoms, HF decompensations, and poor outcomes. These results suggest a new way to implement weight telemonitoring in HF. This suggests also a direct impact of global warming on Human health, with acute episodes that are expected to occur more often, threatening patients with chronic diseases, especially patients with heart failure. In clinical practice, this urges to take into consideration the episodes of extreme heatwave and suggest that we have already useful tools including telemonitoring available in frail patients.\n",
      "--------------------------------------------------\n",
      "Topic 328: 328_current trends gt_trends gt_ais_current trends\n",
      "Representative Documents:\n",
      "  - Recent research has strengthened the understanding of the links between climate and tropical cyclones (TCs) on various timescales. Geological records of past climates have shown century‐long variations in TC numbers. While no significant trends have been identified in the Atlantic since the late 19th century, significant observed trends in TC numbers and intensities have occurred in this basin over the past few decades, and trends in other basins are increasingly being identified. However, understanding of the causes of these trends is incomplete, and confidence in these trends continues to be hampered by a lack of consistent observations in some basins. A theoretical basis for maximum TC intensity appears now to be well established, but a climate theory of TC formation remains elusive. Climate models mostly continue to predict future decreases in global TC numbers, projected increases in the intensities of the strongest storms and increased rainfall rates. Sea level rise will likely contribute toward increased storm surge risk. Against the background of global climate change and sea level rise, it is important to carry out quantitative assessments on the potential risk of TC‐induced storm surge and flooding to densely populated cities and river deltas. Several climate models are now able to generate a good distribution of both TC numbers and intensities in the current climate. Inconsistent TC projection results emerge from modeling studies due to different downscaling methodologies and warming scenarios, inconsistencies in projected changes of large‐scale conditions, and differences in model physics and tracking algorithms. WIREs Clim Change 2016, 7:65–89. doi: 10.1002/wcc.371This article is categorized under:Paleoclimates and Current Trends &gt; Earth System Behavior\n",
      "  - The last quarter century spans the publication of the first assessment report of the Intergovernmental Panel on Climate Change in 1990 and the latest report published in 2013–2014. The five assessment reports appearing over that interval reveal a marked increase in the number of paleoclimate studies addressing the climate of the last 2000 years (the Common Era). An important focus of this work has been on reconstruction of hemispheric and global temperatures. Several early studies in this area generated considerable scientific and public interest, and were followed by high‐profile and sometimes vitriolic debates about the magnitude of temperature changes over all or part of the Common Era and their comparison to 20th‐ and 21st‐century global temperature increases due to increasing levels of atmospheric greenhouse gases. Behind the more public debates, however, several consistent themes of scientific inquiry have developed to better characterize climate variability and change over the Common Era. These include attempts to collect more climate proxy archives and understand the signals they contain, improve the statistical methods used to estimate past temperature variability from proxies and their associated uncertainties, and to compare reconstructed temperature variability and change with climate model simulations. All of these efforts are driving a new age of research on the climate of the Common Era that is developing more cohesive and collaborative investigations into the dynamics of climate on time scales of decades to centuries, and an understanding of the implications for modeled climate projections of the future. WIREs Clim Change 2016, 7:746–771. doi: 10.1002/wcc.418This article is categorized under:Paleoclimates and Current Trends &gt; Paleoclimate\n",
      "  - The potential for carbon dioxide (CO2) in the atmosphere to influence global surface temperatures was first recognized in the mid-nineteenth century. Even so, high-precision measurements of atmospheric CO2 concentration were not commenced until the International Geophysical Year (1957–8), following concerns of the climatic impact of increased use of fossil fuels and the concomitant release of CO2 into the atmosphere.In Australia, an early (1960s–70s) interest in the high-precision measurement of CO2 concentration was stimulated by a study of the photosynthesis and respiration of awheat crop. This study conducted in north-easternVictoria during 19717–2 led two young CSIRO scientists, J. R. Garratt and G. I. Pearman, encouraged by their Chief, C. H. B. Priestley, to extend micro-environment CO2 studies to larger-scale measurements of CO2 concentration in the background atmosphere. The significant extension of the observation programme required refined measurement techniques to improve both the precision and absolute comparability with observations made by laboratories overseas. Joined in 1974 by P. J. Fraser, they identified the impact of pressure broadening on calibration techniques used in the non-dispersive infrared absorption method of CO2 concentration measurement. This, in turn, led to improved inter-comparability of CO2 concentration data collected around the globe.Acomprehensive aircraft-based air sampling programmewas established in the early 1970s, leading to increased understanding of the time and space variability of CO2 concentration throughout the depth of the troposphere and lower stratosphere in the mid-latitudes of the Southern Hemisphere. In turn this led to: (i) the establishment of a permanent ground-based observatory at Cape Grim, north-western Tasmania; (ii) the development of carbon cycle models; and (iii) measurements of 12CO2, 13CO2 and 14CO2 relative abundances in current and past atmospheres, the last from air samples trapped in ice cores (described in Part 2,the companion paper).The accumulated data from these studies, together with those collected by international colleagues, form the basis of our understanding of the changes of CO2 concentration over thousands of years. In addition, the data have contributed to our understanding of the mechanisms of past and present biogeochemical cycling of CO2 that provides the predictive basis for future changes in CO2 concentration.\n",
      "--------------------------------------------------\n",
      "Topic 329: 329_controller_control_harmonics_dfig\n",
      "Representative Documents:\n",
      "  -                In the present paper, the flower pollination algorithm (FPA) is employed for tuning the controller parameters of a doubly fed induction generator (DFIG) in a wind energy system. These parameters are then compared with those generated by the genetic algorithm (GA) and the proportional-integral (PI) (initial design) controllers. Performance analysis of the DFIG is carried out in dynamic mode in two case studies. The first case study is carried out with no failure, the second one is subject to a short circuit in the electrical network. In this latter case study, a break occurs in the rotor circuit and disconnects the DFIG from the power grid. This gives rise to an excessive current in the rotor circuit which in turn influences the converters AC/DC/AC and makes the IGBT very sensitive. The GA and the FPA are used to tune the PI controllers with the purpose of improving the quality of a power supply should electrical disturbances occur. The results show that by applying an optimal PI controller design to a DFIG using the FPA the performance of the DFIG system can be improved in the event of disturbances. When the PI controller tuning using the GA and the initial control system design is compared with the DFIG using the optimized design, a significant decrease in the overshoot of the rotor current and the DC-link voltage is observed.\n",
      "  - The Stanley controller is a proven approach for path tracking control in automated vehicles. If time delays occur, for example, in signal processing and steering angle control, precision and stability decrease. In this article, enhancements for the Stanley controller are proposed to achieve stable behavior with improved tracking accuracy. The approach uses the curvature of the path as feedforward, whereby the reference point for the feedforward input differs from that of the controller setpoints. By choosing a point further along the path, the negative effects of system delay are reduced. First, the parameters of the Stanley controller are calibrated using a straight line and circle maneuver. Then, the newly introduced feedforward parameter is optimized on a dynamic circuit. The approach was evaluated in simulation and validated on a demonstrator vehicle. The validation tests with the demonstrator vehicle on the dynamic circuit revealed a reduction of the root-mean-square cross-track error from 0.11 m to 0.03 m compared to the Stanley controller. We proved that the proposed approach optimizes the Stanley controller in terms of compensating for the negative effects of system delay. This allows it to be used in a wider range of applications that would otherwise require a more complex control approach.\n",
      "  - This paper presents a methodology that aims at identifying virtual inertia (VI) gain limitations from virtual synchronous generators (VSGs) while maintaining the frequency stability considering the delay associated with the frequency measurement process. The phase-locked loop (PLL) is typically used for frequency estimation that is used to calculate the rate of change of frequency (RoCoF) and it drives the VI loop. The PLL is generally accompanied by a low-pass filter that aims to suppress the impact of harmonics. This filter introduces a delay that when used with the VI control loop causes stability issues for high values of VI gain. A comparison of various PLL approaches suggests that certain variants tend to permit higher value of cut-off frequencies which can be utilized to increase the VI gain limit from VSG. This study presents a method by which the upper limit on VI gain can be quantified and related to the cut-off frequency of the PLL low pass filter that is indirectly representing the delay. It is performed using small signal frequency stability analysis on the frequency domain model of the grid with virtual inertia emulating VSG. The effective maximum VI gain from VSG is explored while satisfying the frequency measurement accuracy specification considering harmonics. The results show that the requirements of reaching a stable operation with sufficient stability margins can still be met with a faster PLL-based system and the potential increases in VI support from VSG can be quantified using the proposed method. The study has been first performed on a single machine single inverter bus (SMSIB) system and is generalized to the multi-machine and multi-inverter system.\n",
      "--------------------------------------------------\n",
      "Topic 330: 330_wines_yeast_fermentation_wine\n",
      "Representative Documents:\n",
      "  - This project aims to characterize and define an autochthonous yeast, Saccharomyces bayanus CN1, for wine production from partially dehydrated grapes. The yeast was identified via PCR and Basic Local Alignment Search Tool (BLAST) analysis as Saccharomyces bayanus, and then subsequently used in fermentations using partially dehydrated or control grapes. Wine grapes were dried to 28.0°Brix from the control grapes at a regular harvest of 23.0°Brix. Both the partially dehydrated and control grapes were then vinified with each of two yeast strains, S. bayanus CN1 and S. cerevisiae EC1118, which is a common yeast used for making wine from partially dehydrated grapes. Chemical analysis gas chromatography-flame ionization detector (GC-FID) and enzymatic) of wines at each starting sugar level showed that CN1 produced comparable ethanol levels to EC1118, while producing higher levels of glycerol, but lower levels of oxidative compounds (acetic acid, ethyl acetate, and acetaldehyde) compared to EC1118. Yeast choice impacted the wine hue; the degree of red pigment coloration and total red pigment concentration differed between yeasts. A sensory triangle test (n = 40) showed that wines made from different starting sugar concentrations and yeast strains both differed significantly. This newly identified S. bayanus strain appears to be well-suited for this style of wine production from partially dehydrated grapes by reducing the oxidative compounds in the wine, with potential commercial application for cool climate wine regions.\n",
      "  - Interest in the use of non-Saccharomyces yeast in mixed cultures is increasing due to the perceived improvement in the quality and complexity of the resulting wines. The aim of the study was to determine the ability of monocultures and mixed yeast cultures for deacidification and improvement of the composition of cold climate grape wines. Fermentation of grape musts with increased total acidity was carried out with the use of monocultures of Saccharomyces cerevisiae MH020215 (Sc), Zygosaccharomyces bailii 749 (Zb) and Metschnikowia pulcherrima MG970690 (Mp), and their mixed cultures, inoculated simultaneously and sequentially. Oenological parameters, organic acids and volatile compounds profiles of obtained wines were characterized. The fermentation kinetics and analytical profiles of the obtained wines showed that the use of mixed yeast cultures contributed to the reduction of volatile acidity and acetic acid content in the wines, as well as obtaining a favorable aromatic profile of the wines. The dominant higher alcohols in all wines were 2-methyl-1-propanol, 3-methyl-1-butanol and 2-methyl-1-butanol. Significantly higher amounts of the first two compounds were found in wines obtained with M. pulcherrima MG070690, both in monoculture and in mixed cultures. The monocultures of M. pulcherrima MG070690 (Mp) compared with Z. bailli 749 (Zb) synthesized higher levels of esters in wines, including ethyl acetate, ethyl propionate, isobutyl acetate, ethyl pyroracemate and isoamyl acetate.\n",
      "  - ABSTRACTThe effects of climate change on wine include high-alcohol content, low acidity and aroma imbalance. The potential of several non-Saccharomyces wine yeasts to mitigate these effects was evaluated by sequential fermentation of Treixadura grape must. Fermentations with only Saccharomyces cerevisiae ScXG3 and a spontaneous process were used as control assays. All yeast strains were obtained from the yeast collection of Estación de Viticultura e Enoloxía de Galicia (EVEGA), Galicia, Spain. Fermentation kinetics as well as yeast dynamics and implantation ability varied depending on inoculated yeasts. In addition, the results showed significant differences in the chemical composition of wine. Starmerella bacillaris 474 reduced the alcohol content (1.1% vol) and increased the total acidity (1.2 g L−1) and glycerol of wines. Fermentation with Lachancea thermotolerans Lt93 and Torulaspora delbrueckii Td315 also decreased the alcohol content, although to a lesser extent (0.3% and 0.7% vol, respectively); however, their effect on wine acidity was less significant. The wines also differed in their concentration of volatile compounds and sensory characteristics. Thus, wines made with Metschnikowia fructicola Mf278 and S. cerevisiae ScXG3 had higher content of esters, acetates and some acids than other wines, and were most appreciated by tasters due to their fruity character and overall impression.\n",
      "--------------------------------------------------\n",
      "Topic 331: 331_trout_stream_stream temperature_streams\n",
      "Representative Documents:\n",
      "  - In Yellowstone Lake, Wyoming, the largest inland population of nonhybridized Yellowstone Cutthroat Trout Oncorhynchus clarkii bouvieri, hereafter Cutthroat Trout, declined throughout the 2000s because of predation from invasive Lake Trout Salvelinus namaycush, drought, and whirling disease Myxobolus cerebralis. To maintain ecosystem function and conserve Cutthroat Trout, a Lake Trout gill netting suppression program was established in 1995, decreasing Lake Trout abundance and biomass. Yet, the response of Cutthroat Trout to varying Lake Trout suppression levels, collectively with the influence of disease and climate, is unknown. We developed an ecosystem model (calibrated to historical data) to forecast (2020–2050) whether Cutthroat Trout would achieve recovery benchmarks given disease, varying suppression effort, and climate change. Lake Trout suppression influenced Cutthroat Trout recovery; current suppression effort levels resulted in Cutthroat Trout recovering from historical lows in the early 2000s. However, Cutthroat Trout did not achieve conservation benchmarks when incorporating the influence of disease and climate. Therefore, the National Park Service intends to incorporate age‐specific abundance, spawner biomass, or both in conservation benchmarks to provide better indication of how management actions and environmental conditions influence Cutthroat Trout. Our results illustrate how complex interactions within an ecosystem must be simultaneously considered to establish and achieve realistic benchmarks for species of conservation concern.\n",
      "  - Mountain headwater streams have emerged as important climate refuges for native cold‐water species due to their slow climate velocities and extreme physical conditions that inhibit non‐native invasions. Species persisting in refuges often do so as fragmented, relict populations from broader historical distributions that are subject to ongoing habitat reductions and increasing isolation as climate change progresses. Key for conservation planning is determining where remaining populations will persist and how habitat restoration strategies can improve biological resilience to enhance the long‐term prospects for species of concern. Studying bull trout, a headwater species in the northwestern USA, we developed habitat occupancy models using a data set of population occurrence in 991 natal habitat patches with a suite of novel geospatial covariates derived from high‐resolution hydroclimatic scenarios and other sources representing watershed and instream habitat conditions, patch geometry, disturbance, and biological interactions. The best model correctly predicted bull trout occupancy status in 82.6% of the patches and included effects for: patch size estimated as habitat volume, extent of within‐patch reaches &lt;9°C mean August temperature, distance to nearest occupied patch, road density, invasive brook trout prevalence, patch slope, and frequency of high winter flows. The model was used to assess 16 scenarios of bull trout occurrence within the study streams that represented a range of restoration strategies under three climatic conditions (baseline, moderate change, and extreme change). Results suggested that regional improvements in bull trout status were difficult to achieve in realistic restoration strategies due to the pervasive nature of climate change and the limited extent of restoration actions given their high costs. However, occurrence probabilities in a subset of patches were highly responsive to restoration actions, suggesting that targeted investments to improve the resilience of some populations may be contextually beneficial. A possible strategy, therefore, is focusing effort on responsive populations near more robust population strongholds, thereby contributing to local enclaves where dispersal among populations further enhances resilience. Equally important, strongholds constituted a small numerical percentage of patches (5%–21%), yet encompassed the large majority of occupied habitat by volume (72%–89%) and their protection could have significant conservation benefits for bull trout.\n",
      "  - Understanding how changes in stream temperature affect survival and growth of coldwater fishes, including brown trout (Salmo trutta) and rainbow trout (Oncorhynchus mykiss), is important for conserving coldwater stream fisheries in a changing climate. However, some contemporary stream temperature models assume spatially uniform (i.e. unrealistic) air–stream temperature relationships or demand hydrometeorological predictors (e.g. solar radiation and convection) that are expensive and often impractical for fisheries managers to measure. As such, we produced a relatively cost‐effective, management‐relevant modelling approach for predicting effects of changes in air temperature, precipitation and groundwater inputs on stream temperature and, consequently, the survival and growth of brown trout and rainbow trout in Michigan, USA. We found that precipitation‐ and groundwater‐corrected stream temperature models (mean adjusted R2 = .77, range = 0.65–0.88) performed better than linear air–stream temperature models (mean adjusted R2 = .59, range = 0.21–0.80). Stream temperature was projected to increase by 0.07–3.88°C (1%–22%) with simulated changes in air temperature, precipitation and groundwater inputs. The greatest warming was predicted for surface runoff‐dominated sites with limited groundwater‐driven thermal buffering, where thermal habitat suitability for salmonid survival and growth declined 20%–40%. However, groundwater‐dominated sites may not be immune to temperature warming, especially if groundwater temperature increases or groundwater inputs decline in a changing climate. Our modelling approach provides a reliable, cost‐effective method for predicting effects of climate change on brown trout and rainbow trout survival and growth, allowing for strategic management actions to increase the thermal resilience and sustainability of salmonid populations (e.g. groundwater conservation and riparian/watershed rehabilitation).\n",
      "--------------------------------------------------\n",
      "Topic 332: 332_food_health_public health_world\n",
      "Representative Documents:\n",
      "  - The early drafts of Food Policy Analysis were stimulated by the attention to high food prices following the world food crisis in 1973–74, and the fears of a repeat in 1979–80. But by the fourth full draft, in 1982, it became apparent that surpluses were returning to world food markets. A volume predicated on a world running out of food would have been out of date before the ink was dry, and a full‐scale revamping of the analytical messages was needed. After a nearly complete re‐write, the new theme, which has stood the test of 30 years of market fluctuations, was the need for flexibility to cope with market instability. That message is even more relevant now, as we learn to cope with a new source of instability—climate change. Such flexibility is not a natural feature of domestic policymaking, in the food sector or elsewhere, and providing the analytical tools for understanding how to create flexible responses turned out to be a real challenge. The task in this paper is to ask specifically how climate change would alter the basic message of Food Policy Analysis. Virtually all of the analysis was focused on national policies and domestic markets, an approach that seems problematical for preventing or mitigating climate change, but entirely appropriate for designing adaptation strategies. Climate change is imposing itself as a reality via the increased probability of extreme weather events in general, and also on both global and localized food security outcomes in particular. The ecosystem services provided by the climate are essential for all agricultural production. The most important effects of climate change on agriculture are likely to include a net global loss of agricultural land, changing crop suitability, an increase in the frequency of natural disasters, and greater temporal and geographic variance in production. It will also have negative effects on other areas of agriculture broadly interpreted—reducing the carrying capacity of many rangelands and posing threats to fisheries and aquaculture production systems. Climate change is expected to have highly variable effects on different regions; tropical and equatorial regions will bear the heaviest burdens, with some gains in yields and land availability in temperate regions. Since rural poverty is concentrated in tropical and, in South Asia, coastal areas, climate change is expected to have a disproportionate effect on the already vulnerable. The challenge is to design, analyze, and implement in‐country “climate‐smart agriculture” adaptation projects and programs, which are now part of the food policy agenda, as well as to improve the openness to trade in agricultural commodities to even out geographical instability. Designing appropriate policies for bio‐fuels also needs to be on the analytical agenda.\n",
      "  -                                  Background                  Humans have wandered this planet for hundreds of thousands of years, yet in the last 160 years we have dramatically disrupted planetary systems upon which we depend. Humanity has polluted the oceans, rivers, air and soils. Our persistent burning of fossil fuels to power opulent lifestyles is now perilously close to permanently disrupting global climatic systems.                                                Problem                  It is clear. The problem is us. Australia's summer of horrors provides a terrifying glimpse into our collective future. This rich and exquisitely advantaged nation has voted for governments that have ignored fragile ecosystems, dismantled environmental protection laws, ignored climate science and expanded its fossil fuel exploration, extraction, consumption and exportation. It has systematically silenced science, ignored its duty of care to protect its present and future citizenry.                                                Evidence                  The 2019-2020 summer brought unprecedented disasters to a country familiar with disasters. After the hottest and driest year on record came the world's largest bushfire, which started in winter, and burned uncontainable for 7 months across 5 states. Billions of animals perished, thousands of homes &amp; businesses destroyed, 33 people burned alive. Continental-wide temperatures of 42oC. Smoke levels exceeded hazardous levels by a factor of 25, lingered 6weeks in the national capital, circumnavigated the southern hemisphere. 80% of Australians were affected by the fires in some way, and the nation fell into a deep grief.                                                The public health challenge                  As the world faces new climate regimes, the associated health challenges are elevating to unheralded and unforeseen levels. Public health preparedness for past situations will inevitably fail. Events are no longer singular, short lived or readily managed. Today's events are multifaceted, expansive and protracted. Their sheer magnitude and scale prevent response activities, interrupt transport and supply chains and shut down power and communications.                                                Key messages                  Unfettered human development has degraded planetary systems upon which humanity depends for survival and flourishing. Climate change is disrupting all our key environmental determinants of health. Environmental degradation and climate change now present a rapidly intensifying health emergency. Australia’s summer of disasters demonstrates we need an explosion of public health preparedness.               \n",
      "  -                Food and water are fundamental environmental health determinants. They are necessities of life, such that shortfalls in ready access in sufficient quality and quantity precipitate poor health, failure to thrive, susceptibility to disease, and if not rectified, ultimately lead to death. Archeological and historical records testify that large scale interruptions to food and water supplies trigger widespread social upheaval and when driven by systematic inequities in distribution, can overthrow governments.               The desperation to secure survival is deep-seated. Competition for scarce resources, mass migration and conflict further generate environmental damage, disruptions to social cohesion, and can also herald novel challenges to health and wellbeing. Climate change is accelerating and with it, increasing intensity of extreme events such as heatwaves, droughts, fires, storms and floods. These interrupt food and water supplies and income generation. Unless transformative and rapid reductions in global greenhouse gas emissions can be achieved, and achieved promptly, the global population will be forced to confront escalation in shortfalls.               Will wealthy nations accommodate the needs of the global disadvantaged?               Exposure of agricultural sectors to climate extremes is already reversing gains made towards ending malnutrition and achieving SDG1: Reducing global hunger and malnutrition. Global water insecurity is also intensifying. A perfect storm is looming with accelerated global warming against a backdrop of rapid population growth and existing challenges in ensuring water and food security for all. The combination of lethal heat extremes and intensifying insecurities in these basic human needs threatens to make many homelands uninhabitable.               Humanity is creating a Climate Change Emergency, which translates to a Global Public Health Emergency. It is thus incumbent upon the world's public health community to move beyond engagement in this climate change crisis. We must step up and take leadership to protect the health of all. Is the PPRR risk management model: Prevent, Prepare, Respond and Recover, the way forward?               Workshop participants will have the opportunity to hear from a panel of three public health experts from the World Federation of Public Health Association to gain a deep understanding of the relationship pathways between climate change and these accelerating health threats. Recent global disasters events will illustrate the diversity and extent of this unfolding crisis. Examples of promising Public Health Response solutions will highlight what can be achieved by applying a coordinated public health lens.               This interactive session elicits audience involvement through facilitated Question and Answer discussion. Following the panel presentations, the Q&amp;A session will enable workshop participants to explore how better engagement of the public health sector can serve to help ameliorate the risks, and build resilience through Climate Change PPRR.                                 Key messages                  Interruptions to food and water security generate disease, famine, conflict and in severe circumstances mass migration, disproportionately harming the global disadvantaged, and ultimately everyone. Climate change risks food &amp; water security and thus threatens human wellbeing. Observed effects will dramatically escalate. The global public health community must engage to protect health.               \n",
      "--------------------------------------------------\n",
      "Topic 333: 333_soc_soc stocks_stocks_ha\n",
      "Representative Documents:\n",
      "  - . Sequestration of soil organic carbon (SOC) on cropland has been proposed as a climate change mitigation strategy to reduce global greenhouse gas (GHG) concentrations in the atmosphere, which in particular is needed to achieve the targets proposed in the Paris Agreement to limit the increase in atmospheric temperature to well below 2 ∘C. We analyze the historical evolution and future development of cropland SOC using the global process-based biophysical model LPJmL, which was recently extended by a detailed representation of tillage practices and residue management (version 5.0-tillage2). We find that model results for historical global estimates for SOC stocks are at the upper end of available literature, with ∼2650 Pg C of SOC stored globally in the year 2018, ∼170 Pg C of which is stored in cropland soils. In future projections, assuming no further changes in current cropland patterns and under four different management assumptions with two different climate forcings, RCP2.6 and RCP8.5, results suggest that agricultural SOC stocks decline in all scenarios, as the decomposition of SOC outweighs the increase in carbon inputs into the soil from altered management practices. Different climate change scenarios, as well as assumptions on tillage management, play a minor role in explaining differences in SOC stocks. The choice of tillage practice explains between 0.2 % and 1.3 % of total cropland SOC stock change in the year 2100. Future dynamics in cropland SOC are most strongly controlled by residue management: whether residues are left on the field or harvested. We find that on current cropland, global cropland SOC stocks decline until the end of the century by only 1.0 % to 1.4 % if residue retention management systems are generally applied and by 26.7 % to 27.3 % in the case of residue harvest. For different climatic regions, increases in cropland SOC can only be found for tropical dry, warm temperate moist, and warm temperate dry regions in management systems that retain residues.\n",
      "  -                 Aims                Increasing soil organic carbon (SOC) stocks is discussed as negative emission technology with the potential to remove relevant amounts of carbon from the atmosphere. At the same time, climate change-driven losses of SOC to the atmosphere might impede such goals.                              Methods                In this study, we used an ensemble of different SOC models and climate projections to project SOC stocks in German croplands up to 2099 under different climate change scenarios. We then estimated the required increase in organic carbon (OC) input to preserve or increase SOC stocks.                              Results                Projected SOC stocks of German croplands are estimated to decline under current OC input levels and management, both with and without climate change. Depending on the climate scenario, we estimated that the OC input to the soil in 2099 needs to be between 51% (+ 1.3 Mg ha− 1) and 93% (+ 2.3 Mg ha− 1) higher than today to preserve current SOC stock levels. A SOC stock increase of 34.4% (4‰ a− 1) would even require an OC input increase of between 221% (+ 5.5 Mg ha− 1) and 283% (+ 7.1 Mg ha− 1).                              Conclusions                Our study highlights that under climate change increasing SOC stocks is considerable challenging since projected SOC losses have to be compensated first before SOC built up is possible. This would require unrealistically high OC input increases with drastic changes in agricultural management.              \n",
      "  - Soil organic C (SOC) stock assessments at the regional scale under climate change scenarios are of paramount importance in implementing soil management practices to mitigate climate change. In this study, we estimated the changes in SOC sequestration under climate change conditions in agricultural land in Spain using the RothC model at the regional level. Four Intergovernmental Panel on Climate Change (IPCC) climate change scenarios (CGCM2‐A2, CGCM2‐B2, ECHAM4‐A2, and ECHAM4‐B2) were used to simulate SOC changes during the 2010 to 2100 period across a total surface area of 2.33 × 104 km2. Although RothC predicted a general increase in SOC stocks by 2100 under all climate change scenarios, these SOC sequestration rates were smaller than those under baseline conditions. Moreover, this SOC response differed among climate change scenarios, and in some situations, some losses of SOC occurred. The greatest losses of C stocks were found mainly in the ECHAM4 (highest temperature rise and precipitation drop) scenarios and for rainfed and certain woody crops (lower C inputs). Under climate change conditions, management practices including no‐tillage for rainfed crops and vegetation cover for woody crops were predicted to double and quadruple C sequestration rates, reaching values of 0.47 and 0.35 Mg C ha−1 yr−1, respectively.Core IdeasThe model predicted a general increase in SOC stocks by 2100 in all climate scenarios.Irrigated crops showed the largest SOC stocks.Carbon inputs were the most important driver for SOC stocks.No‐tillage and cover crops have at least doubled SOC sequestration rates.\n",
      "--------------------------------------------------\n",
      "Topic 334: 334_metro_reservoirs_water_cc\n",
      "Representative Documents:\n",
      "  - Flooding events can produce significant disturbances in underground transport systems within urban areas and lead to economic and technical consequences, which can be worsened by variations in the occurrence of climate extremes. Within the framework of the European project RESCCUE (RESilience to cope with Climate Change in Urban arEas—a multi-sectorial approach focusing on water), climate projections for the city of Barcelona manifest meaningful increases in maximum rainfall intensities for the 2100 horizon. A better comprehension of these impacts and their conditions is consequently needed. A hydrodynamic modelling process was carried out on Barcelona Metro Line 3, as it was identified as vulnerable to pluvial flooding events. The Metro line and all its components are simulated in the urban drainage models as a system of computational link and nodes reproducing the main physical characteristics like slopes and cross-sections when embedded in the current 1D/2D hydrodynamic model of Barcelona used in the project RESCCUE. This study presents a risk analysis focused on ensuring transport service continuity in flood events. The results reveal that two of the 26 stations on Metro Line 3 are exposed to a high risk of flooding in current rainfall conditions, and 11 of the 26 stations on Metro Line 3 are exposed to a high risk of flooding in future rainfall conditions for a 20-year return period event, which affects Metro service in terms of increased risk. This research gives insights for stakeholders and policymakers to enhance urban flood risk management, as a reasonable approach to tackle this issue for Metro systems worldwide. This study provides a baseline for assessing potential flood outcomes in Metro systems and can be used to evaluate adaptation measures’ effectiveness.\n",
      "  - In this article, the authors will support Managed Aquifer Recharge (MAR) as a tool to combat Climate Change (CC) adverse impacts on the basis of real sites, indicators, and specific cases located Spain. MAR has been used in Spain in combination with other measures of Integrated Water Resources Management (IWRM) to mitigate and adapt to Climate Change (CC) challenges. The main effects of CC are that the rising of the average atmospheric temperature together with the decreasing average annual precipitation rate cause extreme weather and induce sea level rise. These pattern results in a series of negative impacts reflected in an increase of certain events or parameters, such as evaporation, evapotranspiration, water demand, fire risk, run-off, floods, droughts, and saltwater intrusion; and a decrease of others such as availability of water resources, the wetland area, and the hydro-electrical power production. Solutions include underground storage, lowering the temperature, increasing soil humidity, reclaimed water infiltration, punctual and directed infiltration, self-purification and naturalization, off-river storage, wetland restoration and/or establishment, flow water distribution by gravity, power saving, eventual recharge of extreme flows, multi-annual management and positive barrier wells against saline water intrusion. The main advantages and disadvantages for each MAR solution have been addressed. As success must be measured, some indicators have been designed or adopted and calculated to quantify the actual effect of these solutions and their evolution. They have been expressed in the form of volumes, lengths, areas, percentages, grades, euros, CO2 emissions, and years. Therefore, MAR in Spain demonstrably supports its usefulness in battling CC adverse impacts in a broad variety of environments and circumstances. This situation is comparable to other countries where MAR improvements have also been assessed.\n",
      "  - Semi-arid and arid regions are characterized by their water scarcity, which leads territories to seek ways of increasing the water resources available to meet their demands (urban, agricultural, industrial, leisure and tourism, etc.). For this reason, this article proposes the term “wastewater use basin”; the concept of the “wastewater use basin” is presented as a working unit of a smaller scale than traditional river basins, which allows for a better management of the water collected in the sewerage network and rainwater of urban agglomerations. It is a geographically-focused proposal for the integrated management of wastewater and stormwater that ends up in a wastewater treatment plant for treatment and reuse. The study area is located in the southeast of the Iberian Peninsula, Spain; specifically, the Campo of Cartagena-Mar Menor district (Murcia) and Vega Baja district (Alicante). The results show the trend behaviour of rainfall in the Segura river basin in recent episodes of torrential rainfall. There is a clear tendency for these episodes to occur in the coastal and pre-coastal areas, so that the water does not reach the headwaters where the reservoirs are located. For this reason, the proposed concept includes the area of the basin that would be formed by the wastewater and rainwater collectors which, in short, are intended to be treated in a treatment plant for subsequent reuse. The calculations made on the basis of the capacity of the environmental tanks executed and projected amount to four cubic hectometers which could be added to the hydrological planning of the Segura basin. In conclusion, the collection of rainwater allows the incorporation of an additional volume of water that complements and increases the resources offered by the treatment plants in the hydrological planning. It also serves as a measure of adaptation to climatic extremes (droughts and floods) and to the effects of climate change, supporting a circular management of the use of resources.\n",
      "--------------------------------------------------\n",
      "Topic 335: 335_doc_dom_permafrost_trace\n",
      "Representative Documents:\n",
      "  - Transport of carbon, major and trace elements by rivers in permafrost-affected regions is one of the key factors in circumpolar aquatic ecosystem response to climate warming and permafrost thaw. A snap-shot study of major and trace element concentration in the Lena River basin during the peak of spring flood revealed a specific group of solutes according to their spatial pattern across the river main stem and tributaries and allowed the establishment of a link to certain landscape parameters. We demonstrate a systematic decrease of labile major and trace anion, alkali and alkaline-earth metal concentration downstream of the main stem of the Lena River, linked to change in dominant rocks from carbonate to silicate, and a northward decreasing influence of the groundwater. In contrast, dissolved organic carbon (DOC) and a number of low-soluble elements exhibited an increase in concentration from the SW to the NE part of the river. We tentatively link this to an increase in soil organic carbon stock and silicate rocks in the Lena River watershed in this direction. Among all the landscape parameters, the proportion of sporadic permafrost on the watershed strongly influenced concentrations of soluble highly mobile elements (Cl, B, DIC, Li, Na, K, Mg, Ca, Sr, Mo, As and U). Another important factor of element concentration control in the Lena River tributaries was the coverage of the watershed by light (for B, Cl, Na, K, U) and deciduous (for Fe, Ni, Zn, Ge, Rb, Zr, La, Th) needle-leaf forest (pine and larch). Our results also suggest a DOC-enhanced transport of low-soluble trace elements in the NW part of the basin. This part of the basin is dominated by silicate rocks and continuous permafrost, as compared to the carbonate rock-dominated and groundwater-affected SW part of the Lena River basin. Overall, the impact of rock lithology and permafrost on major and trace solutes of the Lena River basin during the peak of spring flood was mostly detected at the scale of the main stem. Such an impact for tributaries was much less pronounced, because of the dominance of surface flow and lower hydrological connectivity with deep groundwater in the latter. Future changes in the river water chemistry linked to climate warming and permafrost thaw at the scale of the whole river basin are likely to stem from changes in the spatial pattern of dominant vegetation as well as the permafrost regime. We argue that comparable studies of large, permafrost-affected rivers during contrasting seasons, including winter baseflow, should allow efficient prediction of future changes in riverine ‘inorganic’ hydrochemistry induced by permafrost thaw.\n",
      "  - We studied two medium size pristine rivers (Taz and Ket) of boreal and subarctic zone, western Siberia, for a better understanding of the environmental factors controlling major and trace element transport in riverine systems. Our main objective was to test the impact of climate and land cover parameters (permafrost, vegetation, water coverage, soil organic carbon, and lithology) on carbon, major and trace element concentration in the main stem and tributaries of each river separately and when considering them together, across contrasting climate/permafrost zones. In the permafrost-bearing Taz River (main stem and 17 tributaries), sizable control of vegetation on element concentration was revealed. In particular, light coniferous and broadleaf mixed forest controlled DOC, and some nutrients (NO2, NO3, Mn, Fe, Mo, Cd, Ba), deciduous needle-leaf forest positively correlated with macronutrients (PO4, Ptot, Si, Mg, P, Ca) and Sr, and dark needle-leaf forest impacted Ntot, Al, and Rb. Organic C stock in the upper 30–100 cm soil positively correlated with Be, Mn, Co, Mo, Cd, Sb, and Bi. In the Ket River basin (large right tributary of the Ob River) and its 26 tributaries, we revealed a correlation between the phytomass stock at the watershed and alkaline-earth metals and U concentration in the river water. This control was weakly pronounced during high-water period (spring flood) and mostly occurred during summer low water period. Pairwise correlations between elements in both river systems demonstrated two group of solutes—(1) positively correlated with DIC (Si, alkalis (Li, Na), alkaline-earth metals (Mg, Ca, Sr, Ba), and U), this link originated from groundwater feeding of the river when the labile elements were leached from soluble minerals such as carbonates; and (2) elements positively correlated with DOC (trivalent, tetravalent, and other hydrolysates, Se and Cs). This group reflected mobilization from upper silicate mineral soil profile and plant litter, which was strongly facilitated by element colloidal status, notably for low-mobile geochemical tracers. The observed DOC vs DIC control on riverine transport of low-soluble and highly mobile elements, respectively, is also consistent with former observations in both river and lake waters of the WSL as well as in soil waters and permafrost ice. A principal component analysis demonstrated three main factors potentially controlling the major and TE concentrations. The first factor, responsible for 26% of overall variation, included aluminum and other low mobile trivalent and tetravalent hydrolysates, Be, Cr, Nb, and elements strongly complexed with DOM such as Cu and Se. This factor presumably reflected the presence of organo-mineral colloids, and it was positively affected by the proportion of forest and organic C in soils of the watershed. The second factor (14% variation) likely represented a combined effect of productive litter in larch forest growing on carbonate-rich rocks and groundwater feeding of the rivers and acted on labile Na, Mg, Si, Ca, P, and Fe(II), but also DOC, micronutrients (Zn, Rb, Ba), and phytomass at the watershed. Via applying a substituting space for time approach for south-north gradient of studied river basins, we predict that climate warming in northern rivers may double or triple the concentration of DIC, Ca, Sr, U, but also increase the concentration of DOC, POC, and nutrients.\n",
      "  - In order to foresee possible changes in the elementary composition of Arctic river waters, complex studies with extensive spatial coverage, including gradients in climate and landscape parameters, are needed. Here, we used the unique position of the Ob River, draining through the vast partially frozen peatlands of the western Siberia Lowland and encompassing a sizable gradient of climate, permafrost, vegetation, soils and Quaternary deposits, to assess a snap-shot (8–23 July 2016) concentration of all major and trace elements in the main stem (~3000 km transect from the Tom River confluence in the south to Salekhard in the north) and its 11 tributaries. During the studied period, corresponding to the end of the spring flood-summer baseflow, there was a systematic decrease, from the south to the north, of Dissolved Inorganic Carbon (DIC), Specific Conductivity, Ca and some labile trace elements (Mo, W and U). In contrast, Dissolved Organic Carbon (DOC), Fe, P, divalent metals (Mn, Ni, Cu, Co and Pb) and low mobile trace elements (Y, Nb, REEs, Ti, Zr, Hf and Th) sizably increased their concentration northward. The observed latitudinal pattern in element concentrations can be explained by progressive disconnection of groundwaters from the main river and its tributaries due to a northward increase in the permafrost coverage. A northward increase in bog versus forest coverage and an increase in DOC and Fe export enhanced the mobilization of insoluble, low mobile elements which were present in organo-ferric colloids (1 kDa—0.45 µm), as confirmed by an in-situ dialysis size fractionation procedure. The chemical composition of the sampled mainstream and tributaries demonstrated significant (p &lt; 0.01) control of latitude of the sampling point; permafrost coverage; proportion of bogs, lakes and floodplain coverage and lacustrine and fluvio-glacial Quaternary deposits of the watershed. This impact was mostly pronounced on DOC, Fe, P, divalent metals (Mn, Co, Ni, Cu and Pb), Rb and low mobile lithogenic trace elements (Al, Ti, Cr, Y, Zr, Nb, REEs, Hf and Th). The pH and concentrations of soluble, highly mobile elements (DIC, SO4, Ca, Sr, Ba, Mo, Sb, W and U) positively correlated with the proportion of forest, loesses, eluvial, eolian, and fluvial Quaternary deposits on the watershed. Consistent with these correlations, a Principal Component Analysis demonstrated two main factors explaining the variability of major and trace element concentration in the Ob River main stem and tributaries. The DOC, Fe, divalent metals and trivalent and tetravalent trace elements were presumably controlled by a northward increase in permafrost, floodplain, bogs, lakes and lacustrine deposits on the watersheds. The DIC and labile alkaline-earth metals, oxyanions (Mo, Sb and W) and U were impacted by southward-dominating forest coverage, loesses and eluvial and fertile soils. Assuming that climate warming in the WSL will lead to a northward shift of the forest and permafrost boundaries, a “substituting space for time” approach predicts a future increase in the concentration of DIC and labile major and trace elements and a decrease of the transport of DOC and low soluble trace metals in the form of colloids in the main stem of the Ob River. Overall, seasonally-resolved transect studies of large riverine systems of western Siberia are needed to assess the hydrochemical response of this environmentally-important territory to on-going climate change.\n",
      "--------------------------------------------------\n",
      "Topic 336: 336_fhum_events_wpd_projected\n",
      "Representative Documents:\n",
      "  - . The impact of projected climate change on the long-term hydrological balance and seasonal variability in the federal German state of Thuringia was assessed and analysed. For this study projected climate data for the scenarios A2 and B1 were used in conjunction with a conceptual hydrological model. The downscaled climate data are based on outputs of the general circulation model ECHAM5 and provide synthetic climate time series for a large number of precipitation and climate stations in Germany for the time period of 1971 to 2100. These data were used to compute the spatially distributed hydrological quantities, i.e. precipitation, actual evapotranspiration and runoff generation with a conceptual hydrological model. This paper discusses briefly the statistical downscaling method and its validation in Thuringia and includes an overview of the hydrological model. The achieved results show that the projected climate conditions in Thuringia follow the general European climate trends – increased temperature, wetter winters, drier summers. But, in terms of the spatial distribution and interannual variability regional differences occur. The analysis showed that the general increase of the winter precipitation is more distinct in the mid-mountain region and less pronounced in the lowland whereas the decrease of summer precipitation is higher in the lowland and less distinct in the mid-mountains. The actual evapotranspiration showed a statewide increase due to higher temperatures which is largest in the summer period. The resulting runoff generation in winter was found to increase in the mid-mountains and to slightly decrease in the lowland region. In summer and fall a decrease in runoff generation was estimated for the entire area due to lower precipitation and higher evapotranspiration rates. These spatially differentiated results emphasize the need of high resolution climate input data and distributed modelling for regional impact analyses.                    \n",
      "  - Heavy rainfall events during the fall season are causing extended damages in Mediterranean catchments. A peaks‐over‐threshold model is developed for the extreme daily areal rainfall occurrence and magnitude in fall over six catchments in Southern France. The main driver of the heavy rainfall events observed in this region is the humidity flux (FHUM) from the Mediterranean Sea. Reanalysis data are used to compute the daily FHUM during the period 1958–2008, to be included as a covariate in the model parameters. Results indicate that the introduction of FHUM as a covariate can improve the modelling of extreme areal precipitation. The seasonal average of FHUM can improve the modelling of the seasonal occurrences of heavy rainfall events, whereas daily FHUM values can improve the modelling of the events magnitudes. In addition, an ensemble of simulations produced by five different general circulation models are considered to compute FHUM in future climate with the emission scenario A1B and hence to evaluate the effect of climate change on the heavy rainfall distribution in the selected catchments. This ensemble of climate models allows the evaluation of the uncertainties in climate projections. By comparison to the reference period 1960–1990, all models project an amplification of the mean seasonal FHUM from the Mediterranean Sea for the projection period 2070–2099, on average by +22%. This increase in FHUM leads to an increase in the number of heavy rainfall events, from an average of 2.55 events during the fall season in present climate to 3.57 events projected for the period 2070–2099. However, the projected changes have limited effects on the magnitude of extreme events, with only a 5% increase in the median of the 100‐year quantiles. Copyright © 2011 John Wiley &amp; Sons, Ltd.\n",
      "  - Increasing precipitation extremes are one of the possible consequences of a warmer climate. These may exceed the capacity of urban drainage systems, and thus impact the urban environment. Because short‐duration precipitation events are primarily responsible for flooding in urban systems, it is important to assess the response of extreme precipitation at hourly (or sub‐hourly) scales to a warming climate. This study aims to evaluate the projected changes in extreme rainfall events across the region of Sicily (Italy) and, for two urban areas, to assess possible changes in Depth‐Duration‐Frequency (DDF) curves. We used Regional Climate Model outputs from Coordinated Regional Climate Downscaling Experiment for Europe area ensemble simulations at a ~12 km spatial resolution, for the current period and 2 future horizons under the Representative Concentration Pathways 8.5 scenario. Extreme events at the daily scale were first investigated by comparing the quantiles estimated from rain gauge observations and Regional Climate Model outputs. Second, we implemented a temporal downscaling approach to estimate rainfall for sub‐daily durations from the modelled daily precipitation, and, lastly, we analysed future projections at daily and sub‐daily scales. A frequency distribution was fitted to annual maxima time series for the sub‐daily durations to derive the DDF curves for 2 future time horizons and the 2 urban areas. The overall results showed a raising of the growth curves for the future horizons, indicating an increase in the intensity of extreme precipitation, especially for the shortest durations. The DDF curves highlight a general increase of extreme quantiles for the 2 urban areas, thus underlining the risk of failure of the existing urban drainage systems under more severe events.\n",
      "--------------------------------------------------\n",
      "Topic 337: 337_tsunami_rip_shoreline_rip current\n",
      "Representative Documents:\n",
      "  -  Numerical ocean models are considered today as an essential tool to predict spurt in the sea level rise and associated inland extent of flooding that could be generated by a cyclonic storm crossing any coastal stretch. For this purpose, the advanced two-dimensional depth-integrated (ADCIRC-2DDI) circulation model based on finite-element formulation is applied for the simulation of surges and associated water levels off Kalpakkam coast. Using the long term inventory of cyclone database, synthesized tracks are deduced for affected coastal districts of Tamil Nadu, a state bordering the Bay of Bengal encompassing the Kalpakkam region. Return periods are also computed for the intensity and frequency of cyclones at each coastal district of Tamil Nadu. Using the ADCIRC-2DDI model, validation of surges and associated water levels generated by the November 2000 cyclone, which had landfall near Pondicherry coast was initially carried out. The simulation exercise exhibits a good agreement with available observations from post-storm survey reports. Considering the importance of Kalpakkam region, extreme water levels are computed based on a 50-year return period data, for the generation of storm surges, associated water levels and extent of inland inundation. Based on experimental evidence, it is advocated that this region could be inundated from produced water levels when pressure deficit exceeds a threshold value of 66hPa. Also it is noticed that the horizontal extent of inland inundation ranges between 1–1.5 km associated with the peak surge. \n",
      "  -  Nearshore wave transformation is a complex coastal process of shoaling, refraction, diffraction, reflection, and energy dissipation due to bed friction and breaking contributing variations in the wave height, period and direction. A well defined sediment cell of about 45 km extending from Kovalam headland to Varkala cliff which forms a part of Thiruvananthapuram coast along the southwest coast of India, is selected for the wave transformation studies. In the present study MIKE 21 Spectral Wave model (DHI, 2011) was used. The model simulates the growth, decay and transformation of wind generated waves and swells both in offshore and coastal areas. Providing MIKE 21 SW with a suitable bathymetry is essential for obtaining reliable results from the model. Usually the offshore bathymetry is derived from C-MAP, ETOPO, GEBCO etc. and the nearshore bathymetry is generated from close grid bathymetric surveys. In this study offshore bathymetry was generated from GEBCO-08 grid which is a freely available software with 30 arc (∼ 1 km) resolution. In the nearshore zone, surveyed close grid bathymetric data were used. The other inputs such as wave measurements and wind data provided in the model were from observations in Lakshadweep Sea. Model result is calibrated with field observations along this sector. The model has efficiently simulated the process of shoaling and refraction along the coast. The percentage of observed shoaling is 12.7% at a distance of 24 km from the shoreline at a depth of 70m and it was seen to be increasing to 27.9% when it reached around 2.4 km from the shore at a depth of 10m. The model result also shows that the wave is almost aligned parallel to the coast as wave approaches the coast. This model result can be used for further applications in designing along this coast. \n",
      "  - PurposePahang beaches draw more than thousand visitors throughout the year. From the year 2006 to 2018, more than 30 drowning and near-drowning cases were recorded mainly from rip currents. Rip currents are defined as unexpected currents that carried beachgoers away to seaward direction more than approximately 50 m from shore. The prediction of rip current development is very important for the protection of human life. This study aims to conduct preliminary survey and field works to identify rip current hazards.Design/methodology/approachThe output would be an early warning preventative mitigation to public in Pahang. Beach state model, dimensionless fall velocity, littoral environment observation and relative tidal range were recorded for five recreational beaches during two different months (March and April 2018). The morphodynamic parameters such sediment fall velocity, sediment grain size and beach slope are then analysed using software PROFILER. Classification of risks was done based on beach morphodynamic model. The morphodynamics are classified as low tide bar rip, barred and low tide terrace associated with rip current, bar dissipative, reflective, non-bar dissipative, low tide terrace and ultra-dissipative.FindingsResult shows three out of five recreational beaches may develop high-risk rip currents. During the first month of the survey, Batu Hitam (BH) was recorded the only one recreational beach that may develop high-risk rip current followed by Teluk Cempedak (TC) and Kempadang (KEM) as middle-risk rip current beaches, while Balok (BA) and Sepat (SEP) as low-risk rip current beaches. Different during second month of the survey, BA, BH and SEP were recorded as high-risk rip current beaches while TC and KEM as low-risk rip current beaches.Originality/valueThe results are consistent with beach incidents (drowning and near-drowning) reported.\n",
      "--------------------------------------------------\n",
      "Topic 338: 338_original version_corrected pdf_corrected pdf versions_original\n",
      "Representative Documents:\n",
      "  - The original version of this Article contained an error in the spelling of the author Stanley S. Chou, which was incorrectly given as Stan Chou. This has now been corrected in both the PDF and HTML versions of the Article.\n",
      "  - The original version of this Article contained errors in the author affiliations. Affiliation 1 incorrectly read ‘School of Chemical Engineering, University of New South Wales (UNSW), Sydney, NSW 2031, Australia’ and affiliation 4 incorrectly read ‘School of Engineering, RMIT University, Melbourne, VIC 3001, Australia.’ This has now been corrected in both the PDF and HTML versions of the Article.\n",
      "  - The original version of this Article contained an error in Figure 2. In panel a, the x axis of the graph was incorrectly labeled ‘precipitation bias’, and should have read ‘negative precipitation bias’. This error has been corrected in both the PDF and HTML versions of the Article.\n",
      "--------------------------------------------------\n",
      "Topic 339: 339_plots_heaters_heating_canopy\n",
      "Representative Documents:\n",
      "  - Warming open‐field plots using arrays of infrared heaters has proven feasible for conducting experiments to determine the likely effects of global warming on various ecosystems. To date, however, such experiments have been done for only a few degrees (≤3.5°C) of warming, yet climate projections, especially for high latitudes, indicate that future warming may be 10°C or more. Therefore, there is a need to conduct such experiments with more heating, which increases expense. To estimate energy requirements and costs for such temperature free‐air controlled enhancement (T‐FACE) experiments, improved theory was developed whereby: (i) the canopy temperature of an unheated plot is computed using the well‐accepted Monin–Obukhov similarity theory, with some constraints to calculate aerodynamic resistance; (ii) the desired amount of warming is added; and (iii) the energy balance is re‐solved to obtain the additional infrared radiation needed from the heaters to attain the desired temperature of the heated plots. Performance data are presented from T‐FACE experiments with 3‐m‐diameter plots conducted over six wheat (Triticum aestivum L.) crops and for 1‐wk periods over soybean [Glycine max (L.) Merr.] and northern mixed‐grass prairie. The T‐FACE system over wheat provided warming temperatures for day and night that were within 0.1°C of the desired setpoint differences. The measured or predicted energy requirements of the T‐FACE system for raising the wheat canopy temperatures averaged about 7.0 kWh m−2 d−1. Predictions of canopy temperatures and infrared heating requirements agreed with measurements most of the time for wheat, soybean, and prairie.\n",
      "  - In order to study the likely effects of global warming on future ecosystems, a method for applying a heating treatment to open‐field plant canopies (i.e. a temperature free‐air controlled enhancement (T‐FACE) system) is needed which will warm vegetation as expected by the future climate. One method which shows promise is infrared heating, but a theory of operation is needed for predicting the performance of infrared heaters. Therefore, a theoretical equation was derived to predict the thermal radiation power required to warm a plant canopy per degree rise in temperature per unit of heated land area. Another equation was derived to predict the thermal radiation efficiency of an incoloy rod infrared heater as a function of wind speed. An actual infrared heater system was also assembled which utilized two infrared thermometers to measure the temperature of a heated plot and that of an adjacent reference plot and which used proportional–integrative–derivative control of the heater to maintain a constant temperature difference between the two plots. Provided that it was not operated too high above the canopy, the heater system was able to maintain a constant set‐point difference very well. Furthermore, there was good agreement between the measured and theoretical unit thermal radiation power requirements when tested on a Sudan grass (Sorghum vulgare) canopy. One problem that has been identified for infrared heating of experimental plots is that the vapor pressure gradients (VPGs) from inside the leaves to the air outside would not be the same as would be expected if the warming were performed by heating the air everywhere (i.e. by global warming). Therefore, a theoretical equation was derived to compute how much water an infrared‐warmed plant would lose in normal air compared with what it would have lost in air which had been warmed at constant relative humidity, as is predicted with global warming. On an hourly or daily basis, it proposed that this amount of water could be added back to plants using a drip irrigation system as a first‐order correction to this VPG problem.\n",
      "  - There is a need for methodology to warm open‐field plots in order to study the likely effects of global warming on ecosystems in the future. Herein, we describe the development of arrays of more powerful and efficient infrared heaters with ceramic heating elements. By tilting the heaters at 45° from horizontal and combining six of them in a hexagonal array, good uniformity of warming was achieved across 3‐m‐diameter plots. Moreover, there do not appear to be obstacles (other than financial) to scaling to larger plots. The efficiency [ηh (%); thermal radiation out per electrical energy in] of these heaters was higher than that of the heaters used in most previous infrared heater experiments and can be described by: ηh= 10 + 25exp(− 0.17 u), where u is wind speed at 2 m height (m s− 1). Graphs are presented to estimate operating costs from degrees of warming, two types of plant canopy, and site windiness. Four such arrays were deployed over plots of grass at Haibei, Qinghai, China and another at Cheyenne, Wyoming, USA, along with corresponding reference plots with dummy heaters. Proportional integral derivative systems with infrared thermometers to sense canopy temperatures of the heated and reference plots were used to control the heater outputs. Over month‐long periods at both sites, about 75% of canopy temperature observations were within 0.5 °C of the set‐point temperature differences between heated and reference plots. Electrical power consumption per 3‐m‐diameter plot averaged 58 and 80 kW h day− 1 for Haibei and Cheyenne, respectively. However, the desired temperature differences were set lower at Haibei (1.2 °C daytime, 1.7 °C night) than Cheyenne (1.5 °C daytime, 3.0 °C night), and Cheyenne is a windier site. Thus, we conclude that these hexagonal arrays of ceramic infrared heaters can be a successful temperature free‐air‐controlled enhancement (T‐FACE) system for warming ecosystem field plots.\n",
      "--------------------------------------------------\n",
      "Topic 340: 340_cmorph_validation_gnss_method\n",
      "Representative Documents:\n",
      "  - High-resolution real-time satellite-based precipitation estimation datasets can play a more essential role in flood forecasting and risk analysis of infrastructures. This is particularly true for extended deserts or mountainous areas with sparse rain gauges like Iran. However, there are discrepancies between these satellite-based estimations and ground measurements, and it is necessary to apply adjustment methods to reduce systematic bias in these products. In this study, we apply a quantile mapping method with gauge information to reduce the systematic error of the Precipitation Estimation from Remotely Sensed Information using Artificial Neural Networks-Cloud Classification System (PERSIANN-CCS). Due to the availability and quality of the ground-based measurements, we divide Iran into seven climate regions to increase the sample size for generating cumulative probability distributions within each region. The cumulative distribution functions (CDFs) are then employed with a quantile mapping 0.6° × 0.6° filter to adjust the values of PERSIANN-CCS. We use eight years (2009–2016) of historical data to calibrate our method, generating nonparametric cumulative distribution functions of ground-based measurements and satellite estimations for each climate region, as well as two years (2017–2018) of additional data to validate our approach. The results show that the bias correction approach improves PERSIANN-CCS data at aggregated to monthly, seasonal and annual scales for both the calibration and validation periods. The areal average of the annual bias and annual root mean square errors are reduced by 98% and 56% during the calibration and validation periods, respectively. Furthermore, the averages of the bias and root mean square error of the monthly time series decrease by 96% and 26% during the calibration and validation periods, respectively. There are some limitations in bias correction in the Southern region of the Caspian Sea because of shortcomings of the satellite-based products in recognizing orographic clouds.\n",
      "  - Against the background of global climate change and anthropogenic stresses, extreme climate events (ECEs) are projected to increase in both frequency and intensity. Precipitation is one of the main climate parameters for ECE analysis. However, accurate precipitation information for extreme climate events research from dense rain gauges is still difficult to obtain in mountainous or economically disadvantaged regions. Satellite precipitation products (SPPs) with high spatial and temporal resolution offer opportunities to monitor ECE intensities and trends on large spatial scales. In this study, the accuracies of seven SPPs on multiple spatiotemporal scales in the Yangtze River Basin (YRB) during the period of 2003–2017 are evaluated, along with their ability to capture ECE characteristics. The seven products are the Tropical Rainfall Measuring Mission, Climate Hazards Group InfraRed Precipitation with Station Data (CHIRPS) (25), CHIRPS (05), Climate Prediction Center Morphing (CMORPH), Precipitation Estimation from Remotely Sensed Information using Artificial Neural Networks (PERSIANN)-Climate Data Record, PERSIANN-Cloud Classification System, and Global Precipitation Measurement (GPM) IMERG. Rain gauge precipitation data provided by the China Meteorological Administration are adopted as reference data. Various statistical evaluation metrics and different ECE indexes are used to evaluate and compare the performances of the selected products. The results show that CMORPH has the best agreement with the reference data on the daily and annual scales, but GPM IMERG performs relatively well on the monthly scale. With regard to ECE monitoring in the YRB, in general, GPM IMERG and CMORPH provide higher precision. As regards the spatial heterogeneity of the SPP performance in the YRB, most of the examined SPPs have poor accuracy in the mountainous areas of the upper reach. Only CMORPH and GPM IMERG exhibit superior performance; this is because they feature an improved inversion precipitation algorithm for mountainous areas. Furthermore, most SPPs have poor ability to capture extreme precipitation in the estuaries of the lower reach and to monitor drought in the mountainous areas of the upper reach. This study can provide a reference for SPP selection for ECE analysis.\n",
      "  - . Precipitation is one of the most important components of the global water cycle. Precipitation data at high spatial and temporal resolutions are crucial for basin-scale hydrological and meteorological studies. In this study, we propose a cumulative distribution of frequency (CDF)-based downscaling method (DCDF) to obtain hourly 0.05∘ × 0.05∘ precipitation data. The main hypothesis is that a variable with the same resolution of target data should produce a CDF that is similar to the reference data. The method was demonstrated using the 3-hourly 0.25∘ × 0.25∘ Climate Prediction Center morphing method (CMORPH) dataset and the hourly 0.05∘ × 0.05∘ FY2-E geostationary (GEO) infrared (IR) temperature brightness (Tb) data. Initially, power function relationships were established between the precipitation rate and Tb for each 1∘ × 1∘ region. Then the CMORPH data were downscaled to 0.05∘ × 0.05∘. The downscaled results were validated over diverse rainfall regimes in China. Within each rainfall regime, the fitting functions' coefficients were able to implicitly reflect the characteristics of precipitation. Quantitatively, the downscaled estimates not only improved spatio-temporal resolutions, but also performed better (bias: −7.35–10.35 %; correlation coefficient, CC: 0.48–0.60) than the CMORPH product (bias: 20.82–94.19 %; CC: 0.31–0.59) over convective precipitating regions. The downscaled results performed as well as the CMORPH product over regions dominated with frontal rain systems and performed relatively poorly over mountainous or hilly areas where orographic rain systems dominate. Qualitatively, at the daily scale, DCDF and CMORPH had nearly equivalent performances at the regional scale, and 79 % DCDF may perform better than or nearly equivalently to CMORPH at the point (rain gauge) scale. The downscaled estimates were able to capture more details about rainfall motion and changes under the condition that DCDF performs better than or nearly equivalently to CMORPH.\n",
      "--------------------------------------------------\n",
      "Topic 341: 341_reservoir_hydropower_hydropower stations_tsengwen\n",
      "Representative Documents:\n",
      "  - With exacerbating climate change, the current reservoir storage capacity in South Korea is insufficient to meet the future scheduled water demand. No study has yet evaluated the effects of applying the water supply adjustment standard (Standard) and activating the reservoir emergency storage in response to extreme drought. The main objective is to assess the effects of applying Standard and activating emergency storage in meeting the water demand under extreme drought at six multipurpose reservoirs (Andong, Gimcheon-Buhang, Gunwi, Hapcheon, Imha, and Milyang) in the Nakdong River Basin, South Korea. We built a reservoir simulation model (HEC-ResSim), determined the extreme drought scenarios, and emergency storage capacity. We evaluated three reservoir operation cases (general operation, regular Standard, and revised Standard) from 2011 to 2100. The results show that applying the Standard and activating the emergency storage are effective in meeting the future water demand during extreme drought. In conclusion, we need to secure 110 million cubic meters (MCM) (Hapcheon reservoir) and 8 MCM (Gunwi reservoir) of water to reduce the number of days in the emergency stage. This research serves as a fundamental study that can help establish Standard and emergency storage activation criteria for other multipurpose reservoirs in preparation for extreme drought.\n",
      "  - Changes in rainfall and streamflow due to climate change have an adverse impact on hydropower generation reliability and scheduling of cascade hydropower stations. To estimate the impact of climate change on hydropower, a combination of climate, hydrological, and hydropower scheduling models is needed. Here, we take the Jinsha River as an example to estimate the impact of climate change on total power generation of the cascade hydropower stations and residual load variance of the power grid. These two goals are solved by applying an improved multi-objective cuckoo search algorithm, and a variety of strategies for the optimal dispatch of hydropower stations are adopted to improve the efficiency of the algorithm. Using streamflow prediction results of CMIP5 climate data, in conjunction with the Xinanjiang model, the estimated results for the next 30 years were obtained. The results indicated that the negative correlation between total power generation and residual load variance under the RCP 2.6 scenario was weaker than that under the RCP 8.5. Moreover, the average power generation and the average residual load variance in RCP 2.6 was significantly larger than that in RCP 8.5. Thus, reducing carbon emissions is not only beneficial to ecological sustainability, but also has a positive impact on hydropower generation. Our approaches are also applicable for cascade reservoirs in other river catchments worldwide to estimate impact of climate change on hydropower development.\n",
      "  - Climate change and human activities are two driving factors that affect the hydrological cycle of watersheds and water resource evolution. As a pivotal input to hydropower stations, changes in runoff processes may reduce the effectiveness of existing operation procedures. Therefore, it is important to analyze the influences of cascade hydropower stations under climate change and human activities and to propose revised optimal operation strategies. For the present study, three runoff series conditions including: Initial runoff, affected by only climate change, and affected by both climate change and human activities are examined by a simulation model to analyze the influence on power generation with four schemes. Additionally, an optimal operation model of cascade power stations is proposed based on the simulation model to generate single and joint optimal operation charts for future hydrological scenarios. The paper also proposes to change human activities based on optimizing operation rules to reduce its influence on downstream power stations. This procedure is theoretically applied and varied for three power stations in the upper Han River, China. The results show that the influence of climate change is greater than that of human activities in that power generation decreased by 17.95% and 12.83%, respectively, whereas combined, there is a reduction of 25.71%. Under existing hydrological conditions, the modified single and joint operation charts would increase power generation by about 32 million and 47 million kWh. Furthermore, after optimizing the upstream project, the abandoned water and power generation of these cascade power stations would reduce by 150 million m3 and 5 million kWh, respectively. This study has practical significance for the efficient operation of cascade hydropower stations and is helpful for developing reservoir operation theory under changing environments.\n",
      "--------------------------------------------------\n",
      "Topic 342: 342_pv_energy_system_pv system\n",
      "Representative Documents:\n",
      "  - Solar photovoltaic (PV) systems are widely used to mitigate greenhouse gases (GHG), due to their green renewable nature. However, environmental factors such as bird drops, shade, pollution, etc., accommodation on PV panels surface reduce photons transmission to PV cells, which results in lower energy yield and GHG mitigation potential of PV system. In this study, the PV system’s energy and GHG mitigation potential loss is investigated under environmental stresses. Defects/hotspots caused by the environment on PV panel surface have unknown occurrence frequency, time duration, and intensity and are highly variable from location to location. Therefore, different concentrations of defects are induced in a healthy 12 kWp PV system. Healthy PV system has the potential to avoid the burning of 3427.65 L of gasoline by 16,157.9 kWh green energy production per annum. However, in 1% and 20% defective systems, green energy potential reduces to 15,974.3 and 12,485.6 kWh per annum, respectively. It is equivalent to lesser evasion burning of 3388.70, and 2648.64 L of gasoline, respectively. A timely solution to defective panels can prevent losses in the PV system to ensure optimal performance.\n",
      "  -                Development of a zero energy community is more costly in northern cold climates than in moderate regions. Building energy loads are higher, thanks to the colder weather, and site solar photovoltaics (PV) are less productive due to lower solar incidence and misalignment with the buildings’ energy needs (summer production, winter demands). Geothermal energy production can support a zero energy community through application of energy efficiency (demand design), geothermal production (supply design), and asset dispatch as an integrated techno-economic package. This article presents the process used to explore geothermal system integration, our findings, and technical challenges for community-scale adoption of geothermal as an electric and thermal resource. We show that under a wide range of conditions, community-scale geothermal electric power and direct-use thermal energy is economically competitive with “business-as-usual” design and construction practices for zero energy communities. Furthermore, geothermal-produced energy will be self-consumed to a much greater extent than PV, resulting in significant reductions in site energy import and export. We conclude that under appropriate conditions, community-scale geothermal can be the most economically favorable energy resource for northern-climate zero energy community developments. Ongoing geothermal research and development to improve performance and reduce costs will further enhance the value proposition for community-scale geothermal technologies. We expect that including geothermal power and thermal energy in zero energy community design can improve its cost-effectiveness and therefore enhance the benefits of zero energy in more northern climates.\n",
      "  - Increased concerns over global warming and air pollution has pushed governments to consider renewable energy as an alternative to meet the required energy demands of countries. Many government policies are deployed in Taiwan to promote solar and wind energy to cope with air pollution and self-dependency for energy generation. However, the residential sector contribution is not significant despite higher feed-in tariff rates set by government. This study analyzes wind and solar power availability of four different locations of southern Taiwan, based on the Köppen–Geiger climate classification system. The solar–wind hybrid system (SWHS) considered in this study consists of multi-crystalline photovoltaic (PV) modules, vertical wind turbines, inverters and batteries. Global reanalysis weather data and a climate-based electricity load profile at a 1-h resolution was used for the simulation. A general framework for multi-objective optimization using this simulation technique is proposed for solar–wind hybrid system, considering the feed-in tariff regulations, environmental regulations and installation area constraints of Taiwan. The hourly load profile is selected using a climate classification system. A decomposition-based differential evolutionary algorithm is used for finding the optimal Pareto set of two economic objectives and one environmental objective with maximum installation area and maximum PV capacity constraints. Two types of buildings are chosen for analysis at four climate locations. Analysis of Pareto sets revealed that the photovoltaic modules are economic options for a grid-connected mode at all four locations, whereas solar–wind hybrid systems are more environmentally friendly. A method of finding the fitness index for the Pareto front sets and a balanced strategy for choosing the optimal configuration is proposed. The proposed balanced strategy provides savings to users—up to 49% for urban residential buildings and up to 32% for rural residential buildings with respect to buildings without a hybrid energy system (HES)—while keeping carbon dioxide (CO2) emissions lower than 50% for the total project lifecycle time of 20 years. The case study reveals that for all four locations and two building types an HES system comprising a 15 kW photovoltaic system and a small capacity battery bank provides the optimal balance between economic and environmental objectives.\n",
      "--------------------------------------------------\n",
      "Topic 343: 343_ozone_chemistry_chem2d_model\n",
      "Representative Documents:\n",
      "  - . Nudging as an assimilation technique has seen increased use in recent years in the development and evaluation of climate models. Constraining the simulated wind and temperature fields using global weather reanalysis facilitates more straightforward comparison between simulation and observation, and reduces uncertainties associated with natural variabilities of the large-scale circulation. On the other hand, the forcing introduced by nudging can be strong enough to change the basic characteristics of the model climate. In the paper we show that for the Community Atmosphere Model version 5 (CAM5), due to the systematic temperature bias in the standard model and the sensitivity of simulated ice formation to anthropogenic aerosol concentration, nudging towards reanalysis results in substantial reductions in the ice cloud amount and the impact of anthropogenic aerosols on long-wave cloud forcing.  In order to reduce discrepancies between the nudged and unconstrained simulations, and meanwhile take the advantages of nudging, two alternative experimentation methods are evaluated. The first one constrains only the horizontal winds. The second method nudges both winds and temperature, but replaces the long-term climatology of the reanalysis by that of the model. Results show that both methods lead to substantially improved agreement with the free-running model in terms of the top-of-atmosphere radiation budget and cloud ice amount. The wind-only nudging is more convenient to apply, and provides higher correlations of the wind fields, geopotential height and specific humidity between simulation and reanalysis. Results from both CAM5 and a second aerosol–climate model ECHAM6-HAM2 also indicate that compared to the wind-and-temperature nudging, constraining only winds leads to better agreement with the free-running model in terms of the estimated shortwave cloud forcing and the simulated convective activities. This suggests nudging the horizontal winds but not temperature is a good strategy for the investigation of aerosol indirect effects since it provides well-constrained meteorology without strongly perturbing the model's mean climate.                    \n",
      "  - . The new CHEM2D-Ozone Photochemistry Parameterization (CHEM2D-OPP) for high-altitude numerical weather prediction (NWP) systems and climate models specifies the net ozone photochemical tendency and its sensitivity to changes in ozone mixing ratio, temperature and overhead ozone column based on calculations from the CHEM2D interactive middle atmospheric photochemical transport model. We evaluate CHEM2D-OPP performance using both short-term (6-day) and long-term (1-year) stratospheric ozone simulations with the prototype high-altitude NOGAPS-ALPHA forecast model. An inter-comparison of NOGAPS-ALPHA 6-day ozone hindcasts for 7 February 2005 with ozone photochemistry parameterizations currently used in operational NWP systems shows that CHEM2D-OPP yields the best overall agreement with both individual Aura Microwave Limb Sounder ozone profile measurements and independent hemispheric (10°–90° N) ozone analysis fields. A 1-year free-running NOGAPS-ALPHA simulation using CHEM2D-OPP produces a realistic seasonal cycle in zonal mean ozone throughout the stratosphere. We find that the combination of a model cold temperature bias at high latitudes in winter and a warm bias in the CHEM2D-OPP temperature climatology can degrade the performance of the linearized ozone photochemistry parameterization over seasonal time scales despite the fact that the parameterized temperature dependence is weak in these regions.                    \n",
      "  - . We present the third generation of the coupled chemistry–climate model (CCM) SOCOL (modeling tools for studies of SOlar Climate Ozone Links). The most notable modifications compared to the previous model version are (1) the dynamical core has been updated with the fifth generation of the middle-atmosphere general circulation model MA-ECHAM (European Centre/HAMburg climate model), and (2) the advection of the chemical species is now calculated by a mass-conserving and shape-preserving flux-form transport scheme instead of the previously used hybrid advection scheme. The whole chemistry code has been rewritten according to the ECHAM5 infrastructure and transferred to Fortran95. In contrast to its predecessors, SOCOLvs3 is now fully parallelized. The performance of the new SOCOL version is evaluated on the basis of transient model simulations (1975–2004) with different horizontal (T31 and T42) resolutions, following the approach of the CCMVal-1 model validation activity. The advanced advection scheme significantly reduces the artificial loss and accumulation of tracer mass in regions with strong gradients that was observed in previous model versions. Compared to its predecessors, SOCOLvs3 generally shows more realistic distributions of chemical trace species, especially of total inorganic chlorine, in terms of the mean state, but also of the annual and interannual variability. Advancements with respect to model dynamics are for example a better representation of the stratospheric mean state in spring, especially in the Southern Hemisphere, and a slowdown of the upward propagation in the tropical lower stratosphere. Despite a large number of improvements model deficiencies still remain. Examples include a too-fast vertical ascent and/or horizontal mixing in the tropical stratosphere, the cold temperature bias in the lowermost polar stratosphere, and the overestimation of polar total ozone loss during Antarctic springtime.                    \n",
      "--------------------------------------------------\n",
      "Topic 344: 344_lulcc_nbcs_land_land use\n",
      "Representative Documents:\n",
      "  - Nature‐based Climate Solutions (NbCS) are managed alterations to ecosystems designed to increase carbon sequestration or reduce greenhouse gas emissions. While they have growing public and private support, the realizable benefits and unintended consequences of NbCS are not well understood. At regional scales where policy decisions are often made, NbCS benefits are estimated from soil and tree survey data that can miss important carbon sources and sinks within an ecosystem, and do not reveal the biophysical impacts of NbCS for local water and energy cycles. The only direct observations of ecosystem‐scale carbon fluxes, for example, by eddy covariance flux towers, have not yet been systematically assessed for what they can tell us about NbCS potentials, and state‐of‐the‐art remote sensing products and land‐surface models are not yet being widely used to inform NbCS policymaking or implementation. As a result, there is a critical mismatch between the point‐ and tree‐scale data most often used to assess NbCS benefits and impacts, the ecosystem and landscape scales where NbCS projects are implemented, and the regional to continental scales most relevant to policymaking. Here, we propose a research agenda to confront these gaps using data and tools that have long been used to understand the mechanisms driving ecosystem carbon and energy cycling, but have not yet been widely applied to NbCS. We outline steps for creating robust NbCS assessments at both local to regional scales that are informed by ecosystem‐scale observations, and which consider concurrent biophysical impacts, future climate feedbacks, and the need for equitable and inclusive NbCS implementation strategies. We contend that these research goals can largely be accomplished by shifting the scales at which pre‐existing tools are applied and blended together, although we also highlight some opportunities for more radical shifts in approach.\n",
      "  -                 Purpose of Review                As demand for food and fiber, but also for negative emissions, brings most of the Earth’s land surface under management, we aim to consolidate the scientific progress of recent years on the climatic effects of global land use change, including land management, and related land cover changes (LULCC).                              Recent Findings                We review the methodological advances in both modeling and observations to capture biogeochemical and biogeophysical LULCC effects and summarize the knowledge on underlying mechanisms and on the strength of their effects. Recent studies have raised or resolved several important questions related to LULCC: How can we derive CO2 fluxes related to LULCC from satellites? Why are uncertainties in LULCC-related GHG fluxes so large? How can we explain that estimates of afforestation/reforestation potentials diverge by an order of magnitude? Can we reconcile the seemingly contradicting results of models and observations concerning the cooling effect of high-latitude deforestation?                              Summary                Major progress has been achieved in understanding the complementarity of modeling, observations, and inventories for estimating the impacts of various LULCC practices on carbon, energy, and water fluxes. Emerging fields are the operationalization of the recently achieved integration of approaches, such as a full greenhouse gas balance of LULCC, mapping of emissions from global models to country-reported emissions data, or model evaluation against local biogeophysical observations. Fundamental challenges remain, however, e.g., in separating anthropogenic from natural land use dynamics and accurately quantifying the first. Recent progress has laid the foundation for future research to integrate the local to global scales at which the various effects act, to create co-benefits between global mitigation, including land-based carbon dioxide removal, and changes in local climate for effective adaptation strategies.              \n",
      "  - . Land-use and land-cover change (LULCC) represents one of the key drivers of global environmental change. However, the processes and drivers of anthropogenic land-use activity are still overly simplistically implemented in terrestrial biosphere models (TBMs). The published results of these models are used in major assessments of processes and impacts of global environmental change, such as the reports of the Intergovernmental Panel on Climate Change (IPCC). Fully coupled models of climate, land use and biogeochemical cycles to explore land use–climate interactions across spatial scales are currently not available. Instead, information on land use is provided as exogenous data from the land-use change modules of integrated assessment models (IAMs) to TBMs. In this article, we discuss, based on literature review and illustrative analysis of empirical and modeled LULCC data, three major challenges of this current LULCC representation and their implications for land use–climate interaction studies: (I) provision of consistent, harmonized, land-use time series spanning from historical reconstructions to future projections while accounting for uncertainties associated with different land-use modeling approaches, (II) accounting for sub-grid processes and bidirectional changes (gross changes) across spatial scales, and (III) the allocation strategy of independent land-use data at the grid cell level in TBMs. We discuss the factors that hamper the development of improved land-use representation, which sufficiently accounts for uncertainties in the land-use modeling process. We propose that LULCC data-provider and user communities should engage in the joint development and evaluation of enhanced LULCC time series, which account for the diversity of LULCC modeling and increasingly include empirically based information about sub-grid processes and land-use transition trajectories, to improve the representation of land use in TBMs. Moreover, we suggest concentrating on the development of integrated modeling frameworks that may provide further understanding of possible land–climate–society feedbacks.                    \n",
      "--------------------------------------------------\n",
      "Topic 345: 345_ring_chronologies_ring width_width\n",
      "Representative Documents:\n",
      "  -  Red pine (Pinus resinosa Ait.) of northern Minnesota are part of a growing network of tree-ring chronologies aimed at understanding climate dynamics in the Upper Great Lakes Region. Red pine has been widely used in tree-ring studies of fire and climate variability across its range. Earlier studies have relied primarily on total annual ring width. Here we develop annual and subannual (i.e., earlywood, latewood, and adjusted latewood) chronologies from Itasca State Park to refine our understanding of red pine climate response. Our chronologies extend to the early 18th century and display common growth and cross-dating characteristics indicative of a significant common controlling mechanism. We found that total ring width contains dampened attributes reflective of both the temperature-limited earlywood and moisture-dependent latewood chronologies. The strongest relationship between climate and radial growth is between the adjusted latewood chronology and 3-month summer precipitation, suggesting that overall summer wetness rather than any single summer month primarily limits growth. The ability to disaggregate and improve upon the mixed climate signal of red pine highlights the potential of using intra-annual chronologies to strengthen future climate reconstructions. We hope the methodologies demonstrated here serve as a potential guide for future red pine chronology development in the region. \n",
      "  - Projected changes in the seasonality of hydroclimatic regimes are likely to have important implications for water resources and terrestrial ecosystems in the U.S. Pacific Northwest. The tree ring record, which has frequently been used to position recent changes in a longer‐term context, typically relies on signals embedded in the total ring width of tree rings. Additional climatic inferences at a subannual temporal scale can be made using alternative tree ring metrics such as earlywood and latewood widths and the density of tree ring latewood. Here we examine seasonal precipitation and temperature signals embedded in total ring width, earlywood width, adjusted latewood width, and blue intensity chronologies from a network of six Pinus ponderosa sites in and surrounding the upper Columbia River Basin of the U.S. Pacific Northwest. We also evaluate the potential for combining multiple tree ring metrics together in reconstructions of past cool‐ and warm‐season precipitation. The common signal among all metrics and sites is related to warm‐season precipitation. Earlywood and latewood widths differ primarily in their sensitivity to conditions in the year prior to growth. Total and earlywood widths from the lowest elevation sites also reflect cool‐season moisture. Effective correlation analyses and composite‐plus‐scale tests suggest that combining multiple tree ring metrics together may improve reconstructions of warm‐season precipitation. For cool‐season precipitation, total ring width alone explains more variance than any other individual metric or combination of metrics. The composite‐plus‐scale tests show that variance‐scaled precipitation reconstructions in the upper Columbia River Basin may be asymmetric in their ability to capture extreme events.\n",
      "  - Proxy measures of climate based on tree rings can allow reconstruction of climate back past the limit of instrumental records, thereby improving understanding of natural climate variability. We assessed the dendroclimatic potential of tree-ring widths and δ13C of three broadly co-occurring species of Callitris in south-western Western Australia. Ring width chronologies of C. columellaris F.Muell., C. canescens (Parl.) S.T. Blake and C. preissii Miq. met standard measures of dendrochronological acceptability. For all three species, the Expressed Population Signal (EPS) was &gt;0.93 and mean correlations between series in each chronology was &gt;0.79. In contrast, δ13C chronologies were of poorer statistical quality (EPS ranged 0.59 to 0.88, mean correlations ranged 0.33 to 0.65) with both less year-to-year and lower-frequency information (lower mean sensitivity and standard deviation values). The dominant climatic signal in the ring width chronologies was related to rainfall and was strongest over the March–September season (correlations ranged 0.27 to 0.70, all P &lt; 0.05). Consistent with the poorer quality of the δ13C chronologies compared with those from ring widths, tree-ring δ13C was also less strongly correlated with rainfall and rarely significant (P = 0.05). The weaker δ13C correlations may be due to a strong water conservation strategy by Callitris. Our analysis of the whole ring rather than latewood and low sampling effort may also have dampened the δ13C response. However, combining the ring width and δ13C chronologies using Principal Components Analysis did not enhance the extraction of a climatic signal. While the variance explained by the first principal component (PC) was high for all three species (76 to 87%), correlations between the first PC and rainfall were not stronger than for ring widths alone. Tree-ring δ13C, in conjunction with δ18O in particular, may nevertheless provide insight into physiological responses of Callitris to climate variation. However, dendroclimatic studies using Callitris to develop past rainfall records should focus on developing chronologies from ring widths. Further effort to find sites with old trees (250 years or more) should be undertaken and are likely to provide much needed information on past rainfall in Australia.\n",
      "--------------------------------------------------\n",
      "Topic 346: 346_lid_flood_spillway_canesm2\n",
      "Representative Documents:\n",
      "  - The present research introduces a model to find the best shape of a dam's spillway under climate change impacts, considering a benchmark problem (i.e., Ute Dam's labyrinth spillway in the Canadian River watershed, New Mexico, USA). A spillway design is based not only on historical data but also on the future hydrologic events. Climate variables were predicted for the years 2021–2050 based on three representative concentration pathway (RCP2.6, RCP4.5, and RCP8.5) scenarios of the general circulation model from the fifth phase of the coupled model intercomparison project (CMIP5) using the statistical downscaling model. Streamflow at the USGS 07226500 streamgage was simulated by a rainfall–runoff model with predicted data. Instantaneous peak flow was estimated using an empirical method. Flood frequency analysis was used for the estimation of the design flood. The shuffled frog-leaping algorithm (SFLA) is used to optimize a labyrinth spillway design and its results were compared with two other nature-inspired algorithms: invasive weed optimization (IWO) and cuckoo search (CS). The spillway was optimized once with the actual design flood (16,143 m3/s) and again with the design flood under climate change (12,250 m3/s). Results revealed that optimization with realistic design flood reduced the concrete volume of the spillway by 37% and under climate change by 43% using the SFLA.\n",
      "  - This study integrates and develops methods, namely low impact development (LID) selection method and an LID spatial planning model, to enable decision-making to minimize pluvial flooding for a community. The objective is to minimize the flood risk under the worst case of the design storm within the budget constraints. Design storms in current and future climate scenarios are analyzed as input to the Storm Water Management Model (SWMM). Then, LID practices are selected based on the proposed procedure and a spatial planning model is built to identify the optimal LID layouts using the simulated annealing (SA) algorithm. The lower and upper bounds of the generated rainfall intensities of a five-year 1-h duration design storms for the Hadley Centre Global Environment Model version 2 for the atmosphere and oceans (HadGEM2-AO), the Norwegian Earth System Model (NorESM1-ME), and the CSIRO-Mk3.6.0 Atmosphere-Ocean GCM (CSIRO-Mk3.6.0) during 2021–2040 are derived. The LID selection helps efficiently identify appropriate LID. Results show that nearly no flood occurs under the optimal LID layouts found by the LID spatial planning model. Moreover, it is more optimal to invest in LID in the lower sub-catchments in LID planning when the budget is limited. These methods are generally applicable for a community using LIDs as adaptation measures against pluvial flooding.\n",
      "  -                Climate change is a complex and multi-layer issue with global and local entanglement. In this study, Langat River Basin is chosen. Secondary data was used including the historical flood and drought event reports, Standardized Precipitation Index-1 data and Canadian Earth System Model (CanESM2) along with Australian Community Climate and Earth System Simulator Coupled Model (ACCESS CM-2). These data were used to determine the monthly flood and drought precipitation risk based on five regions of Langat River Basin. The CanESM2 and ACCESS CM-2 based on RCP 4.5 and RCP 8.5 scenarios were downscaled and bias corrected for this study. The reliability of these models was then analyzed with Pearson correlation and probability density function (PDF). The future flood and drought risks from year 2020 to 2100 were predicted using the most reliable local climate model local climate hazard thresholds. The CanESM2 RCP 4.5 scenario was identified to have moderate relationship with the historical precipitation trend in Langat River Basin. The Pearson correlation outcomes were then verified by analyzing the PDF curve between models and historical precipitation. The result shows that the downscaled CanESM2 RCP 4.5 was determined to have moderate correlation r = 0.30, whereas highest similarity with the historical precipitation trend 98.63 % based on 2006 to 2018 period. The scenario is consistent with medium emission coupled with increasing mitigation efforts in Malaysia. Furthermore, the flood and drought risk assessment outcomes show that the occurrence rate for Central, Northern, Southern, Western, and Eastern region in Langat River Basin were determined as 41.97 %, 60.19 %, 40.23 %, 20.16 %, and 34.98% respectively. The Central region was predicted having two drought incidences (February 2069 and February 2099) due to extreme dry season predicted based on 2020 to 2100 period.\n",
      "--------------------------------------------------\n",
      "Topic 347: 347_gpp_npp_nep_gpp ratio\n",
      "Representative Documents:\n",
      "  - Gross primary productivity (GPP) quantifies the photosynthetic uptake of carbon by terrestrial ecosystems. High‐temperature extremes and associated droughts significantly reduce terrestrial ecosystem carbon uptake, but there is uncertainty as to whether climatic extremes can be beneficial to ecosystem carbon uptake. In this study, we used three ecological models: the Boreal Ecosystem Productivity Simulator, the Terrestrial Ecosystem Carbon flux model, and the Global Production Efficiency Model coupled with the Carbon Exchange between Vegetation, Soil, and the Atmosphere model, to simulate China's terrestrial ecosystem GPP during the study period of 1982–2015. Positive GPP extremes were identified on yearly scales and analyzed for their temperature, precipitation, and solar radiation attributions. We found that the 3 years of positive GPP extremes occurred in 1990, 1998, and 2013, with the detrended GPP anomalies of 0.4 PgC/year, 0.2 PgC/year, and 0.3 PgC/year, respectively. Maximum GPP years were associated with an increased carbon uptake in response to increasing temperature and solar radiation under adequate precipitation for plant growth. China's subtropical‐tropical monsoonal region, a region dominated by managed forests and agricultural lands, contributed the largest in GPP extremes and accounted for 46%, 50%, and 46% of the total detrended GPP anomalies in 1990, 1998, and 2013, respectively. Positive GPP extremes were associated with increasing temperature and solar radiation, indicating favorable positive climate extremes would be beneficial to carbon uptake in China's terrestrial ecosystem. This study provides a method to assess positive GPP extremes in response to global climate change.\n",
      "  - Differences, arising from differences in gross primary production (GPP) model structures and driving forces, have fuelled arguments concerning interannual changes of GPP in China since 2000. To better investigate the interannual variability of GPP and its covariance with climate factors in China, this study adopted a multi‐model analysis based on three GPP models (i.e., Terrestrial Ecosystem Carbon flux model [TEC], Breathing Earth System Simulator model [BESS], and MOD17 GPP model). The results show that annual GPP in China increased by 0.021–0.057 Pg C year−1from 2000 to 2015 attributable to atmospheric‐CO2fertilization effects and favourable climate change, that is, increasing precipitation (Pr) and temperature (Ta). However, northern China and southern China had a large difference in the amplitude of these GPP changes; annual GPP increased by 0.017–0.039 Pg C year−1in northern China but only 0.001–0.018 Pg C year−1in southern China. Northern China and southern China occupy contrasting climate zones and this contrast produced different interannual variability of GPP through different mechanisms. Northern China has a dry climate with GPP changes sensitive toPr. As a result, morePralong with higherTain northern China produced the strong uptrend of GPP from 2000 to 2015. In contrast, southern China has a wet climate with its GPP sensitive to solar radiation andTa. For the interval of 2000–2015, decreasing radiation plus drought exerted a negative influence on GPP in southern China. This study highlights the diverse mechanisms in which climate change affects GPP in dry and wet climate zones. A robust multi‐model analysis is preferred to reduce uncertainties arising from a single GPP model and its driving data.\n",
      "  - AimCarbon use efficiency [net primary production (NPP)/gross primary production (GPP) ratio] is a parameter related to the allocation of photosynthesized products by plants and is commonly used in many biogeochemical cycling models. But how this parameter changes with climates is still unknown. Faced by an aggravated global warming, there is a heightened necessity in unravelling the dependence of the NPP/GPP ratio on climates. The objective of this study was to examine how ongoing climate change is regulating global patterns of change in the NPP/GPP ratio. The study finding would elucidate whether the global vegetation ecosystem is becoming more or less efficient in terms of carbon storage under climatic fluctuation.LocationThe global planetary ecosystem.MethodsThe annual NPP/GPP ratio of the global terrestrial ecosystem was calculated over a 10‐year period based on Moderate Resolution Imaging Spectroradiometer data and an ecosystem productivity model. The temporal dynamics of the global NPP/GPP ratio and their dependence on climate were investigated.ResultsThe global NPP/GPP ratio exhibited a decreasing trend from 2000 to 2009 due to decreasing NPP and stable GPP over this period. The temporal dynamics of the NPP/GPP ratio were strongly controlled by temperature and precipitation. Increased temperature lowered the NPP/GPP ratio, and increased precipitation led to a higher NPP/GPP ratio.ConclusionsThe NPP/GPP ratio exhibits a clear temporal pattern associated with climatic fluctuations at a global scale. The associations of the NPP/GPP ratio with climatic variability challenge the conventional assumption that the NPP/GPP ratio should be consistent independent of environmental conditions. More importantly, the findings of this study have fundamental significance for our understanding of ongoing global climatic change. In regions and time periods experiencing drought or increased temperatures, plant ecosystems would suffer a higher ecosystem respiration cost and their net productivity would shrink.\n",
      "--------------------------------------------------\n",
      "Topic 348: 348_health_covid 19_covid_healthcare\n",
      "Representative Documents:\n",
      "  - Climate change represents one of the most significant health challenges and global inequities of our generation. As a ‘wicked’ problem, climate change imposes an involuntary exposure on vulnerable individuals and societies that is regressive in its nature, with those least responsible for destroying planetary health at greatest risk of suffering the direct and indirect health consequences of unabated warming of the planet. The current and future generations of children are the most vulnerable population to suffer the effects of climate change. By 2030, there will be 131 000 additional child deaths each year if climate mitigation strategies are not enacted, driven by the synergy of an increasing burden of infectious diseases, food insecurity and political instability. Over half a billion of the world's children live in areas vulnerable to extreme weather events, and there is a pressing risk that our current lack of action to mitigate and adapt to climate change will result in today's children, and future generations, being the first to have poorer physical and mental health than previous generations – creating a significant intergenerational ethical dilemma. Child health‐care professionals need to advocate for policies to address climate change that consider the complex health, planetary and ethical considerations necessary to solve the most significant risk to our children's health today. Without immediate action, the health of the current and future generations of children is perilous.\n",
      "  -                         The tremendous global toll of the COVID-19 pandemic does not fall equally on all populations. Indeed, this crisis has exerted more severe impacts on the most vulnerable communities, spotlighting the continued consequences of longstanding structural, social, and healthcare inequities. This disparity in COVID-19 parallels the unequal health consequences of climate change, whereby underlying inequities perpetuate adverse health outcomes disproportionately among vulnerable populations. As these two crises continue to unfold, there is an urgent need for healthcare practitioners to identify and implement solutions to mitigate adverse health outcomes, especially in the face of global crises. To support this need, the 2021 Clinical Climate Change Conference held a virtual meeting to discuss the implications of the convergence of the climate crisis and COVID-19, particularly for vulnerable patient populations and the clinicians who care for them. Presenters and panelists provided evidence-based solutions to help health professionals improve and adapt their practice to these evolving scenarios. Together, participants explored the community health system and national solutions to reduce the impacts of COVID-19 and the climate crisis, to promote community advocacy, and foster new partnerships between community and healthcare leaders to combat systemic racism and achieve a more just and equitable society.          \n",
      "  - ABSTRACTThe co-occurrence of the 2020 Atlantic hurricane season and the ongoing coronavirus disease 2019 (COVID-19) pandemic creates complex dilemmas for protecting populations from these intersecting threats. Climate change is likely contributing to stronger, wetter, slower-moving, and more dangerous hurricanes. Climate-driven hazards underscore the imperative for timely warning, evacuation, and sheltering of storm-threatened populations – proven life-saving protective measures that gather evacuees together inside durable, enclosed spaces when a hurricane approaches. Meanwhile, the rapid acquisition of scientific knowledge regarding how COVID-19 spreads has guided mass anti-contagion strategies, including lockdowns, sheltering at home, physical distancing, donning personal protective equipment, conscientious handwashing, and hygiene practices. These life-saving strategies, credited with preventing millions of COVID-19 cases, separate and move people apart. Enforcement coupled with fear of contracting COVID-19 have motivated high levels of adherence to these stringent regulations. How will populations react when warned to shelter from an oncoming Atlantic hurricane while COVID-19 is actively circulating in the community? Emergency managers, health care providers, and public health preparedness professionals must create viable solutions to confront these potential scenarios: elevated rates of hurricane-related injury and mortality among persons who refuse to evacuate due to fear of COVID-19, and the resurgence of COVID-19 cases among hurricane evacuees who shelter together.\n",
      "--------------------------------------------------\n",
      "Topic 349: 349_sensor_sensors_rpl_sensor nodes\n",
      "Representative Documents:\n",
      "  - Smart buildings that utilize innovative technologies such as artificial intelligence (AI), the internet of things (IoT), and cloud computing to improve comfort and reduce energy waste are gaining popularity. Smart buildings comprise a range of sensors to measure real-time indoor environment variables essential for the heating, ventilation, and air conditioning (HVAC) system control strategies. For accuracy and smooth operation, current HVAC system control strategies require multiple sensors to capture the indoor environment variables. However, using too many sensors creates an extensive network that is costly and complex to maintain. Our proposed research solves the mentioned problem by implementing a machine-learning algorithm to estimate unmeasured variables utilizing a limited number of sensors. Using a six-month data set collected from a three-story smart building in Japan, several extreme gradient boosting (XGBoost) models were designed and trained to estimate unmeasured room temperature, relative humidity, and CO2 concentrations. Our models accurately estimated temperature, humidity, and CO2 concentration under various case studies with an average root mean squared error (RMSE) of 0.3 degrees, 2.6%, and 26.25 ppm, respectively. Obtained results show an accurate estimation of indoor environment measurements that is applicable for optimal HVAC system control in smart buildings with a reduced number of required sensors.\n",
      "  -  Automatic recognition of personal comfort is critical in realizing autonomous control of building utilities. We can infer human comfort level based on indoor environmental conditions, such as temperature and humidity, collected through sensor networks. However, the majority of methods for optimally deploying sensor networks in indoor climate monitoring mainly focused on achieving accurate measurements such as temperature distribution map with the minimum cost. Indeed, for automatic recognition of comfort using machine learning, we need to collect datasets preserving as much of the discriminatory information for inferring personal comfort with the minimum cost. In this paper, we present a novel method of placing and minimizing sensor nodes for sensor networks in smart energy systems. We have developed ZigBee-based sensor nodes and collected temperature, humidity, and illumination dataset from 13 nodes for a week. Using the dataset, we group the sensor nodes into coherent clusters, and then select a representative node which has the maximum value of RSSI for each cluster and remove the other redundant sensors, reducing the number of sensor nodes deployed. To show the feasibility of the proposed method, we perform a classification analysis of building environment. The recognition accuracy decreased by 13 percent with 6 selected sensor nodes, compared to the result with all 13 sensor nodes. \n",
      "  -             We present            PC-RPL            , a transmission power-controlled IPv6 routing protocol for low-power and lossy wireless networks that significantly improves the end-to-end packet delivery performance under heavy traffic compared to the standard RPL. We show through actual design, implementation, and experiments that a multihop wireless network can achieve better throughput and routing stability when transmission power and routing topology are “jointly and adaptively” controlled. Our experiments show that the predominant “fixed and uniform” transmission power strategy with “link quality and hop distance”–based routing topology construction (i.e., RPL) loses significant bandwidth due to hidden terminal and load imbalance problems. We design an adaptive and distributed control mechanism for transmission power and routing topology, named            PC-RPL            , on top of the standard RPL routing protocol for hidden terminal mitigation and load balancing. We implement            PC-RPL            on real embedded devices and evaluate its performance on a 49-node multihop testbed.            PC-RPL            reduces total end-to-end packet losses by approximately sevenfold without increasing hop distance compared to RPL with the highest transmission power, resulting in 17% improvement in aggregate bandwidth and 64% improvement for the worst-case node by successfully alleviating both hidden terminal and load imbalance problems.          \n",
      "--------------------------------------------------\n",
      "Topic 350: 350_germination_seed_populations_cued\n",
      "Representative Documents:\n",
      "  - Among coastal plant species at risk from rapid environmental changes is the North American Great Lakes dune endemic Cirsium pitcheri. Despite being listed as federally threatened, little is known about how C. pitcheri seed attributes influence germination and dormancy‐break patterns in the context of climate change. Following a previous work where we found differences in the number and weight of C. pitcheri seeds among capitulum positions and study sites, here we examine the effects of seed attributes (capitulum position, seed weight, and site of origin) on the proportion and timing of C. pitcheri seed germination under temperature treatments that simulate projected warming in the Great Lakes (20/10, 25/10, and 30/10°C day/night). Our results demonstrate that C. pitcheri produces diverse cohorts of seeds with seed attributes that significantly influence the timing and probability of germination over a 3‐year soil seed bank. Cirsium pitcheri seed germination proportions were highest at 20°C and decreased successively at 25 and 30°C. Seeds from terminal capitula also had higher germination proportions and took longer to germinate than those from secondary capitula. Lastly, the effect of seed weight on germination probability depended on site of origin and capitulum position, with all effects varying in size and significance over time. Ultimately, our results highlight the considerable differences in germination patterns exhibited by seeds from different capitulum positions and sites of origin and provide insight into the dormancy‐break patterns that C. pitcheri might experience under predicted temperature rise in the Great Lakes region of North America.\n",
      "  - SummarySeed production by Picea engelmannii was monitored at 13 sites distributed across a ˜670 m elevation gradient for 40 years. Time series of annual seed output was investigated for evidence of masting behaviour and trends in seed abundance over time.We used regression models in a likelihood framework to examine climate effects on seed production for critical periods in the species' reproductive cycle.We rigorously evaluated the performance of two gridded climate data sets, PRISM and TopoWx, before using associated variables as predictors in the seed models.Seed production at these sites does not strictly conform to the classic masting concept. Seed abundance was highly variable over time and strongly synchronized among sites, but mast years could not be objectively identified due to intermediate levels of seed output.Model results indicate that climate conditions across multiple years cumulatively determine reproductive output. High seed rain is associated with elevated summer temperatures in the year that seeds are dispersed, low spring snowfall in the year preceding seed dispersal when buds are initiated, and reduced spring snowfall in a so‐called priming year two years prior to seed dispersal. Low spring precipitation putatively increases growing season length and resource accumulation in seed trees.Linear models identified significant positive trends in seed output over time. Anomalous aridity and summer warmth in the latter half of the study period were highly favourable for seed production and were associated with increases in seed abundance.Synthesis. The increases in seed output observed in this study may promote population fitness of P. engelmannii in the face of changing climate regimes and increasing frequencies of fire‐ and insect‐related tree mortality in the Rocky Mountains. Since this species lacks a persistent seed bank, re‐colonization of disturbed areas or dispersal to shifting habitats depends on adequate production of seed by surviving trees, which according to these analyses may be moderately enhanced by current climate trends. However, some evidence also indicates that increases in seed output will ultimately be constrained by threshold high temperatures in the seed maturation year.\n",
      "  - AimEnvironmentally cued germination and seed banking are strategies employed by annual plants to persist in unpredictable climates. Moreover, such strategies may be key to persistence under more extreme and variable future climates. In regions with a mediterranean climate, cold‐cued germination can allow populations to avoid germinating under unfavourable conditions and seed banks can buffer population growth in the face of inter‐annual climate variability. Using widespread native annual plant species in the California Floristic Province (CFP), we ask: (1) How common are cold‐cued germination and persistent seed banks? (2) Does the prevalence of cold‐cued germination and seed bank maintenance shift predictably with climate? (3) Are germination strategies taxonomically linked?LocationCalifornia, USA.MethodsWe assessed seed bank persistence and temperature‐cued germination in c. 175 populations of 42 species (eight families) from across California in the 2006 growing season. We then tested for evidence that the prevalence of these adaptations correlated with latitude, increasing climate variability and taxonomy.ResultsOnly 19% of populations had significantly cold‐cued seed germination and only 52% of populations had detectable seed banks. There were no significant relationships between the prevalence of cold‐cued germination and any climate factor. Seed banking was significantly more common in regions with warm, dry conditions in the preceding year, but was not related to long‐term climate averages. Variance in temperature‐cued germination was best explained at the species level, with no variance explained by family.Main conclusionsOur results suggest that germination of annual plants in the CFP is dominated by general risk aversion strategies rather than locally adaptive strategies linked to long‐term climate factors. High germination variability within and among populations, coupled with increased seed banking under less favourable conditions, suggests that germination strategies are unlikely to limit this flora's persistence under an increasingly harsh and unpredictable climate.\n",
      "--------------------------------------------------\n",
      "Topic 351: 351_locomotor performance_locomotor_thermal_temperatures\n",
      "Representative Documents:\n",
      "  - 1. Because of global climate change and its consequences, estimating the physiological responses of ectothermicorganisms to temperature is of high priority. The thermal increase and changes in fire frequency are some of the consequences of global warming, which could challenge the physiological performance and thermal tolerance of individuals.2. The present study estimates the thermal parameters from field individuals of the tarantula Grammostola vachoni. To achieve this, we determined the critical thermal limits for locomotor performance, the thermal optimum, and the preferred temperatures. We also calculate the thermal performance breadth and thermal tolerance zone.3. Temperature strongly affected the locomotor performance of spiders; the sprint speeds were significantly different between temperatures, and at 5 °C and 25 °C the parameter was significantly different between females and juveniles. The preferred temperature showed a mean value of 26.5 °C, and females preferred lower temperature than juveniles. Grammostola vachoni showed a wide thermal tolerance range (close to 43 °C) and thermal performance breadth (B80), an index defined as the range of temperatures at which performance is at least 80% of the maximum.4. For G. vachoni, these large breadths in the sprint speed represent a substantial buffer against future increases in habitat temperature and shows that the locomotor performance of this species is an adaptable parameter. Understanding the impact of warming in performances is important to make predictions about if this species can remain ecologically viable while facing global change, given the massive worldwide declines in arthropod populations.\n",
      "  -                Sister species that live in sympatry provide the possibility to analyse the level of divergence in their ecological, physiological and life-history traits and how they can coexist without out-competing each other. We studied the thermal sensitivity of locomotor performance in the sympatric lizards Phymaturus querque and Phymaturus zapalensis from Patagonia, Argentina. We measured morphological traits relevant to locomotor performance and the running speed at different body temperatures, and we estimated the critical thermal minimum (CTmin) and maximum (CTmax) at which running performance equals zero. We obtained the maximum speeds, the temperature at which the performance is maximized (optimal temperature, To) and the temperature range over which an individual performs 50% and 80% of their maximal performance (B50 and B80). Also, we recorded the availability of thermal microenvironments for thermoregulation (operative temperatures) and calculated two indices of vulnerability to global warming. Phymaturus zapalensis and P. querque exhibited differences in most of the morphological traits relevant to locomotor performance. Both species presented similar values of To, CTmin and CTmax, but B50 and B80 were broader in P. zapalensis. During the warmest month, the environmental temperatures are already higher than the physiological optimal temperature, indicating that populations could currently be facing challenges in the context of global warming.\n",
      "  - Ecophysiological plasticity determines, to a great extent, the geographic distribution and the vulnerability of ectotherms to climate change. We studied the relationship between locomotor performance and temperature of Liolaemus elongatus lizards in three populations in northern Patagonia, Argentina, differing in thermal characteristics. We related the thermophysiological and locomotor performance parameters with the environmental conditions currently experienced by these populations and analyzed whether the expected increment of the environmental temperature due to climate change could affect these vital traits. We also determined, for one of the populations, the effects of 30 acclimation days at two temperature treatments (22°C and 30°C) on running speed, thermal preference in the laboratory (Tpref), panting threshold, and minimum critical temperature. We found that L. elongatus, despite the differences in environmental temperatures among the three sites, exhibited maximum speed at similar temperatures (optimum temperature for locomotor performance; To). The southern populations currently experience temperatures below that required to reach their maximum locomotor performance while the northernmost population is threatened by peaks of high temperatures that exceed the To. Therefore, global warming could diminish lizards' running performance in northern populations and lizards may spend more time refuging and less time on other activities such as feeding, territory defense, and dispersion. However, we show evidence of plasticity in L. elongatus locomotor performance when acclimated at high temperatures resulting in a potential advantage to cushion the effect of the rising environmental temperatures expected during climate change.\n",
      "--------------------------------------------------\n",
      "Topic 352: 352_sf6_mixtures_c4f7n_co2 mixtures\n",
      "Representative Documents:\n",
      "  - SF6 gas is widely used in the high voltage circuit breakers but considering its high global warming potential other substitutes are being sought. Among them CO2 was investigated and even has been used in some practical products. However, at room temperature, the dielectric properties of CO2 are relatively lower than SF6 and air. The goal of this work is to investigate a CO2-based gas to improve the performance of the pure CO2. In this paper, the dielectric properties of hot CO2/O2 mixtures related to the dielectric recovery phase of the circuit breaker were investigated in the temperature range from 300 K to 4000 K and in the pressure range from 0.01 MPa to 1.0 MPa. The species compositions of hot CO2/O2 were obtained based on Gibbs free energy minimization under the assumptions of local thermodynamic equilibrium and local chemical equilibrium. The reduced critical electric field strength of CO2/O2 was determined by balancing electron generation and loss. These were calculated using the electron energy distribution function by solving the Boltzmann transport equation. The validity of the calculation method and the cross sections data was confirmed by comparing the measurements and calculations of the electron swarm data in previous work. The results indicate that in pure CO2 the critical electric field strength is higher only in higher temperature range. By adding the O2 into the CO2, the critical electric field strength at lower temperature is effectively enhanced. CO2/O2 mixtures have a much better dielectric strength than both the pure CO2 and air and thus have the potential to improve the CO2-based gas circuit breakers. Similar conclusions can also be found in others’ work, which further confirm the validity of these results.\n",
      "  - C4F8-CO2 mixtures are one of the potential substitutes to SF6 in high-voltage circuit breakers. However, the arc quenching ability of C4F8-CO2 mixtures is still unknown. In order to provide the necessary basic data for the further investigation of arc quenching performance, the compositions, thermodynamic properties, transport coefficients, and net emission coefficients (NEC) of various C4F8-CO2 mixtures are calculated at temperatures of 300–30 000 K in this work. The thermodynamic properties are presented as the product of mass density and specific heat, i.e., ρCp. The transport coefficients include electrical conductivity, viscosity, and thermal conductivity. The atomic and molecular radiation are both taken into account in the calculation of NEC. The comparison of the properties between SF6 and C4F8-CO2 mixtures is also discussed to find their differences. The results of compositions show that C4F8-CO2 mixtures have a distinctive advantage over other alternative gases e.g., CF3I and C3F8, because the dissociative product (i.e., C4F6) of C4F8 at low temperatures has a very high dielectric strength. This is good for an arc quenching medium to endure the arc recovery phase. Compared with SF6, C4F8-CO2 mixtures present lower ρCp at temperatures below 2800 K and larger thermal conductivity above 2800 K. Based on the position of peaks in thermal conductivity, we predict that the cooling of C4F8-CO2 arc will be slowed down at higher temperatures than that of SF6 arc. It is also found that the mixing of CO2 shows slight effects on the electrical conductivity and NEC of C4F8-CO2 mixtures.\n",
      "  - Recently, much attention has been paid to SF6-CO2 mixtures as one of substitutes for pure SF6 gas. In this paper, the dielectric breakdown properties of hot SF6-CO2 mixtures are investigated at temperatures of 300–3500 K and pressures of 0.01–1.0 MPa. Under the assumptions of local thermodynamic equilibrium and local chemical equilibrium, the equilibrium compositions of hot SF6-CO2 mixtures with different CO2 proportions are obtained based on Gibbs free energy minimization. The cross sections for interactions between electrons and neutral species are presented. Some unknown ionization cross sections are determined theoretically using Deutsch–Märk (DM) formalism based on quantum chemistry. Two-term Boltzmann equation is adopted to calculate the electron energy distribution function, reduced ionization coefficient, reduced attachment coefficient, and reduced effective ionization coefficient. Then the reduced critical electric field strength of mixtures, corresponding to dielectric breakdown performances, is determined when the generation and loss of electrons are balanced. Finally, the influences of temperature, pressure, and CO2 proportion on the reduced critical electric field strength are studied. It is found that a large percentage of CO2 can obviously reduce concentrations of high-energy electrons. At temperatures above 1750 K, an addition of CO2 to SF6 gas can enhance dielectric breakdown performances. However, at low temperatures, too much CO2 added into mixtures can reduce dielectric breakdown abilities. In addition, increasing gas pressure can improve dielectric breakdown performances. But the influence will be no more significant if pressure is over 0.8 MPa.\n",
      "--------------------------------------------------\n",
      "Topic 353: 353_fd_species_storage effect_competition\n",
      "Representative Documents:\n",
      "  - The impact of climate change on the dynamics of populations has been well documented and is widespread. However, weather variability influences populations both directly and indirectly, and is mediated by species interactions. This complexity may impede proper climate impact assessments. Hence, predicting the consequences of climate change may require including processes that occur both with time lags and across trophic levels. Based on our current understanding of the mechanisms linking local climate and trophic interactions in tundra ecosystems, we used a state-space formulation of a mediation model that allowed for assessing the relative contribution of direct and indirect environmental (weather and trophic) effects on reindeer Rangifer tarandus reproductive success. Our study showed that the mediator effect of body condition caused delayed but predictable effects of weather, plant productivity, and reindeer densities on reproductive success. Furthermore, these predictors also affected reproductive success directly and with the same sign, suggesting that direct and indirect effects pulled in the same direction with respect to their combined total effect on reproductive success. Hence, poor weather conditions not only affect calf production negatively the same year, but also increase the likelihood of poor reproductive success the subsequent year. The results support the expectation that calf slaughter mass (as a proxy for herd body condition) is an important indicator of the state of reindeer herds with respect to their production potential and resilience to weather events and climate change. Finally, the model framework employed in the present study can be further developed as a potential vehicle for near-term forecasting, and thereby constitutes a useful tool for adaptive management.\n",
      "  - Organisms are projected to shift their distribution ranges under climate change. The typical way to assess range shifts is by species distribution models (SDMs), which predict species’ responses to climate based solely on projected climatic suitability. However, life history traits can impact species’ responses to shifting habitat suitability. Additionally, it remains unclear if differences in vital rates across populations within a species can offset or exacerbate the effects of predicted changes in climatic suitability on population viability. In order to obtain a fuller understanding of the response of one species to projected climatic changes, we coupled demographic processes with predicted changes in suitable habitat for the monocarpic thistle Carlina vulgaris across northern Europe. We first developed a life history model with species‐specific average fecundity and survival rates and linked it to a SDM that predicted changes in habitat suitability through time with changes in climatic variables. We then varied the demographic parameters based upon observed vital rates of local populations from a translocation experiment. Despite the fact that the SDM alone predicted C. vulgaris to be a climate ‘winner’ overall, coupling the model with changes in demography and small‐scale habitat suitability resulted in a matrix of stable, declining, and increasing patches. For populations predicted to experience declines or increases in abundance due to changes in habitat suitability, altered fecundity and survival rates can reverse projected population trends.\n",
      "  - Forecasting the impacts of climate change on species persistence in diverse natural communities requires a way to account for indirect effects mediated through species interactions. In particular, we expect species to experience major changes in competition as they track favorable climates. Here, we combine experimental data with a recently developed theoretical framework based on coexistence theory to measure the impact of climate‐driven range shifts on alpine plant persistence under climate change. We transplanted three co‐dominant alpine perennial species to five elevations, creating a maximum of 5°C increase in average growing‐season temperature. We statistically modeled species' demographic rates in response to the environment and interpolated species' intrinsic ranges—the environmental mapping of reproduction in the absence of competition. We used low‐density population growth rates—species' initial rate of invasion into an established community—as a metric of persistence. Further analysis of low‐density growth rates (LGRs) allowed us to parse the direct impacts of climate change from indirect impacts mediated by shifting competition. Our models predict qualitatively different range shifts for each species based on the climate conditions under which growth rates are maximized and where they are zero. Overall, climate change is predicted to increase the intrinsic (competition free) growth rates of all species, as warmer and wetter conditions increase the favorability of alpine habitat. However, these benefits are entirely negated by increased competition arising from greater overlap between competitors in their intrinsic ranges. Species were highly dispersal limited, which can prevent species from tracking shifting intrinsic ranges by reducing population spread rates. Yet dispersal limitation also promoted species' persistence because it promotes persistence mechanisms. Our study demonstrates the complex pathways by which climate change impacts species' persistence by altering their competitive environment, and highlights how a persistence framework based on LGRs can help disentangle impacts.\n",
      "--------------------------------------------------\n",
      "Topic 354: 354_tree mortality_tree_mortality_forests\n",
      "Representative Documents:\n",
      "  - Temporal increases of tree mortality have been observed in regions where global warming has decreased long‐term water availability and/or induced droughts. However, temporal decreases in water availability are not a global phenomenon. Understanding how water deficit‐free forests respond to the recent effects of climate change is paramount towards a full appreciation of the impacts of climate change on global forests. Here, we reveal temporally increasing tree mortality across all study species over the last three decades in the central boreal forests of Canada, where long‐term water availability has increased without apparent climate change‐associated drought. In addition, we find that the effects of conspecific tree‐to‐tree competition have intensified temporally as a mechanism for the increased mortality of shade‐intolerant tree species. Our results suggest that the consequences of climate change on tree mortality are more profound than previously thought.\n",
      "  - Increasing aridity as a result of climate change is expected to exacerbate tree mortality. Reducing forest basal area – the cross‐sectional area of tree stems within a given ground area – can decrease tree competition, which may reduce drought‐induced tree mortality. However, neither the magnitude of expected mortality increases, nor the potential effectiveness of basal area reduction, has been quantified in dryland forests such as those of the drought‐prone Southwest US. We used thousands of repeatedly measured forest plots to show that unusually warm and dry conditions are related to high tree mortality rates and that mortality is positively related to basal area. Those relationships suggest that while increasing high temperature extremes forecasted by climate models may lead to elevated tree mortality during the 21st century, future tree mortality might be partly ameliorated by reducing stand basal area. This adaptive forest management strategy may provide a window of opportunity for forest managers and policy makers to guide forest transitions to species and/or genotypes more suited to future climates.\n",
      "  - Forests around the world are subject to risk of high rates of tree growth decline and increased tree mortality from combinations of climate warming and drought, notably in semi‐arid settings. Here, we assess how climate warming has affected tree growth in one of the world's most extensive zones of semi‐arid forests, in Inner Asia, a region where lack of data limits our understanding of how climate change may impact forests. We show that pervasive tree growth declines since 1994 in Inner Asia have been confined to semi‐arid forests, where growing season water stress has been rising due to warming‐induced increases in atmospheric moisture demand. A causal link between increasing drought and declining growth at semi‐arid sites is corroborated by correlation analyses comparing annual climate data to records of tree‐ring widths. These ring‐width records tend to be substantially more sensitive to drought variability at semi‐arid sites than at semi‐humid sites. Fire occurrence and insect/pathogen attacks have increased in tandem with the most recent (2007–2009) documented episode of tree mortality. If warming in Inner Asia continues, further increases in forest stress and tree mortality could be expected, potentially driving the eventual regional loss of current semi‐arid forests.\n",
      "--------------------------------------------------\n",
      "Topic 355: 355_pet_polym_copolymers_terephthalate\n",
      "Representative Documents:\n",
      "  - The microstructure and crystallization behavior of a set of poly(ethylene terephthalate‐co‐5‐nitroisophthalate) copolymers (PETNI) containing 5‐nitroisophthalic units in the 10–50 mol % range were examined and compared to those of poly(ethylene terephthalate) (PET) and poly(ethylene terephthalate‐co‐isophthalate) (PETI) copolymers. A 13C NMR analysis of PETNI copolymers in a trifluoroacetic acid solution indicates that they are random copolymers with average sequence lengths in accordance with ideal polycondensation statistics. Differential scanning calorimetry (DSC) studies show that PETNI containing 5‐nitroisophthalic units up to 20 mol % are able to crystallize and that crystallization takes place in these copolymers at much slower rates than in PET. Wide‐angle X‐ray diffraction from powder and fibers reveals that crystallizable PETNI adopts the same triclinic crystal structure as PET, with the nitroisophthalate units being excluded from crystallites. Fourier transform infrared in combination with cross‐polarization/magic‐angle spinning 13C NMR spectroscopy demonstrates the occurrence of a gauche–trans conversion encompassing the crystallization process. A correlation between DSC and spectroscopic data leads us to conclude that the content of trans conformer in the noncrystallized phase of PETNI is higher than in both PET and PETI copolymers and suggests that secondary crystallization in the homopolymer must proceed by a mechanism different than that in copolymers. © 2001 John Wiley &amp; Sons, Inc. J Polym Sci Part B: Polym Phys 39: 1553–1564, 2001\n",
      "  - The methanolysis of poly(ethylene terephthalate) (PET) copolymers containing 5‐nitroisophthalic units was investigated. Random copolyesters containing 10 and 30 mol % of such units were prepared via a two‐step melt copolycondensation of bis(2‐hydroxyethyl) terephthalate (BHET) and bis(2‐hydroxyethyl) 5‐nitroisophthalate (BHENI) in the presence of tetrabutyl titanate as a catalyst. First, the susceptibility of these two comonomers toward methanolysis was evaluated, and their reaction rates were estimated with high‐performance liquid chromatography. BHENI appeared to be much more reactive than both BHET and bis(2‐hydroxyethyl) isophthalate. The methanolysis of PET and the copolyesters was carried out at 100 °C, and the degradation process was followed by changes in the weight and viscosity, gel permeation chromatography, differential scanning calorimetry, and 1H and 13C NMR spectroscopy. The copolyesters degraded faster than PET, and the rate of degradation increased with the content of nitrated units. The products resulting from methanolysis were concluded to be dimethyl terephthalate, dimethyl 5‐nitroisophthalate, ethylene glycol, and small, soluble oligomers. For both PET and the copolyesters, an increase in crystallinity was observed during the degradation process, indicating that methanolysis preferentially occurred in the amorphous phase. © 2001 John Wiley &amp; Sons, Inc. J Polym Sci Part A: Polym Chem 40: 76–87, 2002\n",
      "  - The methanolytic degradation of poly(ethylene terephthalate) (PET) copolymers containing nitroterephthalic units was investigated. Random poly(ethylene terephthalate‐co‐nitroterephthalate) copolyesters (PETNT) containing 15 and 30 mol % nitrated units were prepared from ethylene glycol and a mixture of dimethyl terephthalate and dimethyl nitroterephthalate. A detailed study of the influence of the nitro group on the methanolytic degradation rate of the nitrated bis(2‐hydroxyethyl) nitroterephthalate (BHENT) model compound in comparison with the nonnitrated bis(2‐hydroxyethyl) terephthalate (BHET) model compound was carried out. The kinetics of the methanolysis of BHENT and BHET were evaluated with high‐performance liquid chromatography and 1H NMR spectroscopy. BHENT appeared to be much more reactive than BHET. The methanolytic degradation of PET and PETNT copolyesters at 80 °C was followed by changes in the weight and viscosity, gel permeation chromatography, differential scanning calorimetry, scanning electron microscopy, and 1H and 13C NMR spectroscopy. The copolyesters degraded faster than PET, and the degradation increased with the content of nitrated units and occurred preferentially by cleavage of the ester groups placed at the meta position of the nitro group in the nitrated units. For both PET and PETNT copolyesters, an increase in crystallinity accompanied methanolysis. A surface degradation mechanism entailing solubilization of the fragmented polymer and consequent loss of mass was found to operate in the methanolysis of the copolyesters. © 2002 Wiley Periodicals, Inc. J Polym Sci Part A: Polym Chem 40: 2276–2285, 2002\n",
      "--------------------------------------------------\n",
      "Topic 356: 356_cows_thi_cow_milk\n",
      "Representative Documents:\n",
      "  -                The aim of this study was to evaluate the effects of evaporative cooling at two different frequencies per day on the respiration rate (RR) of lactating dairy cows, considering cow-related factors. Twenty multiparous Israeli Holstein dairy cows housed in a naturally ventilated cowshed were divided randomly into two treatment groups. The cows of both groups were exposed to 3 or 8 cooling sessions per day (3xcool vs. 8xcool, respectively). The RR was observed hourly, with a maximum of 12 measurements per day. Body posture (standing vs. lying) was simultaneously documented. Milk yield was recorded daily. Coat color was determined from a digital photograph. The RR of standing and lying cows was lower in the 8xcool group (60.2 and 51.6 breaths per min (bpm), respectively) than in the 3xcool group (73.1 and 65.6 bpm, respectively). For each increment of five kilograms of milk produced, RR increased by one bpm, and the RR of cows in early days in milk (DIM) was 12.3 bpm higher than that of cows in late DIM. In conclusion, eight cooling sessions per day instead of three lead to a RR abatement in heat-stressed cows under hot conditions, and cow-related factors directly impact the RR during heat stress assessment.\n",
      "  -                The main objective of this study was to identify the influences of different climatic conditions and cow-related factors on the respiration rate (RR) of lactating dairy cows. Measurements were performed on 84 lactating Holstein Friesian dairy cows (first to eighth lactation) in Brandenburg, Germany. The RR was measured hourly or twice a day with up to three randomly chosen measurement days per week between 0700 h and 1500 h (GMT + 0100 h) by counting right thoraco-abdominal movements of the cows. Simultaneously with RR measurements, cow body postures (standing vs. lying) were documented. Cows’ milk yield and days in milk were recorded daily. The ambient temperature and relative humidity of the barn were recorded every 5 min to calculate the current temperature-humidity index (THI). The data were analyzed for interactions between THI and cow-related factors (body postures and daily milk yield) on RR using a repeated measurement linear mixed model. There was a significant effect of the interaction between current THI category and body postures on RR. The RRs of cows in lying posture in the THI &lt; 68, 68 ≤ THI &lt; 72 and 72 ≤ THI &lt; 80 categories (37, 46 and 53 breaths per minute (bpm), respectively) were greater than those of standing cows in the same THI categories (30, 38 and 45 bpm, respectively). For each additional kilogram of milk produced daily, an increase of 0.23±0.19 bpm in RR was observed. Including cow-related factors may help to prevent uncertainties of RR in heat stress predictions. In practical application, these factors should be included when predicting RR to evaluate heat stress on dairy farms.\n",
      "  - The objectives of this study were to examine heat stress conditions at cow level and to investigate the relationship to the climate conditions at 5 different stationary locations inside a dairy barn. In addition, we compared the climate conditions at cow level between primiparous and multiparous cows for a period of 1 week after regrouping. The temperature-humidity index (THI) differed significantly between all stationary loggers. The lowest THI was measured at the window logger in the experimental stall and the highest THI was measured at the central logger in the experimental stall. The THI at the mobile cow loggers was 2·33 THI points higher than at the stationary loggers. Furthermore, the mean daily THI was higher at the mobile cow loggers than at the stationary loggers on all experimental days. The THI in the experimental pen was 0·44 THI points lower when the experimental cow group was located inside the milking parlour. The THI measured at the mobile cow loggers was 1·63 THI points higher when the experimental cow group was located inside the milking parlour. However, there was no significant difference for all climate variables between primiparous and multiparous cows. These results indicate, there is a wide range of climate conditions inside a dairy barn and especially areas with a great distance to a fresh air supply have an increased risk for the occurrence of heat stress conditions. Furthermore, the heat stress conditions are even higher at cow level and cows not only influence their climatic environment, but also generate microclimates within different locations inside the barn. Therefore climate conditions should be obtained at cow level to evaluate the heat stress conditions that dairy cows are actually exposed to.\n",
      "--------------------------------------------------\n",
      "Topic 357: 357_mass loss_ice_mass_loss\n",
      "Representative Documents:\n",
      "  - . Continuing global warming will have a strong impact on the Greenland ice sheet in the coming centuries. During the last decade (2000–2010), both increased melt-water runoff and enhanced ice discharge from calving glaciers have contributed 0.6 ± 0.1 mm yr−1 to global sea-level rise, with a relative contribution of 60 and 40% respectively. Here we use a higher-order ice flow model, spun up to present day, to simulate future ice volume changes driven by both atmospheric and oceanic temperature changes. For these projections, the flow model accounts for runoff-induced basal lubrication and ocean warming-induced discharge increase at the marine margins. For a suite of 10 atmosphere and ocean general circulation models and four representative concentration pathway scenarios, the projected sea-level rise between 2000 and 2100 lies in the range of +1.4 to +16.6 cm. For two low emission scenarios, the projections are conducted up to 2300. Ice loss rates are found to abate for the most favourable scenario where the warming peaks in this century, allowing the ice sheet to maintain a geometry close to the present-day state. For the other moderate scenario, loss rates remain at a constant level over 300 years. In any scenario, volume loss is predominantly caused by increased surface melting as the contribution from enhanced ice discharge decreases over time and is self-limited by thinning and retreat of the marine margin, reducing the ice–ocean contact area. As confirmed by other studies, we find that the effect of enhanced basal lubrication on the volume evolution is negligible on centennial timescales. Our projections show that the observed rates of volume change over the last decades cannot simply be extrapolated over the 21st century on account of a different balance of processes causing ice loss over time. Our results also indicate that the largest source of uncertainty arises from the surface mass balance and the underlying climate change projections, not from ice dynamics.                    \n",
      "  - . Around the world, small ice caps and glaciers have been losing mass and retreating since the start of the industrial era. Estimates are that this has contributed approximately 30 % of the observed sea-level rise over the same period. It is important to understand the relative importance of natural and anthropogenic components of this mass loss. One recent study concluded that the best estimate of the magnitude of the anthropogenic mass loss over the industrial era was only 25 % of the total, implying a predominantly natural cause. Here we show that the anthropogenic fraction of the total mass loss of a given glacier depends only on the magnitudes and rates of the natural and anthropogenic components of climate change and on the glacier's response time. We consider climate change over the past millennium using synthetic scenarios, palaeoclimate reconstructions, numerical climate simulations, and instrumental observations. We use these climate histories to drive a glacier model that can represent a wide range of glacier response times, and we evaluate the magnitude of the anthropogenic mass loss relative to the observed mass loss. The slow cooling over the preceding millennium followed by the rapid anthropogenic warming of the industrial era means that, over the full range of response times for small ice caps and glaciers, the central estimate of the magnitude of the anthropogenic mass loss is essentially 100 % of the observed mass loss. The anthropogenic magnitude may exceed 100 % in the event that, without anthropogenic climate forcing, glaciers would otherwise have been gaining mass. Our results bring assessments of the attribution of glacier mass loss into alignment with assessments of others aspects of climate change, such as global-mean temperature. Furthermore, these results reinforce the scientific and public understanding of centennial-scale glacier retreat as an unambiguous consequence of human activity.\n",
      "  - . Mass loss by glaciers has been an important contributor to sea level rise in the past, and is projected to contribute a substantial fraction of total sea level rise during the 21st century. Here, we use a model of the world's glaciers to quantify equilibrium sensitivities of global glacier mass to climate change, and to investigate the role of changes in glacier hypsometry for long-term mass changes. We find that 21st century glacier-mass loss is largely governed by the glacier's response to 20th century climate change. This limits the influence of 21st century climate change on glacier-mass loss, and explains why there are relatively small differences in glacier-mass loss under greatly different scenarios of climate change. The projected future changes in both temperature and precipitation experienced by glaciers are amplified relative to the global average. The projected increase in precipitation partly compensates for the mass loss caused by warming, but this compensation is negligible at higher temperature anomalies since an increasing fraction of precipitation at the glacier sites is liquid. Loss of low-lying glacier area, and more importantly, eventual complete disappearance of glaciers, strongly limit the projected sea level contribution from glaciers in coming centuries. The adjustment of glacier hypsometry to changes in the forcing strongly reduces the rates of global glacier-mass loss caused by changes in global mean temperature compared to rates of mass loss when hypsometric changes are neglected. This result is a second reason for the relatively weak dependence of glacier-mass loss on future climate scenario, and helps explain why glacier-mass loss in the first half of the 20th century was of the same order of magnitude as in the second half of the 20th century, even though the rate of warming was considerably smaller.                    \n",
      "--------------------------------------------------\n",
      "Topic 358: 358_gpp_lue_nee_vegetation carbon\n",
      "Representative Documents:\n",
      "  - We used a land surface model to quantify the causes and extents of biases in terrestrial gross primary production (GPP) due to the use of meteorological reanalysis datasets. We first calibrated the model using meteorology and eddy covariance data from 25 flux tower sites ranging from the tropics to the northern high latitudes and subsequently repeated the site simulations using two reanalysis datasets: NCEP/NCAR and CRUNCEP. The results show that at most sites, the reanalysis‐driven GPP bias was significantly positive with respect to the observed meteorology‐driven simulations. Notably, the absolute GPP bias was highest at the tropical evergreen tree sites, averaging up to ca. 0.45 kg C m−2 yr−1 across sites (ca. 15% of site level GPP). At the northern mid‐/high‐latitude broadleaf deciduous and the needleleaf evergreen tree sites, the corresponding annual GPP biases were up to 20%. For the nontree sites, average annual biases of up to ca. 20–30% were simulated within savanna, grassland, and shrubland vegetation types. At the tree sites, the biases in short‐wave radiation and humidity strongly influenced the GPP biases, while the nontree sites were more affected by biases in factors controlling water stress (precipitation, humidity, and air temperature). In this study, we also discuss the influence of seasonal patterns of meteorological biases on GPP. Finally, using model simulations for the global land surface, we discuss the potential impacts of site‐level reanalysis‐driven biases on the global estimates of GPP. In a broader context, our results can have important consequences on other terrestrial ecosystem fluxes (e.g., net primary production, net ecosystem production, energy/water fluxes) and reservoirs (e.g., soil carbon stocks). In a complementary study (Barman et al., ), we extend the present analysis for latent and sensible heat fluxes, thus consistently integrating the analysis of climate‐driven uncertainties in carbon, energy, and water fluxes using a single modeling framework.\n",
      "  - Large spatial‐scale effects of climate extremes on gross primary production (GPP), the largest terrestrial carbon flux, are highly uncertain even as these extremes increase in frequency and extent. Here we report the impacts of spring warming and summer drought in 2012 on GPP across the contiguous United States (CONUS) using estimates from four GPP models: Vegetation Photosynthesis Model (VPM), MOD17A2H V006, Carnegie‐Ames‐Stanford Approach, and Simple Biosphere/Carnegie‐Ames‐Stanford Approach. VPM simulations are driven by Moderate Resolution Imaging Spectroradiometer, North American Regional Reanalysis climate data, and C3 and C4 cropland maps from the United States Department of Agriculture Cropland Data Layer data set. Across 25 eddy covariance flux tower sites, GPP estimates from VPM (GPPVPM) showed better accuracy in terms of cross‐site variability and interannual variability (R2 = 0.84 and 0.46, respectively) when compared to MOD17 GPP. We further assessed the spatial and temporal (seasonal) consistency between GPP products and the Global Ozone Monitoring Experiment‐2 solar‐induced chlorophyll fluorescence over CONUS during 2008–2014. The results suggested that GPPVPM agrees best with solar‐induced chlorophyll fluorescence across space and time, capturing seasonal dynamics and interannual variations. Anomaly analyses showed that increased GPP during the spring compensated for the reduced GPP during the summer, resulting in near‐neutral changes in annual GPP for the CONUS. This study demonstrates the importance of assessing the impacts of different types and timing of climate extremes on GPP and the need to improve light use efficiency models by incorporating C3 and C4 plant functional types.\n",
      "  - Determining the spatial and temporal distribution of terrestrial gross primary production (GPP) is a critical step in closing the Earth's carbon budget. Dynamical global vegetation models (DGVMs) provide mechanistic insight into GPP variability but diverge in predicting the response to climate in poorly investigated regions. Recent advances in the remote sensing of solar‐induced chlorophyll fluorescence (SIF) opens up a new possibility to provide direct global observational constraints for GPP. Here, we apply an optimal estimation approach to infer the global distribution of GPP from an ensemble of eight DGVMs constrained by global measurements of SIF from the Greenhouse Gases Observing SATellite (GOSAT). These estimates are compared to flux tower data in N. America, Europe, and tropical S. America, with careful consideration of scale differences between models, GOSAT, and flux towers. Assimilation of GOSAT SIF with DGVMs causes a redistribution of global productivity from northern latitudes to the tropics of 7–8 Pg C yr−1 from 2010 to 2012, with reduced GPP in northern forests (~3.6 Pg C yr−1) and enhanced GPP in tropical forests (~3.7 Pg C yr−1). This leads to improvements in the structure of the seasonal cycle, including earlier dry season GPP loss and enhanced peak‐to‐trough GPP in tropical forests within the Amazon Basin and reduced growing season length in northern croplands and deciduous forests. Uncertainty in predicted GPP (estimated from the spread of DGVMs) is reduced by 40–70% during peak productivity suggesting the assimilation of GOSAT SIF with models is well‐suited for benchmarking. We conclude that satellite fluorescence augurs a new opportunity to quantify the GPP response to climate drivers and the potential to constrain predictions of carbon cycle evolution.\n",
      "--------------------------------------------------\n",
      "Topic 359: 359_pliocene_mid pliocene_pliomip2_mid\n",
      "Representative Documents:\n",
      "  - . The Pliocene Model Intercomparison Project Phase 2 (PlioMIP2) is an international collaboration to simulate the climate of the mid-Pliocene interglacial, corresponding to marine isotope stage KM5c (3.205 Mya), using a wide selection of climate models with the objective of understanding the nature of the warming that is known to have occurred during the broader mid-Pliocene warm period. PlioMIP2 builds on the successes of PlioMIP by shifting the focus to a specific interglacial and using a revised set of geographic and orbital boundary conditions. In this paper, we present the details of the mid-Pliocene simulations that we have performed with a slightly modified version of the Community Climate System Model version 4 (CCSM4) and the enhanced variant of the PlioMIP2 boundary conditions. We discuss the simulated climatology through comparisons to our control simulations and to proxy reconstructions of the mid-Pliocene climate. With the new boundary conditions, the University of Toronto version of the CCSM4 model simulates a mid-Pliocene that is more than twice as warm as that with the boundary conditions used for PlioMIP Phase 1. The warming is more enhanced near the high latitudes, which is where most of the changes to the PlioMIP2 boundary conditions have been made. The elevated warming in the high latitudes leads to a better match between the simulated climatology and proxy-based reconstructions than possible with the previous version of the boundary conditions.\n",
      "  - . We present the Alfred Wegener Institute's contribution to the Pliocene Model Intercomparison Project Phase 2 (PlioMIP2) wherein we employ the Community Earth System Models (COSMOS) that include a dynamic vegetation scheme. This work builds on our contribution to Phase 1 of the Pliocene Model Intercomparison Project (PlioMIP1) wherein we employed the same model without dynamic vegetation. Our input to the PlioMIP2 special issue of Climate of the Past is twofold. In an accompanying paper we compare results derived with COSMOS in the framework of PlioMIP2 and PlioMIP1. With this paper we present details of our contribution with COSMOS to PlioMIP2. We provide a description of the model and of methods employed to transfer reconstructed mid-Pliocene geography, as provided by the Pliocene Reconstruction and Synoptic Mapping Initiative Phase 4 (PRISM4), to model boundary conditions. We describe the spin-up procedure for creating the COSMOS PlioMIP2 simulation ensemble and present large-scale climate patterns of the COSMOS PlioMIP2 mid-Pliocene core simulation. Furthermore, we quantify the contribution of individual components of PRISM4 boundary conditions to characteristics of simulated mid-Pliocene climate and discuss implications for anthropogenic warming. When exposed to PRISM4 boundary conditions, COSMOS provides insight into a mid-Pliocene climate that is characterised by increased rainfall (+0.17 mm d−1) and elevated surface temperature (+3.37 ∘C) in comparison to the pre-industrial (PI). About two-thirds of the mid-Pliocene core temperature anomaly can be directly attributed to carbon dioxide that is elevated with respect to PI. The contribution of topography and ice sheets to mid-Pliocene warmth is much smaller in contrast – about one-quarter and one-eighth, respectively, and nonlinearities are negligible. The simulated mid-Pliocene climate comprises pronounced polar amplification, a reduced meridional temperature gradient, a northwards-shifted tropical rain belt, an Arctic Ocean that is nearly free of sea ice during boreal summer, and muted seasonality at Northern Hemisphere high latitudes. Simulated mid-Pliocene precipitation patterns are defined by both carbon dioxide and PRISM4 paleogeography. Our COSMOS simulations confirm long-standing characteristics of the mid-Pliocene Earth system, among these increased meridional volume transport in the Atlantic Ocean, an extended and intensified equatorial warm pool, and pronounced poleward expansion of vegetation cover. By means of a comparison of our results to a reconstruction of the sea surface temperature (SST) of the mid-Pliocene we find that COSMOS reproduces reconstructed SST best if exposed to a carbon dioxide concentration of 400 ppmv. In the Atlantic to Arctic Ocean the simulated mid-Pliocene core climate state is too cold in comparison to the SST reconstruction. The discord can be mitigated to some extent by increasing carbon dioxide that causes increased mismatch between the model and reconstruction in other regions.\n",
      "  - . We compare results obtained from modeling the mid-Pliocene warm period using the Community Earth System Models (COSMOS, version: COSMOS-landveg r2413, 2009) with the two different modeling methodologies and sets of boundary conditions prescribed for the two phases of the Pliocene Model Intercomparison Project (PlioMIP), tagged PlioMIP1 and PlioMIP2. Here, we bridge the gap between our contributions to PlioMIP1 (Stepanek and Lohmann, 2012) and PlioMIP2 (Stepanek et al., 2020). We highlight some of the effects that differences in the chosen mid-Pliocene model setup (PlioMIP2 vs. PlioMIP1) have on the climate state as derived with COSMOS, as this information will be valuable in the framework of the model–model and model–data comparison within PlioMIP2. We evaluate the model sensitivity to improved mid-Pliocene boundary conditions using PlioMIP's core mid-Pliocene experiments for PlioMIP1 and PlioMIP2 and present further simulations in which we test model sensitivity to variations in paleogeography, orbit, and the concentration of CO2. Firstly, we highlight major changes in boundary conditions from PlioMIP1 to PlioMIP2 and also the challenges recorded from the initial effort. The results derived from our simulations show that COSMOS simulates a mid-Pliocene climate state that is 0.29 ∘C colder in PlioMIP2 if compared to PlioMIP1 (17.82 ∘C in PlioMIP1, 17.53 ∘C in PlioMIP2; values based on simulated surface skin temperature). On the one hand, high-latitude warming, which is supported by proxy evidence of the mid-Pliocene, is underestimated in simulations of both PlioMIP1 and PlioMIP2. On the other hand, spatial variations in surface air temperature (SAT), sea surface temperature (SST), and the distribution of sea ice suggest improvement of simulated SAT and SST in PlioMIP2 if employing the updated paleogeography. Our PlioMIP2 mid-Pliocene simulation produces warmer SSTs in the Arctic and North Atlantic Ocean than those derived from the respective PlioMIP1 climate state. The difference in prescribed CO2 accounts for 0.5 ∘C of temperature difference in the Arctic, leading to an ice-free summer in the PlioMIP1 simulation, and a quasi ice-free summer in PlioMIP2. Beyond the official set of PlioMIP2 simulations, we present further simulations and analyses that sample the phase space of potential alternative orbital forcings that have acted during the Pliocene and may have impacted geological records. Employing orbital forcing, which differs from that proposed for PlioMIP2 (i.e., corresponding to pre-industrial conditions) but falls into the mid-Pliocene time period targeted in PlioMIP, leads to pronounced annual and seasonal temperature variations. Our result identifies the changes in mid-Pliocene paleogeography from PRISM3 to PRISM4 as the major driver of the mid-Pliocene warmth within PlioMIP and not the minor differences in forcings.\n",
      "--------------------------------------------------\n",
      "Topic 360: 360_soil_soils_organic_soc\n",
      "Representative Documents:\n",
      "  - Although forest soils play an important role in the carbon cycle, the influence of topography has received little attention. Since the topographical gradient may affect CO2 emissions and C sequestration, the aims of the study were: (1) to identify the basic physicochemical and microbial parameters of the top, mid-slope, and bottom of a forest gully; (2) to carry out a quantitative assessment of CO2 emission from these soils incubated at different moisture conditions (9% and 12% v/v) and controlled temperature (25 °C); and (3) to evaluate the interdependence between the examined parameters. We analyzed the physicochemical (content of total N, organic C, pH, clay, silt, and sand) and microbial (enzymatic activity, basal respiration, and soil microbial biomass) parameters of the gully upper, mid-slope, and bottom soil. The Fourier Transformed Infrared spectroscopy (FTIR) method was used to measure CO2 emitted from soils. The position in the forest gully had a significant effect on all soil variables with the gully bottom having the highest pH, C, N concentration, microbial biomass, catalase activity, and CO2 emissions. The sand content decreased as follows: top &gt; bottom &gt; mid-slope and the upper area had significantly lower clay content. Dehydrogenase activity was the lowest in the mid-slope, probably due to the lower pH values. All samples showed higher CO2 emissions at higher moisture conditions, and this decreased as follows: bottom &gt; top &gt; mid-slope. There was a positive correlation between soil CO2 emissions and soil microbial biomass, pH, C, and N concentration, and a positive relationship with catalase activity, suggesting that the activity of aerobic microorganisms was the main driver of soil respiration. Whilst the general applicability of these results to other gully systems is uncertain, the identification of the slope-related movement of water and inorganic/organic materials as a significant driver of location-dependent differences in soil respiration, may result in some commonality in the changes observed across different gully systems.\n",
      "  - Roadways traverse many forest areas and they often have harmful effects on forest soils, including the modified stability of soil organic matter (SOM). Soil CO2 respiration is an important indicator of SOM biological stability. The aim of this study was to test the hypotheses that a roadway will (1) modify the composition of the cation exchange capacity of adjacent forest soils, and (2) significantly decrease the stability of SOM. Two study sites were established in Scots pine and Silver fir stands, located close to the S7 highway in central Poland, which was opened to traffic in 1984. From each site, samples were taken at 2, 12 and 22 m from the forest edge. Soil CO2 respiration was determined using closed chamber incubation with an alkali trap. We also conducted a comprehensive analysis of soil chemical properties. The stoichiometric ratios of chosen chemical parameters to total carbon (Ct) were calculated. In both sites, we observed increased soil pH and CO2 respiration in the vicinity of the highway, as well as increased ratios of exchangeable calcium (Ca), magnesium (Mg) and sodium (Na) to Ct. In the fir site, the humic and fulvic acids, the dissolved organic carbon (DOC) content and aluminum (Al) to Ct ratio were depleted in close proximity to the highway. We suggest that the combined effect of Ca and Na ions, originating from winter de-icing, caused the depletion of Al and hydrogen (H) in the soil close to the forest edge and, therefore, resulted in lower SOM stability expressed as the decreased DOC and pyrophosphate-extractable carbon content, as well as the release of CO2. We conclude that the changes of SOM stability with distance were the effect of modification of ion-exchange relationships (particularly base cations versus Al3+ with H+) rather than forest stand species or intrinsic SOM properties (like functional groups, the recalcitrance of bindings etc.). Our work supports earlier studies, confirming the significant impact of Al and H on SOM stability.\n",
      "  - In the present field survey, 72 sites were sampled to assess the effect of climate (Monaro, Boorowa and Coleambally regions) and parent material (Monaro region only; basalt and granite) on soil organic carbon (OC) under perennial pastures. In the higher-rainfall zone (Monaro and Boorowa; &gt;500mm mean annual rainfall), OC stocks under introduced and native perennial pastures were compared, whereas in the lower-rainfall zone (Coleambally; &lt;500mm mean annual rainfall) OC stocks under crops and pastures were compared. Carbon fractions included total OC (TOC), particulate OC (POC), resistant OC (ROC) and humic OC (HUM). Higher OC stocks were associated with higher spring and summer rainfall and lower annual temperatures. Within a climatic zone, parent material affected the stock of OC fractions in the 0–30cm soil layer. Within a climatic zone, when grouped by parent material, there was no difference in OC stock with vegetation type. There were significant correlations between soil factors associated with parent material and OC concentration, including negative correlations between SiO2 and HUM (P&lt;0.05) and positive correlations between cation exchange capacity and TOC, POC and ROC (P&lt;0.01). TOC was also positively correlated with total nitrogen (N) and available sulfur (S; P&lt;0.05), indicating organic matter in soil is important for N and S supply for plant production in the studied regions, and vice versa. Although ensuring adequate available S may increase OC stocks in south-eastern Australia, the large stock of OC in the soil under perennial pastures, and the dominating effect of climate and parent material on this stock, may mean that modest increases in soil OC due to management factors go undetected.\n",
      "--------------------------------------------------\n",
      "Topic 361: 361_students_mental readiness_course_readiness\n",
      "Representative Documents:\n",
      "  -                Weather and Climate of Alaska is an undergraduate course for nonscience majors where students study meteorology from their home as part of a statewide network of classmates. The students draw on their experience of the weather and climate by observing weather locally and sharing their work with classmates across the state. The goal of the class is to have this cohort of students understand weather and climate through exploring the relationships between processes at the local, regional, and global scales. The class is organized around weekly investigations where the students use an equipment kit to make observations, report their work with videos, and discuss the work with the instructor and their peers. The students use NWS resources extensively, including station data to check the quality of their observations, weather maps and satellite images to understand the weather they have observed, weather forecasts to evaluate different forecasting techniques, and long-term data to compare their observations with the climate record. The course also includes traditional quizzes and exams. The instructor has regular teleconferences with students and discusses their work firsthand. A teaching assistant also supports the students. Students take pre- and postcourse tests and show gains typical of interactive science classes. The level of student support results in high student course completion rates.\n",
      "  - Competencies required for dentistry go far beyond the academic or scientific spheres. They incorporate important mental readiness concepts at its core with an appropriate balance of operational readiness (i.e., technical, physical, mental readiness). The aim of this exploratory study was to investigate the importance of mental readiness for optimal performance in the daily challenges faced by dentists using an Operational Readiness Framework. One-on-one interviews were conducted with a select group of seasoned dentists to determine their mental readiness before, during and after successfully performing in challenging situations. Quantitative and qualitative analyses of mental readiness were applied. Study findings were compared with a Wheel of Excellence based on results from other high-performance domains such as surgery, policing, social services and Olympic athletics. The analysis revealed that specific mental practices are required to achieve peak performance, and the balance between physical, technical and mental readiness underpins these dentists’ competency. Common elements of success were found—commitment, confidence, visualization, mental preparation, focus, distraction control, and evaluation and coping. This exploration confirmed many similarities in mental readiness practices engaged across high-risk professions. Universities, clinics and hospitals are looking for innovative ways to build teamwork and capacity through inter-professional collaboration. Results from these case studies warrant further investigation and may be significant enough to stimulate innovative curriculum design. Based on these preliminary dentistry findings, three training/evaluation tools from other professions in population health were adapted to demonstrate future application.\n",
      "  - Many high school students learn about nutrient cycling during biology, environmental science, and agriculture classes. These lessons often focus on soil and plants, and nutrient cycling is usually taught independently from climate change. Scientists know that animals, including fish, can have strong effects on nutrient cycling (i.e., nitrogen and phosphorus) in ecosystems. Additionally, research has shown that nitrogen and phosphorus excretion rates of animals increase with water temperatures. We worked with high school students to design and conduct nutrient excretion experiments using common fish (zebrafish) to explore the impact of climate change on nutrient cycling. This allowed students to have hands-on laboratory experience. In 2021, we worked with students participating in a residential summer program in Georgia. Meanwhile, in 2022, students enrolled in the local high school visited the university campus on two occasions to participate in the experiments, and we once again worked with students in Georgia. Students from all three groups showed an increased understanding of the role of animals in nutrient cycling and ways climate change may impact these processes, despite variable results from the excretion experiments. Students also showed increased understanding of science processes and were more likely to feel like part of the science community. We believe that these experiments can be done in high school classrooms to expand students’ understanding of the scientific process, nutrient cycling, and climate change.\n",
      "--------------------------------------------------\n",
      "Topic 362: 362_stations_metadata_ushcn_soms\n",
      "Representative Documents:\n",
      "  -                High-impact extratropical cyclones (ETCs) cause considerable damage along the northeast coast of the United States through strong winds and inundation, but these relatively rare events are difficult to analyze owing to limited historical records. Using a 1505-yr simulation from the GFDL FLOR coupled model, statistical analyses of extreme events are performed including exceedance probability computations to compare estimates from shorter segments to estimates that could be obtained from a record of considerable length. The most extreme events possess characteristics including exceptionally low central pressure, hurricane-force winds, and a large surge potential, which would greatly impact nearby regions. Return level estimates of metrics of ETC intensity using shorter, historical-length segments of the FLOR simulation are underestimated compared to levels determined using the full simulation. This indicates that if the underlying distributions of observed ETC metrics are similar to those of the 1505-yr FLOR distributions, the actual frequency of extreme ETC events could also be underestimated. Comparisons between FLOR and reanalysis products suggest that not all features of simulated high-impact ETCs are representative of observations. Spatial track densities are similar, but FLOR exhibits a negative bias in central pressure and a positive bias in wind speed, particularly for more intense events. Although the existence of these model biases precludes the quantitative use of model-derived return statistics as a substitute for those derived from shorter observational records, this work suggests that statistics from future models of higher fidelity could be used to better constrain the probability of extreme ETC events and their impacts.\n",
      "  - Extratropical cyclones (ETCs) are responsible for the majority of cool‐season extreme events in the northeastern United States (NEUS), often leading to high‐impact weather conditions that can have wide‐ranging socioeconomic impacts. Evaluating the ability of climate models to adequately simulate ETC dynamics is essential for improving model performance and increasing confidence in future projections used by stakeholders and policymakers. ETCs are traditionally studied using techniques such as case studies and synoptic typing, however, these approaches can be time‐consuming, require subjective analysis, and do not necessarily identify the coincident large‐scale meteorological patterns (LSMPs). Here, we apply self‐organizing maps (SOMs) as an automated machine‐learning approach to characterize the LSMPs and associated frequency and intensity of discrete ETC events over NEUS. The dominant patterns of geopotential height variability are identified through SOM analysis of five reanalysis products during the last four decades. ETC events are tracked using TempestExtremes and are integrated with SOMs to classify the accumulated cyclone activity (ACA) associated with each pattern. We then evaluate the skill of CMIP6 historical experiments in simulating the LSMPs and ETC events identified in the SOM. Our results identify a robust bias toward more zonal patterns, with models struggling to reproduce the more amplified patterns typically associated with the highest cyclone activity. While model resolution has some impact on simulation credibility, model configuration appears to be more important in LSMP representation. The vast majority of CMIP6 models produce too few ETCs, although model errors are distributed around historical reanalyses when ACA is normalized by storm frequency.\n",
      "  -                Urban heat island (UHI) analyses for the conterminous United States were performed using three different forms of metadata: nightlights-derived metadata, map-based metadata, and gridded U.S. Census Bureau population metadata. The results indicated that metadata do matter. Whether a UHI signal was found depended on the metadata used. One of the reasons is that the UHI signal is very weak. For example, population was able to explain at most only a few percent of the variance in temperature between stations. The nightlights metadata tended to classify lower population stations as rural compared to map-based metadata while the map-based metadata urban stations had, on average, higher populations than urban nightlights. Analysis with gridded population metadata indicated that statistically significant urban heat islands could be found even when quite urban stations were classified as rural, indicating that the primary signal was coming from the relatively high population sites. If ∼30% of the highest population stations were removed from the analysis, no statistically significant urban heat island was detected. The implications of this work on U.S. climate change analyses is that, if the highest population stations are avoided (populations above 30 000 within 6 km), the analysis should not be expected to be contaminated by UHIs. However, comparison between U.S. Historical Climatology Network (HCN) time series from the full dataset and a subset excluding the high population sites indicated that the UHI contamination from the high population stations accounted for very little of the recent warming.\n",
      "--------------------------------------------------\n",
      "Topic 363: 363_resolution file_download_file_please\n",
      "Representative Documents:\n",
      "  - Editors note: For easy download the posted pdf of the Explaining Extreme Events of 2014 is a very low-resolution file. A high-resolution copy of the report is available by clicking here. Please be patient as it may take a few minutes for the high-resolution file to download.\n",
      "  - Editors note: For easy download the posted pdf of the State of the Climate for 2012 is a very low-resolution file. A high-resolution copy of the report is available by clicking here. Please be patient as it may take a few minutes for the high-resolution file to download.\n",
      "  - Editors note: For easy download the posted pdf of the State of the Climate for 2014 is a very low-resolution file. A high-resolution copy of the report is available by clicking here. Please be patient as it may take a few minutes for the high-resolution file to download.\n",
      "--------------------------------------------------\n",
      "Topic 364: 364_op_palm_oil palm_oil\n",
      "Representative Documents:\n",
      "  - Palm oil is a very important commodity which will be required well into the future. However, the consequences of growing oil palm (OP) are often detrimental to the environment and contribute to climate change. On the other hand, climate change stress will decrease the production of palm oil by causing mortality and ill health of OP, as well as reducing yields. Genetically modified OP (mOP) may be produced in the future to resist climate change stress, although it will take a long time to develop and introduce, if they are successfully produced at all. It is crucial to understand the benefits mOP may bring for resisting climate change and increasing the sustainability of the palm oil industry. This paper employs modeling of suitable climate for OP using the CLIMEX program in (a) Indonesia and Malaysia, which are the first and second largest growers of OP respectively, and (b) Thailand and Papua New Guinea, which are much smaller growers. It is useful to compare these countries in terms of future palm oil production and what benefits planting mOP may bring. Uniquely, narrative models are used in the current paper to determine how climate change will affect yields of conventional OP and mOP. The effect of climate change on the mortality of mOP is also determined for the first time. The gains from using mOP were moderate, but substantial, if compared to the current production of other continents or countries. This was especially the case for Indonesia and Malaysia. The development of mOP requires a realistic appreciation of what benefits may accrue.\n",
      "  - The high economic return from sales of palm oil is because of its inclusion in a vast range of commodities, and Malaysia is the second largest producer after Indonesia. However, increasing cultivation of oil palm has a negative environmental impact threatening sustainability. Basal stem rot (BSR) by Ganoderma boninense is of major concern to sustainability of the palm oil industry. CLIMEX, a computer model, provided suitability‐for‐future‐growth maps of oil palm in Malaysia. The present study used this model to determine how climate affects oil palm growth, providing quantitative scenarios of future oil palm mortality and BSR incidence in Malaysia under a 'no change' presumption. Unsuitable climate for oil palm will make the plant susceptible to disease. High and low levels of oil palm mortality and BSR incidence were predicted from the CLIMEX model in Peninsular Malaysia and Sabah, respectively, by 2100. Sabah represented the most sustainable region in Malaysia for palm oil production followed by Sarawak. Overall, climate change will not affect the incidence of BSR greatly until 2050 but the situation will deteriorate thereafter. These scenarios can be monitored for accuracy in the future. Methods to ameliorate climate change effects on oil palm and concomitantly reducing BSR incidence are required. Palm oil production may be unsustainable after 2050, and urgent action must be taken.\n",
      "  - Palms are crucial species to the flora of south-east (SE) Asia. Oil palm (OP) is a highly significant introduced species to the region and produces palm oil, an especially important commodity. OPs are grown in huge plantations in SE Asia, predominantly in Malaysia and Indonesia. These palms have detrimental effects on the environment, particularly from deforestation when creating new plantations. Future climate scenarios have indicated mostly reductions in suitable climate for growing OP throughout SE Asia and it is crucial to consider how the palms can be conserved. Climate change has been shown to stimulate poleward movements in some other species, which assist in conserving them and may permit assisted colonisation. However, poleward movement to these refuges is unlikely from the tropics. Recent research has indicated potential longitudinal refuges for OP in Africa and phased longitudinal refuges in South America, based on future suitable climate (SC) for growing OP. These data indicate how the sustainability of OP could be maintained rather than experiencing the complete decimation of the crop, which might otherwise occur. This current work was undertaken to determine trends of future SC for growing OP in SE Asia and to indicate refuges with implications for conservation and plantation management. The results are compared with those for Africa and South America. The longitudes considered in SE Asia were from 100°E to 146°E, which is an intentionally large area of land. The maps obtained from the climate modelling program CLIMEX, of climate suitability for growing OP, were employed to obtain the percentage SC in SE Asian regions and countries for current time (CT), 2050 and 2100. The average percentage SC decreased for 2050 and further for 2100. Increasing longitudinal trends in SC for growing OP were observed from CT to 2050, CT to 2100 and 2050 to 2100 from west to east. Vietnam, the Philippines, Papua New Guinea (PNG) and island Malaysia had increased SC by 2050. Large decreases in SC by 2050 for Thailand, Laos and Cambodia, which are towards the west of SE Asia, were observed. There was an increasing trend in suitable climate from CT to 2100 and a smaller trend from 2050 to 2100. Hence, OP may find suitable refuges by natural seed spreading towards the east of SE Asia, hence avoiding extinction. Similarly, new plantations could be established in the same direction, although environmental concerns are paramount. Vietnam, the Philippines, PNG and island Malaysia may become more suitable than Thailand, Laos and Cambodia. The sustainability of OP plantations is likely to decrease substantially with climate change. However, there is scope for a more sustainable situation towards the east of SE Asia. New plantations cannot be established without considering the severe effects on the environment from deforestation and increased greenhouse gases. Overall, urgent action is required to reduce the effects of climate change.\n",
      "--------------------------------------------------\n",
      "Topic 365: 365_paris_un_kyoto_international\n",
      "Representative Documents:\n",
      "  - There is no doubt that the discourse around climate change has matured over the years and has become one of the central features of international relations. We all know of the international legal regime that has developed to deal with climate change, starting from the United Nations Framework Convention on Climate Change and finishing with the Paris Agreement. Climate change is also either at the core or on the fringes of many other international debates, from international security to international economic relations. In 2018, the Intergovernmental Panel on Climate Change released a (yet again) stark warning alerting to the risks of not moving towards a 1.5 degrees goal, rather than a 2.0 degrees as the Paris Agreement seems to be suggesting. The truth is that the trend countries are moving toward with their pledges in their nationally determined contributions is not going to meet the 2.0 objective, let alone the 1.5 degrees objective. Against this background, it is not surprising that sectors of society interested in pursuing stronger climate change policies have explored multiple governance routes to take forward their agenda. This has led to the emergence of a polycentric and multilevel governance in the field of climate change. It is within this greater picture that climate change litigation has become a key facet in the fight against climate change.\n",
      "  - In the wake of the 2021 Glasgow meeting of the Paris Agreement, where states embedded a 2050 pathway to net zero that will overshoot the Earth's remaining carbon budget for 1.5°C, attention is turning to the flaws of the UN Framework Convention on Climate Change. This article highlights ways in which it blocks effective climate action, which has been acknowledged by states who are now pursuing voluntary and nonbinding initiatives on coal, forests, and oil and gas. The article assesses new proposals for treaties on deforestation, the elimination of coal, and a fossil fuel nonproliferation treaty. It argues that states should take these proposals to the UN General Assembly and adopt them as binding treaties consistent with holding global heating at 1.5°C. Following the model of the Nuclear Weapons Convention it further argues that these treaties should be folded into a full Greenhouse Convention, supported by a powerful International Climate Agency, to secure a net zero world. Drawing upon new proposals for an Earth‐centric law that takes in the totality of social‐natural processes at the planetary scale, these proposals could form part of a reformed international legal architecture that could be equal to the diabolical governance challenges of the Anthropocene.\n",
      "  - The international system is unstable due to the absence of a global regulating body, but countries are sovereign and independent. Although intergovernmental and multilateral organizations exist, there is no world government to regulate the behaviour of nations. In such an environment, states are highly concerned about their security and domestic interest over the idea of climate justice. However, the United States, with a firm hold on the economy, repeatedly refuses to take a suitable stand, from Kyoto to the Paris Accord, for reducing its greenhouse gas (GHG) emissions and endlessly demands the developing world’s engagement in climate action. The US’s withdrawal from the Paris Agreement shocked world leaders and criticized the stand of President Trump’s backpaddling, which setback climate action. It influences global emissions, at least for the time being, forcing developing economies to reduce their standard of emissions extensively. Significantly, how conscious is the United States of climate justice? How fast will the United States come back in acting the jeopardy of climate change? This article reviews the US action, shifting governments’ policy and stands on climate change from Rio Earth Summit 1992 to Glasgow Climate Accord 2021 conditions. The author has taken the 1992 to 2021 period, a blueprint for crucial climate action decided in 1992 led to the formation of UNFCCC, while the United States has re-engaged in the Paris Accord in 2021. Also, it tries to understand the shift across federal governments and the influence of local governments on climate change. Furthermore, it sheds light on the obscure image of the United States on carbon trading and tax subsidies for GHGs.\n",
      "--------------------------------------------------\n",
      "Topic 366: 366_legal_law_rights_unfccc\n",
      "Representative Documents:\n",
      "  -                Environmental principles with their various forms, natures and different legal roles across jurisdictions are gaining increasing attention in energy and climate scholarship. The trend in the literature has been to discuss these principles in the context of developed countries, considering, for example, the impact of and significant literature on the polluter-pays principle. This article offers an original review with a contribution in discussing the new Middle Eastern energy and climate ambitions of the Kingdom of Saudi Arabia (KSA). These goals are contained within the promising policy document known as Vision 2030, and this review explores these energy and climate ambitions in the legal context of environmental principles. The study reviews the literature on the environmental principles in the Middle Eastern context of the Kingdom of Saudi Arabia and utilizes doctrinal and socio-legal methods (including expert interviews) to explore the practice of Vision 2030. This article advocates that, with the advent of the Kingdom of Saudi Arabia Vision 2030, the application of these principles can fill an existing lacuna in legal scholarship and advance governance in the areas of energy and climate change.\n",
      "  - With the ever-increasing need for corporate responsibility in mitigating climate risks, this paper aims to analyse the legal duties of directors and their role in climate risk mitigation. This is done by analysing the scope of the codified director duties in the context of climate change under the company law, securities regulations, and environmental regime. However, directors face challenges in understanding the nature of their legal obligations due to the systemic nature of climate change (Breitinger &amp; Litvak, 2018). Against this backdrop, the paper attempts to analyse the scope and interpret the emergence of director duties through judicial pronouncements. The paper adopts doctrinal legal methodology involving a comprehensive review of relevant legal frameworks, including case law and legislative provisions in India. The paper suggests that such legal interventions may aid corporates in addressing climate change, which entails that directors must consider climate risks and conduct themselves accordingly. The paper concludes by discussing what measures corporations must take to help India progress towards becoming a low-carbon economy. The significance of this paper lies in providing a reference for corporations to navigate their responsibilities and take measures to address climate change through legal intervention\n",
      "  - Domestic climate change litigation is prospering across the globe to the extent of becoming a transnational phenomenon of growing importance. At the international level the Paris Agreement, although still in its infancy, has been established as the core element of the climate change governance framework. This article explores the still opaque relationship between domestic climate change litigation and the Paris Agreement. It is argued that dynamic interaction between domestic litigation and the Paris Agreement may improve the overall efficacy of both regimes. On the one hand, an examination of the Paris Agreement's architecture and provisions reveals pathways that are already being used or can be explored further in litigation. On the other hand, litigation can assist and complement the Paris Agreement with regard to its implementation and progress towards its overall goals. The result may deliver more than a multi-level perspective on climate change law. As it captures the law in action on different levels, the proposed ‘cross-level’ approach has due regard to the implications of the mutual supportiveness or complementarity of legal tools. It also thereby responds to the concern of whether the law can be of significant benefit in addressing complex global issues like climate change.\n",
      "--------------------------------------------------\n",
      "Topic 367: 367_disease problem_asian disease_asian disease problem_belief\n",
      "Representative Documents:\n",
      "  - Everyday public denial of anthropogenically caused climate change (ACC) has complex antecedents and exists on both individual and institutional levels. Earlier research has linked ACC denial to opposition to formal science and elites, perceived threats to the industrialist capitalist order and existing system properties. Research also suggest that trust in public organizations is a key factor in determining support or opposition to climate change policies. In this paper, we explore the possibility that right wing populism and anti-elitist attitudes fuel both ACC denial and low trust in environmental institutions. We surveyed a representative sample of Norwegians (N = 3032) to measure ACC denial, how denial is linked to socio-demographic characteristics, trust in environmental institutions, attitudes toward elites and immigration, as well as environmental attitude orientations. Results show that lack of trust in environmental institutions is strongly associated with ACC denial, and furthermore that the degree of trust—or lack thereof—is partly a function of anti-elitist attitudes, opposition to migration and views of nature.\n",
      "  -  Societies seem to have emotional climates that affect how people feel and act in public situations. Unlike the emotions experienced in an individual's personal life, these modal feelings reflect a collective response to the socio‐economic‐political situation of the society and influence how most people behave toward one another and their government. A government may foster a climate of fear to ensure social control, or it may encourage the formation of heterogeneous social groups to facilitate a climate of trust between people from different groups. On one hand, emotional climates may be viewed as reflecting the relative peacefulness or violence of a society. Thus, an assessment of emotional climate may provide a subjective index of human security to complement objective measures of democracy, human rights, equality, and other factors that we presume are beneficial to human welfare. On the other hand, we may view emotional climates as influences that act to further or to impede the development of the culture of peace advocated by the General Assembly of the United Nations. Thus, their assessment may have predictive power, and measuring a society's emotional climate may help us to create desirable policy. In this article we show that it is possible to measure some important aspects of the emotional climates of three nations that have different degrees of a culture of peace: Norway, the United States, and India. We show that estimates of the collective emotions that constitute climate can be distinguished from reports of personal emotions in that the former are more influenced by nation and the latter by social class. It is the subjective experience of national emotional climate, rather than personal emotional experience, that appears most related to objective indices for the culture of peace in the different nations. \n",
      "  - The Asian disease problem has long been studied since first introduced by Tversky and Kahneman in 1981. This study explores the mechanics of the Asian disease problem to a scenario reflecting deaths attributed to climate change. The study examines the gain/loss frame setup of the Asian disease problem. To research the Asian disease problem, in partnership with a Qualtrics panel, we surveyed 1209 customers of Utah utilities. Through statistical tests on the survey data, we confirmed the existence of the gain/loss framing effect. Moreover, the framing effect held when separating and examining responses based on unique socio-economic characteristics (i.e., age, gender, race, marital status, income, educational attainment, political preference, living status, household size, years at current residence, and energy-saving preference). In short, like the original Asian disease problem, the framing impact varied regardless of the characteristic studied. Based on these findings, we recommend implementing the framing effects of the Asian disease problem to an expanded realm for energy- and climate-related programs, initiatives, and academic research. We believe that this framing could spur action to mitigate climate change. Moreover, we recommend an expanded empirical study of the Asian disease problem to novel and understudied realms beyond our focus area.\n",
      "--------------------------------------------------\n",
      "Topic 368: 368_mariculture_fisheries_marine_rebuilding\n",
      "Representative Documents:\n",
      "  - Human‐induced climate change and ocean acidification (CC‐OA) is changing the physical and biological processes occurring within the marine environment, with poorly understood implications for marine life. Within the aquaculture sector, molluskan culture is a relatively benign method of producing a high‐quality, healthy, and sustainable protein source for the expanding human population. We modeled the vulnerability of global bivalve mariculture to impacts of CC‐OA over the period 2020–2100, under RCP8.5. Vulnerability, assessed at the national level, was dependent on CC‐OA‐related exposure, taxon‐specific sensitivity and adaptive capacity in the sector. Exposure risk increased over time from 2020 to 2100, with ten nations predicted to experience very high exposure to CC‐OA in at least one decade during the period 2020–2100. Predicted high sensitivity in developing countries resulted, primarily, from the cultivation of species that have a narrow habitat tolerance, while in some European nations (France, Ireland, Italy, Portugal, and Spain) high sensitivity was attributable to the relatively high economic value of the shellfish production sector. Predicted adaptive capacity was low in developing countries primarily due to governance issues, while in some developed countries (Denmark, Germany, Iceland, Netherlands, Sweden, and the United Kingdom) it was linked to limited species diversity in the sector. Developing and least developed nations (n = 15) were predicted to have the highest overall vulnerability. Across all nations, 2060 was identified as a tipping point where predicted CC‐OA will be associated with the greatest challenge to shellfish production. However, rapid declines in mollusk production are predicted to occur in the next decade for some nations, notably North Korea. Shellfish culture offers human society a low‐impact source of sustainable protein. This research highlights, on a global scale, the likely extent and nature of the CC‐OA‐related threat to shellfish culture and this sector enabling early‐stage adaption and mitigation.\n",
      "  - The sustainability of global seafood supply to meet increasing demand is facing several challenges, including increasing consumption levels due to a growing human population, fisheries resources over‐exploitation and climate change. Whilst growth in seafood production from capture fisheries is limited, global mariculture production is expanding. However, climate change poses risks to the potential seafood production from mariculture. Here, we apply a global mariculture production model that accounts for changing ocean conditions, suitable marine area for farming, fishmeal and fish oil production, farmed species dietary demand, farmed fish price and global seafood demand to project mariculture production under two climate and socio‐economic scenarios. We include 85 farmed marine fish and mollusc species, representing about 70% of all mariculture production in 2015. Results show positive global mariculture production changes by the mid and end of the 21st century relative to the 2000s under the SSP1‐2.6 scenario with an increase of 17%±5 and 33%±6, respectively. However, under the SSP5‐8.5 scenario, an increase of 8%±5 is projected, with production peaking by mid‐century and declining by 16%±5 towards the end of the 21st century. More than 25% of mariculture‐producing nations are projected to lose 40%–90% of their current mariculture production potential under SSP5‐8.5 by mid‐century. Projected impacts are mainly due to the direct ocean warming effects on farmed species and suitable marine areas, and the indirect impacts of changing availability of forage fishes supplies to produce aquafeed. Fishmeal replacement with alternative protein can lower climate impacts on a subset of finfish production. However, such adaptation measures do not apply to regions dominated by non‐feed‐based farming (i.e. molluscs) and regions losing substantial marine areas suitable for mariculture. Our study highlights the importance of strong mitigation efforts and the need for different climate adaptation options tailored to the diversity of mariculture systems, to support climate‐resilient mariculture development.\n",
      "  - Previous studies have focused on changes in the geographical distribution of terrestrial biomes and species targeted by marine capture fisheries due to climate change impacts. Given mariculture's substantial contribution to global seafood production and its growing significance in recent decades, it is essential to evaluate the effects of climate change on mariculture and their socio‐economic consequences. Here, we projected climate change impacts on the marine aquaculture diversity for 85 of the currently most commonly farmed fish and invertebrate species in the world's coastal and/or open ocean areas. Results of ensemble projections from three Earth system models and three species distribution models show that climate change may lead to a substantial redistribution of mariculture species richness potential, with an average of 10%–40% decline in the number of species being potentially suitable to be farmed in tropical to subtropical regions. In contrast, mariculture species richness potential is projected to increase by about 40% at higher latitudes under the ‘no mitigation policy’ scenario (RCP 8.5) by the mid‐21st century. In Exclusive Economic Zones where mariculture is currently undertaken, we projected an average future decline of 1.3% and 5% in mariculture species richness potential under RCP 2.6 (‘strong mitigation’) and RCP 8.5 scenarios, respectively, by the 2050s relative to the 2000s. Our findings highlight the opportunities and challenges for climate adaptation in the mariculture sector through the redistribution of farmed species and expansion of mariculture locations. Our results can help inform adaptation planning and governance mechanisms to minimize local environmental impacts and potential conflicts with other marine and coastal sectors in the future.\n",
      "--------------------------------------------------\n",
      "Topic 369: 369_sww_wacs_warming_arctic\n",
      "Representative Documents:\n",
      "  - In January 2016, a robust reversal of the Arctic Oscillation took place associated with a rapid tropospheric warming in the Arctic region; this was followed by the occurrence of a classic sudden stratospheric warming in March. The succession of these two distinct Arctic warming events provides a stimulating opportunity to examine their characteristics in terms of similarities and differences. Historical cases of these two types of Arctic warming were identified and validated based upon tropical linkages with the Madden‐Julian Oscillation and El Niño as documented in previous studies. The analysis indicates a recent and seemingly accelerated increase in the tropospheric warming type versus a flat trend in stratospheric warming type. The shorter duration and more rapid transition of tropospheric warming events may connect to the documented increase in midlatitude weather extremes, more so than the route of stratospheric warming type. Forced simulations with an atmospheric general circulation model suggest that the reduced Arctic sea ice contributes to the observed increase in the tropospheric warming events and associated remarkable strengthening of the cold Siberian high manifest in 2016.\n",
      "  - . The Southern Hemisphere Westerly Winds (SWW) have been suggested to exert a critical influence on global climate through the wind-driven upwelling of deep water in the Southern Ocean and the potentially resulting atmospheric CO2 variations. The investigation of the temporal and spatial evolution of the SWW along with forcings and feedbacks remains a significant challenge in climate research. In this study, the evolution of the SWW under orbital forcing from the mid-Holocene (7 kyr BP) to pre-industrial modern times (250 yr BP) is examined with transient experiments using the comprehensive coupled global climate model CCSM3. In addition, a model inter-comparison is carried out using orbitally forced Holocene transient simulations from four other coupled global climate models. Analyses and comparison of the model results suggest that the annual and seasonal mean SWW were subject to an overall strengthening and poleward shifting trend during the course of the mid-to-late Holocene under the influence of orbital forcing, except for the austral spring season, where the SWW exhibited an opposite trend of shifting towards the equator.                    \n",
      "  - Eurasia has experienced more frequent bitter winters over the past two decades, which concurred with a prominent “Warm Arctic‐Cold Siberia” (WACS) pattern that is unexpected from global warming. Here we show, by analysis of 117‐year observations and climate model's millennial simulations, that the WACS is an internal mode of winter temperature variability, which cannot be excited by greenhouse gases and solar forcing. Observational and simulated results suggest that frequent occurrences of that WACS pattern are instigated by warm phases of Atlantic Multidecadal Oscillation (AMO). North Atlantic warming may activate the WACS by generating a background Atlantic‐Eurasian wave train characterized by enhanced Ural Mountain ridge and East Asian trough, which is conducive to recurrent WACS pattern. The wave train‐induced the Barents Sea ice melting can act as an amplifier, reinforcing the WACS. Although increased greenhouse gases favor a uniform warming pattern, they may contribute to WACS formation by affecting AMO.\n",
      "--------------------------------------------------\n",
      "Topic 370: 370_original publication_publication_original_figure\n",
      "Representative Documents:\n",
      "  - In the original publication [...]\n",
      "  - In the original publication [...]\n",
      "  - In the original publication [...]\n",
      "--------------------------------------------------\n",
      "Topic 371: 371_tmax_wind gust_projected_rainfall\n",
      "Representative Documents:\n",
      "  - The global climate has changed, and there are concerns about the effects on both humans and the environment, necessitating more research for improved adaptation. In this study, we analyzed extreme temperature and rainfall events and projected future climate change scenarios for the coastal Savannah agroecological zone (CSAZ) of Ghana. We utilized the ETCCDI, the RClimDex software (version 1.0), the Mann–Kendall test, Sen’s slope estimator, and standardized anomalies to analyze homogeneity, trends, magnitude, and seasonal variations in temperature (Tmax and Tmin) and rainfall datasets for the zone. The SDSM was also used to downscale future climate change scenarios based on the CanESM2 (RCP 2.6, 4.5, and 8.5 scenarios) and HadCM3 (A2 and B2 scenarios) models for the zone. Model performance was evaluated using statistical methods such as R2, RMSE, and PBIAS. Results revealed more changepoints in Tmin than in Tmax and rainfall. Results again showed that the CSAZ has warmed over the last four decades. The SU25, TXn, and TN90p have increased significantly in the zone, and the opposite is the case for the TN10p and DTR. Spatially varied trends were observed for the TXx, TNx, TNn, TX10p, TX90p, and the CSDI across the zone. The decrease in RX1day, RX5day, SDII, R10, R95p, and R99p was significant in most parts of the central region compared to the Greater Accra and Volta regions, while the CDD significantly decreased in the latter two regions than in the former. The trends in CWD and PRCPTOT were insignificant throughout the zone. The overall performance of both models during calibration and validation was good and ranged from 58–99%, 0.01–1.02 °C, and 0.42–11.79 °C for R2, RMSE, and PBIAS, respectively. Tmax is expected to be the highest (1.6 °C) and lowest (−1.6 °C) across the three regions, as well as the highest (1.5 °C) and lowest (−1.6 °C) for the entire zone, according to both models. Tmin is projected to be the highest (1.4 °C) and lowest (−2.1 °C) across the three regions, as well as the highest (1.4 °C) and lowest (−2.3 °C) for the entire zone. The greatest (1.6 °C) change in mean annual Tmax is expected to occur in the 2080s under RCP8.5, while that of the Tmin (3.2 °C) is expected to occur in the 2050s under the same scenario. Monthly rainfall is expected to change between −98.4 and 247.7% across the three regions and −29.0 and 148.0% for the entire zone under all scenarios. The lowest (0.8%) and highest (79%) changes in mean annual rainfall are expected to occur in the 2030s and 2080s. The findings of this study could be helpful for the development of appropriate adaptation plans to safeguard the livelihoods of people in the zone.\n",
      "  -  Hourly/daily wind gust simulation models and regression-based downscaling methods were developed to assess possible impacts of climate change on future hourly/daily wind gust events over the province of Ontario, Canada. Since the climate/weather validation process is critical, a formal model result verification process has been built into the analysis to ascertain whether the methods are suitable for future projections. The percentage of excellent and good simulations among all studied seven wind gust categories ranges from 94% to 100% and from 69% to 95%, respectively, for hourly and daily wind gusts, for both model development and validation.  The modeled results indicate that frequencies of future hourly/daily wind gust events are projected to increase late this century over the study area under a changing climate. For example, across the study area, the annual mean frequency of future hourly wind gust events ≥28, ≥40, and ≥70 km h−1 for the period 2081–2100 derived from the ensemble of downscaled eight-GCM A2 simulations is projected to be about 10%–15%, 10%–20%, and 20%–40% greater than the observed average during the period 1994–2007, respectively. The corresponding percentage increase for future daily wind gust events is projected to be &lt;10%, ~10%, and 15%–25%. Inter-GCM-model and interscenario uncertainties of future wind gust projections were quantitatively assessed. On average, projected percentage increases in frequencies of future hourly/daily wind gust events ≥28 and ≥40 km h−1 are about 90%–100% and 60%–80% greater than inter-GCM-model–interscenario uncertainties, respectively. For wind gust events ≥70 km h−1, the corresponding projected percentage increases are about 25%–35% greater than the interscenario uncertainties and are generally similar to inter-GCM-model uncertainties. \n",
      "  -                This paper attempts to project possible changes in the frequency of daily rainfall events late in this century for four selected river basins (i.e., Grand, Humber, Rideau, and Upper Thames) in Ontario, Canada. To achieve this goal, automated synoptic weather typing as well as cumulative logit and nonlinear regression methods was employed to develop within-weather-type daily rainfall simulation models. In addition, regression-based downscaling was applied to downscale four general circulation model (GCM) simulations to three meteorological stations (i.e., London, Ottawa, and Toronto) within the river basins for all meteorological variables (except rainfall) used in the study. Using downscaled GCM hourly climate data, discriminant function analysis was employed to allocate each future day for two windows of time (2046–65, 2081–2100) into one of the weather types. Future daily rainfall and its extremes were projected by applying within-weather-type rainfall simulation models together with downscaled future GCM climate data. A verification process of model results has been built into the whole exercise (i.e., statistical downscaling, synoptic weather typing, and daily rainfall simulation modeling) to ascertain whether the methods are stable for projection of changes in frequency of future daily rainfall events.               Two independent approaches were used to project changes in frequency of daily rainfall events: method I—comparing future and historical frequencies of rainfall-related weather types, and method II—applying daily rainfall simulation models with downscaled future climate information. The increases of future daily rainfall event frequencies and seasonal rainfall totals (April–November) projected by method II are usually greater than those derived by method I. The increase in frequency of future daily heavy rainfall events greater than or equal to 25 mm, derived from both methods, is likely to be greater than that of future daily rainfall events greater than or equal to 0.2 mm: 35%–50% versus 10%–25% over the period 2081–2100 derived from method II. In addition, the return values of annual maximum 3-day accumulated rainfall totals are projected to increase by 20%–50%, 30%–55%, and 25%–60% for the periods 2001–50, 2026–75, and 2051–2100, respectively. Inter-GCM and interscenario uncertainties of future rainfall projections were quantitatively assessed. The intermodel uncertainties are similar to the interscenario uncertainties, for both method I and method II. However, the uncertainties are generally much smaller than the projection of percentage increases in the frequency of future seasonal rain days and future seasonal rainfall totals. The overall mean projected percentage increases are about 2.6 times greater than overall mean intermodel and interscenario uncertainties from method I; the corresponding projected increases from method II are 2.2–3.7 times greater than overall mean uncertainties.\n",
      "--------------------------------------------------\n",
      "Topic 372: 372_sdg_trade offs_offs_sustainable development\n",
      "Representative Documents:\n",
      "  - Post-2015 global agendas; namely the Sendai Framework for Disaster Risk Reduction 2015–2030, the Paris Agreement, and the 2030 Agenda for Sustainable Development (including Sustainable Development Goals (SDGs)), pose a challenge to the coherence among Disaster Risk Reduction (DRR), Climate Change Adaptation, and Sustainable Development to achieve the common goal; disaster resilience. These agendas are more outcome-oriented with monitoring mechanisms than previous ones and require a coherent multi-stakeholder, cross-sectoral approach across government levels. Above all, the global indicators for monitoring the Sendai Framework have been adopted as SDG indicators in Goals 1, 11, and 13. Interlinkages between DRR, climate change, and sustainable development are observed from the integrated monitoring of agendas, which enhances coordination and coherence. Disaggregated data have revealed that major disaster mortality and economic losses in recent years have been triggered by weather-, climate-, and water-related disasters. More detailed data support evidence-based policymaking and promote coherence. To achieve Target E of the Sendai Framework, countries are developing DRR strategies to promote policy coherence with sustainable development and climate change. Both the number of national DRR strategies and alignment scores have increased over the years. DRR strategies and national adaptation plans (NAPs) should adopt a risk-informed, integrated approach to sustainable development through comprehensive planning and implementation. To achieve disaster resilience, national plans in these domains should be better integrated to maximize the effectiveness of actions toward disaster resilience and passed on to the sub-national level for implementation as place-based policies. Japanese experiences toward disaster resilience highlight interdisciplinary or transdisciplinary approaches by various stakeholders with technological innovation, which presents promising progress.\n",
      "  -                 Background                The EU “Winter Package” sets out specific energy and climate goals and urged formation of National Energy and Climate Plans (NECPs) by Member States for 2020 to 2030. Integrating scaled-up mitigation technologies within existing economic and social structures face numerous difficulties and require careful planning. While some options may be less suitable than others within a given country context, solutions exist to mitigate negative impacts and build local acceptance. We assess the resulting plans in the context of: (i) economic effects, the trade-offs arising from scaled-up technologies in terms of energy system- and macroeconomic effects; (ii) climate effectiveness, via assessment of carbon payback times of technologies, and (iii) social aspects, with a focus on identifying approaches for wider social adoption and acceptance of mitigation options. Assessment takes the form of case studies for Greece, Austria, and the Netherlands, three EU member states with very different preconditions.                              Results                In terms of economic efficiency, NECPs lack consideration of the unique properties inherent in large-scale renewable energy deployment, and we suggest a possible way forward for future macroeconomic assessment via incorporating integration costs. For economic efficiency, we find that countries may be overestimating their contributions to GHG reduction targets via failure to incorporate life-cycle based analysis. Addressing feasibility, we find that countries address acceptance to different extents, with Greece and Austria holding stakeholder workshops and allowing for public comment on draft NECPs, while the Netherlands undertook a more extensive effort to ensure local public acceptance and involvement in planning.                              Conclusions                The results illustrate that even though NECPs may be finalized, their success is far from ensured, and neglecting to consider key aspects of efficiency, effectiveness and feasibility may result in underestimation of impacts, failure to have as large an impact on GHG reduction as expected, or increasing public resistance to climate policies. We present approaches to deal with gaps in economic and environmental assessment, and highlight methods for improving public acceptance via examples from the case studies and related literature.              \n",
      "  - The Sixth Assessment Report of Inter-Governmental Panel on Climate Change (IPCC) has highlighted the urgency of accelerated climate actions harnessing synergies and minimizing trade-offs with various SDG. This calls for a clear understanding of linkages between climate goals and other SDGs at national level for formulating synergistic policies and strategies and developing different sectoral programs and coherent cross-sectoral policies. This is even more important for least developed countries such as Nepal where these linkages are less understood and development challenges are multifaceted. In this context, this paper aims to evaluate potential synergies and trade-offs among selected SDGs and their associated targets in Nepal in a linear pairwise comparison. Synergies and trade-offs related to climate action (SDG 13), access to energy (SDG 7), sustainable consumption and production (SDG 12), and life on land (SDG 15) have been evaluated using historical data for the period from 1990 to 2018 employing a mixed methods approach. Network analysis to map the conceptual linkages between the SDGs and their targets was combined with the advance sustainability analysis (ASA) to quantitatively evaluate the synergy and trade-offs between SDGs. The results illustrate the presences of a continual trade-off between emission reductions targets of SDG 13 with per capita energy consumption and share of renewable energy of SDG 7, land use for agricultural production target of SDG 12, and forest area target of SDG 15. This indicates that climate action is strongly interlinked with GHG emissions from economic activities and energy consumption. The results of the study represent a valuable input for the policy makers, supporting coherent and sustainable development planning as Nepal plans to graduate to a middle-income country.\n",
      "--------------------------------------------------\n",
      "Topic 373: 373_climate sensitivity_sensitivity_uncertainty_lines evidence\n",
      "Representative Documents:\n",
      "  - The spread in climate sensitivity obtained from 12 general circulation model runs used in the Fourth Assessment of the Intergovernmental Panel on Climate Change indicates a 95% confidence interval of 2.1°–5.5°C, but this reflects compensation between model feedbacks. In particular, cloud feedback strength negatively covaries with the albedo feedback as well as with the combined water vapor plus lapse rate feedback. If the compensation between feedbacks is removed, the 95% confidence interval for climate sensitivity expands to 1.9°–8.0°C. Neither of the quoted 95% intervals adequately reflects the understanding of climate sensitivity, but their differences illustrate that model interdependencies must be understood before model spread can be correctly interpreted.The degree of negative covariance between feedbacks is unlikely to result from chance alone. It may, however, result from the method by which the feedbacks were estimated, physical relationships represented in the models, or from conditioning the models upon some combination of observations and expectations. This compensation between model feedbacks—when taken together with indications that variations in radiative forcing and the rate of ocean heat uptake play a similar compensatory role in models—suggests that conditioning of the models acts to curtail the intermodel spread in climate sensitivity. Observations used to condition the models ought to be explicitly stated, or there is the risk of doubly calling on data for purposes of both calibration and evaluation. Conditioning the models upon individual expectation (e.g., anchoring to the Charney range of 3° ± 1.5°C), to the extent that it exists, greatly complicates statistical interpretation of the intermodel spread.\n",
      "  -                In this paper, the authors address the impact of uncertainty on estimates of transient climate sensitivity (TCS) of the globally averaged surface temperature, including both uncertainty in past forcing and internal variability in the climate record. This study provides a range of probabilistic estimates of the TCS that combine these two sources of uncertainty for various underlying assumptions about the nature of the uncertainty. The authors also provide estimates of how quickly the uncertainty in the TCS may be expected to diminish in the future as additional observations become available. These estimates are made using a nonlinear Kalman filter coupled to a stochastic, global energy balance model, using the filter and observations to constrain the model parameters. This study verifies that model and filter are able to emulate the evolution of a comprehensive, state-of-the-art atmosphere–ocean general circulation model and to accurately predict the TCS of the model, and then apply the methodology to observed temperature and forcing records of the twentieth century.               For uncertainty assumptions best supported by global surface temperature data up to the present time, this paper finds a most likely present-day estimate of the transient climate sensitivity to be 1.6 K, with 90% confidence the response will fall between 1.3 and 2.6 K, and it is estimated that this interval may be 45% smaller by the year 2030. The authors calculate that emissions levels equivalent to forcing of less than 475 ppmv CO2 concentration are needed to ensure that the transient temperature response will not exceed 2 K with 95% confidence. This is an assessment for the short-to-medium term and not a recommendation for long-term stabilization forcing; the equilibrium temperature response to this level of CO2 may be much greater. The flat temperature trend of the last decade has a detectable but small influence on TCS. This study describes how the results vary if different uncertainty assumptions are made and shows they are robust to variations in the initial prior probability assumptions.\n",
      "  - Recent assessments of climate sensitivity per doubling of atmospheric CO2concentration have combined likelihoods derived from multiple lines of evidence. These assessments were very influential in the Intergovernmental Panel on Climate Change Sixth Assessment Report (AR6) assessment of equilibrium climate sensitivity, thelikelyrange lower limit of which was raised to 2.5 °C (from 1.5 °C previously). This study evaluates the methodology of and results from a particularly influential assessment of climate sensitivity that combined multiple lines of evidence, Sherwood et al. (Rev Geophys 58(4):e2019RG000678, 2020). That assessment used a subjective Bayesian statistical method, with an investigator-selected prior distribution. This study estimates climate sensitivity using an Objective Bayesian method with computed, mathematical priors, since subjective Bayesian methods may produce uncertainty ranges that poorly match confidence intervals. Identical model equations and, initially, identical input values to those in Sherwood et al. are used. This study corrects Sherwood et al.'s likelihood estimation, producing estimates from three methods that agree closely with each other, but differ from those that they derived. Finally, the selection of input values is revisited, where appropriate adopting values based on more recent evidence or that otherwise appear better justified. The resulting estimates of long-term climate sensitivity are much lower and better constrained (median 2.16 °C, 17–83% range 1.75–2.7 °C, 5–95% range 1.55–3.2 °C) than in Sherwood et al. and in AR6 (central value 3 °C,very likelyrange 2.0–5.0 °C). This sensitivity to the assumptions employed implies that climate sensitivity remains difficult to ascertain, and that values between 1.5 °C and 2 °C are quite plausible.\n",
      "--------------------------------------------------\n",
      "Topic 374: 374_snowfall_snow_dry hot seasons_spells\n",
      "Representative Documents:\n",
      "  - Risks associated to extreme hydrological conditions, such as floods and droughts, are expected to increase in future climate because of projected changes in precipitation and temperature. Assessing how wet and dry persisting conditions (or spells) will evolve in future climate is a crucial step in the study of extreme hydrological events. Projected changes over the north‐eastern part of North America in the annual number of wet days, wet, and dry spells characteristics (number, duration), and wet spells intensities are analyzed. Two regional climate model ensembles are considered: the multimember ensemble from the Canadian RCM v5 (CRCM5‐LE), and 16 simulations from the NA‐CORDEX multimodel ensemble both using the Representative Concentration Pathway 8.5 (RCP8.5) scenario. Comparison of observed and simulated wet and dry spells characteristics is first performed in present climate (1971–2000). Regional Climate Model (RCM)s tend to generate too many wet days and wet or dry spells resulting in shorter dry spells and slightly longer wet spells. Modeling uncertainties are accounted for a bigger contribution to the bias than internal variability since the multimodel ensemble dispersion is the largest. Throughout the 21st century, both ensembles project significant trends in winter at higher latitudes resulting in increasing wet day frequency, increasing number of wet spell, longer wet spells and shorter dry spells. For other seasons, internal variability of the CRCM5‐LE and differences among the various NA‐CORDEX simulations seems to overwhelm the climate change signal. Wet spell intensities increases are projected for all seasons over almost the entire domain. Globally, wetter climate with potential significant hydrological impacts are expected in many regions.\n",
      "  - . Twenty-first century snowfall changes over the European Alps are assessed based on high-resolution regional climate model (RCM) data made available through the EURO-CORDEX initiative. Fourteen different combinations of global and regional climate models with a target resolution of 12 km and two different emission scenarios are considered. As raw snowfall amounts are not provided by all RCMs, a newly developed method to separate snowfall from total precipitation based on near-surface temperature conditions and accounting for subgrid-scale topographic variability is employed. The evaluation of the simulated snowfall amounts against an observation-based reference indicates the ability of RCMs to capture the main characteristics of the snowfall seasonal cycle and its elevation dependency but also reveals considerable positive biases especially at high elevations. These biases can partly be removed by the application of a dedicated RCM bias adjustment that separately considers temperature and precipitation biases.Snowfall projections reveal a robust signal of decreasing snowfall amounts over most parts of the Alps for both emission scenarios. Domain and multi-model mean decreases in mean September–May snowfall by the end of the century amount to −25 and −45 % for representative concentration pathway (RCP) scenarios RCP4.5 and RCP8.5, respectively. Snowfall in low-lying areas in the Alpine forelands could be reduced by more than −80 %. These decreases are driven by the projected warming and are strongly connected to an important decrease in snowfall frequency and snowfall fraction and are also apparent for heavy snowfall events. In contrast, high-elevation regions could experience slight snowfall increases in midwinter for both emission scenarios despite the general decrease in the snowfall fraction. These increases in mean and heavy snowfall can be explained by a general increase in winter precipitation and by the fact that, with increasing temperatures, climatologically cold areas are shifted into a temperature interval which favours higher snowfall intensities. In general, percentage changes in snowfall indices are robust with respect to the RCM postprocessing strategy employed: similar results are obtained for raw, separated, and separated–bias-adjusted snowfall amounts. Absolute changes, however, can differ among these three methods.                    \n",
      "  - ABSTRACTTwenty‐first century snow depth and snow water equivalent (SWE) changes are assessed for three time periods (2020–2049, 2045–2079 and 2070–2099) at 11 stations in Switzerland with the physics‐based snow model SNOWPACK and meteorological input data perturbed by the output from ten regional climate models (RCMs) through the delta change method. Unlike in previous studies, incoming long‐wave radiation has also been modified for future climatic conditions. We thus show the range of future snow simulations assuming different RCM projections.Model validation yields satisfying results for simulating snow depth and SWE for the reference period with errors in the order of 9% and 15%, respectively. For the end of the century, the stations between 1000–1700 m a.s.l. show no pronounced elevation dependence but surprisingly react quite similarly in terms of the relative magnitude of snow cover decrease, which may reach 90%. The projected small increase in winter precipitation has almost no effect at these stations, but incoming long‐wave radiation has an important effect. At the high‐elevation station Weissfluhjoch (2540 m a.s.l.) however, the precipitation increase is partly able to compensate for the increased temperature. This would imply that the snow cover at mid‐elevation stations becomes temperature and radiation dominated and will react similarly to the spatially small differences in the projected temperature change. The low‐elevation stations already show a strong decrease in the near future, and the inclusion of modified incoming long‐wave radiation has almost no effect on the decrease of future snow depth and SWE because the temperatures are already close to the melting point in the reference period. At the end of the century, mean snow depth/SWE are reduced by 35/32%, 83/86% and 96/97% at high‐, mid‐ and low‐elevations, respectively.\n",
      "--------------------------------------------------\n",
      "Topic 375: 375_icing_idf curves_idf_atmospheric icing\n",
      "Representative Documents:\n",
      "  - . The Inn River basin is a highly relevant study region in terms of potential hydrological impacts of climate change and cross boundary water management tasks in the Alpine Space. Regional analyses in this catchment were performed within the EU co-funded project AdaptAlp. Objective of the study was to gain scientifically based knowledge about impacts of climate change on the water balance and runoff regime for the Inn River basin, this being fundamental for the derivation of adaptation measures.  An ensemble of regional climate projections is formed by combinations of global and regional climate models on the basis of both statistical and bias-corrected dynamical downscaling procedures. Several available reference climate datasets for the study region are taken into account. As impact model, the process-oriented hydrological model WaSiM-ETH is set up.  As expected, regional climate projections indicate temperature increases for the future in the study area. Projections of precipitation change are less homogenous, especially regarding winter months, though most indicate a decrease in the summer. Hydrological simulation results point towards climate induced changes in the water regime of the study region. The analysis of hydrological projections at both ends of the ensemble bandwidth is a source of adaptation relevant information regarding low-flow and high-flow conditions. According to a \"drought-prone scenario\", mean monthly low flow could decrease up to −40% in the time frame of 2071–2100. A \"high-flow-increase-scenario\" points towards an increase in mean monthly high flow in the order of +50% in the winter, whilst showing a decrease in autumn.                    \n",
      "  - Changes in the hydrologic cycle due to increase in greenhouse gases cause variations in intensity, duration, and frequency of precipitation events. Quantifying the potential effects of climate change and adapting to them is one way to reduce urban vulnerability. Since rainfall characteristics are often used to design water structures, reviewing and updating rainfall characteristics (i.e., Intensity–Duration–Frequency (IDF) curves) for future climate scenarios is necessary (Reg Environ Change 13(1 Supplement):25-33, 2013).The present study regards the evaluation of the IDF curves for three case studies: Addis Ababa (Ethiopia), Dar Es Salaam (Tanzania) and Douala (Cameroon). Starting from daily rainfall observed data, to define the IDF curves and the extreme values in a smaller time window (10′, 30′, 1 h, 3 h, 6 h, 12 h), disaggregation techniques of the collected data have been used, in order to generate a synthetic sequence of rainfall, with statistical properties similar to the recorded data. Then, the rainfall pattern of the three test cities was analyzed and IDF curves were evaluated.In order to estimate the contingent influence of climate change on the IDF curves, the described procedure was applied to the climate (rainfall) simulations over the time period 2010–2050, provided by CMCC (Centro Euro-Mediterraneo sui Cambiamenti Climatici). The evaluation of the IDF curves allowed to frame the rainfall evolution of the three case studies, considering initially only historical data, then taking into account the climate projections, in order to verify the changes in rainfall patterns. The same set of data and projections was also used for evaluating the Probable Maximum Precipitation (PMP).\n",
      "  -  Analyses of atmospheric icing events hold the key for computing the significant parameters leading to icing load calculations. In the cold regions of the high north, atmospheric icing loads on structures become important when it comes to design and safety of infrastructures. Furthermore, icing load calculations over a certain period of time provide a vital input for designers to improve the safety of structures. Patterns of icing events can be evaluated in correlation with other meteorological parameters such as atmospheric temperature, relative humidity and wind speed to better estimate icing loads. A field study has been performed in the complex terrain of northern Norway, by the atmospheric icing research team of Narvik University College, where customized meteorological atmospheric ice monitoring stations were installed to study atmospheric icing events in relation with the associated weather parameters. The meteorological parameters of three different sites in the vicinity of Narvik ( 68°25′ 14′ N17°33′ 36′ E) were collected, sorted, averaged to standardized timeline and further validated with recordings of weathers parameters obtained from the national weather forecasts, where a good agreement was found. Analyses were mainly performed between accreted ice loads and associated meteorological parameters. The results presented can be used as base for the development of more detailed mathematical models for the better prediction of atmospheric icing events in complex terrains. \n",
      "--------------------------------------------------\n",
      "Topic 376: 376_ice_sea ice_arctic_sea\n",
      "Representative Documents:\n",
      "  - Climate simulations in a global coupled model are investigated using a dynamic‐thermodynamic sea ice and snow model with sophisticated thermodynamics and a subgrid scale parameterization for multiple ice thicknesses. In addition to the sea ice component, the model includes a full primitive‐equation ocean and a simple energy‐moisture balance atmosphere. We introduce a formulation of the ice thickness distribution that is Lagrangian in thickness‐space. The method is designed to use fewer thickness categories because it adjusts to place resolution where it is needed most and it is free of diffusive effects that tend to smooth Eulerian distributions. Experiments demonstrate that the model does reasonably well in simulating the mean Arctic climate. We find the climate of the Arctic and northern North Atlantic is sensitive to resolving the ice‐thickness distribution when comparing the model results to a simulation with a two‐level sea ice model. The ice‐thickness distribution causes ice export through Fram Strait to be more variable and more strongly linked to meridional overturning in the North Atlantic Ocean.The Lagrangian formulation of the ice‐thickness distribution allows for the inclusion of a vertical temperature profile with relative ease compared to an Eulerian method. We find ice growth rates and ocean surface salinity differ in our model with a well‐resolved vertical temperature profile in the ice and snow and an explicit brine‐pocket parameterization compared to a simulation with Semtner zero‐layer thermodynamics. Although these differences are important for the climate of the Arctic, the effects of an ice thickness distribution are more dramatic and extend into the northern North Atlantic. Sensitivity experiments indicate that five ice‐thickness categories with ∼50‐cm vertical temperature resolution capture the effects of the ice‐thickness distribution on the heat and freshwater exchange across the surface in the presence of sea ice in these simulations.\n",
      "  - . The CSIRO Mk3L climate system model is a coupled general circulation model, designed primarily for millennial-scale climate simulation and palaeoclimate research. Mk3L includes components which describe the atmosphere, ocean, sea ice and land surface, and combines computational efficiency with a stable and realistic control climatology. It is freely available to the research community. This paper evaluates the response of the model to external forcings which correspond to past and future changes in the climate system.  A simulation of the mid-Holocene climate is performed, in which changes in the seasonal and meridional distribution of incoming solar radiation are imposed. Mk3L correctly simulates increased summer temperatures at northern mid-latitudes and cooling in the tropics. However, it is unable to capture some of the regional-scale features of the mid-Holocene climate, with the precipitation over Northern Africa being deficient. The model simulates a reduction of between 7 and 15% in the amplitude of El Niño-Southern Oscillation, a smaller decrease than that implied by the palaeoclimate record. However, the realism of the simulated ENSO is limited by the model's relatively coarse spatial resolution.  Transient simulations of the late Holocene climate are then performed. The evolving distribution of insolation is imposed, and an acceleration technique is applied and assessed. The model successfully captures the temperature changes in each hemisphere and the upward trend in ENSO variability. However, the lack of a dynamic vegetation scheme does not allow it to simulate an abrupt desertification of the Sahara.  To assess the response of Mk3L to other forcings, transient simulations of the last millennium are performed. Changes in solar irradiance, atmospheric greenhouse gas concentrations and volcanic emissions are applied to the model. The model is again broadly successful at simulating larger-scale changes in the climate system. Both the magnitude and the spatial pattern of the simulated 20th century warming are consistent with observations. However, the model underestimates the magnitude of the relative warmth associated with the Mediaeval Climate Anomaly.  Finally, three transient simulations are performed, in which the atmospheric CO2 concentration is stabilised at two, three and four times the pre-industrial value. All three simulations exhibit ongoing surface warming, reduced sea ice cover, and a reduction in the rate of North Atlantic Deep Water formation followed by its gradual recovery. Antarctic Bottom Water formation ceases, with the shutdown being permanent for a trebling and quadrupling of the CO2 concentration. The transient and equilibrium climate sensitivities of the model are determined. The short-term transient response to a doubling of the CO2 concentration at 1% per year is a warming of 1.59 ± 0.08 K, while the long-term equilibrium response is a warming of at least 3.85 ± 0.02 K.                    \n",
      "  -                The Arctic sea ice cover declined over the last few decades and reached a record minimum in 2007, with a slight recovery thereafter. Inspired by this the authors investigate the response of atmospheric and oceanic properties to a 1-yr period of reduced sea ice cover. Two ensembles of equilibrium and transient simulations are produced with the Community Climate System Model. A sea ice change is induced through an albedo change of 1 yr. The sea ice area and thickness recover in both ensembles after 3 and 5 yr, respectively. The sea ice anomaly leads to changes in ocean temperature and salinity to a depth of about 200 m in the Arctic Basin. Further, the salinity and temperature changes in the surface layer trigger a “Great Salinity Anomaly” in the North Atlantic that takes roughly 8 yr to travel across the North Atlantic back to high latitudes. In the atmosphere the changes induced by the sea ice anomaly do not last as long as in the ocean. The response in the transient and equilibrium simulations, while similar overall, differs in specific regional and temporal details. The surface air temperature increases over the Arctic Basin and the anomaly extends through the whole atmospheric column, changing the geopotential height fields and thus the storm tracks. The patterns of warming and thus the position of the geopotential height changes vary in the two ensembles. While the equilibrium simulation shifts the storm tracks to the south over the eastern North Atlantic and Europe, the transient simulation shifts the storm tracks south over the western North Atlantic and North America. The authors propose that the overall reduction in sea ice cover is important for producing ocean anomalies; however, for atmospheric anomalies the regional location of the sea ice anomalies is more important.               While observed trends in Arctic sea ice are large and exceed those simulated by comprehensive climate models, there is little evidence based on this particular model that the seasonal loss of sea ice (e.g., as occurred in 2007) would constitute a threshold after which the Arctic would exhibit nonlinear, irreversible, or strongly accelerated sea ice loss. Caution should be exerted when extrapolating short-term trends to future sea ice behavior.\n",
      "--------------------------------------------------\n",
      "Topic 377: 377_phytoplankton_biological_ocean_fjords\n",
      "Representative Documents:\n",
      "  -             The pelagic ocean harbors one of the largest ecosystems on Earth. It is responsible for approximately half of global primary production, sustains worldwide fisheries, and plays an important role in the global carbon cycle. Ocean warming caused by anthropogenic climate change is already starting to impact the marine biota, with possible consequences for ocean productivity and ecosystem services. Because temperature sensitivities of marine autotrophic and heterotrophic processes differ greatly, ocean warming is expected to cause major shifts in the flow of carbon and energy through the pelagic system. Attempts to integrate such biological responses into marine ecosystem and biogeochemical models suffer from a lack of empirical data. Here, we show, using an indoor-mesocosm approach, that rising temperature accelerates respiratory consumption of organic carbon relative to autotrophic production in a natural plankton community. Increasing temperature by 2–6 °C hence decreased the biological drawdown of dissolved inorganic carbon in the surface layer by up to 31%. Moreover, warming shifted the partitioning between particulate and dissolved organic carbon toward an enhanced accumulation of dissolved compounds. In line with these findings, the loss of organic carbon through sinking was significantly reduced at elevated temperatures. The observed changes in biogenic carbon flow have the potential to reduce the transfer of primary produced organic matter to higher trophic levels, weaken the ocean's biological carbon pump, and hence provide a positive feedback to rising atmospheric CO            2            .          \n",
      "  - Benthic iron (Fe) fluxes from continental shelf sediments are an important source of Fe to the global ocean, yet the magnitude of these fluxes is not well constrained. Processing of Fe in sediments is of particular importance in the Arctic Ocean, which has a large shelf area and Fe limitation of primary productivity. In the Arctic fjords of Svalbard, glacial weathering delivers high volumes of Fe‐rich sediment to the fjord benthos. Benthic redox cycling of Fe proceeds through multiple pathways of reduction (i.e., dissimilatory iron reduction and reduction by hydrogen sulfide) and re‐oxidation. There are few estimates of the magnitude and controlling factors of the benthic Fe flux in Arctic fjords. We collected cores from two Svalbard fjords (Kongsfjorden and Lilliehöökfjorden), measured dissolved Fe2+ concentrations using a two‐dimensional sensor, and analyzed iron, manganese, carbon, and sulfur species to study benthic Fe fluxes. Benthic fluxes of Fe2+ vary throughout the fjords, with a “sweet spot” mid‐fjord controlled by the availability of organic carbon linked to sedimentation rates. The flux is also impacted by fjord circulation and sea ice cover, which influence overall mineralization rates in the sediment. Due to ongoing Arctic warming, we predict an increase in the benthic Fe2+ flux with reduced sea ice cover in some fjords and a decrease in the Fe2+ flux with the retreat of tidewater glaciers in other regions. Decreasing benthic Fe2+ fluxes in fjords may exacerbate Fe limitation of primary productivity in the Arctic Ocean.\n",
      "  - There are complex physical and biological processes controlling the exchange of carbon dioxide (CO2) between the ocean and atmosphere. In coral reef ecosystems, the balance of biological processes such as calcium carbonate (CaCO3) formation and organic carbon production can either lead to CO2 being retained in the oceanic environment (i.e., oceanic sink of CO2) or returned to the atmosphere through gas exchange (oceanic source of CO2). What remains uncertain is the fate of CO2 in reefs subject to seasonal change and the annual balance of air—sea CO2 flux in such systems. Here it is shown that the Bermuda coral reef acts as a sourc of CO2 to seawater overlying the reef. The magnitude of this source of CO2 varies seasonally in response to changes in the reef community between coral‐ and macroalga‐dominated states, reflecting changes in the net balance between calcification and organic carbon production. With knowledge of the calcification rate (~5.6 to 10.6 g CaCO3 m−2 d−1) and observed modification in seawater fCO2 by reef metabolism, rates (—0.6 to 3.3 g C m−2 d−1) and seasonal patterns of macroalgal productivity were estimated. Whether the Bermuda coral reef system acts as an oceanic sink or source of CO2 to the atmosphere not only depends on this seasonal variation, but, more importantly, depends on the pre‐existing air‐sea CO2 disequilibrium of open ocean waters surrounding the reef system. The Bermuda coral reef system serves as a useful model for understanding the fate of CO2 in other reefs, particularly those reefs changing because of environmental stress.\n",
      "--------------------------------------------------\n",
      "Topic 378: 378_cvr_reactivity_cbf_blood\n",
      "Representative Documents:\n",
      "  - BackgroundAn ongoing multi‐center study of a consortium of Alzheimer’s Disease Centers in Los Angeles (USC), Dallas (UT‐SWMC) and Kansas City (KUMC) has explored quantitatively the dynamics of the homeostatic mechanism that maintains adequate cortical tissue oxygenation during a rise in blood CO2 tension. The results from cognitively normal subjects and MCI/AD patients were compared to assess differences in the dynamics of this important homeostatic mechanism.MethodQuantification of the dynamics of cortical tissue oxygenation was achieved through extraction of predictive models from five‐minute data‐records of spontaneous fluctuations in cortical tissue oxygenation (CTO), measured non‐invasively via near infrared spectroscopy at the prefrontal cortex, and the associated fluctuations in arterial blood pressure (ABP) and end‐tidal CO2 (etCO2). Using a novel kernel‐based modeling methodology, we analyzed the time‐series data from 25 MCI patients, 7 AD patients and 45 age‐matched cognitively normal controls (NC) and obtained predictive models of the dynamic effects of ABP and etCO2 (viewed as a proxy for blood CO2 tension) upon CTO. These predictive models were used to quantify the dynamics of cortical CO2 reactivity (CCR) in each participant, as the time‐average of the model‐predicted CTO response to unit‐step etCO2 change over the first 30 sec. The obtained CCR indices were used to evaluate the differences between NC and MCI/AD patients.ResultThe obtained CCR indices were significantly different for the 32 patients (MCI and AD lumped together due to small number of AD) vs. 45 age‐matched controls (p= 0.0083), with respective mean (SD): 0.014 (0.108) vs ‐0.059 (0.119). This is illustrated in Figure 1, where the average model‐predicted CTO responses to a unit‐step change of etCO2 are shown for 32 MCI/AD patients (red line) and 45 controls (blue line). Note the negative values of the average CTO response for patients (red line) to unit‐step increase of etCO2 that indicates polarity reversal of the normal CO2 vasomotor reactivity (blue line).ConclusionQuantitative analysis of cortical oxygenation dynamics under resting spontaneous conditions in 32 MCI/AD patients relative to 45 age‐matched controls revealed a significant impairment of the homeostatic mechanism that maintains adequate oxygenation of cortical tissue during a rise in blood CO2 tension.\n",
      "  - BackgroundVascular cognitive decline is a prominent cause of late‐life cognitive impairment. Compared to Alzheimer’s disease(AD), there is a paucity of biomarkers for its diagnosis, stratification, and treatment monitoring. Cerebrovascular‐Reactivity(CVR) MRI measures small‐vessel dilation to vasoactive‐stimuli(e.g. CO2), and has been shown to be associated with cognitive impairment. However, previous CVR studies were based on Blood‐Oxygenation‐Level‐Dependent (BOLD) MRI signal, which reflects a complex interplay of many physiological parameters and thus presents interpretation challenges. We measured CVR using quantitative CBF‐imaging in older participants, and tested for associations with diagnosis (Healthy Control [HC] vs. mild‐cognitive‐impairment [MCI] vs. dementia) cognitive and physical function, amyloid and tau burden, and vascular risk.MethodsA cross‐sectional study enrolled 67 participants aged 69±6.5 years (22 HC, 37 MCI, 8 dementia). MoCA (Montreal‐Cognitive‐Assessment) and composite cognition (a z‐score average of 4‐domains: verbal‐memory, executive‐function, language, processing‐speed) assessed overall cognition. Gait(sec,4‐meter‐walk) and chair‐stands (sec,5‐chair‐stands) assessed physical‐function. Clinical Dementia Rating(CDR)7 indexed disease‐severity. Phase‐contrast flow MRI(3T) was performed while participants breathed room‐air for 1‐minute, followed by ‘CO2‐enriched‐air’(5%CO2, 21%O2, 74%N2) for 2‐minutes. Blood‐flux at Superior‐Sagittal‐Sinus(SSS)(Figure‐1) was quantified for both states. Breathing rate and End‐tidal(Et)‐CO2 were recorded via capnography. CBF‐based CVR was then obtained by: CBF‐CVR = [HypercapniaSSSflux(ml/min)‐RoomairSSSflux(ml/min)]/RoomairSSSflux(ml/min) HypercapniaEtCo2(mmHg)‐RoomairEtCo2(mmHg) FLAIR‐MRI‐images were assigned Fazekas‐scores by a neuroradiologist. AD‐Biomarkers Aβ40, Aβ42, tau, and p‐tau181(pg/ml), were measured in cerebrospinal fluid (CSF) and vascular‐biomarkers HbA1c (mg/dL), homocysteine (umol/l), HDL(mg/dL), and LDL (mg/dL) in blood. Vascular‐Risk‐Score (VRS) is a composite score based on the presence of hypertension, hypercholesterolemia, diabetes, smoking or obesity (body mass index&gt;30 kg/m2).ResultsTable‐1 summarizes participant‐demographics. CBF‐CVR (%/mmHg) differentiated diagnostic‐categories, and was lower in impaired vs. HC (p=0.027, Figure‐2a). Higher CBF‐CVR predicted better cognitive‐performance [MoCA(p=0.000089) (Figure‐2b), composite‐cognition (p=0.007) and language (p=0.000064)], physical function [faster gait(p=0.001), chair‐stands(p=0.021)], and disease‐severity [global‐CDR (p=0.003), CDR‐sum‐of‐boxes (p=0.001)(Table‐2). These relationships remained after adjusting for AD‐biomarkers. CBF‐CVR remained associated with cognition and physical‐function except chair‐stands, after adjusting for vascular‐markers: WMH‐Fazekas‐score, VRS, and whole‐brain‐CBF(Table‐2). CBF‐CVR was associated with HbA1c(p=0.007) and history of Diabetes (p=0.043), but not other blood biomarkers or VRS.ConclusionWe show that a 3‐minute CBF‐based CVR MRI can differentiate diagnostic‐categories, and predict cognitive and physical function, independent of AD pathology.\n",
      "  - Background: By age 30, over 50% of sickle cell disease (SCD) patients have suffered a cerebral infarct. In response to anemia and the reduction in oxygen-carrying capacity, cerebral blood flow (CBF) increases to match metabolic demand. Increased velocity of CBF in major cerebral arteries is a strong risk factor for stroke in SCD children and adolescents. Despite generally increased CBF, silent cerebral infarcts (SCI) can still occur in patients receiving optimal transfusions. This suggests that the increased CBF does not meet metabolic demand and that vasodilatory response is compromised.               Hypothesis: In adult patients with SCD, cerebrovascular reactivity (slope of the vasodilatory response to CO2 (CVR) and the steady-state CVR (amplitude) and speed of the vasodilatory response (tau) to a standardized vasodilatory stimulus CO2), are reduced compared to normal subjects. We also explored for possible associations with clinical characteristics.               Methods: Functional brain imaging performed as part of routine care in adult (≥18) SCD patients (any phenotype) at the University Health Network Comprehensive Sickle Cell Center (Toronto, Canada) between 2017 and 2018 were reviewed. Patients with known cerebral vasculopathy were excluded. CVR was calculated as the change in CBF measured as the blood oxygenation level dependent (BOLD)-MRI signal, in response to a standard vasoactive stimulus of CO2 (delivered by RespirActTM). To calculate the dynamic (tau) and steady-state CVR (amplitude) components of the BOLD signal response, the PET CO2 waveform was convolved with an exponential decay function. The tau corresponding to the best fit between the convolved CO2 and BOLD signal was defined as the speed of vascular response. The slope of the regression between the convolved CO2 and BOLD signal was defined as amplitude.               CVR, amplitude and tau were normalized voxel-wise relative to the mean and standard deviation of the same metric in the corresponding voxels of a previously generated atlas of 42 healthy controls (Z scores). These Z scores were averaged over the vascular territories of the brain for both grey (GM) and white matter (WM). Fisher exact and Pearson correlations were performed to identify possible associations between CVR metrics and SCD comorbid conditions, laboratory parameters, and use of disease-modifying therapy. Associations with univariate P &amp;lt;0.20 were included in the multiple linear regression model. Multi-collinearity was assessed.               Results: Fifteen patients were included in the study. The median age was 27 [IQR22-35]. 5/15 (33.3%) were male. 9/15 (60%) were SS or S/b0 and 5/15 (33.3%) were SC. 4/15 (26.7%) were on transfusion. MRI/MRA uncovered Moya moya in 1 patient. SCI were present in 3/15 (21.4%). Compared to the reference atlas of normal subjects, CVR and amplitude were reduced both in GM and WM (mean Z-score for CVR -0.52 [-1.8 - 0.28] and -0.63 [-2.31 - 0.66]; amplitude -0.26 [-2.61 - 0.66] and -0.28 [-2.70 - 0.60] respectively). Tau was lengthened in GM and WM (mean tau Z-score +0.90 [-0.49 - 3.32] and +0.76 [-0.66 - 2.78] respectively). These abnormal metrics were observed with varying severities in all 3 main vascular territories (Figure). CVR decreased linearly with decreasing hematocrit (Hct) (r=0.59, p=0.03). There was also a trend towards lower CVR in SS or S/b0 patients (t=-1.41, p=0.18, d=0.76) and was highly collinear with Hct. Hematocrit was the only significant independent predictor of CVR metrics on multivariable regression.               Conclusions: All three measures of cerebrovascular health (CVR, amplitude and tau) in SCD patients were abnormal compared to normal controls. Hematocrit appears to be the strongest independent predictor of these measures. The protocol we applied for measuring CVR provides a standardized reproducible vasodilatory stimulus, enabling comparison against a population of healthy individuals for more accurate assessment of CVR in individual subjects. Furthermore, the stimulus protocol produces rapid changes in arterial CO2 levels within one breath that can be used to measure the speed of response of the vasculature representing a novel metric of vascular performance postulated to represent vessel compliance and functional endothelial integrity. These findings show that CVR methodology represents a promising tool to assess disease state, stroke risk, and therapeutic efficacy in sickle cell patients and merits further investigation.               Figure 1                                 Disclosures                  Forté: Canadian Hematology Society: Research Funding; Pfizer - Global Medical Grants: Research Funding. Sobczyk:Thornhill Research Inc.: Current Employment. Duffin:Thornhill Research Inc.: Current Employment. Fisher:Thornhill Research Inc.: Current equity holder in private company. Mikulis:Thornhill Research Inc.: Current equity holder in private company. Kuo:Bioverativ: Membership on an entity's Board of Directors or advisory committees; Novartis: Consultancy, Honoraria; Bluebird Bio: Consultancy; Agios: Consultancy, Membership on an entity's Board of Directors or advisory committees; Alexion: Consultancy, Honoraria; Pfizer: Consultancy, Research Funding; Apellis: Consultancy; Celgene: Consultancy.               \n",
      "--------------------------------------------------\n",
      "Topic 379: 379_particle_particles_aerosol_soa\n",
      "Representative Documents:\n",
      "  - . Field studies in polluted areas over the last decade have observed large formation of secondary organic aerosol (SOA) that is often poorly captured by models. The study of SOA formation using ambient data is often confounded by the effects of advection, vertical mixing, emissions, and variable degrees of photochemical aging. An oxidation flow reactor (OFR) was deployed to study SOA formation in real-time during the California Research at the Nexus of Air Quality and Climate Change (CalNex) campaign in Pasadena, CA, in 2010. A high-resolution aerosol mass spectrometer (AMS) and a scanning mobility particle sizer (SMPS) alternated sampling ambient and reactor-aged air. The reactor produced OH concentrations up to 4 orders of magnitude higher than in ambient air. OH radical concentration was continuously stepped, achieving equivalent atmospheric aging of 0.8 days–6.4 weeks in 3 min of processing every 2 h. Enhancement of organic aerosol (OA) from aging showed a maximum net SOA production between 0.8–6 days of aging with net OA mass loss beyond 2 weeks. Reactor SOA mass peaked at night, in the absence of ambient photochemistry and correlated with trimethylbenzene concentrations. Reactor SOA formation was inversely correlated with ambient SOA and Ox, which along with the short-lived volatile organic compound correlation, indicates the importance of very reactive (τOH  ∼  0.3 day) SOA precursors (most likely semivolatile and intermediate volatility species, S/IVOCs) in the Greater Los Angeles Area. Evolution of the elemental composition in the reactor was similar to trends observed in the atmosphere (O : C vs. H : C slope  ∼  −0.65). Oxidation state of carbon (OSc) in reactor SOA increased steeply with age and remained elevated (OSC  ∼  2) at the highest photochemical ages probed. The ratio of OA in the reactor output to excess CO (ΔCO, ambient CO above regional background) vs. photochemical age is similar to previous studies at low to moderate ages and also extends to higher ages where OA loss dominates. The mass added at low-to-intermediate ages is due primarily to condensation of oxidized species, not heterogeneous oxidation. The OA decrease at high photochemical ages is dominated by heterogeneous oxidation followed by fragmentation/evaporation. A comparison of urban SOA formation in this study with a similar study of vehicle SOA in a tunnel suggests the importance of vehicle emissions for urban SOA. Pre-2007 SOA models underpredict SOA formation by an order of magnitude, while a more recent model performs better but overpredicts at higher ages. These results demonstrate the value of the reactor as a tool for in situ evaluation of the SOA formation potential and OA evolution from ambient air.\n",
      "  - . Aerosol particle nucleation, or new-particle formation, is the dominant contributor to particle number in the atmosphere. However, these particles must grow through condensation of low-volatility vapors without coagulating with the larger, preexisting particles in order to reach climate-relevant sizes (diameters larger than 50–100 nm), where the particles may affect clouds and radiation. In this paper, we use 1 year of size-distribution measurements from Egbert, Ontario, Canada to calculate the frequency of regional-scale new-particle-formation events, new-particle-formation rates, growth rates and the fraction of new particles that survive to reach climate-relevant sizes. Regional-scale new-particle-formation events occur on 14–31% of the days (depending on the stringency of the classification criteria), with event frequency peaking in the spring and fall. New-particle-formation rates and growth rates are similar to those measured at other midlatitude continental sites. We calculate that roughly half of the climate-relevant particles (with diameters larger than 50–100 nm) at Egbert are formed through new-particle-formation events. With the addition of meteorological and SO2 measurements, we find that new-particle formation at Egbert often occurs under synoptic conditions associated with high surface pressure and large-scale subsidence that cause sunny conditions and clean-air flow from the north and west. However, new-particle formation also occurs when air flows from the polluted regions to the south and southwest of Egbert. The new-particle-formation rates tend to be faster during events under the polluted south/southwest flow conditions.\n",
      "  - . Aerosol particles impact the Arctic climate system both directly and indirectly by modifying cloud properties, yet our understanding of their vertical distribution, chemical composition, mixing state, and sources in the summertime Arctic is incomplete. In situ vertical observations of particle properties in the high Arctic combined with modelling analysis on source attribution are in short supply, particularly during summer. We thus use airborne measurements of aerosol particle composition to demonstrate the strong contrast between particle sources and composition within and above the summertime Arctic boundary layer. In situ measurements from two complementary aerosol mass spectrometers, the Aircraft-based Laser Ablation Aerosol Mass Spectrometer (ALABAMA) and an Aerodyne high-resolution time-of-flight aerosol mass spectrometer (HR-ToF-AMS), are presented alongside black carbon measurements from an single particle soot photometer (SP2). Particle composition analysis was complemented by trace gas measurements, satellite data, and air mass history modelling to attribute particle properties to particle origin and air mass source regions. Particle composition above the summertime Arctic boundary layer was dominated by chemically aged particles, containing elemental carbon, nitrate, ammonium, sulfate, and organic matter. From our analysis, we conclude that the presence of these particles was driven by transport of aerosol and precursor gases from mid-latitudes to Arctic regions. Specifically, elevated concentrations of nitrate, ammonium, and organic matter coincided with time spent over vegetation fires in northern Canada. In parallel, those particles were largely present in high CO environments (&gt; 90 ppbv). Additionally, we observed that the organic-to-sulfate ratio was enhanced with increasing influence from these fires. Besides vegetation fires, particle sources in mid-latitudes further include anthropogenic emissions in Europe, North America, and East Asia. The presence of particles in the Arctic lower free troposphere, particularly sulfate, correlated with time spent over populated and industrial areas in these regions. Further, the size distribution of free tropospheric particles containing elemental carbon and nitrate was shifted to larger diameters compared to particles present within the boundary layer. Moreover, our analysis suggests that organic matter, when present in the Arctic free troposphere, can partly be identified as low molecular weight dicarboxylic acids (oxalic, malonic, and succinic acid). Particles containing dicarboxylic acids were largely present when the residence time of air masses outside Arctic regions was high. In contrast, particle composition within the marine boundary layer was largely driven by Arctic regional processes. Air mass history modelling demonstrated that alongside primary sea spray particles, marine biogenic sources contributed to secondary aerosol formation via trimethylamine, methanesulfonic acid, sulfate, and other organic species. Our findings improve our knowledge of mid-latitude and Arctic regional sources that influence the vertical distribution of particle chemical composition and mixing state in the Arctic summer.                    \n",
      "--------------------------------------------------\n",
      "Topic 380: 380_polyol_kinetic_foaming_thermal degradation\n",
      "Representative Documents:\n",
      "  - One of the alternatives to reduce CO2 emissions from industrial sources (mainly the oil and gas industry) is CO2 capture. Absorption with chemical solvents (alkanolamines in aqueous solutions) is the most widely used conventional technology for CO2 capture. Despite the competitive advantages of chemical solvents, the technological challenge in improving the absorption process is to apply alternative solvents, reducing energy demand and increasing the CO2 captured per unit of solvent mass. This work presents an experimental study related to the kinetic and thermodynamic analysis of high-pressure CO2 capture using ethylenediamine (EDA) as a chemical solvent. EDA has two amine groups that can increase the CO2 capture capacity per unit of solvent. A non-stirred experimental setup was installed and commissioned for CO2 capture testing. Tests of the solubility of CO2 in water were carried out to validate the experimental setup. CO2 capture testing was accomplished using EDA in aqueous solutions (0, 5, 10, and 20 wt.% in amine). Finally, a kinetic model involving two steps was proposed, including a rapid absorption step and a slow diffusion step. EDA accelerated the CO2 capture performance. Sudden temperature increases were observed during the initial minutes. The CO2 capture was triggered after the absorption of a minimal amount of CO2 (~10 mmol) into the liquid solutions, and could correspond to the “lean amine acid gas loading” in a typical sweetening process using alkanolamines. At equilibrium, there was a linear relationship between the CO2 loading and the EDA concentration. The CO2 capture behavior obtained adapts accurately (AAD &lt; 1%) to the kinetic mechanism.\n",
      "  - Potassium carbonate (K2CO3) is a promising material for the long-term storage of renewable energy. A reactor vessel filled with K2CO3 can potentially be used as a domestic heat battery. The hydration and dehydration reactions of salt hydrates in a reactor vessel are generally described using a one-process model, such as the ‘Arrhenius-f(α)’ model. However, this modeling approach cannot always be applied correctly. If the reaction does not proceed in a pseudo-steady state, and/or when nucleation and growth processes are simultaneously active during the transformation from an anhydrous to a hydrated state, the one-process modeling approach should not be applied. In this paper, it is investigated using simultaneous thermal analysis (STA) experiments whether the pseudo-steady state approximation is valid during the hydration reaction of K2CO3. Additionally, ‘jump experiments’ using STA are employed to investigate the rate-determining step (RDS) of the hydration reaction by applying step-wise changes in partial water vapor pressure. The presence of nucleation and growth processes during the hydration reaction is investigated by fitting isotropic models to STA data. The STA results showed that indeed the hydration of K2CO3 happens in a pseudo-steady state, and the reaction can be described using a RDS. An isotropic nucleation and growth model shows that the hydration reaction can be described by assuming instantaneous nucleation followed by diffusion-limited growth. This leads to the general conclusion that the one-process modeling approach, such as the Arrhenius-f(α) model, is valid to describe the hydration reaction of K2CO3 particles.\n",
      "  -  In commercial slabstock foaming, liquid CO2 technology is increasingly applied to replace previously used liquid auxiliary blowing agents like CFCs and methylene chloride. Knowledge of physical properties of mixtures which are used in liquidCO2 foaming may contribute to the further development of the liquid CO2 technology.  Equations have been determined which do predict, for specific operational conditions and formulations, the pressures which are required in commercial foam operation to keep theCO2 dissolved both in the polyol/CO2 and in the foaming mixture/CO2 solutions. The evident dependence on temperature ofCO2 solubility, established for both polyol and foaming mixtures, strongly supports tight temperature control of the feedstocks in slabstock liquid CO2 foaming.  The solubility of CO2 in polyol was found to increase with the EO content of the polyol where the effect of molecular weight was found to be negligible.  It was established that small amounts of water and surfactant lower the CO2 solubility, and it is predicted that the commonly used levels of TDI do the same. Based on this information, it is advisable to conduct the mixing of TDI and auxiliary components at pressures a fraction higher than the saturation pressure of the liquid CO2 polyol mixture.  A significant decrease of both viscosity and surface tension is quantified for polyol and model foaming systems at increasing liquidCO2 concentration. These decreases may explain why very small cell sizes can be obtained with liquid CO2 foaming, as the nucleation process takes place at high liquid CO2 concentration. The rise in viscosity upon evaporation ofCO2 into the froth may explain the relative stability of the unreacted froth.  A cooling capacity of about 1°C per part of CO2 per hundred parts of polyol is determined from two independent experiments. However, for safety reasons, it is advisable to keep the current assumption of 0°C per part of CO2 per hundred parts of polyol in commercial foaming until a further study on the temperature evolution of liquidCO2 blown foaming under practical conditions is conducted. \n",
      "--------------------------------------------------\n",
      "Topic 381: 381_lubrication_liquid_inducers_co2 removal\n",
      "Representative Documents:\n",
      "  - Computational fluid dynamics (CFD) are an essential tool for the development of diesel engine aftertreatment systems using selective catalytic reduction (SCR) to reduce nitrous oxides (NOx). In urea-based SCR, liquid urea–water solution (UWS) is injected into the hot exhaust gas, where it transforms into gaseous ammonia. This ammonia serves as a reducing agent for NOx. CFD simulations are used to predict the ammonia distribution in the exhaust gas at the catalyst inlet. The goal is to achieve the highest possible uniformity to realize homogeneous NOx reduction across the catalyst cross section. The current work focuses on the interaction of UWS droplets with the hot walls of the exhaust system. This is a crucial part of the preparation of gaseous ammonia from the injected liquid UWS. Following experimental investigations, a new impingement model is described based on the superposition of four basic impingement behaviors, each featuring individual secondary droplet characteristics. The droplet–wall heat transfer, depending on surface temperature and impingement behavior, is also calculated using a newly parameterized model. Applying the presented approach, the cooling of a steel plate from intermittent spray impingement is simulated and compared to measurements. The second validation case is the distribution of ammonia at the catalyst inlet of an automotive SCR system. Both applications show good agreement and demonstrate the quality of the new model.\n",
      "  - The storage of propellants in space as well as the transfer and filling of spacecraft tanks is a prerequisite for future long-term space exploration missions. In this work, the vented filling of a partially filled tank, which is envisioned as a spacecraft tank, was investigated experimentally under compensated gravity in the Bremen Drop Tower. Experiments were performed with a partially filled tank and a test liquid HFE-7500. The drop tower provides 9 s of compensated gravity. The shape of the free liquid surface inside a right circular cylinder changes from the normal gravity configuration to a free fall configuration during the test. The filling was initiated after 3.5 s and continued until the end at 9 s. The interaction of the incoming liquid jet with the liquid interface was studied for different volumetric flow rates. A stable, but not steady liquid interface was characterized by a deformation due to the incoming liquid jet and the formation of a geyser. The growth of the geyser and the following disintegration into liquid droplets indicated an unstable liquid interface. Subcritical, critical and supercritical regimes of the volumetric flow rates were identified to classify stable and unstable liquid interfaces. The critical Weber number was found to be 1.04, which corresponds to a critical volumetric flow rate of 1.30 mL s-1. This critical Weber number was compared with the existing literature. Additionally, the behaviour of the liquid interface during the reorientation of the liquid inside the tank was observed.\n",
      "  - In tilting-pad journal bearings (TPJB), power loss corresponds to the internal friction in the shearing of the oil. Besides the lubrication gap, intermediate spaces between the pads account for a notable amount of frictional losses. Against the background of increasing demands for efficiency and sustainable use of resources, the reduction of power loss takes a key position in the further development of bearings. In our research, we compare two bearing lubrication concepts of a five-pad TPJB. Our objective is to work out the influence of different lubrication methods and bearing housing designs on the bearing operation characteristics. We conduct experimental testing of a 500 mm TPJB in two different bearing configurations with respect to the lubrication concept: an oil-flooded and non-flooded bearing design. In the flooded bearing design, oil is supplied via spray-bars and axial seals ensure the inter-pad spaces to be completely filled with oil. The non-flooded design comes without axial seals but oil drain channels to avoid oil accumulation in the bearing. In the latter design, oil is fed in via leading edge grooves (LEG). For the non-flooded bearing design, the experimental data show that the unloaded pads are not completely filled with oil and therefore, no pressure build-up occurs. The absence of additional load on the lower pads compared to the flooded design results in an increase of minimum film thickness. With the non-flooded design, power loss at high speeds is reduced to almost half. As a result, the efficiency of the entire turbomachinery application can be considerably improved.\n",
      "--------------------------------------------------\n",
      "Topic 382: 382_traits_flowering_drought_populations\n",
      "Representative Documents:\n",
      "  - A general prediction of ecological theory is that climate change will favor invasive nonindigenous plant species (NIPS) over native species. However, the relative fitness advantage enjoyed by NIPS is often affected by resource limitation and potentially by extreme climatic events such as drought. Genetic constraints may also limit the ability of NIPS to adapt to changing climatic conditions. In this study, we investigated evidence for potential NIPS advantage under climate change in two sympatric perennial stipoid grasses from southeast Australia, the NIPS Nassella neesiana and the native Austrostipa bigeniculata. We compared the growth and reproduction of both species under current and year 2050 drought, temperature and CO2 regimes in a multifactor outdoor climate simulation experiment, hypothesizing that NIPS advantage would be higher under more favorable growing conditions. We also compared the quantitative variation and heritability of growth traits in populations of both species collected along a 200 km climatic transect. In contrast to our hypothesis we found that the NIPS N. neesiana was less responsive than  A. bigeniculata to winter warming but maintained higher reproductive output during spring drought. However, overall tussock expansion was far more rapid in N. neesiana, and so it maintained an overall fitness advantage over A. bigeniculata in all climate regimes.  N. neesiana also exhibited similar or lower quantitative variation and growth trait heritability than A. bigeniculata within populations but greater variability among populations, probably reflecting a complex past introduction history. We found some evidence that additional spring warmth increases the impact of drought on reproduction but not that elevated atmospheric CO2 ameliorates drought severity. Overall, we conclude that NIPS advantage under climate change may be limited by a lack of responsiveness to key climatic drivers, reduced genetic variability in range-edge populations, and complex drought-CO2 interactions.\n",
      "  - Premise of the studyAs global climate change alters drought regimes, rapid evolution of traits that facilitate adaptation to drought can rescue populations in decline. The evolution of phenological advancement can allow plant populations to escape drought, but evolutionary responses in phenology can vary across a species' range due to differences in drought intensity and standing genetic variation.MethodsMimulus cardinalis, a perennial herb spanning a broad climatic gradient, recently experienced a period of record drought. Here, we used a resurrection study comparing flowering time and stem height at first flower of pre‐drought ancestors and post‐drought descendants from northern‐edge, central, and southern‐edge populations in a common environment to examine the evolution of drought escape across the latitudinal range.Key resultsContrary to the hypothesis of the evolution of advanced phenology in response to recent drought, flowering time did not advance between ancestors and descendants in any population, though storage condition and maternal effects could have impacted these results. Stem height was positively correlated with flowering time, such that plants that flowered earlier were shorter at first flower. This correlation could constrain the evolution of earlier flowering time if selection favors flowering early at a large size.ConclusionsThese findings suggest that rapid evolution of phenology will not rescue these populations from recent climate change. Future work is needed to examine the potential for the evolution of alternative drought strategies and phenotypic plasticity to buffer M. cardinalis populations from changing climate.\n",
      "  - Climate change is likely to spur rapid evolution, potentially altering integrated suites of life‐history traits. We examined evolutionary change in multiple life‐history traits of the annual plantBrassica rapacollected before and after a recent 5‐year drought in southern California. We used a direct approach to examining evolutionary change by comparing ancestors and descendants. Collections were made from two populations varying in average soil moisture levels, and lines propagated from the collected seeds were grown in a greenhouse and experimentally subjected to conditions simulating either drought (short growing season) or high precipitation (long growing season) years. Comparing ancestors and descendants, we found that the drought caused many changes in life‐history traits, including a shift to earlier flowering, longer duration of flowering, reduced peak flowering and greater skew of the flowering schedule. Descendants had thinner stems and fewer leaf nodes at the time of flowering than ancestors, indicating that the drought selected for plants that flowered at a smaller size and earlier ontogenetic stage rather than selecting for plants to develop more rapidly. Thus, there was not evidence for absolute developmental constraints to flowering time evolution. Common principal component analyses showed substantial differences in the matrix of trait covariances both between short and long growing season treatments and between populations. Although the covariances matrices were generally similar between ancestors and descendants, there was evidence for complex evolutionary changes in the relationships among the traits, and these changes depended on the population and treatment. These results show that a full appreciation of the impacts of global change on phenotypic evolution will entail an understanding of how changes in climatic conditions affect trait values and the structure of relationships among traits.\n",
      "--------------------------------------------------\n",
      "Topic 383: 383_gruan_data_gosic_nasaaccess\n",
      "Representative Documents:\n",
      "  -                The three main objectives of the Global Climate Observing System (GCOS) Reference Upper-Air Network (GRUAN) are to provide long-term high-quality climate records of vertical profiles of selected essential climate variables (ECVs), to constrain and calibrate data from more spatially comprehensive global networks, and to provide measurements for process studies that permit an in-depth understanding of the properties of the atmospheric column. In the five years since the first GRUAN implementation and coordination meeting and the printing of an article (Seidel et al.) in this publication, GRUAN has matured to become a functioning network that provides reference-quality observations to a community of users.               This article describes the achievements within GRUAN over the past five years toward making reference-quality observations of upper-air ECVs. Milestones in the evolution of GRUAN are emphasized, including development of rigorous criteria for site certification and assessment, the formal certification of the first GRUAN sites, salient aspects of the GRUAN manual and guide to operations, public availability of GRUAN’s first data product, outcomes of a network expansion workshop, and key results of scientific studies designed to provide a sound scientific foundation for GRUAN operations.               Two defining attributes of GRUAN are 1) that every measurement is accompanied by a traceable estimate of the measurement uncertainty and 2) that data quality and continuity are maximized because network changes are minimized and managed. This article summarizes how these imperatives are being achieved for existing and planned data products and provides an outlook for the future, including expected new data streams, network expansion, and critical needs for the ongoing success of GRUAN.\n",
      "  - . Ecosystem-scale manipulation experiments represent large science investments that require well-designed data acquisition and management systems to provide reliable, accurate information to project participants and third party users. The SPRUCE project (Spruce and Peatland Responses Under Climatic and Environmental Change, http://mnspruce.ornl.gov) is such an experiment funded by the Department of Energy's (DOE), Office of Science, Terrestrial Ecosystem Science (TES) Program. The SPRUCE experimental mission is to assess ecosystem-level biological responses of vulnerable, high carbon terrestrial ecosystems to a range of climate warming manipulations and an elevated CO2 atmosphere. SPRUCE provides a platform for testing mechanisms controlling the vulnerability of organisms, biogeochemical processes, and ecosystems to climatic change (e.g., thresholds for organism decline or mortality, limitations to regeneration, biogeochemical limitations to productivity, and the cycling and release of CO2 and CH4 to the atmosphere). The SPRUCE experiment will generate a wide range of continuous and discrete measurements.  To successfully manage SPRUCE data collection, achieve SPRUCE science objectives, and support broader climate change research, the research staff has designed a flexible data system using proven network technologies and software components. The primary SPRUCE data system components are the following:  1. data acquisition and control system – set of hardware and software to retrieve biological and engineering data from sensors, collect sensor status information, and distribute feedback to control components;  2. data collection system – set of hardware and software to deliver data to a central depository for storage and further processing;  3. data management plan – set of plans, policies, and practices to control consistency, protect data integrity, and deliver data.  This publication presents our approach to meeting the challenges of designing and constructing an efficient data system for managing high volume sources of in situ observations in a remote, harsh environmental location. The approach covers data flow starting from the sensors and ending at the archival/distribution points, discusses types of hardware and software used, examines design considerations that were used to choose them, and describes the data management practices chosen to control and enhance the value of the data.                    \n",
      "  - . The National Aeronautics and Space Administration (NASA) has launched a new initiative, the Open-Source Science Initiative (OSSI), to enable and support science towards openness. The OSSI supports open-source software development and dissemination. In this work, we present NASAaccess, which is an open-source software package and web-based environmental modeling application for earth observation data accessing, reformatting, andpresenting quantitative data products. The main objective of developing theNASAaccess platform is to facilitate exploration, modeling, and understanding of earth data for scientists, stakeholders, and concerned citizens whose objectives align with the new OSSI goals. The NASAaccess platform is available as software packages (i.e., the R and conda packages) as well as an interactive-format web-based environmental modeling application for earth observation data developed with Tethys Platform. NASAaccess has been envisioned as lowering the technical barriers and simplifying the process of accessing scalable distributed computing resources and leveraging additional software for data and computationally intensive modeling frameworks. Specifically, NASAaccess has been developed to meet the need for seamless earth observation remote-sensing and climate data ingestion into various hydrological modeling frameworks. Moreover, NASAaccess is also contributing to keeping interested parties and stakeholders engaged with environmental modeling, accessing the information available in various remote-sensing products. NASAaccess' current capabilities cover various NASA datasets and products that include the Global Precipitation Measurement (GPM) data products, the Global Land Data Assimilation System (GLDAS) land surface states and fluxes, and the NASA Earth Exchange Global Daily Downscaled Projections (NEX-GDDP) Coupled Model Intercomparison Project Phase 5 (CMIP5) and Coupled Model Intercomparison Project Phase 6 (CMIP6) climate change dataset products.                    \n",
      "--------------------------------------------------\n",
      "Topic 384: 384_contact_nacl_clathrate_nacl dihydrate\n",
      "Representative Documents:\n",
      "  - ABSTRACTThe interaction of volatile species with carbonaceous interstellar dust analogues is of relevance in the chemistry and physics of dense clouds in the interstellar medium. Two deposits of hydrogenated amorphous carbon (HAC), with different morphologies and aromatic versus aliphatic ratio in their structure, have been grown to model interstellar dust. The interaction of N2, CO, CH4, and CO2 with these two surfaces has been investigated using thermal programmed desorption (TPD). Desorption energy distributions were obtained by analysing TPD spectra for one monolayer coverage with the Polanyi–Wigner equation. The desorption energies found in this work for N2, CO, and CH4 are larger by 10–20 per cent than those reported in the literature for siliceous or amorphous solid water surfaces. Moreover, the experiments suggest that the interaction of the volatiles with the aromatic substructure of HAC is stronger than that with the aliphatic part. Desorption of CO2 from the HAC surfaces follows zero-order kinetics, reflecting the predominance of CO2–CO2 interactions. A model simulation of the heating of cold cloud cores shows that the volatiles considered in this work would desorb sequentially from carbonaceous dust surfaces with desorption times ranging from hundreds to tens of thousands of years, depending on the molecule and on the mass of the core.\n",
      "  - Recent laboratory studies indicate that the hydrated form of crystalline NaCl is potentially important for atmospheric processes involving depositional ice nucleation on NaCl dihydrate particles under cirrus cloud conditions. However, recent experimental studies reported a strong discrepancy between the temperature intervals where the efflorescence of NaCl dihydrate has been observed. Here we report the measurements of the volume specific nucleation rate of crystalline NaCl in the aqueous solution droplets of pure NaCl suspended in an electrodynamic balance at constant temperature and humidity in the range from 250 K to 241 K. Based on these measurements, we derive the interfacial energy of crystalline NaCl dihydrate in a supersaturated NaCl solution and determined its temperature dependence. Taking into account both temperature and concentration dependence of nucleation rate coefficients, we explain the difference in the observed fractions of NaCl dihydrate reported in the previous studies. Applying the heterogeneous classical nucleation theory model, we have been able to reproduce the 5 K shift of the NaCl dihydrate efflorescence curve observed for the sea salt aerosol particles, assuming the presence of super-micron solid inclusions (hypothetically gypsum or hemihydrate of CaSO4). These results support the notion that the phase transitions in microscopic droplets of supersaturated solution should be interpreted by accounting for the stochastic nature of homogeneous and heterogeneous nucleation and cannot be understood on the ground of bulk phase diagrams alone.\n",
      "  - We propose a method to calculate the equilibrium contact angle of heterogeneous 3-phase solid/fluid/fluid systems using molecular dynamics simulations. The proposed method, which combines the phantom-wall method [F. Leroy and F. Müller-Plathe, J. Chem. Phys. 133, 044110 (2010)] and Bennett’s acceptance ratio approach [C. H. Bennett, J. Comput. Phys. 22, 245 (1976)], is able to calculate the solid/fluid surface tension relative to the solid surface energy. The calculated relative surface tensions can then be used in Young’s equation to estimate the equilibrium contact angle. A fluid droplet is not needed for the proposed method, in contrast to the situation for direct simulations of contact angles. In addition, while prior free-energy based methods for contact angles mainly focused on the wetting of fluids in coexistence with their vapor on solid surfaces, the proposed approach was designed to study the contact angles of fluid mixtures on solid surfaces above the fluid saturation pressures. Using the proposed approach, the contact angles of binary Lennard-Jones fluid mixtures on a non-polar solid substrate were calculated at various interaction parameters and the contact angle of water in equilibrium with CO2 on a hydrophilic polar silica surface was obtained. For both non-polar and polar systems, the calculated contact angles from the proposed method were in agreement with those obtained from the geometry of a cylindrical droplet. The computational cost of the proposed method was found to be comparable to that of simulations that use fluid droplets, but the new method provides a way to calculate the contact angle directly from Young’s equation without ambiguity.\n",
      "--------------------------------------------------\n",
      "Topic 385: 385_eto_hargreaves_penman monteith_monteith\n",
      "Representative Documents:\n",
      "  - The Penman–Monteith equation (FAO-56) is accepted as the standard model for estimating reference evapotranspiration (ETo). However, the major obstacle to using FAO-56 widely is that it requires numerous climatic data. The Hargreaves–Samani (HS) method is frequently used for the calculation of ETo since it is based on measurements of daily minimum and maximum air temperature alone. Those are commonly recorded at many meteorological stations throughout the world. It is the objective of this paper to evaluate the quality of HS and calibrate the coefficients of this method for different climates as represented by the Köppen classification. Estimated values are compared with Penman–Monteith ETo values in terms of the coefficient of efficiency Ceff as well as the root mean square error, the mean absolute error and the Bayes information criterion. The Penman–Monteith equation for ETo (FAO-56) is based on physics and known to provide best estimates of ETo. The results of our work show that the correlation between long-term monthly means of HS and FAO-56 can be improved significantly by introducing climate-class specific coefficients.\n",
      "  - The Food and Agricultural Organization of the United Nations (FAO) Penman–Monteith (PM) method is widely regarded as the most effective reference evapotranspiration (ETo) estimator; however, it requires a wide range of data that may be scarce in some rural regions. When feasible relative humidity, solar radiation and wind speed data are unavailable, a temperature-based method may be useful to estimate ETo and provide suitable data to support irrigation management. This study has evaluated the accuracy of two ETo estimations methods: (1) a locally and monthly adjusted Hargreaves–Samani (HS) equation; (2) a simple procedure that only uses maximum temperature and a temperature adjustment coefficient (MaxTET). Results show that, if a monthly adjusted radiation adjustment coefficient (kRs) is calibrated for each site, acceptable ETo estimations (RMSE and R2 equal to 0.79 for the entire region) can be achieved. Results also show that a procedure to estimate ETo based only on maximum temperature performs acceptably, when compared with ETo estimation using PM equation (RMSE = 0.83 mm day−1 and R2 = 0.77 for Alentejo). When comparing these results with the ones attained when adopting a monthly adjusted HS method, the MaxTET procedure proves to be an accurate ETo estimator. Results also show that both methods can be used to estimate ETo when weather data are scarce.\n",
      "  - This study aims at assessing the accuracy of estimating daily reference evapotranspiration (ETo) computed with NASA POWER reanalysis products. Daily ETo estimated from local observations of weather variables in 14 weather stations distributed across Alentejo Region, Southern Portugal were compared with ETo derived from NASA POWER weather data, using raw and bias-corrected datasets. Three different methods were used to compute ETo: (a) FAO Penman-Monteith (PM); (b) Hargreaves-Samani (HS); and (c) MaxTET. Results show that, when using raw NASA POWER datasets, a good accuracy between the observed ETo and reanalysis ETo was observed in most locations (R2 &gt; 0.70). PM shows a tendency to over-estimating ETo with an RMSE as high as 1.41 mm d−1, while using a temperature-based ET estimation method, an RMSE lower than 0.92 mm d−1 is obtained. If a local bias correction is adopted, the temperature-based methods show a small over or underestimation of ETo (–0.40 mm d−1 ≤ MBE &lt; 0.40 mm d−1). As for PM, ETo is still underestimated for 13 locations (MBE &lt; 0 mm d−1) but with an RMSE never higher than 0.77 mm d−1. When NASA POWER raw data is used to estimate ETo, HS_Rs proved the most accurate method, providing the lowest RMSE for half the locations. However, if a data regional bias correction is used, PM leads to the most accurate ETo estimation for half the locations; also, when a local bias correction is performed, PM proved the be the most accurate ETo estimation method for most locations. Nonetheless, MaxTET proved to be an accurate method; its simplicity may prove to be successful not only when only maximum temperature data is available but also due to the low data required for ETo estimation.\n",
      "--------------------------------------------------\n",
      "Topic 386: 386_snow_smb_ssmb_drifting snow\n",
      "Representative Documents:\n",
      "  -                The modeling of the surface mass balance (SMB) of the Greenland Ice Sheet (GIS) requires high-resolution models in order to capture the observed large gradients in the steep marginal areas. Until now, global climate models have not been considered suitable to model ice sheet SMB owing to model biases and insufficient resolution. This study analyzes the GIS SMB simulated for the period 1850–2005 by the Community Earth System Model (CESM), which includes a new ice sheet component with multiple elevation classes for SMB calculations. The model is evaluated against observational data and output from the regional model Regional Atmospheric Climate Model version 2 (RACMO2). Because of a lack of major climate biases, a sophisticated calculation of snow processes (including surface albedo evolution) and an adequate downscaling technique, CESM is able to realistically simulate GIS surface climate and SMB. CESM SMB agrees reasonably well with in situ data from 475 locations (r = 0.80) and output from RACMO2 (r = 0.79). The simulated mean SMB for 1960–2005 is 359 ± 120 Gt yr−1 in the range of estimates from regional climate models. The simulated seasonal mass variability is comparable with mass observations from the Gravity Recovery and Climate Experiment (GRACE), with synchronous annual maximum (May) and minimum (August–September) and similar amplitudes of the seasonal cycle. CESM is able to simulate the bands of precipitation maxima along the southeast and northwest margins, but absolute precipitation rates are underestimated along the southeastern margin and overestimated in the high interior. The model correctly simulates the major ablation areas. Total refreezing represents 35% of the available liquid water (the sum of rain and melt).\n",
      "  - Temporal and spatial characteristics of the Antarctic specific surface mass balance (SSMB) are presented, including its components solid precipitation, sublimation/deposition and melt. For this purpose, we use the output of a regional atmospheric climate model (RACMO2/ANT, horizontal resolution of ~55 km) for the period 1958–2002. RACMO2/ANT uses European Centre for Medium-Range Weather Forecasts (ECMWF) 40 year re-analysis (ERA-40) fields as forcing at the lateral boundaries. RACMO2/ANT underestimates SSMB in the high interior of East and West Antarctica and overestimates SSMB on the steep coastal slopes. Otherwise, the modeled spatial pattern of SSMB is in good qualitative agreement with recent compilations of in situ observations. Large-scale patterns, like the precipitation shadow effect of the Antarctic Peninsula, are well reproduced, and mesoscale SSMB patterns, such as the strong precipitation gradients on Law Dome, are well represented in the model. The integrated SSMB over the grounded ice sheet is 153mmw.e. a–1 for the period 1958–2002, which agrees within 5% with the latest measurement compilations. Sublimation and melt remove 7% and &lt;1% respectively of the solid precipitation. We found significant seasonality of solid precipitation, with a maximum in autumn and a minimum in summer. No meaningful trend was identified for the SSMB, because the time series of solid precipitation and SSMB are affected by an inhomogeneity in 1980 within the ERA-40 fields that drive RACMO2/ANT. Sublimation, melt and liquid precipitation increase in time, which is related to a modeled increase in 2m temperature.\n",
      "  - . The interaction of mountain terrain with meteorological processes causes substantial temporal and spatial variability in snow accumulation and ablation. Processes impacted by complex terrain include large-scale orographic enhancement of snowfall, small-scale processes such as gravitational and wind-induced transport of snow, and variability in the radiative balance such as through terrain shadowing. In this study, a multi-scale modelling approach is proposed to simulate the temporal and spatial evolution of high-mountain snowpacks. The multi-scale approach combines atmospheric data from a numerical weather prediction system at the kilometre scale with process-based downscaling techniques to drive the Canadian Hydrological Model (CHM) at spatial resolutions allowing for explicit snow redistribution modelling. CHM permits a variable spatial resolution by using the efficient terrain representation by unstructured triangular meshes. The model simulates processes such as radiation shadowing and irradiance to slopes, blowing-snow transport (saltation and suspension) and sublimation, avalanching, forest canopy interception and sublimation, and snowpack melt. Short-term, kilometre-scale atmospheric forecasts from Environment and Climate Change Canada's Global Environmental Multiscale Model through its High Resolution Deterministic Prediction System (HRDPS) drive CHM and are downscaled to the unstructured mesh scale. In particular, a new wind-downscaling strategy uses pre-computed wind fields from a mass-conserving wind model at 50 m resolution to perturb the mesoscale HRDPS wind and to account for the influence of topographic features on wind direction and speed. HRDPS-CHM was applied to simulate snow conditions down to 50 m resolution during winter 2017/2018 in a domain around the Kananaskis Valley (∼1000 km2) in the Canadian Rockies. Simulations were evaluated using high-resolution airborne light detection and ranging (lidar) snow depth data and snow persistence indexes derived from remotely sensed imagery. Results included model falsifications and showed that both wind-induced and gravitational snow redistribution need to be simulated to capture the snowpack variability and the evolution of snow depth and persistence with elevation across the region. Accumulation of windblown snow on leeward slopes and associated snow cover persistence were underestimated in a CHM simulation driven by wind fields that did not capture lee-side flow recirculation and associated wind speed decreases. A terrain-based metric helped to identify these lee-side areas and improved the wind field and the associated snow redistribution. An overestimation of snow redistribution from windward to leeward slopes and subsequent avalanching was still found. The results of this study highlight the need for further improvements of snowdrift-permitting models for large-scale applications, in particular the representation of subgrid topographic effects on snow transport.\n",
      "--------------------------------------------------\n",
      "Topic 387: 387_predictability_predictable_skill_skillful predictions\n",
      "Representative Documents:\n",
      "  - After more than one hundred years of statistical forecasting and fifty years of climate model development, this paper shows that the skill of predicting Indian monsoon rainfall with coupled atmosphere‐ocean models initialized in May is statistically significant, and much higher than can be predicted empirically from May sea surface temperatures (SSTs). The superior skill of dynamical models is attributed to the fact that slowly evolving sea surface temperatures are the primary source of predictability, and to the fact that climate models produce more skillful predictions of June‐September sea surface temperatures. The recent apparent breakdown in SST‐monsoon relation can be simulated in coupled models, even though the relation is significant and relatively constant on an ensemble mean basis, suggesting that the observed breakdown could be due, in large part, to sampling variability. Despite the observed breakdown, skillful predictions of monsoon rainfall can be constructed using sea surface temperaturespredictedby dynamical models. This fact opens the possibility of using readily available seasonal predictions of sea surface temperatures to make real‐time skillful predictions of Indian summer monsoon rainfall. In addition, predictors based on tendency of SST during spring information show skill during both the recent and historical periods and hence may provide more skillful predictions of monsoon rainfall than predictors based on a single month.\n",
      "  -                The Madden–Julian oscillation (MJO) represents a primary source of predictability on the intraseasonal time scales and its influence extends from seasonal variations to weather and extreme events. While the last decade has witnessed marked improvement in dynamical MJO prediction, an updated estimate of MJO predictability from a contemporary suite of dynamic models, in conjunction with an estimate of their corresponding prediction skill, is crucial for guiding future research and development priorities. In this study, the predictability of the boreal winter MJO is revisited based on the Intraseasonal Variability Hindcast Experiment (ISVHE), a set of dedicated extended-range hindcasts from eight different coupled models. Two estimates of MJO predictability are made, based on single-member and ensemble-mean hindcasts, giving values of 20–30 days and 35–45 days, respectively. Exploring the dependence of predictability on the phase of MJO during hindcast initiation reveals a slightly higher predictability for hindcasts initiated from MJO phases 2, 3, 6, or 7 in three of the models with higher prediction skill. The estimated predictability of MJO initiated in phases 2 and 3 (i.e., convection in Indian Ocean with subsequent propagation across Maritime Continent) being equal to or higher than other MJO phases implies that the so-called Maritime Continent prediction barrier may not actually be an intrinsic predictability limitation. For most of the models, the skill for single-member (ensemble mean) hindcasts is less than the estimated predictability limit by about 5–10 days (15–25 days), implying that significantly more skillful MJO forecasts can be afforded through further improvements of dynamical models and ensemble prediction systems (EPS).\n",
      "  -  A new statistical optimization method is used to identify components of surface air temperature and precipitation on six continents that are predictable in multiple climate models on multiyear time scales. The components are identified from unforced “control runs” of the Coupled Model Intercomparison Project phase 3 dataset. The leading predictable components can be calculated in independent control runs with statistically significant skill for 3–6 yr for surface air temperature and 1–3 yr for precipitation, depending on the continent, using a linear regression model with global sea surface temperature (SST) as a predictor. Typically, lag-correlation maps reveal that the leading predictable components of surface air temperature are related to two types of SST patterns: persistent patterns near the continent itself and an oscillatory ENSO-like pattern. The only exception is Europe, which has no significant ENSO relation. The leading predictable components of precipitation are significantly correlated with an ENSO-like SST pattern. No multiyear predictability of land precipitation could be verified in Europe. The squared multiple correlations of surface air temperature and precipitation for nonzero lags on each continent are less than 0.4 in the first year, implying that less than 40% of variations of the leading predictable component can be predicted from global SST. The predictable components describe the spatial structures that can be predicted on multiyear time scales in the absence of anthropogenic and natural forcing, and thus provide a scientific rationale for regional prediction on multiyear time scales. \n",
      "--------------------------------------------------\n",
      "Topic 388: 388_wireless_radio_communication_usage\n",
      "Representative Documents:\n",
      "  - Health and usage monitoring systems (HUMS) are the basis for condition-based maintenance of helicopters. One of the most critical systems in terms of safety and maintenance expense that can be monitored by HUMS are the main gearboxes of helicopters with turbine engines. While the health monitoring part of HUMS aims to model the health state from the collected sensor data with advanced algorithms, such as machine learning, the usage monitoring part tracks the time of use and operating parameters of the system, such as load, to determine lifetime consumption. In the presented work, a combination of automatic dependent surveillance-broadcast (ADS-B) flight data with a generic helicopter performance model is used to acquire torque profiles of the gearboxes. With damage accumulation methods, the load spectra are transformed to aggregated indicators that reflect the individual gearbox usage. The methodology is applied to samples of two helicopters from a five-year ADS-B data set of German helicopter emergency medical services (HEMS) acquired for the study. The results demonstrate the feasibility of the generic approach, which can support maintenance scheduling and new usage-based maintenance services independent of direct access to installed HUMS.\n",
      "  - Visibility and communication are the essential pillars for safe flight operations in dense airspaces. Small Unmanned Aerial Vehicles (UAVs) of the order of up to 25 kg are increasingly being used at airports as a cost-effective alternative for maintenance and calibration work. However, the joint operation of manned and unmanned aircraft in busy airspaces poses a major challenge. Due to the small diameter of such UAVs, the established principle of “see and avoid” is difficult or even impossible to implement, especially during take-off and landing. For this reason, a certified Mode A/C/S transponder supporting ADS-B was extended with an embedded system and a cellular interface to realize a Multi-Mode-Transceiver (MMT). Integrated into a UAV, the MMT can provide aircraft visibility in the context of traditional manned Air Traffic Management (ATM) and future UAS Traffic Management (UTM) at the same time. This multimodal communication approach was investigated in flight test campaigns with two commercially available UAS that were connected to an experimental UTM with a simulated controlled airspace. The results confirm the safety gain of the multimodal cooperative approach. Furthermore, the collaborative interface with ATC enables the digital transmission of transponder codes, entry clearances and emergency procedures without the need for a voice radio communication. However, the parallel operation of both radio technologies in a confined space requires modifications to the transmission power and alignment of the radio antennas to avoid mutual interference. Furthermore, different reference planes of barometric altitude measurement in manned and unmanned aviation pose additional challenges that need to be addressed.\n",
      "  - Efficiency and reliable turnaround time are core features of modern aircraft transportation and key to its future sustainability. Given the connected aircraft cabin, the deployment of digitized and interconnected sensors, devices and passengers provides comprehensive state detection within the cabin. More specifically, passenger localization and occupancy detection can be monitored using location-aware communication systems, also known as wireless sensor networks. These multi-purpose communication systems serve a variety of capabilities, ranging from passenger convenience communication services, over crew member devices, to maintenance planning. In addition, radio-based sensing enables an efficient sensory basis for state monitoring; e.g., passive seat occupancy detection. Within the scope of the connected aircraft cabin, this article presents a multipath-assisted radio sensing (MARS) approach using the propagation information of transmitted signals, which are provided by the channel impulse response (CIR) of the wireless communication channel. By performing a geometrical mapping of the CIR, reflection sources are revealed, and the occupancy state can be derived. For this task, both probabilistic filtering and k-nearest neighbor classification are discussed. In order to evaluate the proposed methods, passenger occupancy detection and state detection for the future automation of passenger safety announcements and checks are addressed. Therefore, experimental measurements are performed using commercially available wideband communication devices, both in close to ideal conditions in an RF anechoic chamber and a cabin seat mockup. In both environments, a reliable radio sensing state detection was achieved. In conclusion, this paper provides a basis for the future integration of energy and spectrally efficient joint communication and sensing radio systems within the connected aircraft cabin.\n",
      "--------------------------------------------------\n",
      "Topic 389: 389_ecosystem services_ssfs_carbon_forest\n",
      "Representative Documents:\n",
      "  - Ecosystem destruction and biodiversity loss are now widespread, extremely rapid, and among the top global anthropogenic risks both in terms of likelihood and overall impact. Thorough impact evaluation of these environmental abuses—essential for conservation and future project planning—requires good analysis of local ecological and environmental data in addition to social and economic impacts. We characterized the deforestation and biodiversity impacts of energy investments in Southeast Asia using multiple geospatial data sources related to forest cover and loss data from 2000 to 2018, other landcover data, and the location, type, and characteristics of energy investments. This study paid particular attention to different types of power plants and financing sources. We identified critical buffer zones and forest structures impacted by these projects in accordance with IUCN criteria and spatial ecology. The paper introduces a novel, replicable analytical framework that goes beyond earlier studies in which all forests are treated as equivalent. It characterizes forests based on spatial morphological structures such as core forest, edges, islands, and bridges, allowing for a more nuanced understanding of deforestation and its impacts on biodiversity. Preliminary findings suggest that projects financed by Chinese development banks pose different risks compared to non-Chinese financing. The study also reveals significant differences in biodiversity impacts based on the type of energy source, be it coal or hydro. The study offers critical insights into the trade-offs between energy development and biodiversity conservation. It provides actionable metrics and strategies for policymakers, conservationists, and development banks to prioritize forest and habitat preservation in Southeast Asia and globally.\n",
      "  - Forest plantations are a possible way of increasing forest productivity in temperate and tropical forests, and therefore also increasing above- and belowground carbon pools. In the context of climate change, monospecific plantations might become an alternative to mitigate global warming; however, their contribution to the structural complexity, complementarity, and biodiversity of forests has not been addressed. Mixed forest plantations can ensure that objectives of climate change mitigation are met through carbon sequestration, while also delivering anticipated ecosystem services (e.g., nutrient cycling, erosion control, and wildlife habitat). However, mixed forest plantations pose considerable operational challenges and research opportunities. For example, it is essential to know how many species or functional traits are necessary to deliver a set of benefits, or what mixture of species and densities are key to maintaining productive plantations and delivering multiple ecosystem services. At the same time, the establishment of forest plantations in Mexico should not be motivated solely by timber production. Forest plantations should also increase carbon sequestration, maintain biodiversity, and provide other ecosystem services. This article analyzes some matters that affect the development of planted forests in the Mexican national context, and presents alternatives for forest resources management through the recommendation of mixed forest plantations as a means of contributing to climate change mitigation and the delivery of ecosystem services.\n",
      "  - Conventional nature conservation has attempted to protect biodiversity, ecological integrity (i.e., composition and biomass/abundance of native species), and ecosystem services in parallel, assuming generally positive relationships among them. However, many native species are potentially weakened by and maladapted to a new, warmer climate. Such native species may not be able to offer ecosystem services at previous levels. If the relationship between ecosystem services and native species is no longer positive due to climate change, pursuing ecological integrity could be ineffective for maximizing ecosystem services. Hence, there is room to investigate future relationships among biodiversity, ecological integrity, and ecosystem services. This investigation can be done by describing the changes in ecosystem services as a function of biodiversity and ecological integrity. Herein, biodiversity and ecological integrity can be expressed by phylogenetic diversity and species intactness indices based on abundance, respectively. According to my hypothetical figure, the metrics of biodiversity and ecological integrity are potentially not positively but rather negatively related to ecosystem services. The hypothetical figure can be examined and improved using three different approaches: computer simulations (e.g., the LANDIS‐II forest simulation model), collection of actual data (e.g., measuring ecosystem services of some sites with psychrophilic and thermophilic species), and questionnaire surveys about cultural services (e.g., using digitally manipulated photographs and generative adversarial networks). Thus, we can successfully enable practitioners to understand new relationships, which will be relevant to ecosystem management under changing climates.\n",
      "--------------------------------------------------\n",
      "Topic 390: 390_pollen_modern pollen_modern_reconstructions\n",
      "Representative Documents:\n",
      "  - AimFossil pollen spectra from lake sediments in central and western Mongolia have been used to interpret past climatic variations, but hitherto no suitable modern pollen–climate calibration set has been available to infer past climate changes quantitatively. We established such a modern pollen dataset and used it to develop a transfer function model that we applied to a fossil pollen record in order to investigate: (1) whether there was a significant moisture response to the Younger Dryas event in north‐western Mongolia; and (2) whether the early Holocene was characterized by dry or wet climatic conditions.LocationCentral and western Mongolia.MethodsWe analysed pollen data from surface sediments from 90 lakes. A transfer function for mean annual precipitation (Pann) was developed with weighted averaging partial least squares regression (WA‐PLS) and applied to a fossil pollen record from Lake Bayan Nuur (49.98° N, 93.95° E, 932 m a.s.l.). Statistical approaches were used to investigate the modern pollen–climate relationships and assess model performance and reconstruction output.ResultsRedundancy analysis shows that the modern pollen spectra are characteristic of their respective vegetation types and local climate. Spatial autocorrelation and significance tests of environmental variables show that the WA‐PLS model for Pann is the most valid function for our dataset, and possesses the lowest root mean squared error of prediction.Main conclusionsPrecipitation is the most important predictor of pollen and vegetation distributions in our study area. Our quantitative climate reconstruction indicates a dry Younger Dryas, a relatively dry early Holocene, a wet mid‐Holocene and a dry late Holocene.\n",
      "  - Aims and location The potential of pollen records in quantitative climate reconstructions has been widely debated but seldom tested. Our aim is to develop a pollen–climate transfer function for northern Europe and test its performance and inference power by numerical cross‐validation with modern climate data. Annual mean temperature (Tann) was assessed as the critical climatic variable becauseTannhas a distinct south–north gradient (5.5 to −4.7 °C) in the study region with a corresponding zonal vegetation gradient from the hemiboreal zone in the south to the northern boreal zone in the north.Methods We collected 137 pollen surface samples from small‐ to medium size lakes from southern Estonia to northern Finland. The transfer function forTannwas developed with weighted averaging partial least squares (WA‐PLS) regression. All 102 terrestrial pollen and spore types were included in the calculation sum and all 137 surface samples and all 102 taxa were included in the transfer function. The performance of the WA‐PLS transfer function was evaluated by leave‐one‐out cross‐validation.Results A cross‐validated root mean square error of prediction (RMSEP) of our model is 0.89 °C and the coefficient of determination (r2) between the observed meteorologicalTannvalues and those predicted by the model in leave‐one‐out cross‐validation is 0.88. The RMSEP as a percentage of the gradient length ofTannis 8.8%. These figures indicate high performance statistics for our transfer function compared with other inference models. This is probably because of standardization of our surface‐sampling and pollen‐analytical procedures, careful selection of the surface sample sites with consideration of the relevant pollen source area, the simple patterns of vegetation zones and climate in the study area, and the mostly natural floristic composition of the forests in northern Europe. However, we also demonstrate the limitations of our model in reliably detecting fine‐scale climatic variability.Main conclusions The study shows the strong influence ofTannon modern pollen composition and demonstrates the potential of pollen data for long‐term climate reconstructions in northern Europe. It also provides evidence against simple interpretations of fine‐scale variations in a single climate reconstruction. In particular, our results highlight the importance of careful study design and implementation in the construction of pollen–climate transfer functions.\n",
      "  - Aim  Fossil pollen spectra from lake sediments on the Tibetan Plateau have been used for qualitative climate reconstruction, but no modern pollen–climate calibration set based on lake sediments is available to infer past climate quantitatively. This study aims to develop such a dataset and apply it to fossil data.Location  The Tibetan Plateau, between 30 and 40° N and 87 and 103° E.Methods  We collected surface sediments from 112 lakes and analysed them palynologically. The lakes span a wide range of mean annual precipitation (Pann; 31–1022 mm), mean annual temperature (Tann; −6.5 to 1 °C), and mean July temperature (TJuly; 2.6–19.7 °C). Redundancy analysis showed that the modern pollen spectra are characteristic of their respective vegetation types and local climate. Transfer functions for Pann, Tann and TJuly were developed with weighted averaging partial least squares. Model performance was assessed by leave‐one‐out cross‐validation.Results  The root mean square errors of prediction (RMSEP) were 104 mm (Pann), 1.18 °C (Tann) and 1.17 °C (TJuly). The RMSEPs, when expressed as percentages of the gradient sampled, were 10.6% (Pann), 15.7% (Tann) and 11.9% (TJuly). These low values indicate the good performance of our models. An application of the models to fossil pollen spectra covering the last c. 50 kyr yielded realistic results for Luanhaizi Lake in the Qilian Mountains on the north‐eastern Tibetan Plateau (modern Pann 480 mm; Tann−1 °C). Tann and Pann values similar to present ones were reconstructed for late Marine Isotope Stage 3, with minimum values for the Last Glacial Maximum (c. 300 mm and 2 °C below present), and maximum values for the early Holocene (c. 70 mm and 0.5 °C greater than present).Main conclusions  The modern pollen–climate calibration set will potentially be useful for quantitative climate reconstructions from lake‐sediment pollen spectra from the Tibetan Plateau, an area of considerable climatic and biogeographical importance.\n",
      "--------------------------------------------------\n",
      "Topic 391: 391_policy_fcs_georgia_carbon\n",
      "Representative Documents:\n",
      "  - As drivers of climate action, cities are taking measures to reduce greenhouse gas (GHG) emissions, which if left unabated pose a challenge to meeting long-term climate targets. The economics of climate action needs to be at the forefront of climate dialogue to prioritize investments among competing mitigation measures. A marginal abatement cost (MAC) curve is an effective visualization of climate action that initiates a technical and economic discussion of the cost-effectiveness and abatement potential of such actions among local leaders, policy makers, and climate experts. More commonly demonstrated for countries, MAC curves need to be developed for cities because of their heterogeneity, which vary in their urban activities, energy supply, infrastructure stock, and commuting patterns. The methodology for constructing bottom-up MAC curves for cities is presented for technologies that offer fuel switching and/or energy efficiencies, while considering technology lifetimes, city-specific electricity and fuel prices, and emission intensities. Resulting MAC curves are unique to every city, and chart the pathway towards low-carbon growth by prioritizing measures based on cost-effectiveness. A case study of Toronto’s climate targets demonstrates the prioritization of select technologies. Leveraging MAC curves to support climate programs enables cities to strategically invest in financing climate action and designing incentives.\n",
      "  - Carbon‐based liquid fuels are highly valued for transportation; they are the world's largest form of commercial energy and second largest source of anthropogenic carbon dioxide (CO2) emissions. Strategies to address their CO2 emissions have been shaped by fuel cycle analysis (FCA), a version of lifecycle assessment that examines fuel products and their supply chains. FCA studies have diverse findings and large uncertainties. Disagreements are particularly sharp for biofuels, which are seen as key replacements for petroleum fuels. A critical reading of the evolving literature reveals problems of model structure, including system boundary misspecification, flawed carbon cycle representation, and use of a static framework to analyze dynamic systems. New analytic paradigms are needed for liquid fuels, given their tradability, the realities of the carbon cycle, and the implausibility of capturing carbon from mobile sources. Logical decomposition of options shows that, beyond measures to limit fuel demand, CO2 emissions from liquid fuels must be balanced by increasing the rate of net carbon fixation. Further analysis and discussion are needed of carbon accounting methods, energy research priorities, ways to link CO2 removal options to fuel‐related mitigation efforts, and the transportation elements of climate policy. WIREs Energy Environ 2015, 4:98–114. doi: 10.1002/wene.133This article is categorized under:Bioenergy &gt; Climate and EnvironmentEnergy and Climate &gt; Economics and PolicyEnergy Research &amp; Innovation &gt; Science and Materials\n",
      "  - Several recent studies have identified emerging and near‐commercial process and technological options to transition heavy industry to global net‐zero greenhouse gas (GHG) emissions by mid‐century, as required by the Paris Agreement. To reduce industrial emissions with sufficient speed to meet the Paris goals, this review article argues for the rapid formation of regional and sectoral transition plans, implemented through comprehensive policy packages. These policy packages, which will differ by country, sector, and level of development, must reflect regional capacities, politics, resources, and other key circumstances, and be informed and accepted by the stakeholders who must implement the transition. These packages will likely include a mix of the following mutually reinforcing strategies: reducing and substituting the demand for GHG intense materials (i.e., material efficiency) while raising the quantity and quality of recycling through intentional design and regulation; removal of energy subsidies combined with carbon pricing with competitiveness protection; research and development support for decarbonized production technologies followed by lead markets and subsidized prices during early stage commercialization; sunset policies for older high carbon facilities; electricity, hydrogen and carbon capture, and storage infrastructure planning and support; and finally, supporting institutions, including for a “just workforce &amp; community transition” and monitoring and adjustment of policy effectiveness. Given the paucity of industrial decarbonization perspectives available for in‐transition and less‐developed countries, the review finishes with a discussion of priorities and responsibilities for developed, in‐transition and less developed countries.This article is categorized under:Climate Economics &gt; Economics of MitigationClimate and Development &gt; Decoupling Emissions from Development\n",
      "--------------------------------------------------\n",
      "Topic 392: 392_rice_crop_soil_rice production\n",
      "Representative Documents:\n",
      "  - Soils are vital for supporting food security and other ecosystem services. Climate change can affect soil functions both directly and indirectly. Direct effects include temperature, precipitation, and moisture regime changes. Indirect effects include those that are induced by adaptations such as irrigation, crop rotation changes, and tillage practices. Although extensive knowledge is available on the direct effects, an understanding of the indirect effects of agricultural adaptation options is less complete. A review of 20 agricultural adaptation case‐studies across Europe was conducted to assess implications to soil threats and soil functions and the link to the Sustainable Development Goals (SDGs). The major findings are as follows: (a) adaptation options reflect local conditions; (b) reduced soil erosion threats and increased soil organic carbon are expected, although compaction may increase in some areas; (c) most adaptation options are anticipated to improve the soil functions of food and biomass production, soil organic carbon storage, and storing, filtering, transforming, and recycling capacities, whereas possible implications for soil biodiversity are largely unknown; and (d) the linkage between soil functions and the SDGs implies improvements to SDG 2 (achieving food security and promoting sustainable agriculture) and SDG 13 (taking action on climate change), whereas the relationship to SDG 15 (using terrestrial ecosystems sustainably) is largely unknown. The conclusion is drawn that agricultural adaptation options, even when focused on increasing yields, have the potential to outweigh the negative direct effects of climate change on soil degradation in many European regions.\n",
      "  - Major sources of greenhouse gas (GHG) emissions from agricultural crop production are nitrous oxide (N2O) emissions resulting from the application of mineral and organic fertilizer, and carbon dioxide (CO2) emissions from soil carbon losses. Consequently, choice of fertilizer type, optimizing fertilizer application rates and timing, reducing microbial denitrification and improving soil carbon management are focus areas for mitigation. We have integrated separate models derived from global data on fertilizer‐induced soil N2O emissions, soil nitrification inhibitors, and the effects of tillage and soil inputs of soil C stocks into a single model to determine optimal mitigation options as a function of soil type, climate, and fertilization rates. After Monte Carlo sampling of input variables, we aggregated the outputs according to climate, soil and fertilizer factors to consider the benefits of several possible emissions mitigation strategies, and identified the most beneficial option for each factor class on a per‐hectare basis. The optimal mitigation for each soil‐climate‐region was then mapped to propose geographically specific optimal GHG mitigation strategies for crops with varying N requirements. The use of empirical models reduces the requirements for validation (as they are calibrated on globally or continentally observed phenomena). However, as they are relatively simple in structure, they may not be applicable for accurate site‐specific prediction of GHG emissions. The value of this modelling approach is for initial screening and ranking of potential agricultural mitigation options and to explore the potential impact of regional agricultural GHG abatement policies. Given the clear association between management practice and crop productivity, it is essential to incorporate characterization of the yield effect on a given crop before recommending any mitigation practice.\n",
      "  -                       The overall purpose of this review is to assess current and future greenhouse gas (GHG) emissions from irrigated rice fields with emphasis on the ongoing trends in both, (i) crop and residue management practices and (ii) global climate change. While irrigated rice fields were traditionally flooded for the entire vegetation period or at least a substantial portion thereof, current trends in crop management encompass lower consumption of irrigation water through intensification (using water more efficiently under high yield levels) and diversification (replacing the second or third rice crop per year by an upland crop like wheat or maize). These trends have numerous impacts on the GHG budget. Methane emissions will be lower, but these emission savings are at least in part offset by increased nitrous oxide emissions. Moreover, the shift to prevailing upland conditions entails (in most cases) losses in soil organic carbon that translate into carbon dioxide emissions and may threaten the sustainability of the cropping system as a whole. Increasing temperatures exert another risk for rice production systems mainly through spikelet sterility as the principal mechanism of heat damage in rice plants. However, the temperature effect has to be seen in context with the simultaneous increase in carbon dioxide (CO            2            ). Based on the available results for temperature and CO            2            effects, we assume that GHG emissions will increase unless the production base of the irrigated rice systems is severely damaged. The ongoing pressure on rice production systems from societal and environmental drivers limits the scope for designing mitigation options. We have outlined several mitigation approaches of crop and residue management as promising candidates that reconcile low emissions and high production levels and that can also be seen as adaptive response to changing socio-economic and environmental conditions.          \n",
      "--------------------------------------------------\n",
      "Topic 393: 393_terr dom_terr_dom_waters\n",
      "Representative Documents:\n",
      "  - Permafrost thaw increases active layer thickness, changes landscape hydrology and influences vegetation species composition. These changes alter belowground microbial and geochemical processes, affecting production, consumption and net emission rates of climate forcing trace gases. Net carbon dioxide (CO2) and methane (CH4) fluxes determine the radiative forcing contribution from these climate-sensitive ecosystems. Permafrost peatlands may be a mosaic of dry frozen hummocks, semi-thawed or perched sphagnum dominated areas, wet permafrost-free sedge dominated sites and open water ponds. We revisited estimates of climate forcing made for 1970 and 2000 for Stordalen Mire in northern Sweden and found the trend of increasing forcing continued into 2014. The Mire continued to transition from dry permafrost to sedge and open water areas, increasing by 100% and 35%, respectively, over the 45-year period, causing the net radiative forcing of Stordalen Mire to shift from negative to positive. This trend is driven by transitioning vegetation community composition, improved estimates of annual CO2and CH4exchange and a 22% increase in the IPCC's 100-year global warming potential (GWP_100) value for CH4. These results indicate that discontinuous permafrost ecosystems, while still remaining a net overall sink of C, can become a positive feedback to climate change on decadal timescales.This article is part of a discussion meeting issue ‘Rising methane: is warming feeding warming? (part 2)’.\n",
      "  - One of the most robust changes in the hydrological cycle predicted by Earth System Models (ESMs) during the remainder of 21st century is an increase in the difference between precipitation and evapotranspiration (P‐E) in arctic and boreal regions. We explore the long‐term consequences of this change for marine ecosystems in the Arctic Ocean using the Community Earth System Model forced with a business as usual scenario of future greenhouse gas concentrations. We find that by the year 2300 increases in freshwater delivery considerably reduce Arctic Ocean surface salinity, creating a freshwater lens that has far‐reaching impacts on marine biogeochemistry. The expanding freshwater lens limits vertical nutrient supply into the euphotic zone by enhancing vertical stratification and accelerating surface lateral mixing with surface waters in the North Atlantic, which become increasingly nutrient depleted from weakening of the Atlantic Meridional Overturning Circulation (AMOC). The resulting increase in nutrient stress reduces marine export production in the Arctic Ocean by 53% in 2300 relative to the 1990s and triggers a shift in community composition with small phytoplankton replacing diatoms. At the same time, the seasonal timing of export production undergoes a 2‐month forward shift, with the peak advancing from July to May. This suggests that the threat to food webs and higher trophic levels may intensify after the year 2100 as gains in productivity from sea ice loss saturate and freshwater impacts on nutrient stress continue to strengthen. Our analysis highlights the critical importance of changing terrestrial hydrology and land‐ocean coupling as drivers of long‐term biogeochemical change in the Arctic Ocean and the necessity of multi‐century climate change projections.\n",
      "  - Arctic shelf seas receive greater quantities of river runoff than any other ocean region and are experiencing increased freshwater loads and associated terrestrial matter inputs since recent decades. Amplified terrestrial permafrost thaw and coastal erosion is exposing previously frozen organic matter, enhancing its mobilization and release to nearshore regions. Changing terrestrial dissolved organic matter (terr-DOM) loads and composition may alter shelf primary productivity and respiration, ultimately affecting net regional CO2 air–sea fluxes. However, the future evolution of Arctic Ocean climate feedbacks are highly dependent upon the biological degradability of terr-DOM in coastal waters, a factor often omitted in modelling studies. Here, we assess the sensitivity of CO2 air–sea fluxes from East Siberian Arctic Shelf (ESAS) waters to changing terr-DOM supply and degradability using a biogeochemical model explicitly accounting for bacteria dynamics and shifting terr-DOM composition. We find increasing terr-DOM loads and degradability trigger a series of biogeochemical and ecological processes shifting ESAS waters from a net sink to a net source of CO2, even after accounting for strengthening coastal productivity by additional land-derived nutrients. Our results suggest that future projected inputs of labile terr-DOM from peat and permafrost thaw may strongly increase the CO2 efflux from the Arctic shelf sea, causing currently unquantified positive feedback to climate change.\n",
      "--------------------------------------------------\n",
      "Topic 394: 394_mortgage_risk_flood_default\n",
      "Representative Documents:\n",
      "  - This paper examines the integration of climate risks into structural credit risk models. We focus on applications in housing finance and argue that mortgage defaults due to climate disasters have different statistical features than default due to household-specific reasons. We propose two models incorporating climate risk based on two separate default definitions. The first focuses on default as a response to a decrease in home value, and the second defines default as a consequence of missed mortgage payments. Using mortgage performance data during Hurricane Harvey, we conduct an empirical study whose results suggest that climate events are potentially another source of undiversifiable credit risk affecting homeowners’ ability to make contractual monthly payments. We also show that incorporating this climate-specific default process may capture additional uncertainty in default probability assessments.\n",
      "  - Climate change impacts threaten the stability of the US housing market. In response to growing concerns that increasing costs of flooding are not fully captured in property values, we quantify the magnitude of unpriced flood risk in the housing market by comparing the empirical and economically efficient prices for properties at risk. We find that residential properties exposed to flood risk are overvalued by US$121–US$237 billion, depending on the discount rate. In general, highly overvalued properties are concentrated in counties along the coast with no flood risk disclosure laws and where there is less concern about climate change. Low-income households are at greater risk of losing home equity from price deflation, and municipalities that are heavily reliant on property taxes for revenue are vulnerable to budgetary shortfalls. The consequences of these financial risks will depend on policy choices that influence who bears the costs of climate change.\n",
      "  - Rising sea levels necessitate careful consideration of different forms of coastal protection but cost-benefit analysis is limited when important non-market social costs have not been measured. Seawalls protect individual properties but can potentially impose negative externalities on neighboring properties via accelerated beach loss. We conduct a hedonic valuation of seawalls in two coastal California counties: San Diego and Santa Cruz. We find no strong evidence to suggest that the presence of a seawall is positively correlated with the value of the home protected. However, we find that seawalls are strongly negatively correlated with the value of neighboring properties in Santa Cruz but not in San Diego county, suggesting that the effect of seawalls depend on certain geographical attributes. Our results are robust to accounting for the public-good nature of locational attributes and the potential spatial dependence of housing prices. Simulation reveals that doubling the extent of seawalls in San Diego and Santa Cruz could reduce property tax revenues by $7 million and $54 million, respectively.\n",
      "--------------------------------------------------\n",
      "Topic 395: 395_flame_condensation_gas bubble_hydrate\n",
      "Representative Documents:\n",
      "  - In order to successfully study the condensation and separation of a steam–CO2 mixture, a boundary layer model was applied to the mixture condensation of steam and CO2 on horizontal and vertical plates. The modified condensation boundary layer model of steam and CO2, given the CO2 solubility in the condensate, was established, numerically solved, and verified with existing experimental data. Different condensation data of steam–air and steam–CO2 mixtures were compared, and the effect of CO2 solubility on the mixed gas condensation was analyzed under multiple pressure conditions (1 atm–10 MPa). The simulation data show that the presence of CO2 will deteriorate the condensation heat transfer, just like air. Given that CO2 is slightly soluble, some CO2 can pass through the gas–liquid interface to enter the condensate film and reduce the accumulated CO2 on the gas–liquid interface, which improves the condensation. However, the solubility of CO2 is only significant under high-pressure conditions, inducing its effects on condensation. A comparison of the condensation coefficients of the steam–CO2 mixture shows the lower impact of CO2 condensation on the horizontal plate compared to that on the vertical plate. For most conditions, the steam–CO2 mixture gas condensation heat transfer coefficient on the vertical plate surface is still larger than that on the horizontal plate surface, and the improvement in the condensation heat transfer coefficient caused by low CO2 solubility (2 or 10%) at 10 MPa on the vertical plate is also larger than that of the horizontal plate.\n",
      "  - A mechanistic model has been developed and validated to quantify a single gas bubble growth with considering multicomponent gas diffusion in solvent(s)–CO2–heavy oil systems under nonequilibrium conditions. Experimentally, constant-composition expansion (CCE) experiments are conducted for C3H8–CO2–heavy oil systems under equilibrium and nonequilibrium conditions, respectively. Theoretically, the classic continuity equation, motion equation, diffusion–convection equation, real gas equation, and Peng–Robinson equation of state (PR EOS) are integrated into an equation matrix to dynamically predict gas bubble growth. Also, the viscous term of motion equation on the gas phase pressure is included due mainly to the viscous nature of heavy oil. The newly proposed model has been validated by using the experimentally measured gas bubble radius as a function of time with good accuracy. Combining with the experimental measurements, the critical nucleus radius and gas bubble growth are quantitatively predicted with the newly proposed model. Effects of mass transfer, supersaturation pressure, mole concentration of each component, liquid cell radius, and pressure decline rate on the gas bubble growth are examined and analyzed. In general, gas bubble growth rate is found to increase with an increase of each of the aforementioned five parameters though the contribution of individual component in a gas mixture to the bubble growth rate is different. A one-step pressure drop and the unlimited liquid volume surrounding a gas bubble are considered to be the necessary conditions to generate the linear relationship between gas bubble radius and the square root of time.\n",
      "  - To fundamentally elucidate the mixing and its effects on the characteristics of methane/oxygen flame in a rapidly mixed tubular flame burner, experiments were conducted under various oxygen mole fractions and flow rates. Two inert gases of nitrogen and carbon dioxide were used, respectively. The inert gas was added to both the oxidizer and fuel slits to maintain the oxidizer/fuel injection velocity ratio near unity. Based on flow visualization, the mixing process around injection slits and that in the axial downstream were discussed. The Damköhler number (Da1), defined as the ratio of molecular mixing time to reaction time, was selected as a parameter to quantitatively examine the criterion for the establishment of tubular flame from low to ultrahigh oxygen mole fractions (0.21–0.86). The mixing around slit exit determined the tubular flame establishment. Due to a flow time between two neighboring injection slits of fuel and oxidizer, part of the fuel was mixed in the downstream swirling flow, resulting in luminous helical structures. Hence, the Damköhler number (Da2), defined as the flow to the reaction time ratio, was examined. Detailed observations indicated that when Da2 was smaller than unity, the flame was uniform in luminosity, whereas the flame was nonuniform when Da2 ≥ 1. The value of Da2 was about 1.5 times as Da1; however, they correspond to different mixing zones and Da2 can be more easily calculated. The differences in flame stability between N2 and CO2 diluted combustion were also studied.\n",
      "--------------------------------------------------\n",
      "Topic 396: 396_water quality_water_phosphorus_sediments\n",
      "Representative Documents:\n",
      "  - Mining regions in different parts of the world have been associated with the significant pollution of water, sediments, and soils by manganese and other chemical elements. This study assessed the degree of geochemical transformation caused by open-pit extraction and processing of mineral resources in the Kovdorsky District of Murmansk Oblast, 20 km from the Russia–Finland border. A second objective was to predict further changes co-driven by industrial pressure and high climatic instability in the polar region. The field study involved sampling water and sediments from virgin background streams and from the tailings storage facility, settling ponds, rivers, and lakes affected by ore mining and disintegration. Laboratory analyses included the study of elemental composition, redox potential, alkalinity and acidity, organic matter content, and other geochemical characteristics for a better understanding of pollutant migration patterns. We revealed elevated levels of potentially toxic elements in surface waters and bottom sediments which pose a risk to the human health via the household and drinking water supply. Pollution with manganese (Mn) was found to be the major environmental issue. Its natural presence in the river water was overridden a hundredfold by anthropogenic enrichment. This is problematic as Mn is easily bioaccumulated, which can lead to unwanted ecotoxicological effects, and—in the case of prolonged exposure to high doses of Mn and its compounds—to detrimental human health impacts. We believe that the changing climate may raise the water flow and thus expand the area of the hydrochemical anomaly. On the other hand, the activation of self-purification and dilution processes could lead to decreasing environmental Mn concentrations.\n",
      "  - It is generally recognized that climate change will affect the discharge regime of the Rhine River. Especially the anticipated increase in extreme river discharges (floods and droughts) poses serious problems to water management, both with regard to water quantity and water quality. Water quality effects of climate change are not sufficiently recognized, however. The purpose of this study is to investigate the impact of droughts on the water quality of the River Rhine. Time series of river flow and water quality were analyzed for station Lobith, located at the Dutch-German border. Over the past three decades, three major droughts were identified, occurring in the years 1976, 1991, and 2003. The water quality during these dry years was compared with the water quality in reference years, characterized by average hydrological conditions and similar chemical pollution. Four groups of water quality parameters were investigated: 1, general variables (water temperature, dissolved oxygen, chlorophyll-a); 2, major ions (chloride, sodium, sulfate, fluoride, bromide); 3, nutrients; and 4, heavy metals. It was found that water quality is negatively influenced by (summer) droughts, with respect to water temperature, eutrophication, major ions and heavy metals. Effects on nutrient concentrations were small for ammonium and could not be demonstrated for nitrate, nitrite and phosphate. The decline in water quality during summer droughts is both related to the high water temperatures and to low river discharges (limited dilution of the chemical load from point sources). Moreover, the impact of the 1976 drought on water quality was far more important than that of the 2003 drought, indicating that the impact of droughts on water quality will be greater when the water quality is already poor.\n",
      "  - The article deals with problem of the fresh waters salinization in view of its relevance for normal functioning of the aquatic ecosystems, development of different branches of industry and agriculture, and human health. Attention is focused on the fact that the fresh waters' salinization inevitably results in decrease of the ecosystem services scope. The main factors and anthropogenic sources of influence on total dissolved solids in the fresh waters and metamorphosis of their ion composition are considered. It is stated that climate changes potentially affect and will affect the surface waters mineralization in future owing to volume and frequency of the atmospheric precipitation, intensity of the rocks and minerals weathering, the ground feeding of the rivers, the marine water penetration into the estuaries along with reducing of the river water yield, etc. The possible impact of mineralization changes on migration of substances from bottom sediments into the water thickness, that is on the intensity of its secondary pollution, is discussed. This impact can be direct and indirect. First of all, it concerns the migration ability of metals in bottom sediments. Elevated content of Na&lt;sup&gt;+&lt;/sup&gt;, Ca&lt;sup&gt;2+&lt;/sup&gt; and Mg&lt;sup&gt;2+&lt;/sup&gt; in water intensifies migration of metals of the exchangeable fraction of bottom sediments. The indirect effect of elevated mineralization is expressed in the oxygen regime of the water bodies, which usually deteriorates in the near-bottom water layers of deep lakes and reservoirs, mouth areas of the rivers and estuaries. The dissolved oxygen deficit becomes usual, anoxic conditions are formed, which favor release of Fe(III) and Mn(IV) from oxyhydroxides or the oxide fraction of the bottom sediments. A review also considers some aspects of potential impact of the fresh waters salinization on survival of the aquatic plants and animals and biodiversity.\n",
      "--------------------------------------------------\n",
      "Topic 397: 397_richness_species_dispersal_rls\n",
      "Representative Documents:\n",
      "  - Spatial variation in climatic conditions along elevation gradients provides an important backdrop by which communities assemble and diversify. Lowland habitats tend to be connected through time, whereas highlands can be continuously or periodically isolated, conditions that have been hypothesized to promote high levels of species endemism. This tendency is expected to be accentuated among taxa that show niche conservatism within a given climatic envelope. While species distribution modeling approaches have allowed extensive exploration of niche conservatism among target taxa, a broad understanding of the phenomenon requires sampling of entire communities. Species‐rich groups such as arthropods are ideal case studies for understanding ecological and biodiversity dynamics along elevational gradients given their important functional role in many ecosystems, but community‐level studies have been limited due to their tremendous diversity. Here, we develop a novel semi‐quantitative metabarcoding approach that combines specimen counts and size‐sorting to characterize arthropod community‐level diversity patterns along elevational transects on two different volcanoes of the island of Hawai‘i. We found that arthropod communities between the two transects became increasingly distinct compositionally at higher elevations. Resistance surface approaches suggest that climatic differences between sampling localities are an important driver in shaping beta‐diversity patterns, though the relative importance of climate varies across taxonomic groups. Nevertheless, the climatic niche position of OTUs between transects was highly correlated, suggesting that climatic filters shape the colonization between adjacent volcanoes. Taken together, our results highlight climatic niche conservatism as an important factor shaping ecological assembly along elevational gradients and suggest topographic complexity as an important driver of diversification.\n",
      "  - Dispersal ability will largely determine whether species track their climatic niches during climate change, a process especially important for populations at contracting (low‐latitude/low‐elevation) range limits that otherwise risk extinction. We investigate whether dispersal evolution at contracting range limits is facilitated by two processes that potentially enable edge populations to experience and adjust to the effects of climate deterioration before they cause extinction: (i) climate‐induced fitness declines towards range limits and (ii) local adaptation to a shifting climate gradient. We simulate a species distributed continuously along a temperature gradient using a spatially explicit, individual‐based model. We compare range‐wide dispersal evolution during climate stability vs. directional climate change, with uniform fitness vs. fitness that declines towards range limits (RLs), and for a single climate genotype vs. multiple genotypes locally adapted to temperature. During climate stability, dispersal decreased towards RLs when fitness was uniform, but increased when fitness declined towards RLs, due to highly dispersive genotypes maintaining sink populations at RLs, increased kin selection in smaller populations, and an emergent fitness asymmetry that favoured dispersal in low‐quality habitat. However, this initial dispersal advantage at low‐fitness RLs did not facilitate climate tracking, as it was outweighed by an increased probability of extinction. Locally adapted genotypes benefited from staying close to their climate optima; this selected against dispersal under stable climates but for increased dispersal throughout shifting ranges, compared to cases without local adaptation. Dispersal increased at expanding RLs in most scenarios, but only increased at the range centre and contracting RLs given local adaptation to climate.\n",
      "  - Climate adaptation has major consequences in the evolution and ecology of all living organisms. Though phytophagous insects are an important component of Earth's biodiversity, there are few studies investigating the evolution of their climatic preferences. This lack of research is probably because their evolutionary ecology is thought to be primarily driven by their interactions with their host plants. Here, we use a robust phylogenetic framework and species‐level distribution data for the conifer‐feeding aphid genus Cinara to investigate the role of climatic adaptation in the diversity and distribution patterns of these host‐specialized insects. Insect climate niches were reconstructed at a macroevolutionary scale, highlighting that climate niche tolerance is evolutionarily labile, with closely related species exhibiting strong climatic disparities. This result may suggest repeated climate niche differentiation during the evolutionary diversification of Cinara. Alternatively, it may merely reflect the use of host plants that occur in disparate climatic zones, and thus, in reality the aphid species' fundamental climate niches may actually be similar but broad. Comparisons of the aphids' current climate niches with those of their hosts show that most Cinara species occupy the full range of the climatic tolerance exhibited by their set of host plants, corroborating the hypothesis that the observed disparity in Cinara species' climate niches can simply mirror that of their hosts. However, 29% of the studied species only occupy a subset of their hosts' climatic zone, suggesting that some aphid species do indeed have their own climatic limitations. Our results suggest that in host‐specialized phytophagous insects, host associations cannot always adequately describe insect niches and abiotic factors must be taken into account.\n",
      "--------------------------------------------------\n",
      "Topic 398: 398_guest_clathrate_molecules_guest molecules\n",
      "Representative Documents:\n",
      "  - Equilibrium and non-equilibrium molecular dynamics (MD) simulations have been performed to investigate thermal-driven break-up of planar CO2 hydrate interfaces in liquid water at 300–320 K. Different guest compositions, at 85%, 95%, and 100% of maximum theoretical occupation, led to statistically-significant differences in the observed initial dissociation rates. The melting temperatures of each interface were estimated, and dissociation rates were observed to be strongly dependent on temperature, with higher dissociation rates at larger over-temperatures vis-à-vis melting. A simple coupled mass and heat transfer model developed previously was applied to fit the observed dissociation profiles, and this helps to identify clearly two distinct régimes of break-up; a second well-defined region is essentially independent of composition and temperature, in which the remaining nanoscale, de facto two-dimensional system's lattice framework is intrinsically unstable. From equilibrium MD of the two-phase systems at their melting point, the relaxation times of the auto-correlation functions of fluctuations in number of enclathrated guest molecules were used as a basis for comparison of the variation in the underlying, non-equilibrium, thermal-driven dissociation rates via Onsager's hypothesis, and statistically significant differences were found, confirming the value of a fluctuation-dissipation approach in this case.\n",
      "  - The recent discovery that molecular CO2 transforms under compression into carbon four-coordinated, 3-dimensional network solid phases has generated considerable interests on possible new phases in the fourth-main-group elemental oxides. Based on density-functional theory calculations, we have investigated the thermodynamic stability, mechanical properties and electronic structure of proposed guest-free clathrates, quartz and cristobalite phases for CO2, SiO2, and GeO2, and the dry ice phase for CO2. It was predicted that a GeO2 clathrate, likely a semiconductor, could be synthesized presumably with some suitable guest molecules. The hypothetical CO2 guest-free clathrate phase was found hardly to be formed due to the large energy difference with respect to the other polymorphs. This phase is unstable at all pressures, which is also implied by its different electronic structure in comparison with SiO2 and GeO2. Finally, the SiO2 clathrate presents a uniquely high bulk modulus, which is higher than that of quartz and three times of the experimental data, might not be a weak point of ab-initio calculations such as pseudopotentials, correlation functional etc., instead it can be readily understood by the constraint as imposed by the high symmetry. Either temperature or an “exhausted” relaxation (without any symmetry constraint) can remedy this problem.\n",
      "  - This paper analyzes the structural, energetic and mechanical properties of carbon dioxide hydrate clathrates calculated using finite cluster and periodic ab initio density-functional theory methodologies. Intermolecular interactions are described by the exchange-hole dipole moment method. The stability, gas saturation energetics, guest–host interactions, cage deformations, vibrational frequencies, and equation of state parameters for the low-pressure sI cubic phase of the CO2@H2O clathrate hydrate are presented. Our results reveal that: (i) the gas saturation process energetically favors complete filling; (ii) carbon dioxide molecules prefer to occupy the larger of the two cages in the sI structure; (iii) blue shifts occur in both the symmetric and antisymmetric stretching frequencies of CO2 upon encapsulation; and (iv) free rotation of guest molecules is restricted to a plane parallel to the hexagonal faces of the large cages. In addition, we calculate the librational frequency of the hindered rotation of the guest molecule in the plane perpendicular to the hexagonal faces. Our calculated spectroscopic data can be used as signatures for the detection of clathrate hydrates in planetary environments.\n",
      "--------------------------------------------------\n",
      "Topic 399: 399_energy_electricity_primary energy_buildings\n",
      "Representative Documents:\n",
      "  -                The energy efficiency – indoor air quality dilemma is well known and the main drawback to operate the mechanical ventilation is electricity costs as concluded from previous studies. Educational buildings are one of the places where future taxpayers spend a lot of time. This paper aims to study an alternative solution on how to reduce energy efficiency – indoor air quality dilemma in educational buildings by adopting systems that use renewable energy sources. A typical education building in Latvia is taken as a case study by changing it from a consumer to prosumer. This building type has a specific electricity usage profile that makes the choice of photovoltaics (PV) power quite challenging so the various power options have been analysed and used for an electricity solution. Also, the more decentralised preference is chosen – disconnect from a public heating provider and using a local system with a pellet boiler. Educational buildings using PV can reduce the electricity tariff, but the payback periods are still not very satisfactory without subsidies. The average electricity tariff per month varies between scenarios and the best one is for the scenario with 30 kW installed power. The educational building partly using 16 kW PV system reduces not only its bill for electricity but also reduces CO2 emissions by around 36 tons. The education buildings as energy prosumers using renewable energy sources are reducing GHG emissions by having high indoor air quality.\n",
      "  -                Numerical optimization methods are used to reduce the operative costs and emissions of domestic houses comprising photovoltaic energy production and battery electrical storage combined with time-variant electricity prices. The modelling of the system comprises the different involved devices, energy flows and their constraints, and an objective function, which parametrizes the object of the optimization. The solution of the optimization problem defines the most adequate charging and discharging strategy of the battery into the future (prediction horizon). Power inverter efficiencies are usually modelled by assuming that they have constant values, and hence, that charging and discharging energy-flows lie on the most probably operating region of the inverter. A more realistic modelling of the power inverter efficiencies should consider a nonlinear parametrization of the efficiency curves. This consideration converts the optimization problem into a nonlinear one. It this paper, we modify a method to solve nonlinear optimization problems means iterations of linear optimization problems. The first iteration uses as seed values the solution of an optimization problem, which considers constant efficiencies of the battery inverter provided by the manufacturer of the battery. With the values of the solution of the optimization problem and with help of measured (dis)charging power curves and the optimized (dis)charging, new values of the efficiencies of the inverter of the battery will be determined, and the optimization problem will be with these values again computed. If a certain number of iterations is achieved or the values of the efficiencies converge, then the process stops.\n",
      "  -  The Iron Ore Line (Malmbanan) is a 473 km long track section located in northern Sweden and has been in operation since 1903. This track section stretches through two countries, namely Sweden and Norway, and the main part of the track runs on the Swedish side, where the owner is the Swedish Government and the infrastructure manager is Trafikverket (the Swedish Transport Administration). The ore trains are owned and managed by the freight operator and mining company LKAB. Due to the high axle load exerted by transportation of the iron ore, 30 tonnes, and the high demand for a constant flow of ore and pellets, the track and wagons must be monitored and maintained on a regular basis. The condition of the wagon wheel is one of the most important aspects in this connection, and here the wheel profile plays an important role. For this reason an automatic laser-based wheel profile monitoring system (WPMS) has been installed on this line using a system lifecycle approach that is based on the reliability, availability, maintainability and safety (RAMS) approach for railways. The system was prepared and installed and is being operated in a collaborative project between the freight operator and infrastructure manager. The measurements are used to diagnose the condition of the wheels, and to further optimize their maintenance. This paper presents a study of the concepts and ideas of the WPMS, and the selection, installation and validation of the equipment using a system lifecycle approach that is based on RAMS for railways. Results from the profile measurements and validation are shown. The system’s reliability during performance in extreme climate conditions, with severe cold and large quantities of snow, is presented. Then the benefits, perceived challenges and acquired knowledge of the system are discussed, and an improved V-model for the lifecycle approach is presented. \n",
      "--------------------------------------------------\n",
      "Topic 400: 400_farmers_crop_ration_ration balancing\n",
      "Representative Documents:\n",
      "  - In the literature, a lot is discussed about how agroforestry can achieve the mitigation, adaptation and productivity goals of climate-smart agriculture (CSA). However, this may be relatively too broad to assess the trade-offs and synergies of how specific agroforestry technologies or practices achieve the three pillars of CSA. Here, we provide an overview of how improved fallows (an agroforestry technology consisting of planting mainly legume tree/shrub species in rotation with cultivated crops) may achieve the goals of climate-smart agriculture in Sub-Saharan Africa (SSA). Our review showed that improved fallow systems have real potential to contribute to food security and climate change mitigation and adaptation in SSA. Under proper management, improved fallows can increase maize yields to about 6 t ha−1, which is comparable to conventional maize yields under fertilization. This is attributed to improved soil fertility and nutrient use efficiency. Although data was generally limited, the growing literature showed that improved fallows increased soil carbon sequestration and reduced greenhouse emissions. Further, as a multiple output land use system, improved fallows may increase fodder availability during dry periods and provide substantial biomass for charcoal production. These livelihood options may become important financial safety nets during off seasons or in the event of crop failures. This notwithstanding, the adoption of improved fallows is mainly in Southern and Eastern Africa, where over 20,000 farmers are now using Sesbania sesban, Tephrosia vogelii, and Cajanus cajan in two-year fallows followed by maize rotations. Land tenure issues, lack of social capital, and improved germplasm and accessions of fallow species have been cited as constraints to scaling up. However, development of seed orchards, nursery development, and the willingness of policy makers to create a policy environment that addresses market failures and alleviates disincentives should improve adoption and future scaling up.\n",
      "  -                       In recent years, the share of developing countries in global milk production has increased significantly. Despite the breakthroughs in milk production, average productivity of livestock is quite low in the region, mainly because of imbalanced feeding in terms of protein, energy and minerals. Farmers do not have adequate knowledge, resources and skills to formulate a least cost balanced ration. Feed shortages notwithstanding in the region, considerable potential exists for improving livestock productivity and reducing the carbon footprint of milk by ration balancing with available feed resources. The National Dairy Development Board of India has developed a user-friendly ration balancing software for preparing a least cost balanced ration, using available feed resources and area-specific mineral mixtures. To educate farmers, a large-scale ration balancing programme has been implemented in different states of India. Various studies indicate that ration balancing has resulted in an increase in farmers' net daily income by increasing milk yield or milk fat, while reducing feeding costs. Ration balancing has also helped improve feed conversion efficiency and microbial protein synthesis, while reducing enteric methane emissions. A study on the            cradle-to-farm gate            life cycle assessment of lifetime milk production indicated that enteric methane is the largest contributor to the carbon footprint of milk. A significant reduction in the carbon footprint of milk has been observed when feeding a balanced ration. The present review summarizes the application of ration balancing approach at the farmers' doorstep that could serve as a climate-smart strategy for achieving sustainable increases in livestock productivity in developing countries.          \n",
      "  - In the south of the Tibet Autonomous Region of China there is a network of valleys where intensive agriculture is practiced. Although considered highly productive by Tibetans, farm incomes in the region are low, leading to a range of government initiatives to boost grain and fodder production. However, there is limited information available on current farming practices, yields, and likely yield constraints. The present paper uses available data and farmer interviews to describe the agro-climate and current systems of crop and livestock production, and considers possible strategies to boost production. Although winters in Tibet are cold and dry, summer and autumn provide ideal conditions for crop growth. Cropping systems are characterised by heavy tillage, frequent irrigation, high seeding rates and fertiliser applications, some use of herbicides, and little stubble retention or mechanisation. Spring barley and winter wheat are the predominant crops, followed by rapeseed, winter barley, and minor fodder and vegetable crops. Average yields for the main grain crops are around 4.0 t/ha for spring barley and 4.5 t/ha for winter wheat, significantly lower than should be possible in the environment. Farmers typically keep five or six cattle tethered near the household. Cattle are fed diets based on crop residues but are generally malnourished and rarely produce beyond the needs of the family. It is suggested that research and extension in the areas of crop nutrition, weed control, irrigation, seeding technology, and crop varieties should enable significant increases in grain yield. Increases in cattle production will require increases in the supply of good quality fodder. Cereal/fodder intercrops or double crops sown using no-till seed drills might enable the production of useful amounts of fodder in many areas without jeopardising food grain supply, and allow more crop residues to be retained in fields for improved soil health.\n",
      "--------------------------------------------------\n",
      "Topic 401: 401_pe_hydropower_tsca_intrusion\n",
      "Representative Documents:\n",
      "  -           Natural-resource managers and stakeholders face difficult challenges when managing interactions between natural and societal systems. Potential changes in climate could alter interactions between environmental and societal systems and adversely affect the availability of water resources in many coastal communities. The availability of freshwater in coastal streams can be threatened by saltwater intrusion. Even though the collective interests and computer skills of the community of managers, scientists and other stakeholders are quite varied, there is an overarching need for equal access by all to the scientific knowledge needed to make the best possible decisions. This paper describes a decision support system, PRISM-2, developed to evaluate salinity intrusion due to potential climate change along the South Carolina coast in southeastern USA. The decision support system is disseminated as a spreadsheet application and integrates the output of global circulation models, watershed models and salinity intrusion models with real-time databases for simulation, graphical user interfaces, and streaming displays of results. The results from PRISM-2 showed that a 31-cm and 62-cm increase in sea level reduced the daily availability of freshwater supply to a coastal municipal intake by 4% and 12% of the time, respectively. Future climate change projections by a global circulation model showed a seasonal change in salinity intrusion events from the summer to the fall for the majority of events.\n",
      "  -  The pilot facility-level climate change adaptation assessment for Little Indian Creek was a climate change adaptation assessment for a culvert conveying Little Indian Creek at the confluence of North Feather Fork in Plumas County, California, U.S. In previous reports, the culvert was found to be potentially vulnerable to climate change impacts, such as snow melt and wildfire. Snowmelt introduces varying runoff patterns throughout the year depending on the size and saturation of the snowpack. Similarly, burn-scarred landscapes following wildfires can significantly enhance flood flows, sediment, and debris in streams and rivers. Extreme flood and debris flows produced from these conditions significantly affect downstream transportation infrastructure, causing damage to bridges, culverts, and roadways. A baseline stormwater management model (SWMM) was composed to understand the watershed hydrology assuming only rainfall precipitation and natural, healed land cover. Subsequent modeling of the independent variables determined the degree of hydrologic change based on project climate stressors and to what degree the infrastructure is affected. The final goal was to identify the most cost-effective adaptation solution that meets all agency and community standards and needs. The Little Indian Creek Culvert Assessment provides a useful pilot, and draft tools and process, to inform similar projects at departments of transportation. \n",
      "  - ABSTRACTUnderstanding the trade‐offs between water for the environment and water for hydropower in regulated rivers can inform decision making about hydropower system planning, policy and operations, especially with anticipated climate warming–induced changes in runoff. This study used a multireservoir optimisation model to assess the hydropower effects of increasing minimum instream flows (MIFs) and imposing weekly scale down ramp rates (DRRs) in three locations in California's Upper Yuba River (UYR). The UYR is currently used for hydropower generation yet has high potential for freshwater habitat restoration. Trade‐offs between DRRs, MIFs and hydropower generation and revenue are explored with uniform air temperature increases of 0 °C, 2 °C, 4 °C and 6 °C to approximate anticipated regional climate warming. With 6 °C warming, the most ecologically beneficial MIF and DRR reduced hydropower generation by 7.9% and revenue by 5.5% compared with base case management and a historical climate. This has important implications for licensure of the UYR project and other hydropower projects, where multiple benefits under current and potential future conditions must be balanced. This study provides a methodological approach that can be used by water managers, regulators and stakeholders to better understand inherent trade‐offs in allocating water for multiple beneficial uses in a nonstationary hydroclimate. Copyright © 2012 John Wiley &amp; Sons, Ltd.\n",
      "--------------------------------------------------\n",
      "Topic 402: 402_waccm6_cloud_cam_smcm\n",
      "Representative Documents:\n",
      "  - This paper describes the performance of the Community Atmosphere Model (CAM) versions 4 and 5 in simulating near-surface parameters. CAM is the atmospheric component of the Community Earth System Model (CESM). Most of the parameterizations in the two versions are substantially different, and that is also true for the boundary layer scheme: CAM4 employs a nonlocal K-profile scheme, whereas CAM5 uses a turbulent kinetic energy (TKE) scheme. The evaluation focuses on the diurnal cycle and global observational and reanalysis datasets are used together with multiyear observations from 35 flux tower sites, providing high-frequency measurements in a range of different climate zones. It is found that both model versions capture the timing of the diurnal cycle but considerably overestimate the diurnal amplitude of net radiation, temperature, wind, and turbulent heat fluxes. The seasonal temperature range at mid- and high latitudes is also overestimated with too warm summer temperatures and too cold winter temperatures. The diagnosed boundary layer is deeper in CAM5 over ocean in regions with low-level marine clouds as a result of the turbulence generated by cloud-top cooling. Elsewhere, the boundary layer is in general shallower in CAM5. The two model versions differ substantially in their representation of near-surface wind speeds over land. The low-level wind speed in CAM5 is about half as strong as in CAM4, and the difference is even larger in areas where the subgrid-scale terrain is significant. The reason is the turbulent mountain stress parameterization, only applied in CAM5, which acts to increase the surface stress and thereby reduce the wind speed.\n",
      "  - The cloud‐to‐precipitation transition process in warm clouds simulated by state‐of‐the‐art global climate models (GCMs), including both traditional climate models and a high‐resolution model, is evaluated against A‐Train satellite observations. The models and satellite observations are compared in the form of the statistics obtained from combined analysis of multiple‐satellite observables that probe signatures of the cloud‐to‐precipitation transition process. One common problem identified among these models is the too‐frequent occurrence of warm precipitation. The precipitation is found to form when the cloud particle size and the liquid water path (LWP) are both much smaller than those in observations. The too‐efficient formation of precipitation is found to be compensated for by errors of cloud microphysical properties, such as underestimated cloud particle size and LWP, to an extent that varies among the models. However, this does not completely cancel the precipitation formation bias. Robust errors are also found in the evolution of cloud microphysical properties from nonprecipitating to drizzling and then to raining clouds in some GCMs, implying unrealistic interaction between precipitation and cloud water. Nevertheless, auspicious information is found for future improvement of warm precipitation representations: the adoption of more realistic autoconversion scheme in the high‐resolution model improves the triggering of precipitation, and the introduction of a sophisticated subgrid variability scheme in a traditional model improves the simulated precipitation frequency over subtropical eastern ocean. However, deterioration in other warm precipitation characteristics is also found accompanying these improvements, implying the multisource nature of warm precipitation biases in GCMs.\n",
      "  - Cumulus parameterization (CP) in state‐of‐the‐art global climate models is based on the quasi‐equilibrium assumption (QEA), which views convection as the action of an ensemble of cumulus clouds, in a state of equilibrium with respect to a slowly varying atmospheric state. This view is not compatible with the organization and dynamical interactions across multiple scales of cloud systems in the tropics and progress in this research area was slow over decades despite the widely recognized major shortcomings. Novel ideas on how to represent key physical processes of moist convection‐large‐scale interaction to overcome the QEA have surged recently. The stochastic multicloud model (SMCM) CP in particular mimics the dynamical interactions of multiple cloud types that characterize organized tropical convection. Here, the SMCM is used to modify the Zhang‐McFarlane (ZM) CP by changing the way in which the bulk mass flux and bulk entrainment and detrainment rates are calculated. This is done by introducing a stochastic ensemble of plumes characterized by randomly varying detrainment level distributions based on the cloud area fraction of the SMCM. The SMCM is here extended to include shallow cumulus clouds resulting in a unified shallow‐deep CP. The new stochastic multicloud plume CP is validated against the control ZM scheme in the context of the single column Community Climate Model of the National Center for Atmospheric Research using data from both tropical ocean and midlatitude land convection. Some key features of the SMCM CP such as it capability to represent the tri‐modal nature of organized convection are emphasized.\n",
      "--------------------------------------------------\n",
      "Topic 403: 403_lucas soil_lucas_dataset_aidb\n",
      "Representative Documents:\n",
      "  - . The concept of plant functional types (PFTs) is shown to be beneficial in representing the complexity of plant characteristics in land use and climate change studies using regional climate models (RCMs). By representing land use and land cover (LULC) as functional traits, responses and effects of specific plant communities can be directly coupled to the lowest atmospheric layers. To meet the requirements of RCMs for realistic LULC distribution, we developed a PFT dataset for Europe (LANDMATE PFT Version 1.0; http://doi.org/10.26050/WDCC/LM_PFT_LandCov_EUR2015_v1.0, Reinhart et al., 2021b). The dataset is based on the high-resolution European Space Agency Climate Change Initiative (ESA-CCI) land cover dataset and is further improved through the additional use of climate information. Within the LANDMATE – LAND surface Modifications and its feedbacks on local and regional cliMATE – PFT dataset, satellite-based LULC information and climate data are combined to create the representation of the diverse plant communities and their functions in the respective regional ecosystems while keeping the dataset most flexible for application in RCMs. Each LULC class of ESA-CCI is translated into PFT or PFT fractions including climate information by using the Holdridge life zone concept. Through consideration of regional climate data, the resulting PFT map for Europe is regionally customized. A thorough evaluation of the LANDMATE PFT dataset is done using a comprehensive ground truth database over the European continent. The assessment shows that the dominant LULC types, cropland and woodland, are well represented within the dataset, while uncertainties are found for some less represented LULC types. The LANDMATE PFT dataset provides a realistic, high-resolution LULC distribution for implementation in RCMs and is used as a basis for the Land Use and Climate Across Scales (LUCAS) Land Use Change (LUC) dataset which is available for use as LULC change input for RCM experiment set-ups focused on investigating LULC change impact.                    \n",
      "  -                                   Key message                                The purpose of this report is to increase the transparency of applications of the CBM-CFS3 model by climate-related policy-makers and researchers. The report provides explicit information on the parametrization of a new Archive Index Database used with this model to simulate forest carbon dynamics in 26 EU countries. The database can be accessed at                      https://data.europa.eu/89h/jrc-cbm-eu-aidb                    , primary metadata are available in Kull et al. (2017), and additional metadata are available at                      https://metadata-afs.nancy.inra.fr/geonetwork/srv/fre/catalog.search#/metadata/df48155b-973f-4169-a722-100bb6bfc76c                    .                The Carbon Budget Model of the Canadian Forest Sector (CBM-CFS3) has been adapted, tested, and applied to forests of 26 EU countries over the last 7 years for EU policy making and scientific research. The overall purpose of this exercise is to increase the transparency of how the EU Archive Index Database (EU-AIDB) was parameterized while supporting both the policy making and research communities interested in applying the CBM-CFS3 with ecological parameters specific to the EU context. In addition to preparing model input data reflecting various management and disturbance scenarios for CBM-CFS3 projects, an essential step was to update the original AIDB with information specific to the EU context and create an EU-AIDB. The AIDB is the Microsoft Access database behind the CBM-CFS3 that stores default ecological information and parameters pertaining to the forest ecosystems of a country, among other functions. The EU-AIDB incorporates 1034 spatial units resulting from the intersection of 204 European administrative regions and ecological boundaries representing 35 climatic units. It also contains updated parameters for 192 of the main tree species reported by the National Forest Inventories of each EU country. The release of this database allows CBM-33 CFS3 users in the EU to apply European administrative and ecological units and tree species in forest carbon modeling projects.              \n",
      "  - SummarySoil is a non‐renewable resource that requires constant monitoring to prevent its degradation and promote its sustainable management. The ‘Land Use/Cover Area frame statistical Survey Soil’ (LUCAS Soil) is an extensive and regular topsoil survey that is carried out across the European Union to derive policy‐relevant statistics on the effect of land management on soil characteristics. Approximately 45 000 soil samples have been collected from two time‐periods, 2009–2012 and 2015. A new sampling series will be undertaken in 2018, with new measurements included. The organization for the 2018 sampling campaign represents an opportunity to summarize past LUCAS Soil achievements and present its future objectives. In 2009–2012 and 2015, LUCAS Soil surveys targeted physicochemical properties, including pH, organic carbon, nutrient concentrations and cation exchange capacity. Data from 2009–2012 (ca. 22 000 points) and derived output (more than 20 maps) are available freely from the European Soil Data Centre website. Analyses of samples collected during 2015 are ongoing and data will be available at the end of 2017. In the 2018 LUCAS Soil sampling campaign, additional properties, including bulk density, soil biodiversity, specific measurements for organic‐rich soil and soil erosion will be measured. Here we present the current dataset (LUCAS Soil 2009–2012 and 2015), its potential for reuse and future development plans (LUCAS Soil 2018 and over). LUCAS Soil represents the largest harmonized open‐access dataset of topsoil properties available for the European Union at the global scale. It was developed as an expandable resource, with the possibility to add new properties and sampling locations during successive sampling campaigns. Data are available to the scientific community and decision makers, thus contributing to both research and the development of the land‐focused policy agenda.HighlightsLUCAS Soil consists of soil physicochemical and biological properties data from Europe.Harmonized and open‐access dataset allowing inclusion of soil in large‐scale inter‐disciplinary assessments.LUCAS Soil has a broad pool of users from scientists to policy makers, and applications from map validation to modelling.LUCAS Soil confirms the need for open‐access and a large‐scale dataset for soil properties.\n",
      "--------------------------------------------------\n",
      "Topic 404: 404_climate sensitivity_oceanic heat uptake_heat uptake_oceanic heat\n",
      "Representative Documents:\n",
      "  - Predictions of 21st century climate by different atmosphere‐ocean general circulation models depend on the sensitivities of the models to external radiative forcing and on their rates of heat uptake by the deep ocean. This study constrains these properties by comparing radiosonde‐based observations of temperature trends in the free troposphere and lower stratosphere with corresponding simulations of a fast, flexible climate model, using objective techniques based on optimal fingerprinting. Parameter choices corresponding either to low sensitivity, or to high sensitivity combined with slow oceanic heat uptake are rejected provided the variability estimates used from the HadCM2 control run are correct. Nevertheless, the range of acceptable values is significantly wider than that usually quoted. The IPCC's range of possible sensitivities, 1.5 to 4.5 K, corresponds at best to only an 80% confidence interval. Therefore, climate change projections based on current general circulation models do not span the range of possibilities consistent with the recent climate record.\n",
      "  -                The framework of feedback analysis is used to explore the controls on the shape of the probability distribution of global mean surface temperature response to climate forcing. It is shown that ocean heat uptake, which delays and damps the temperature rise, can be represented as a transient negative feedback. This transient negative feedback causes the transient climate change to have a narrower probability distribution than that of the equilibrium climate response (the climate sensitivity). In this sense, climate change is much more predictable than climate sensitivity. The width of the distribution grows gradually over time, a consequence of which is that the larger the climate change being contemplated, the greater the uncertainty is about when that change will be realized. Another consequence of this slow growth is that further efforts to constrain climate sensitivity will be of very limited value for climate projections on societally relevant time scales. Finally, it is demonstrated that the effect on climate predictability of reducing uncertainty in the atmospheric feedbacks is greater than the effect of reducing uncertainty in ocean feedbacks by the same proportion. However, at least at the global scale, the total impact of uncertainty in climate feedbacks is dwarfed by the impact of uncertainty in climate forcing, which in turn is contingent on choices made about future anthropogenic emissions.\n",
      "  - A persistent feature of empirical climate sensitivity estimates is their heavy tailed probability distribution indicating a sizeable probability of high sensitivities. Previous studies make general claims that this upper heavy tail is an unavoidable feature of (i) the Earth system, or of (ii) limitations in our observational capabilities. Here we show that reducing the uncertainty about (i) oceanic heat uptake and (ii) aerosol climate forcing can—in principle—cut off this heavy upper tail of climate sensitivity estimates. Observations of oceanic heat uptake result in a negatively correlated joint likelihood function of climate sensitivity and ocean vertical diffusivity. This correlation is opposite to the positive correlation resulting from observations of surface air temperatures. As a result, the two observational constraints can rule out complementary regions in the climate sensitivity‐vertical diffusivity space, and cut off the heavy upper tail of the marginal climate sensitivity estimate.\n",
      "--------------------------------------------------\n",
      "Topic 405: 405_gross income_income_water supply_mar\n",
      "Representative Documents:\n",
      "  - The western U.S. is expected to experience more frequent and severe droughts as a result of climate change, with potentially large impacts on agricultural production and the economy. Irrigated farmers have multiple options for minimizing the impact of drought including switching to more efficient irrigation technologies. More efficient technologies that increase the fraction of the water available to the crop root zone would allow farmers to maintain current production levels with less water. However, these systems are capital intensive. The objective of this study is to explore when (and under what climatic conditions) it makes economic sense for farmers to invest in new irrigation systems. We examine this in the Yakima River Basin in Washington State of the U.S. We use VIC‐CropSyst, a large‐scale grid‐based modeling framework that mechanistically simulates hydrologic and agricultural processes. Water supply simulated by VIC‐CropSyst drives a river system and water management model (YAK‐RW). A computational platform was developed to perform the economic analysis for each grid cell, crop type, and future climate scenario separately, which allowed us to explore whether the implementation of more efficient irrigation systems would be economically viable. Our results indicate that investing in a more efficient irrigation system improves agricultural economy of the Yakima River Basin (9% −25%). We also show that at the farm level, more significant droughts can provide economic incentives for investment up to a point. For severe climate change projections, droughts become frequent and severe enough that economic benefits of improving water use efficiency do not exceed investment costs.\n",
      "  - Two approaches to augment irrigation water supply are managed aquifer recharge (MAR) and on‐farm reservoirs with tail‐water recovery (OFS‐TWR). We explore the joint use of MAR and OFS‐TWR to sustain groundwater and agricultural income with climate variability by farmer risk preference. We find that MAR use declines slightly with greater risk aversion and declines rapidly with MAR cost. The use of OFS‐TWR increases with risk aversion. The use of MAR increases income by a larger percentage for risk‐neutral than very risk‐averse producers. Across risk aversion degree, the use of MAR leads to a percentage increase in income that is double the percentage increase in the standard deviation of income (i.e., income risk). At a low cost of MAR, there is little difference in MAR use between a very risk‐averse and a risk‐neutral producer across scenarios of crop profit margin and the initial depth to water. Large differences in OFS‐TWR use between a very risk‐averse and a risk‐neutral producer occur when there are relatively high crop profit margin, low initial water depth, or a low discount rate.\n",
      "  -  In an earlier paper (Kirby et al. 2014a), we showed that climate change and a new policy which reallocates water to the environment will impact both the flow of water and the income derived from irrigation in the Murray–Darling Basin. Here, we extend the analysis to consider irrigator and environmental water management strategies to adapt to these new circumstances. Using an integrated hydrology-economics model, we examine a range of strategies and their impact on flows and the gross income of irrigation.  We show that the adaptation strategies provide a range of flow and economic outcomes in the Basin. Several strategies offer significant scope to enhance flows without large adverse impacts on the gross income of irrigation overall. Some environmental water management strategies enhance flows in the Murray part of the basin even under the drying influence of a projected median climate change. Irrigator strategies that include carryover of water in storage from one year to the next provide for lesser year to year variability in gross income and may be regarded as more advantageous in providing security against droughts. Flows and the gross income of low value irrigation industries strategies are sensitive to climate change, irrespective of adaptation strategy. Should a projected dry extreme climate change be realized, no strategy can prevent a large reduction in flows and also in gross income, particularly of low value irrigation industries. Nevertheless, environmental water management strategies mitigate the impact on flows, and in some cases may also help mitigate the impacts on gross income. High value irrigation industries are less affected (in terms of gross income, though net income will reduce because of rising water prices) by projected climate change, consistent with observation in the recent long term drought. \n",
      "--------------------------------------------------\n",
      "Topic 406: 406_ice_sea ice_atlantic_sea\n",
      "Representative Documents:\n",
      "  -                The inception of the Little Ice Age (~1400–1700 AD) is believed to have been driven by an interplay of external forcing and climate system internal variability. While the hemispheric signal seems to have been dominated by solar irradiance and volcanic eruptions, the understanding of mechanisms shaping the climate on a continental scale is less robust. In an ensemble of transient model simulations and a new type of sensitivity experiments with artificial sea ice growth, the authors identify a sea ice–ocean–atmosphere feedback mechanism that amplifies the Little Ice Age cooling in the North Atlantic–European region and produces the temperature pattern suggested by paleoclimatic reconstructions. Initiated by increasing negative forcing, the Arctic sea ice substantially expands at the beginning of the Little Ice Age. The excess of sea ice is exported to the subpolar North Atlantic, where it melts, thereby weakening convection of the ocean. Consequently, northward ocean heat transport is reduced, reinforcing the expansion of the sea ice and the cooling of the Northern Hemisphere. In the Nordic Seas, sea surface height anomalies cause the oceanic recirculation to strengthen at the expense of the warm Barents Sea inflow, thereby further reinforcing sea ice growth. The absent ocean–atmosphere heat flux in the Barents Sea results in an amplified cooling over Northern Europe. The positive nature of this feedback mechanism enables sea ice to remain in an expanded state for decades up to a century, favoring sustained cold periods over Europe such as the Little Ice Age. Support for the feedback mechanism comes from recent proxy reconstructions around the Nordic Seas.\n",
      "  - Present global warming is amplified in the Arctic and accompanied by unprecedented sea ice decline. Located along the main pathway of Atlantic Water entering the Arctic, the Barents Sea is the site of coupled feedback processes that are important for creating variability in the entire Arctic air‐ice‐ocean system. As warm Atlantic Water flows through the Barents Sea, it loses heat to the Arctic atmosphere. Warm periods, like today, are associated with high northward heat transport, reduced Arctic sea ice cover, and high surface air temperatures. The cooling of the Atlantic inflow creates dense water sinking to great depths in the Arctic Basins, and ~60% of the Arctic Ocean carbon uptake is removed from the carbon‐saturated surface this way. Recently, anomalously large ocean heat transport has reduced sea ice formation in the Barents Sea during winter. The missing Barents Sea winter ice makes up a large part of observed winter Arctic sea ice loss, and in 2050, the Barents Sea is projected to be largely ice free throughout the year, with 4°C summer warming in the formerly ice‐covered areas. The heating of the Barents atmosphere plays an important role both in “Arctic amplification” and the Arctic heat budget. The heating also perturbs the large‐scale circulation through expansion of the Siberian High northward, with a possible link to recent continental wintertime cooling. Large air‐ice‐ocean variability is evident in proxy records of past climate conditions, suggesting that the Barents Sea has had an important role in Northern Hemisphere climate for, at least, the last 2500 years.\n",
      "  - An important question is will deep convection sites, where deep waters are ventilated and air-gas exchange into the deep ocean occurs, emerge in the Arctic Ocean with the warming climate. As sea ice retreats northward and as Arctic sea ice becomes younger and thinner, air-sea interactions are strengthening in the high-latitude oceans. This includes new and extreme deep convection events. We investigate the associated physical processes and examine impacts and implications. Focusing on a region near the Arctic gateway of Fram Strait, our study confirms a significant sea ice cover reduction north of Svalbard in 2018 compared to the past decade, shown in observations and several numerical studies. We conduct our study using the regional configuration Arctic and North Hemisphere Atlantic of the ocean/sea ice model NEMO, running at 1/12° resolution (ANHA12). Our numerical study shows that the open water condition during the winter of 2018 allows intense winter convection over the Yermak Plateau, as more oceanic heat is lost to the atmosphere without the insulating sea ice cover, causing the mixed layer depth to reach over 600 m. Anomalous wind prior to the deep convection event forces offshore sea ice movement and contributes to the reduced sea ice cover. The sea ice loss is also attributed to the excess heat brought by the Atlantic Water, which reaches its maximum in the preceding winter in Fram Strait. The deep convection event coincides with enhanced mesoscale eddy activity on the boundary of the Yermak Plateau, especially to the east. The resulting substantial heat loss to the atmosphere also leads to a heat content reduction integrated over the Yermak Plateau region. This event can be linked to the minimum southward sea ice volume flux through Fram Strait in 2018, which is a potential negative freshwater anomaly in the subpolar Atlantic.\n",
      "--------------------------------------------------\n",
      "Topic 407: 407_dansgaard oeschger_oeschger_dansgaard_greenland\n",
      "Representative Documents:\n",
      "  - . Dansgaard–Oeschger events are a prominent mode of variability in the records of the last glacial cycle. Various prototype models have been proposed to explain these rapid climate fluctuations, and no agreement has emerged on which may be the more correct for describing the palaeoclimatic signal. In this work, we assess the bimodality of the system, reconstructing the topology of the multi-dimensional attractor over which the climate system evolves. We use high-resolution ice core isotope data to investigate the statistical properties of the climate fluctuations in the period before the onset of the abrupt change. We show that Dansgaard–Oeschger events have weak early warning signals if the ensemble of events is considered. We find that the statistics are consistent with the switches between two different climate equilibrium states in response to a changing external forcing (e.g. solar, ice sheets), either forcing directly the transition or pacing it through stochastic resonance. These findings are most consistent with a model that associates Dansgaard–Oeschger with changing boundary conditions, and with the presence of a bifurcation point.                    \n",
      "  - . At scales much longer than the deterministic predictability limits (about 10 days), the statistics of the atmosphere undergoes a drastic transition, the high-frequency weather acts as a random forcing on the lower-frequency macroweather. In addition, up to decadal and centennial scales the equivalent radiative forcings of solar, volcanic and anthropogenic perturbations are small compared to the mean incoming solar flux. This justifies the common practice of reducing forcings to radiative equivalents (which are assumed to combine linearly), as well as the development of linear stochastic models, including for forecasting at monthly to decadal scales. In order to clarify the validity of the linearity assumption and determine its scale range, we use last millennium simulations, with both the simplified Zebiak–Cane (ZC) model and the NASA GISS E2-R fully coupled GCM. We systematically compare the statistical properties of solar-only, volcanic-only and combined solar and volcanic forcings over the range of timescales from 1 to 1000 years. We also compare the statistics to multiproxy temperature reconstructions. The main findings are (a) that the variability in the ZC and GCM models is too weak at centennial and longer scales; (b) for longer than  ≈  50 years, the solar and volcanic forcings combine subadditively (nonlinearly) compounding the weakness of the response; and (c) the models display another nonlinear effect at shorter timescales: their sensitivities are much higher for weak forcing than for strong forcing (their intermittencies are different) and we quantify this with statistical scaling exponents.\n",
      "  - . We investigate both the European Project for Ice Coring in Antarctica Dronning Maud Land (EDML) and North Greenland Ice-Core Project (NGRIP) data sets to study both the time evolution of the so-called Dansgaard–Oeschger events and the dynamics at longer timescales during the last glacial period. Empirical mode decomposition (EMD) is used to extract the proper modes of both the data sets. It is shown that the time behavior at the typical timescales of Dansgaard–Oeschger events is captured through signal reconstructions obtained by summing five EMD modes for NGRIP and four EMD modes for EDML. The reconstructions obtained by summing the successive modes can be used to describe the climate evolution at longer timescales, characterized by intervals in which Dansgaard–Oeschger events happen and intervals when these are not observed. Using EMD signal reconstructions and a simple model based on the one-dimensional Langevin equation, it is argued that the occurrence of a Dansgaard–Oeschger event can be described as an excitation of the climate system within the same state, while the longer timescale behavior appears to be due to transitions between different climate states. Finally, on the basis of a cross-correlation analysis performed on EMD reconstructions, evidence that the Antarctic climate changes lead those of Greenland by a lag of &amp;amp;approx; 3.05 kyr is presented.                    \n",
      "--------------------------------------------------\n",
      "Topic 408: 408_yield_anthesis_wheat yield_crop\n",
      "Representative Documents:\n",
      "  - Northeast China (NEC) is a region sensitive to climate change. However, the adoption of long-season maize cultivars in NEC has caused a substantial yield increase under climate change conditions. It is important to determine whether such cultivar adoptions are effective throughout the whole NEC to sustainably increase grain yield. In this study, phenological observations and meteorological data at six sites from 1981 to 2018 were used to detect thermal time (TT) trends during the maize growing period. TT, as a parameter for measuring changes in maize cultivars, was used in the crop simulation model CERES-Maize to examine the variations in maize yield produced with different cultivar × climate combinations in different decades. In NEC, both TTs from emergence to anthesis and from anthesis to physiological maturity showed significant increasing trends from 1981 to 2018. Simulation results for humid areas revealed that adopting longer-season cultivars during 2000–2018 caused yield increases, ranging from 6.3% to 13.3%, compared with the 1980s. However, for stations in semi-humid areas, maize grain yield showed a decrease or a small increase (from −12.7% to 8.0%) when longer-season cultivars were adopted during 2000–2018. For semi-humid areas, decreasing trends in the ratios of rainfed yield to no water-stress yield (Yrainfed/Yno water-stress) and lower Yrainfed/Yno water-stress values during 2000–2018 indicated a growing sensitivity of maize production to water, which was attributed to changes in TT and precipitation. Our results indicate that, for the semi-humid area, maize yield was limited by water after introducing cultivars with higher TT requirement under climate change conditions. Therefore, securing food supplies will depend on increases in water-use efficiency levels and other adaptive strategies, such as varietal diversification, drought-resistant varieties, conservation tillage and irrigation.\n",
      "  - Understanding the impact of the warming trend on phenological stages and phases of cotton (Gossypium hirsutum L.) in central and lower Punjab, Pakistan, may assist in optimizing crop management practices to enhance production. This study determined the influence of the thermal trend on cotton phenology from 1980–2015 in 15 selected locations. The results demonstrated that observed phenological stages including sowing (S), emergence (E), anthesis (A) and physiological maturity (M) occurred earlier by, on average, 5.35, 5.08, 2.87 and 1.12 days decade−1, respectively. Phenological phases, sowing anthesis (S-A), anthesis to maturity (A-M) and sowing to maturity (S-M) were reduced by, on average, 2.45, 1.76 and 4.23 days decade−1, respectively. Observed sowing, emergence, anthesis and maturity were negatively correlated with air temperature by, on average, −2.03, −1.93, −1.09 and −0.42 days °C−1, respectively. Observed sowing-anthesis, anthesis to maturity and sowing-maturity were also negatively correlated with temperature by, on average, −0.94, −0.67 and −1.61 days °C−1, respectively. Applying the cropping system model CSM-CROPGRO-Cotton model using a standard variety in all locations indicated that the model-predicted phenology accelerated more due to warming trends than field-observed phenology. However, 30.21% of the harmful influence of the thermal trend was compensated as a result of introducing new cotton cultivars with higher growing degree day (thermal time) requirements. Therefore, new cotton cultivars which have higher thermal times and are high temperature tolerant should be evolved.\n",
      "  - Yield is influenced by the length of the growing season, which is affected by weather conditions and management practices of a crop, including sowing dates and shifting of cultivars. It is necessary to understand the effects of agronomic management practices and weather variables on phenological stages and crop phases in order to develop strategies for adaptation of agricultural systems to changes in climatic conditions. The goal of this study was to determine the impact of warming trends on phenology of canola from 1980 to 2014 for central and southern Punjab, Pakistan. Sowing, emergence, anthesis and physiological maturity dates were delayed by an average of 6.02, 3.14, 3.31 and 1.89 days per decade, respectively. The duration of sowing to anthesis, sowing to physiological maturity and anthesis to physiological maturity phases decreased an average 2.71, 4.13 and 1.42 days per decade, respectively, for all 10 locations that were analysed in this study. The sowing, emergence, anthesis and physiological maturity dates were positively correlated with an increase in temperature by an average 2.71, 1.41, 1.49 and 0.85 days per °C, respectively. However, the phenological phases such as sowing to anthesis, anthesis to maturity and sowing to maturity were negatively correlated with an increase in temperature by an average of 1.22, 0.64 and 1.86 days per °C, respectively, for all 10 locations. Applying a process‐based CSM‐CROPGRO‐Canola model using a standard cultivar (field tested) for all locations and years indicated that the simulated phenological stages occurred earlier due to the warming trend compared to the observed phenological stages. One‐quarter of the negative effects of this thermal trend was compensated by growing new cultivars that had higher thermal time requirements. Therefore, new canola genotypes with a higher number of growing degree day requirement and high temperature tolerance should be a priority for evolving new cultivars.\n",
      "--------------------------------------------------\n",
      "Topic 409: 409_t2dm_cvc_vasodilation_cvcmax\n",
      "Representative Documents:\n",
      "  -  Cutaneous sensory nerve-mediated vasodilation is an important component of normal microvascular responsiveness to thermal and nonthermal stimuli. Since both neural and microvascular function can be impaired in type 2 diabetes mellitus (T2DM), we tested the hypothesis that local sensory nerve-mediated vasodilation during nonpainful local warming of the skin is less in T2DM compared with healthy controls (C) matched for age and body size. The rapid vasodilation during the first ∼5 min of this local warming (“initial peak”) was previously shown to rely primarily on local sensory nerves. We measured skin blood flow in T2DM and C subjects ( n = 7 in each group) at baseline and during 35 min of local warming of the skin to 42°C at two sites on the ventral forearm. One site was pretreated with 4% lidocaine (LIDO) to block local sensory innervation. During local warming, cutaneous vascular conductance (CVC) during the initial peak was not different between groups, either at the untreated site [T2DM 75 ± 2 vs. C 81 ± 6% of maximum CVC (%maxCVC); P &gt; 0.05] or at the LIDO site (T2DM 63 ± 7 vs. C 64 ± 6%maxCVC; P &gt; 0.05). The difference between untreated and LIDO sites (sensory nerve contribution) was also similar between groups (T2DM 13 ± 5 vs. C 18 ± 5%maxCVC; P &gt; 0.05) and was smaller with LIDO than was previously shown with other local anesthetics. Our results suggest that relatively healthy individuals with T2DM do not exhibit impairments in local sensory nerve vasodilation during thermal stimulation compared with controls of similar age and body size. \n",
      "  -  Nitric oxide (NO) participates in the cutaneous vasodilation caused by increased local skin temperature (Tloc) and whole body heat stress in humans. In forearm skin, endothelial NO synthase (eNOS) participates in vasodilation due to elevated Tloc and neuronal NO synthase (nNOS) participates in vasodilation due to heat stress. To explore the relative roles and interactions of these isoforms, we examined the effects of a relatively specific eNOS inhibitor, Nω-amino-l-arginine (LNAA), and a specific nNOS inhibitor, Nω-propyl-l-arginine (NPLA), both separately and in combination, on skin blood flow (SkBF) responses to increased Tloc and heat stress in two protocols. In each protocol, SkBF was monitored by laser-Doppler flowmetry (LDF) and mean arterial pressure (MAP) by Finapres. Cutaneous vascular conductance (CVC) was calculated (CVC = LDF/MAP). Intradermal microdialysis was used to treat one site with 5 mM LNAA, another with 5 mM NPLA, a third with combined 5 mM LNAA and 5 mM NPLA (Mix), and a fourth site with Ringer only. In protocol 1, Tloc was controlled with combined LDF/local heating units. Tloc was increased from 34°C to 41.5°C to cause local vasodilation. In protocol 2, after a period of normothermia, whole body heat stress was induced (water-perfused suits). At the end of each protocol, all sites were perfused with 58 mM nitroprusside to effect maximal vasodilation for data normalization. In protocol 1, at Tloc = 34°C, CVC did not differ between sites ( P &gt; 0.05). LNAA and Mix attenuated CVC increases at Tloc = 41.5°C to similar extents ( P &lt; 0.05, LNAA or Mix vs. untreated or NPLA). In protocol 2, in normothermia, CVC did not differ between sites ( P &gt; 0.05). During heat stress, NPLA and Mix attenuated CVC increases to similar extents, but no significant attenuation occurred with LNAA ( P &lt; 0.05, NPLA or Mix vs. untreated or LNAA). In forearm skin, eNOS mediates the vasodilator response to increased Tloc and nNOS mediates the vasodilator response to heat stress. The two isoforms do not appear to interact during either response. \n",
      "  -  We hypothesized that nitric oxide activation of soluble guanylyl cyclase (sGC) participates in cutaneous vasodilation during whole body heat stress and local skin warming. We examined the effects of the sGC inhibitor, 1H-[1,2,4]oxadiazolo[4,3-a]quinoxalin-1-one (ODQ), on reflex skin blood flow responses to whole body heat stress and on nonreflex responses to increased local skin temperature. Blood flow was monitored by laser-Doppler flowmetry, and blood pressure by Finapres to calculate cutaneous vascular conductance (CVC). Intradermal microdialysis was used to treat one site with 1 mM ODQ in 2% DMSO and Ringer, a second site with 2% DMSO in Ringer, and a third site received Ringer. In protocol 1, after a period of normothermia, whole body heat stress was induced. In protocol 2, local heating units warmed local skin temperature from 34 to 41°C to cause local vasodilation. In protocol 1, in normothermia, CVC did not differ among sites [ODQ, 15 ± 3% maximum CVC (CVCmax); DMSO, 14 ± 3% CVCmax; Ringer, 17 ± 6% CVCmax; P &gt; 0.05]. During heat stress, ODQ attenuated CVC increases (ODQ, 54 ± 4% CVCmax; DMSO, 64 ± 4% CVCmax; Ringer, 63 ± 4% CVCmax; P &lt; 0.05, ODQ vs. DMSO or Ringer). In protocol 2, at 34°C local temperature, CVC did not differ among sites (ODQ, 17 ± 2% CVCmax; DMSO, 18 ± 4% CVCmax; Ringer, 18 ± 3% CVCmax; P &gt; 0.05). ODQ attenuated CVC increases at 41°C local temperature (ODQ, 54 ± 5% CVCmax; DMSO, 86 ± 4% CVCmax; Ringer, 90 ± 2% CVCmax; P &lt; 0.05 ODQ vs. DMSO or Ringer). sGC participates in neurogenic active vasodilation during heat stress and in the local response to direct skin warming. \n",
      "--------------------------------------------------\n",
      "Topic 410: 410_rice genotypes_genotypes_rice_construction\n",
      "Representative Documents:\n",
      "  -                Productivity is a significant aspect of construction industry that plays vital role for success and failure of any construction project. This industry generates 11% to 13% of GDP all around the globe and the cost of labour in any building project is 20% to 35% of the cost of Building. On daily basis labour utilizes 30% of time on productive activities rest 70% of the time is ruined in non-productive activities, there are multi factors which are affecting the labour production in construction industry hence this study provides an overview of productivity, Total Factor productivity, method used to measure accurate productivity in construction projects. The objective of this study is find out percentage up to what extent labour production is affected due to weather conditions, however this study is carried out in arid climate region in Month of June 2018, where minimum temperature was recorded 26.0 Celsius degree at 7:30 AM and Maximum was 47.80 Celsius degree at 3:00 PM. A descriptive survey research design approach was adopted using continuous observation method of study. Project work study manual served as the research instrument to collect the data on selected building sites for 30 working days. Data collected were analyzed using descriptive statics. The results show that average monthly production of mason gang was recorded with less production of 28.759%, Carpentry gang with average monthly loss of production 16.74% &amp; steel fixer gang had average monthly loss of production was 12.188. This concludes that prior to signing the contract for construction project. The location, environment, topography of region, capacity of construction operatives must be kept in mind to decide the proper timeline for the successful of project.\n",
      "  - Present paper deals with different components of next generation phenomics for characterizing rice genotypes for water deficit stress. Major sensors used in the study were non-imaging hyperspectal remote sensing, thermal imaging at ground platform and RGB and multispectral imaging sensors from drone platform. Different spectral indices were evaluated along with new proposed index and different multivariate models were studied for non-invasive estimation of relative water content (RWC) and sugar content in rice plant using spectral reflectance data collected in spectral range 350 to 2500 nm. Spectral data were further used for spectral discrimination of rice genotypes. Crop water stress index derived from thermal images acquired for rice genotypes could well characterize the drought resistant and sensitive genotypes. Initial study on field phenotyping through drone remote sensing using multispectral and RGB sensor was also explored to capture differential response of genotypes, trait and heat map mapping. All developed protocols as reliable alternative to conventional methods are fast, economic and non-invasive and in use in plant phenomics centre for high throughput plant phenotyhping for water deficit stress studies.\n",
      "  - Present paper deals with different components of next generation phenomics for characterizing rice genotypes for water deficit stress. Major sensors used in the study were non-imaging hyperspectal remote sensing, thermal imaging at ground platform and RGB and multispectral imaging sensors from drone platform. Different spectral indices were evaluated along with new proposed index and different multivariate models were studied for non-invasive estimation of relative water content (RWC) and sugar content in rice plant using spectral reflectance data collected in spectral range 350 to 2500 nm. Spectral data were further used for spectral discrimination of rice genotypes. Crop water stress index derived from thermal images acquired for rice genotypes could well characterize the drought resistant and sensitive genotypes. Initial study on field phenotyping through drone remote sensing using multispectral and RGB sensor was also explored to capture differential response of genotypes, trait and heat map mapping. All developed protocols as reliable alternative to conventional methods are fast, economic and non-invasive and in use in plant phenomics centre for high throughput plant phenotyhping for water deficit stress studies.\n",
      "--------------------------------------------------\n",
      "Topic 411: 411_key_regime characteristics_levee_flood\n",
      "Representative Documents:\n",
      "  - Key PointsSpatially distributed measure of water stress integrates supply and demandMetric assesses risk posed by within year and over-year variations in supplyMuch of the water concerns could be alleviated without significant modifications\n",
      "  - Key PointsPeak discharge and runoff ratio distributions vary greatly between urban basinsStormwater detention infrastructure increases response times and runoff ratiosSpatial and temporal properties of flood‐producing rainfall vary over the basins\n",
      "  - Key PointsWe characterize key deep uncertainties surrounding flood risk projections for a levee ring in New Orleans using 18 probabilistic scenariosThe levee system alone may provide flood protection between the 100‐ and 500‐year return periodUncertainty in the storm surge distribution shape parameter is the primary driver of flood risk variability\n",
      "--------------------------------------------------\n",
      "Topic 412: 412_ozone_clo_vortex_september\n",
      "Representative Documents:\n",
      "  - . Middle atmospheric ozone, water vapour and zonal and meridional wind profiles have been measured with the two ground-based microwave radiometers GROMOS-C and MIAWARA-C.The instruments have been located at the Arctic research base AWIPEV at Ny-Ålesund, Svalbard (79∘ N, 12∘ E), since September 2015. GROMOS-C measures ozone spectra in the four cardinal directions with an elevation angle of 22∘.This means that the probed air masses at an altitude of 3 hPa (37 km) have a horizontal distance of 92 km to Ny-Ålesund. We retrieve four separate ozone profiles along the lines of sight and calculate daily mean horizontal ozone gradients which allow us to investigate the small-scale spatial variability of ozone above Ny-Ålesund.We present the evolution of the ozone gradients at Ny-Ålesund during winter 2018/2019, when a major sudden stratospheric warming (SSW) took place with the central date at 2 January, and link it to the planetary wave activity.We further analyse the SSW and discuss our ozone and water vapour measurements in a global context.At 3 hPa we find a distinct seasonal variation of the ozone gradients.The strong polar vortex during October and March results in a decreasing ozone volume mixing ratio towards the pole. In November the amplitudes of the planetary waves grow until they break in the end of December and an SSW takes place.From November until February ozone increases towards higher latitudes and the magnitude of the ozone gradients is smaller than in October and March. We attribute this to the planetary wave activity of wave numbers 1 and 2 which enabled meridional transport. The MERRA-2 reanalysis and the SD-WACCM model are able to capture the small-scale ozone variability and its seasonal changes.                    \n",
      "  - The 3D version of the Chemical Lagrangian Model of the Stratosphere (CLAMS) is used to study the transport of CH4 and O3 in the Antarctic stratosphere between 1 September and 30 November 2002, that is, over the time period when unprecedented major stratospheric warming in late September split the polar vortex into two parts. The isentropic and cross-isentropic velocities in CLAMS are derived from ECMWF winds and heating/cooling rates calculated with a radiation module. The irreversible part of transport, that is, mixing, is driven by the local horizontal strain and vertical shear rates with mixing parameters deduced from in situ observations.The CH4 distribution after the vortex split shows a completely different behavior above and below 600 K. Above this potential temperature level, until the beginning of November, a significant part of vortex air is transported into the midlatitudes up to 40°S. The lifetime of the vortex remnants formed after the vortex split decreases with the altitude with values of about 3 and 6 weeks at 900 and 700 K, respectively.Despite this enormous dynamical disturbance of the vortex, the intact part between 400 and 600 K that “survived” the major warming was strongly isolated from the extravortex air until the end of November. According to CLAMS simulations, the air masses within this part of the vortex did not experience any significant dilution with the midlatitude air.By transporting ozone in CLAMS as a passive tracer, the chemical ozone loss was estimated from the difference between the observed [Polar Ozone and Aerosol Measurement III (POAM III) and Halogen Occultation Experiment (HALOE)] and simulated ozone profiles. Starting from 1 September, up to 2.0 ppmv O3 around 480 K and about 70 Dobson units between 450 and 550 K were destroyed until the vortex was split. After the major warming, no additional ozone loss can be derived, but in the intact vortex part between 450 and 550 K, the accumulated ozone loss was “frozen in” until the end of November.\n",
      "  - In September 2002 the Antarctic polar vortex split in two under the influence of a sudden warming. During this event, the Odin satellite was able to measure both ozone (O3) and chlorine monoxide (ClO), a key constituent responsible for the so‐called “ozone hole”, together with nitrous oxide (N2O), a dynamical tracer, and nitric acid (HNO3) and nitrogen dioxide (NO2), tracers of denitrification. The submillimeter radiometer (SMR) microwave instrument and the Optical Spectrograph and Infrared Imager System (OSIRIS) UV‐visible light spectrometer (VIS) and IR instrument on board Odin have sounded the polar vortex during three different periods: before (19–20 September), during (24–25 September), and after (1–2 and 4–5 October) the vortex split. Odin observations coupled with the Reactive Processes Ruling the Ozone Budget in the Stratosphere (REPROBUS) chemical transport model at and above 500 K isentropic surfaces (heights above 18 km) reveal that on 19–20 September the Antarctic vortex was dynamically stable and chemically nominal: denitrified, with a nearly complete chlorine activation, and a 70% O3 loss at 500 K. On 25–26 September the unusual morphology of the vortex is monitored by the N2O observations. The measured ClO decay is consistent with other observations performed in 2002 and in the past. The vortex split episode is followed by a nearly complete deactivation of the ClO radicals on 1–2 October, leading to the end of the chemical O3 loss, while HNO3 and NO2 fields start increasing. This acceleration of the chlorine deactivation results from the warming of the Antarctic vortex in 2002, putting an early end to the polar stratospheric cloud season. The model simulation suggests that the vortex elongation toward regions of strong solar irradiance also favored the rapid reformation of ClONO2. The observed dynamical and chemical evolution of the 2002 polar vortex is qualitatively well reproduced by REPROBUS. Quantitative differences are mainly attributable to the too weak amounts of HNO3 in the model, which do not produce enough NO2 in presence of sunlight to deactivate chlorine as fast as observed by Odin.\n",
      "--------------------------------------------------\n",
      "Topic 413: 413_isotope_samples_wet oxidation_δ13c\n",
      "Representative Documents:\n",
      "  - RationaleThe stable isotopic compositions of biogenic carbonates like fish otoliths (ear bones) are widely used for palaeoclimatic reconstruction. The conventional method using acid‐digestion of micro‐milled samples is a multi‐step time‐consuming process. Here we report a fast method based on laser heating of otolith carbonates to obtain accurate and high‐resolution stable isotopic compositions.MethodOtoliths of catfish from the Gulf of Kutch were analysed to check the precision, accuracy and time‐resolution of the isotope ratios. The CO2, generated by heating otoliths with a 50 W CO2 laser, was analysed for its oxygen and carbon isotope ratio [δ18O and δ13C, with precision: 0.12 and 0.17‰ (1σ), accuracy: 0.13 and 0.25‰, respectively] using a continuous‐flow isotope ratio mass spectrometer. The effect of laser power (0.7–2 W) was assessed for reproducible data. Samples were roasted and analysed to account for the effect of the inherent organic matter on the isotopic values.ResultsRoasting did not alter the δ18O of the otoliths but increased the δ13C slightly. High‐resolution (125 μm) analysis of the right and left otolith of a fish yielded similar δ18O and δ13C values, suggesting the suitability of either of them for deriving the climate signal. An increase in δ18O values from ~ −2‰ to ~ −1‰, observed across the ontogeny, is consistent with the known migratory behaviour of the catfish between freshwater and the sea.ConclusionsThe otolith δ18O value of an adult fish records the sea surface temperature (with ~3°C uncertainty) on a monthly scale. The otolith δ13C values, with the knowledge of dietary δ13C, provide the mean annual δ13C value of dissolved inorganic carbon. The study provides a rapid method for retrieving high‐resolution seasonal climate data from otoliths found aplenty in geological/archaeological records.\n",
      "  - . A new online method to analyse water isotopes of speleothem fluid inclusions using a wavelength scanned cavity ring down spectroscopy (WS-CRDS) instrument is presented. This novel technique allows us simultaneously to measure hydrogen and oxygen isotopes for a released aliquot of water. To do so, we designed a new simple line that allows the online water extraction and isotope analysis of speleothem samples. The specificity of the method lies in the fact that fluid inclusions release is made on a standard water background, which mainly improves the δ D robustness.  To saturate the line, a peristaltic pump continuously injects standard water into the line that is permanently heated to 140 °C and flushed with dry nitrogen gas. This permits instantaneous and complete vaporisation of the standard water, resulting in an artificial water background with well-known δ D and δ18O values. The speleothem sample is placed in a copper tube, attached to the line, and after system stabilisation it is crushed using a simple hydraulic device to liberate speleothem fluid inclusions water. The released water is carried by the nitrogen/standard water gas stream directly to a Picarro L1102-i for isotope determination. To test the accuracy and reproducibility of the line and to measure standard water during speleothem measurements, a syringe injection unit was added to the line.  Peak evaluation is done similarly as in gas chromatography to obtain &amp;amp;delta D; and δ18O isotopic compositions of measured water aliquots. Precision is better than 1.5 ‰ for δ D and 0.4 ‰ for δ18O for water measurements for an extended range (−210 to 0 ‰ for δ D and −27 to 0 ‰ for δ18O) primarily dependent on the amount of water released from speleothem fluid inclusions and secondarily on the isotopic composition of the sample. The results show that WS-CRDS technology is suitable for speleothem fluid inclusion measurements and gives results that are comparable to the isotope ratio mass spectrometry (IRMS) technique.                    \n",
      "  - For ocean‐climate research, carbonates are extracted from large organic‐rich bulk sediments for specific geochemical analyses. This is conventionally achieved by time‐consuming dry oxidation or nonoxidative preprocessing. To significantly shorten sample preparation time we designed and evaluated a rapid technique that uses sequential wet oxidization of bulk samples in a hot alkaline 18% H2O2 solution. We successfully tested this wet oxidation technique on multiple bulk aliquots from two sediment trap samples and a core top sediment that were also processed by dry oxidation and without oxidation. From all aliquots four calcitic foraminifera species and an aragonitic juvenile bivalve from the 250–315 μm fraction were analyzed for size‐normalized weight (SNW), δ18O, δ13C, Mg/Ca, and Sr/Ca. In addition, these proxies were determined on powdered bulk aliquots from the 150–250 μm fraction processed by wet oxidation, dry oxidation, and without oxidation. At an initial pH of 8 and temperature of 70°C the alkaline H2O2 solution appeared to be most stable and reactive. Carbonate dissolution did not occur as no reduction was observed in SNW of the four foraminifera species G. ruber, G. trilobus, N. dutertrei, G. bulloides, and the aragonitic bivalve shells. For sediment traps the δ18O and δ13C between the three cleaning methods only deviated between 0.05 and 0.3‰ compared to 0.1 and 0.6‰ in sediments, with equally small variation in Mg/Ca and Sr/Ca ratios (0.1–0.4 mmol/mol). Lowest Ba/Ca ratios show that wet oxidation successfully removed organic matter along with residual salts. No significant systematic differences between samples or methods were found, but a residual scatter remained, particularly in the nonoxidized sediment because of intraspecies and intrashell inhomogeneity. Given proper preprocessing all three techniques performed well, with the proposed wet oxidation method emerging as a fast technique for extracting carbonate shells from wet, gram‐sized bulk samples. Within 3 h wet oxidation produced clean, dry residues of unaltered calcareous shells from batches of four wet bulk samples without time‐consuming intermediate steps. For Mg/Ca thermometry on time series sediment trap samples, wet oxidation results approached those obtained using the Barker et al. (2003) protocol with improved sample recovery. Consequently, the proposed wet oxidation offers a rapid alternative to conventional extraction techniques for carbonate geochemistry.\n",
      "--------------------------------------------------\n",
      "Topic 414: 414_uptake_co2 uptake_co2_see text uptake\n",
      "Representative Documents:\n",
      "  - The North Atlantic is one of the major sinks for anthropogenic carbon in the global ocean. Improved understanding of the underlying mechanisms is vital for constraining future projections, which presently have high uncertainties. To identify some of the causes behind this uncertainty, this study investigates the North Atlantic’s anthropogenically altered carbon uptake and inventory, that is, changes in carbon uptake and inventory due to rising atmospheric CO2and climate change (abbreviated as [Formula: see text]-uptake and [Formula: see text]-inventory). Focus is set on an ensemble of 11 Earth system models and their simulations of a future with high atmospheric CO2. Results show that the model spread in the [Formula: see text]-uptake originates in middle and high latitudes. Here, the annual cycle of oceanic pCO2reveals inherent model mechanisms that are responsible for different model behavior: while it is SST-dominated for models with a low future [Formula: see text]-uptake, it is dominated by deep winter mixing and biological production for models with a high future [Formula: see text]-uptake. Models with a high future [Formula: see text]-uptake show an efficient carbon sequestration and hence store a large fraction of their contemporary North Atlantic [Formula: see text]-inventory below 1000-m depth, while the opposite is true for models with a low future [Formula: see text]-uptake. Constraining the model ensemble with observation-based estimates of carbon sequestration and summer oceanic pCO2anomalies yields later flattening of the [Formula: see text]-uptake than previously estimated. This result highlights the need to depart from the concept of unconstrained model ensembles in order to reduce uncertainties associated with future projections.\n",
      "  -                The increase in atmospheric CO2 over this century depends on the evolution of the oceanic air–sea CO2 uptake, which will be driven by the combined response to rising atmospheric CO2 itself and climate change. Here, the future oceanic CO2 uptake is simulated using an ensemble of coupled climate–carbon cycle models. The models are driven by CO2 emissions from historical data and the Special Report on Emissions Scenarios (SRES) A2 high-emission scenario. A linear feedback analysis successfully separates the regional future (2010–2100) oceanic CO2 uptake into a CO2-induced component, due to rising atmospheric CO2 concentrations, and a climate-induced component, due to global warming. The models capture the observation-based magnitude and distribution of anthropogenic CO2 uptake. The distributions of the climate-induced component are broadly consistent between the models, with reduced CO2 uptake in the subpolar Southern Ocean and the equatorial regions, owing to decreased CO2 solubility; and reduced CO2 uptake in the midlatitudes, owing to decreased CO2 solubility and increased vertical stratification. The magnitude of the climate-induced component is sensitive to local warming in the southern extratropics, to large freshwater fluxes in the extratropical North Atlantic Ocean, and to small changes in the CO2 solubility in the equatorial regions. In key anthropogenic CO2 uptake regions, the climate-induced component offsets the CO2-induced component at a constant proportion up until the end of this century. This amounts to approximately 50% in the northern extratropics and 25% in the southern extratropics and equatorial regions. Consequently, the detection of climate change impacts on anthropogenic CO2 uptake may be difficult without monitoring additional tracers, such as oxygen.\n",
      "  - Marine biology plays an important role in the ocean carbon cycle. However, the effect of warming‐induced changes in biological rates on oceanic CO2 uptake has been largely overlooked. We use an Earth system model of intermediate complexity to investigate the effect of temperature‐induced changes in biological rates on oceanic uptake of atmospheric CO2 and compare it with the effects from warming‐induced changes in CO2 solubility and ocean mixing and circulation. Under the representative CO2 concentration pathway RCP 8.5 and its extension, by year 2500, relative to the simulation without warming effect on the ocean carbon cycle, CO2‐induced warming reduces cumulative oceanic CO2 uptake by 469 Pg C, of which about 20% is associated with the warming‐induced change in marine biological rates. In our simulations, the bulk effect of biological‐mediated changes on CO2 uptake is smaller than that mediated by changes in CO2 solubility and ocean mixing and circulation. However, warming‐induced changes in individual biological rates, including phytoplankton growth, phytoplankton mortality, and detritus remineralization, are found to affect oceanic CO2 uptake by an amount greater than or comparable to that caused by changes in CO2 solubility and ocean physics. Our simulations, which include only a few temperature‐dependent biological processes, demonstrate the important role of biological rates in the oceanic CO2 uptake. In reality, many more complicated biological processes are sensitive to temperature change, and their responses to warming could substantially affect oceanic uptake of atmospheric CO2.\n",
      "--------------------------------------------------\n",
      "Topic 415: 415_target_bioenergy_emissions_population affluence consumption\n",
      "Representative Documents:\n",
      "  - Human activities have caused global temperatures to increase by 1.25°C, and the current emissions trajectory suggests that we will exceed 1.5°C in less than 10 years. Though the growth rate of global carbon dioxide emissions has slowed and many countries have strengthened their emissions targets, current midcentury net zero goals are insufficient to limit global warming to 1.5°C above preindustrial temperatures. The primary barriers to the achievement of a 1.5°C-compatible pathway are not geophysical but rather reflect inertia in our political and technological systems. Both political and corporate leadership are needed to overcome this inertia, supported by increased societal recognition of the need for system-level and individual lifestyle changes. The available evidence does not yet indicate that the world has seriously committed to achieving the 1.5°C goal.\n",
      "  - The Intergovernmental Panel on Climate Change concludes that climate change has already caused substantial damages at the current 1.2°C of global warming and that warming of 1.5°C would elevate risks of a wide-range of climate tipping points. For example, wet-bulb temperatures are already exceeding safe levels, and the melting of the Greenland and West Antartic ice sheets would lead to over ten metres of sea level rise, representing an existential threat to coastal cities, low-lying nation states, and human wellbeing worldwide. We call for a broad scientific discussion about a stricter and more ambitious climate target of 1.0°C by the end of this century. Comprehensive electrification and highly renewable energy systems offer a pathway to sub-1.5°C futures through rapid defossilisation and large-scale, electricity-based carbon dioxide removal. Independent scenarios show that restoring a stable and safe climate is attainable with coordinated policy and economic support.\n",
      "  - Bioenergy can come to play a significant role in the global energy system and perhaps account for one fifth of global energy supply in 50 years in response to ambitions to reduce carbon dioxide emissions. But bioenergy is complicated. There are both traditional and modern forms. In this article, I will exclusively look at modern forms, i.e., biomass for electricity, transport and heat, and process heat (not traditional forms used for cooking in developing countries). Furthermore, there are both ‘good’ and ‘bad’ kinds, expensive and inexpensive technologies, bioenergy systems that lead to massive carbon dioxide emissions and systems that are carbon neutral, and even ones that remove carbon dioxide from the atmosphere while delivering energy. There is concern that certain bioenergy forms will, in response to increasing carbon prices, become so attractive that food prices increase significantly, that poor people are evicted from their lands, and that rainforest and other sensitive ecosystem are destroyed in order to pave the way for bioenergy plantations. This article offers a survey of these risks, and the policy instruments intended to deal with the challenges. WIREs Clim Change 2011 2 309–323 DOI: 10.1002/wcc.109This article is categorized under:The Carbon Economy and Climate Mitigation &gt; Decarbonizing Energy and/or Reducing Demand\n",
      "--------------------------------------------------\n",
      "Topic 416: 416_lizards_high elevation_climate warming_surface activity\n",
      "Representative Documents:\n",
      "  - Ongoing climate change has profoundly affected global biodiversity, but its impacts on populations across elevations remain understudied. Using mechanistic niche models incorporating species traits, we predicted ecophysiological responses (activity times, oxygen consumption and evaporative water loss) for lizard populations at high‐elevation (&lt;3600 m asl) and extra‐high‐elevation (≥3600 m asl) under recent (1970–2000) and future (2081–2100) climates. Compared with their high‐elevation counterparts, lizards from extra‐high‐elevation are predicted to experience a greater increase in activity time and oxygen consumption. By integrating these ecophysiological responses into hybrid species distribution models (HSDMs), we were able to make the following predictions under two warming scenarios (SSP1‐2.6, SSP5‐8.5). By 2081–2100, we predict that lizards at both high‐ and extra‐high‐elevation will shift upslope; lizards at extra‐high‐elevation will gain more and lose less habitat than will their high‐elevation congeners. We therefore advocate the conservation of high‐elevation species in the context of climate change, especially for those populations living close to their lower elevational range limits. In addition, by comparing the results from HSDMs and traditional species distribution models, we highlight the importance of considering intraspecific variation and local adaptation in physiological traits along elevational gradients when forecasting species' future distributions under climate change.\n",
      "  - A huge fraction of global biodiversity resides within biogenic habitats that ameliorate physical stresses. In most cases, details of how physical conditions within facilitative habitats respond to external climate forcing remain unknown, hampering climate change predictions for many of the world’s species. Using intertidal mussel beds as a model system, we characterize relationships among external climate conditions and within‐microhabitat heat and desiccation conditions. We use these data, along with physiological tolerances of two common inhabitant taxa (the isopod Cirolana harfordi and the porcelain crab Petrolisthes cinctipes), to examine the magnitude of climate risk inside and outside biogenic habitat, applying an empirically derived model of evaporation to simulate mortality risk under a high‐emissions climate‐warming scenario. We found that biogenic microhabitat conditions responded so weakly to external climate parameters that mortality risk was largely unaffected by climate warming. In contrast, outside the biogenic habitat, desiccation drove substantial mortality in both species, even at temperatures 4.4–8.6°C below their hydrated thermal tolerances. These findings emphasize the importance of warming‐exacerbated desiccation to climate‐change risk and the role of biogenic habitats in buffering this less‐appreciated stressor. Our results suggest that, when biogenic habitats remain intact, climate warming may have weak direct effects on organisms within them. Instead, risk to such taxa is likely to be indirect and tightly coupled with the fate of habitat‐forming populations. Conserving and restoring biogenic habitats that offer climate refugia could therefore be crucial to supporting biodiversity in the face of climate warming.\n",
      "  - Wildlife are faced with numerous threats to survival, none more pressing than that of climate change. Understanding how species will respond behaviorally, physiologically, and demographically to a changing climate is a cornerstone of many contemporary ecological studies, especially for organisms, such as amphibians, whose persistence is closely tied to abiotic conditions. Activity is a useful parameter for understanding the effects of climate change because activity is directly linked to fitness as it dictates foraging times, energy budgets, and mating opportunities. However, activity can be challenging to measure directly, especially for secretive organisms like plethodontid salamanders, which only become surface active when conditions are cool and moist because of their anatomical and physiological restrictions. We estimated abiotic predictors of surface activity for the seven species of the Plethodon jordani complex. Five independent data sets collected from 2004 to 2017 were used to determine the parameters driving salamander surface activity in the present day, which were then used to predict potential activity changes over the next 80 yrs. Average active seasonal temperature and vapor pressure deficit were the strongest predictors of salamander surface activity and, without physiological or behavioral modifications, salamanders were predicted to exhibit a higher probability of surface activity during peak active season under future climate conditions. Temperatures during the active season likely do not exceed salamander thermal maxima to cause activity suppression and, until physiological limits are reached, future conditions may continue to increase activity. Our model is the first comprehensive field‐based study to assess current and future surface activity probability. Our study provides insights into how a key behavior driving fitness may be affected by climate change.\n",
      "--------------------------------------------------\n",
      "Topic 417: 417_turfgrass_forest_fire_management\n",
      "Representative Documents:\n",
      "  - Core IdeasClimate change will affect temperature and precipitation patterns.Increasing temperatures will cause a shift in turfgrass species to more northen climates.Variation among varieties of turfgrass provide opportunity to increase climate resilience.Climate change will increase abiotic and biotic stresses on turfgrass.Climate change is occurring and is impacting biological systems through increased temperatures, more variable precipitation, and increased CO2 in the atmosphere. These effects have been documented for agricultural species, primarily grain crops, pasture and rangeland species. The extension of these relationships to turfgrass has been limited; however, these plants are an important part of our ecosystems and preservation of these plantings adds to social value and ecosystem services. Turfgrasses can be divided into cool‐season and warm‐season species and the projected changes in maximum air temperatures, along with increased root zone temperatures may promote a Northward migration of warm‐season turfgrasses. Increased spring precipitation and more variable summer precipitation coupled with more intense precipitation events are projected to occur requiring enhanced management of soil water. Turfgrass management to ensure adequate root zone soil water, and the selection of varieties or species with greater drought tolerance in the warmer regions will be necessary to preserve turfgrass plantings. Increases in CO2 benefits turfgrass growth and positively affects water use efficiency, which decreases the potential effects of a more variable precipitation regime because of impacts on soil water use. Genotypic variation in response to soil water deficits provides a foundation for screening turfgrass species to adapt to climatic stresses. Changes in temperature and precipitation variation will increase the potential for abiotic and biotic stresses on turfgrasses. Turfgrass management will require increased attention to increased abiotic and biotic stresses.\n",
      "  - Forest landscapes across western North America (wNA) have experienced extensive changes over the last two centuries, while climatic warming has become a global reality over the last four decades. Resulting interactions between historical increases in forested area and density and recent rapid warming, increasing insect mortality, and wildfire burned areas, are now leading to substantial abrupt landscape alterations. These outcomes are forcing forest planners and managers to identify strategies that can modify future outcomes that are ecologically and/or socially undesirable. Past forest management, including widespread harvest of fire‐ and climate‐tolerant large old trees and old forests, fire exclusion (both Indigenous and lightning ignitions), and highly effective wildfire suppression have contributed to the current state of wNA forests. These practices were successful at meeting short‐term demands, but they match poorly to modern realities. Hagmann et al. review a century of observations and multi‐scale, multi‐proxy, research evidence that details widespread changes in forested landscapes and wildfire regimes since the influx of European colonists. Over the preceding 10 millennia, large areas of wNA were already settled and proactively managed with intentional burning by Indigenous tribes. Prichard et al. then review the research on management practices historically applied by Indigenous tribes and currently applied by some managers to intentionally manage forests for resilient conditions. They address 10 questions surrounding the application and relevance of these management practices. Here, we highlight the main findings of both papers and offer recommendations for management. We discuss progress paralysis that often occurs with strict adherence to the precautionary principle; offer insights for dealing with the common problem of irreducible uncertainty and suggestions for reframing management and policy direction; and identify key knowledge gaps and research needs.\n",
      "  - We review science‐based adaptation strategies for western North American (wNA) forests that include restoring active fire regimes and fostering resilient structure and composition of forested landscapes. As part of the review, we address common questions associated with climate adaptation and realignment treatments that run counter to a broad consensus in the literature. These include the following: (1) Are the effects of fire exclusion overstated? If so, are treatments unwarranted and even counterproductive? (2) Is forest thinning alone sufficient to mitigate wildfire hazard? (3) Can forest thinning and prescribed burning solve the problem? (4) Should active forest management, including forest thinning, be concentrated in the wildland urban interface (WUI)? (5) Can wildfires on their own do the work of fuel treatments? (6) Is the primary objective of fuel reduction treatments to assist in future firefighting response and containment? (7) Do fuel treatments work under extreme fire weather? (8) Is the scale of the problem too great? Can we ever catch up? (9) Will planting more trees mitigate climate change in wNA forests? And (10) is post‐fire management needed or even ecologically justified? Based on our review of the scientific evidence, a range of proactive management actions are justified and necessary to keep pace with changing climatic and wildfire regimes and declining forest heterogeneity after severe wildfires. Science‐based adaptation options include the use of managed wildfire, prescribed burning, and coupled mechanical thinning and prescribed burning as is consistent with land management allocations and forest conditions. Although some current models of fire management in wNA are averse to short‐term risks and uncertainties, the long‐term environmental, social, and cultural consequences of wildfire management primarily grounded in fire suppression are well documented, highlighting an urgency to invest in intentional forest management and restoration of active fire regimes.\n",
      "--------------------------------------------------\n",
      "Topic 418: 418_aerosol_mh_cld_ozone\n",
      "Representative Documents:\n",
      "  - Surface ozone increased unexpectedly over northern China during the COVID-19 lockdown (CLD) period (23 January–29 February 2020), which was characterized by vigorous emission reduction. The reasons for this ozone enhancement have been speculated from perspectives of chemical responses to the emissions and meteorology. As known, the processes of natural stratospheric ozone injecting to the troposphere are most active in winter and spring. Yet, little attention was paid to stratospheric influences on this ozone enhancement. Here we report a stratospheric intrusion (SI) that reached the surface over northern China on 15–17 February during the CLD. The coevolution of enhanced ozone and sharply declined carbon monoxide and relative humidity (RH) was indicative of the SI occurrence. We show that the SI was facilitated by a cutoff low system that led to abnormally high surface ozone in most part of northern China. We estimate that over the SI period, the injected stratospheric ozone constituted up to 40–45% of the surface ozone over northern China. If the stratospheric ozone inputs were scaled over the entire CLD period, these inputs would account for 4–8% of the surface ozone. In view of the unexpected ozone increase during the CLD, this SI event could explain up to 18% of the ozone increase in some cities, and average 5–10% over larger areas that were affected. Hence, the nonnegligible stratospheric influences urge extra consideration of natural ozone sources in disentangling the role of emission reduction and meteorological conditions during the CLD in China and elsewhere in the world.\n",
      "  - Observations show that the Arctic sea ice cover has been shrinking at an unprecedented rate since the 1970s. Even though the accumulation of greenhouse gases in the atmosphere has been closely linked with the loss of Arctic sea ice, the role of atmospheric aerosols in past and future Arctic climate change remains elusive. Using a state-of-the-art fully coupled climate model, the authors assess the equilibrium responses of the Arctic sea ice to the different aerosol emission scenarios and investigate the pathways by which aerosols impose their influence in the Arctic. These sensitivity experiments show that the impacts of aerosol perturbations on the pace of sea ice melt effectively modulate the ocean circulation and atmospheric feedbacks. Because of the contrasting evolutions of particulate pollution in the developed and developing countries since the 1970s, the opposite aerosol forcings from different midlatitude regions are nearly canceled out in the Arctic during the boreal summer, resulting in a muted aerosol effect on the recent sea ice changes. Consequently, the greenhouse forcing alone can largely explain the observed Arctic sea ice loss up to the present. In the next few decades, the projected alleviation of particulate pollution in the Northern Hemisphere can contribute up to 20% of the total Arctic sea ice loss and 0.7°C surface warming over the Arctic. The authors’ model simulations further show that aerosol microphysical effects on the Arctic clouds are the major component in the total aerosol radiative forcing over the Arctic. Compared to the aerosol-induced energy imbalance in lower latitudes outside the Arctic, the local radiative forcing by aerosol variations within the Arctic, due to either local emissions or long-range transports, is more efficient in determining the sea ice changes and Arctic climate change.\n",
      "  - . The mid-Holocene (MH) is the most recent typical climate period and a subject of great interest in global paleocultural research. Following the latest Paleoclimate Modeling Intercomparison Project phase 4 (PMIP4) protocol and using a fully coupled climate model, we simulated the climate during both the MH and the preindustrial (PI) periods and quantified the effects of Earth orbital parameters (ORBs) and greenhouse gases (GHGs) on climate differences, focusing on the simulated differences in the Atlantic meridional overturning circulation (AMOC) between these two periods. Compared to the PI simulation, the ORB effect in the MH simulation led to seasonal enhancement of temperature, consistent with previous findings. In the MH simulation, the ORB effect led to a markedly warmer climate in the mid–high latitudes and increased precipitation in the Northern Hemisphere, which were partially offset by the cooling effect of the lower GHGs. The AMOC in the MH simulation was about 4 % stronger than that in the PI simulation. The ORB effect led to 6 % enhancement of the AMOC in the MH simulation, which was, however, partly neutralized by the GHG effect. Transient simulation from the MH to the PI further demonstrated the opposite effects of ORBs and GHGs on the evolution of the AMOC during the past 6000 years. The simulated stronger AMOC in the MH was mainly due to the thinner sea ice in the polar oceans caused by the ORB effect, which reduced the freshwater flux export to the subpolar Atlantic and resulted in a more saline North Atlantic. This study may help us quantitatively understand the roles of different external forcing factors in Earth's climate evolution since the MH.                    \n",
      "--------------------------------------------------\n",
      "Topic 419: 419_prize_agu_climate communication prize_communication prize\n",
      "Representative Documents:\n",
      "  - Jeffrey T. Kiehl was awarded the 2012 Climate Communication Prize at the AGU Fall Meeting Honors Ceremony, held on 5 December 2012 in San Francisco, Calif. The Climate Communication Prize is funded by Nature's Own, a purveyor of fossils, minerals, and handcrafted jewelry based in Boulder, Colo. The prize honors an “AGU member‐scientist for the communication of climate science, and highlights the importance of promoting scientific literacy, clarity of message, and efforts to foster respected and understanding of science‐based values as they relate to the implications of climate change.”\n",
      "  - Gavin A. Schmidt was awarded the 2011 Climate Communication Prize at the AGU Fall Meeting Honors Ceremony, held on 7 December in San Francisco, Calif. The Climate Communication Prize is funded by Nature's Own, a purveyor of fossils, minerals, and handcrafted jewelry in Boulder, Colo. The prize honors an “AGU member‐scientist for the communication of climate science, and highlights the importance of promoting scientific literacy, clarity of message, and efforts to foster respected and understanding of science‐based values as they relate to the implications of climate change.”\n",
      "  - Gavin A. Schmidt was awarded the 2011 Climate Communication Prize at the AGU Fall Meeting Honors Ceremony, held on 7 December in San Francisco, Calif. The Climate Communication Prize is funded by Nature's Own, a purveyor of fossils, minerals, and handcrafted jewelry in Boulder, Colo. The prize honors an “AGU member‐scientist for the communication of climate science, and highlights the importance of promoting scientific literacy, clarity of message, and efforts to foster respected and understanding of science‐based values as they relate to the implications of climate change.”\n",
      "--------------------------------------------------\n",
      "Topic 420: 420_feedbacks_negative feedbacks_forests_positive feedbacks\n",
      "Representative Documents:\n",
      "  - The world's forests influence climate through physical, chemical, and biological processes that affect planetary energetics, the hydrologic cycle, and atmospheric composition. These complex and nonlinear forest-atmosphere interactions can dampen or amplify anthropogenic climate change. Tropical, temperate, and boreal reforestation and afforestation attenuate global warming through carbon sequestration. Biogeophysical feedbacks can enhance or diminish this negative climate forcing. Tropical forests mitigate warming through evaporative cooling, but the low albedo of boreal forests is a positive climate forcing. The evaporative effect of temperate forests is unclear. The net climate forcing from these and other processes is not known. Forests are under tremendous pressure from global change. Interdisciplinary science that integrates knowledge of the many interacting climate services of forests with the impacts of global change is necessary to identify and understand as yet unexplored feedbacks in the Earth system and the potential of forests to mitigate climate change.\n",
      "  -  Most modeling studies on terrestrial feedbacks to warming over the twenty-first century imply that the net feedbacks are negative—that changes in ecosystems, on the whole, resist warming, largely through ecosystem carbon storage. Although it is clear that potentially important mechanisms can lead to carbon storage, a number of less well-understood mechanisms, several of which are rarely or incompletely modeled, tend to diminish the negative feedbacks or lead to positive feedbacks. At high latitudes, negative feedbacks from forest expansion are likely to be largely or completely compensated by positive feedbacks from decreased albedo, increased carbon emissions from thawed permafrost, and increased wildfire. At low latitudes, negative feedbacks to warming will be decreased or eliminated, largely through direct human impacts. With modest warming, net feedbacks of terrestrial ecosystems to warming are likely to be negative in the tropics and positive at high latitudes. Larger amounts of warming will generally push the feedbacks toward the positive. \n",
      "  -  In the boreal forests of Alaska, recent changes in climate have influenced the exchange of trace gases, water, and energy between these forests and the atmosphere. These changes in the structure and function of boreal forests can then feed back to impact regional and global climates. In this manuscript, we examine the type and magnitude of the climate feedbacks from boreal forests in Alaska. Research generally suggests that the net effect of a warming climate is a positive regional feedback to warming. Currently, the primary positive climate feedbacks are likely related to decreases in surface albedo due to decreases in snow cover. Fewer negative feedbacks have been identified, and they may not be large enough to counterbalance the large positive feedbacks. These positive feedbacks are most pronounced at the regional scale and reduce the resilience of the boreal vegetation – climate system by amplifying the rate of regional warming. Given the recent warming in this region, the large variety of associated mechanisms that can alter terrestrial ecosystems and influence the climate system, and a reduction in the boreal forest resilience, there is a strong need to continue to quantify and evaluate the feedback pathways. \n",
      "--------------------------------------------------\n",
      "Topic 421: 421_control_model predictive_model predictive control_predictive control\n",
      "Representative Documents:\n",
      "  - The absorption process of CO2 by ethanolamine solution is essentially a dynamic system, which is greatly affected by the power plant startup and flue gas load changes. Hence, studying the optimal control of the CO2 chemical capture process has always been an important part in academic fields. Model predictive control (MPC) is a very effective control strategy used for such process, but the most intractable problem is the lack of accurate and effective model. In this work, Aspen Plus and Aspen Plus Dynamics are used to establish the process of monoethanolamine (MEA) absorption of CO2 related models based on subspace identification. The nonlinear distribution of the system under steady-state operation is analyzed. Dynamic tests were carried out to understand the dynamic characteristics of the system under variable operating conditions. Systematic subspace identification on open-loop experimental data was performed. We designed a model predictive controller based on the identified model combined with the state-space equation using Matlab/Simulink to analyze the changes of the system under two different disturbances. The simulation results show that the control performance of the MPC algorithm is significantly better than that of the traditional proportion integral differential (PID) system, with excellent setpoint tracking ability and robustness, which improve the stability and flexibility of the system.\n",
      "  - Greenhouses are closed environments that require careful climatic control, which can benefit from a system control method to cope with the high nonlinearity, complex coupling, and robustness of unknown disturbances. This paper presents a general framework for an integral sliding mode controller based on a disturbance observer combined with feedback linearization for a greenhouse temperature and humidity system. The first-principle greenhouse climate model is described as a standard affine nonlinear system. The feedback linearization control law is used to achieve a system consisting of two separate integrator channels for temperature and humidity. System compound disturbances are estimated by applying a sliding mode disturbance observer. Based on the observer, an integral sliding mode control is incorporated to enhance the robustness against uncertainties and guarantee satisfactory tracking performance even when there are unknown estimation errors. The validity and efficacy of the proposed control technique for greenhouse climate tracking were verified by comparison with simulation results obtained using the common sliding mode control method using feedback linearization without the disturbance observer. Based on this comparison, the developed controller shows a faster system response speed, higher control precision, and stronger anti-interference ability. This method can be applied to improve greenhouse climate control systems.\n",
      "  - Due to the lack of comparative studies between discontinuous pulse-width modulation and model predictive control methods for reducing switching losses in two-level three-phase voltage source inverter, a comparative analysis of a generalized discontinuous pulse-width modulation and two model predictive control approaches for reducing switching losses is studied in this paper. Both generalized discontinuous pulse-width modulation and two model predictive control approaches are described and conducted in the simulation and experiment. The output performance is obtained by these methods after conducting in various conditions, including switching frequency, output power, and load conditions. It is validated that the generalized discontinuous pulse-width modulation control scheme achieves a better control performance at steady-state, while two model predictive control schemes have better transient-state performance with a superior dynamic. Additionally, the generalized discontinuous pulse-width modulation approach achieves better reducing switching losses performance and has slightly higher efficiency than that of two model predictive control approaches.\n",
      "--------------------------------------------------\n",
      "Topic 422: 422_ligurian sea_ligurian_mediterranean_wwn\n",
      "Representative Documents:\n",
      "  - In contrast to Antarctic krill Euphausia superba, Antarctic salps (Salpa thompsoni) respond positively to warmer water temperatures and have the ability to create massive blooms under favourable conditions. Therefore, they can compete with krill for primary production. Over the last three decades, significant variability in S. thompsoni occurrence has been observed as a response to the environmental fluctuations of the Southern Ocean ecosystem (e.g. changes in sea surface temperature and ice‐cover shrinkage around the cold Antarctic waters).This study presents historical abundance data of salps from the south‐west Atlantic Sector of the Southern Ocean, covering a time span of 26 years. These data allow tracking of fluctuations in Antarctic salp abundance and their distribution with bottom depth, temperature, and ice conditions, aiming to reveal salp hot spots and to predict the future range of S. thompsoni distribution with upcoming climate warming in the next 50 years.Results showed the highest salp density in shallow shelf waters with ice cover and low temperatures between 1 and −1°C. In the studied area, S. thompsoni hot spots were located mostly around Elephant Island, but also the islands around Brensfield and Gerlache Straits, as well as to the south near the Bellingshausen Sea. Inferences made of future salp distribution suggest that the range of S. thompsoni will move southwards, enlarging their habitat area by nearly 500,000 km2, which may have significant implications on the whole Antarctic food web. The information presented herein may be used for Antarctic ecosystem management, protection, and conservation.\n",
      "  - Since the 17th century, the Tonnarella of Camogli, a small tuna trap, has been used to catch pelagic fish along the western coast of the Portofino Promontory (Ligurian Sea, Northwestern Mediterranean). The availability of long‐term datasets on fish yields (1950–1974 and 1996–2011), with information related to the seawater temperatures and the North Atlantic Oscillation (NAO), has allowed us to study the qualitative and quantitative changes in fish yields in the last decade and the possible relationships with the seasonal anomalies of temperature that have occurred in the Ligurian Sea. In 1950–1974, yields remained relatively constant over time (average of 35.6 ± 8.7 t·year−1). From 1996 through 2011, yields were high (42.9 ± 15.9 t·year−1) but inconsistent with strong annual variability in catches. The primary catches are Seriola dumerili, Auxis rochei, Trachurus spp. and Sarda sarda. Changes in species composition have occurred as well: S. dumerili, Sardinella sp. and Belone belone have appeared recently. Moreover, a significant decrease in the boreal scombroid (Scomber scombrus) and an increase of warm‐temperate carangids and other typically Southern Mediterranean species such as Coryphaena hippurus and Sphyraena viridensis, appear to be linked to the warming of the surface water layer, particularly evident in the Ligurian Sea, for the last 10 years. The analysis of this kind of trend may be a powerful tool for assessing structural changes of the pelagic fish community in the Ligurian Sea (Northwestern Mediterranean).\n",
      "  - Global warming is facilitating the poleward range expansion of plant and animal species. In the Mediterranean Sea, the concurrent temperature increase and abundance of (sub)tropical non-indigenous species (NIS) is leading to the so-called ‘tropicalization’ of the Mediterranean Sea, which is dramatically evident in the south-eastern sectors of the basin. At the same time, the colder north-western sectors of the basin have been said to undergo a process of ‘meridionalization’, that is the establishment of warm-water native species (WWN) previously restricted to the southern sectors. The Gulf of Genoa (Ligurian Sea) is the north-western reach for southern species of whatever origin in the Mediterranean. Recent (up to 2015) observations of NIS and WWN by diving have been collated to update previous similar inventories. In addition, the relative occurrences of both groups of southern species have been monitored by snorkelling between 2009 and 2015 in shallow rocky reefs at Genoa, and compared with the trend in air and sea surface temperatures. A total of 20 southern species (11 NIS and 9 WWN) was found. Two WWN (the zebra seabream Diplodus cervinus and the parrotfish Sparisoma cretense) and three NIS (the SW Atlantic sponge Paraleucilla magna, the Red Sea polychaete Branchiomma luctuosum, and the amphi-American and amphi-Atlantic crab Percnon gibbesi) are new records for the Ligurian Sea, whereas juveniles of the Indo-Pacific bluespotted cornetfish Fistularia commersonii have been found for the first time. While temperature has kept on increasing for the whole period, with 2014 and 2015 being the warmest years since at least 1950, the number of WWN increased linearly, that of NIS increased exponentially, contradicting the idea of meridionalization and supporting that of tropicalization even in the northern sectors of the Mediterranean basin.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "topic_info = model.get_topic_info()\n",
    "rep_docs = model.get_representative_docs()\n",
    "\n",
    "# Iterate over topics and print name with representative documents\n",
    "for topic_id, topic_name in zip(topic_info['Topic'], topic_info['Name']):\n",
    "    if topic_id == -1:\n",
    "        continue\n",
    "    print(f\"Topic {topic_id}: {topic_name}\")\n",
    "    print(\"Representative Documents:\")\n",
    "    for doc in rep_docs.get(topic_id, []): \n",
    "        print(f\"  - {doc}\")\n",
    "    print(\"-\" * 50) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
